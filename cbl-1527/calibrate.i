# 1 "init/calibrate.c"
# 1 "<built-in>" 1
# 1 "<built-in>" 3
# 341 "<built-in>" 3
# 1 "<command line>" 1
# 1 "<built-in>" 2
# 1 "././include/linux/compiler-version.h" 1
# 2 "<built-in>" 2
# 1 "././include/linux/kconfig.h" 1




# 1 "./include/generated/autoconf.h" 1
# 6 "././include/linux/kconfig.h" 2
# 3 "<built-in>" 2
# 1 "././include/linux/compiler_types.h" 1
# 65 "././include/linux/compiler_types.h"
# 1 "./include/linux/compiler_attributes.h" 1
# 66 "././include/linux/compiler_types.h" 2
# 80 "././include/linux/compiler_types.h"
# 1 "./include/linux/compiler-clang.h" 1
# 81 "././include/linux/compiler_types.h" 2
# 99 "././include/linux/compiler_types.h"
# 1 "./arch/mips/include/asm/compiler.h" 1
# 100 "././include/linux/compiler_types.h" 2


struct ftrace_branch_data {
 const char *func;
 const char *file;
 unsigned line;
 union {
  struct {
   unsigned long correct;
   unsigned long incorrect;
  };
  struct {
   unsigned long miss;
   unsigned long hit;
  };
  unsigned long miss_hit[2];
 };
};

struct ftrace_likely_data {
 struct ftrace_branch_data data;
 unsigned long constant;
};
# 4 "<built-in>" 2
# 1 "init/calibrate.c" 2







# 1 "./include/linux/jiffies.h" 1




# 1 "./include/linux/cache.h" 1




# 1 "./include/uapi/linux/kernel.h" 1




# 1 "./include/uapi/linux/sysinfo.h" 1




# 1 "./include/linux/types.h" 1





# 1 "./include/uapi/linux/types.h" 1




# 1 "./arch/mips/include/asm/types.h" 1
# 14 "./arch/mips/include/asm/types.h"
# 1 "./include/asm-generic/int-ll64.h" 1
# 11 "./include/asm-generic/int-ll64.h"
# 1 "./include/uapi/asm-generic/int-ll64.h" 1
# 12 "./include/uapi/asm-generic/int-ll64.h"
# 1 "./arch/mips/include/uapi/asm/bitsperlong.h" 1






# 1 "./include/asm-generic/bitsperlong.h" 1




# 1 "./include/uapi/asm-generic/bitsperlong.h" 1
# 6 "./include/asm-generic/bitsperlong.h" 2
# 8 "./arch/mips/include/uapi/asm/bitsperlong.h" 2
# 13 "./include/uapi/asm-generic/int-ll64.h" 2







typedef __signed__ char __s8;
typedef unsigned char __u8;

typedef __signed__ short __s16;
typedef unsigned short __u16;

typedef __signed__ int __s32;
typedef unsigned int __u32;


__extension__ typedef __signed__ long long __s64;
__extension__ typedef unsigned long long __u64;
# 12 "./include/asm-generic/int-ll64.h" 2




typedef __s8 s8;
typedef __u8 u8;
typedef __s16 s16;
typedef __u16 u16;
typedef __s32 s32;
typedef __u32 u32;
typedef __s64 s64;
typedef __u64 u64;
# 15 "./arch/mips/include/asm/types.h" 2
# 6 "./include/uapi/linux/types.h" 2








# 1 "./include/uapi/linux/posix_types.h" 1




# 1 "./include/linux/stddef.h" 1




# 1 "./include/uapi/linux/stddef.h" 1
# 6 "./include/linux/stddef.h" 2




enum {
 false = 0,
 true = 1
};
# 6 "./include/uapi/linux/posix_types.h" 2
# 25 "./include/uapi/linux/posix_types.h"
typedef struct {
 unsigned long fds_bits[1024 / (8 * sizeof(long))];
} __kernel_fd_set;


typedef void (*__kernel_sighandler_t)(int);


typedef int __kernel_key_t;
typedef int __kernel_mqd_t;

# 1 "./arch/mips/include/uapi/asm/posix_types.h" 1
# 13 "./arch/mips/include/uapi/asm/posix_types.h"
# 1 "./arch/mips/include/uapi/asm/sgidefs.h" 1
# 14 "./arch/mips/include/uapi/asm/posix_types.h" 2







typedef long __kernel_daddr_t;


# 1 "./include/uapi/asm-generic/posix_types.h" 1
# 15 "./include/uapi/asm-generic/posix_types.h"
typedef long __kernel_long_t;
typedef unsigned long __kernel_ulong_t;



typedef __kernel_ulong_t __kernel_ino_t;



typedef unsigned int __kernel_mode_t;



typedef int __kernel_pid_t;



typedef int __kernel_ipc_pid_t;



typedef unsigned int __kernel_uid_t;
typedef unsigned int __kernel_gid_t;



typedef __kernel_long_t __kernel_suseconds_t;







typedef unsigned int __kernel_uid32_t;
typedef unsigned int __kernel_gid32_t;



typedef __kernel_uid_t __kernel_old_uid_t;
typedef __kernel_gid_t __kernel_old_gid_t;



typedef unsigned int __kernel_old_dev_t;
# 68 "./include/uapi/asm-generic/posix_types.h"
typedef unsigned int __kernel_size_t;
typedef int __kernel_ssize_t;
typedef int __kernel_ptrdiff_t;
# 79 "./include/uapi/asm-generic/posix_types.h"
typedef struct {
 int val[2];
} __kernel_fsid_t;





typedef __kernel_long_t __kernel_off_t;
typedef long long __kernel_loff_t;
typedef __kernel_long_t __kernel_old_time_t;



typedef long long __kernel_time64_t;
typedef __kernel_long_t __kernel_clock_t;
typedef int __kernel_timer_t;
typedef int __kernel_clockid_t;
typedef char * __kernel_caddr_t;
typedef unsigned short __kernel_uid16_t;
typedef unsigned short __kernel_gid16_t;
# 25 "./arch/mips/include/uapi/asm/posix_types.h" 2
# 37 "./include/uapi/linux/posix_types.h" 2
# 15 "./include/uapi/linux/types.h" 2
# 29 "./include/uapi/linux/types.h"
typedef __u16 __le16;
typedef __u16 __be16;
typedef __u32 __le32;
typedef __u32 __be32;
typedef __u64 __le64;
typedef __u64 __be64;

typedef __u16 __sum16;
typedef __u32 __wsum;
# 52 "./include/uapi/linux/types.h"
typedef unsigned __poll_t;
# 7 "./include/linux/types.h" 2






typedef u32 __kernel_dev_t;

typedef __kernel_fd_set fd_set;
typedef __kernel_dev_t dev_t;
typedef __kernel_ulong_t ino_t;
typedef __kernel_mode_t mode_t;
typedef unsigned short umode_t;
typedef u32 nlink_t;
typedef __kernel_off_t off_t;
typedef __kernel_pid_t pid_t;
typedef __kernel_daddr_t daddr_t;
typedef __kernel_key_t key_t;
typedef __kernel_suseconds_t suseconds_t;
typedef __kernel_timer_t timer_t;
typedef __kernel_clockid_t clockid_t;
typedef __kernel_mqd_t mqd_t;

typedef _Bool bool;

typedef __kernel_uid32_t uid_t;
typedef __kernel_gid32_t gid_t;
typedef __kernel_uid16_t uid16_t;
typedef __kernel_gid16_t gid16_t;

typedef unsigned long uintptr_t;
# 46 "./include/linux/types.h"
typedef __kernel_loff_t loff_t;
# 55 "./include/linux/types.h"
typedef __kernel_size_t size_t;




typedef __kernel_ssize_t ssize_t;




typedef __kernel_ptrdiff_t ptrdiff_t;




typedef __kernel_clock_t clock_t;




typedef __kernel_caddr_t caddr_t;



typedef unsigned char u_char;
typedef unsigned short u_short;
typedef unsigned int u_int;
typedef unsigned long u_long;


typedef unsigned char unchar;
typedef unsigned short ushort;
typedef unsigned int uint;
typedef unsigned long ulong;




typedef u8 u_int8_t;
typedef s8 int8_t;
typedef u16 u_int16_t;
typedef s16 int16_t;
typedef u32 u_int32_t;
typedef s32 int32_t;



typedef u8 uint8_t;
typedef u16 uint16_t;
typedef u32 uint32_t;


typedef u64 uint64_t;
typedef u64 u_int64_t;
typedef s64 int64_t;
# 125 "./include/linux/types.h"
typedef u64 sector_t;
typedef u64 blkcnt_t;
# 145 "./include/linux/types.h"
typedef u32 dma_addr_t;


typedef unsigned int gfp_t;
typedef unsigned int slab_flags_t;
typedef unsigned int fmode_t;




typedef u32 phys_addr_t;


typedef phys_addr_t resource_size_t;





typedef unsigned long irq_hw_number_t;

typedef struct {
 int counter;
} atomic_t;
# 178 "./include/linux/types.h"
struct list_head {
 struct list_head *next, *prev;
};

struct hlist_head {
 struct hlist_node *first;
};

struct hlist_node {
 struct hlist_node *next, **pprev;
};

struct ustat {
 __kernel_daddr_t f_tfree;



 unsigned long f_tinode;

 char f_fname[6];
 char f_fpack[6];
};
# 220 "./include/linux/types.h"
struct callback_head {
 struct callback_head *next;
 void (*func)(struct callback_head *head);
} __attribute__((aligned(sizeof(void *))));


typedef void (*rcu_callback_t)(struct callback_head *head);
typedef void (*call_rcu_func_t)(struct callback_head *head, rcu_callback_t func);

typedef void (*swap_func_t)(void *a, void *b, int size);

typedef int (*cmp_r_func_t)(const void *a, const void *b, const void *priv);
typedef int (*cmp_func_t)(const void *a, const void *b);
# 6 "./include/uapi/linux/sysinfo.h" 2


struct sysinfo {
 __kernel_long_t uptime;
 __kernel_ulong_t loads[3];
 __kernel_ulong_t totalram;
 __kernel_ulong_t freeram;
 __kernel_ulong_t sharedram;
 __kernel_ulong_t bufferram;
 __kernel_ulong_t totalswap;
 __kernel_ulong_t freeswap;
 __u16 procs;
 __u16 pad;
 __kernel_ulong_t totalhigh;
 __kernel_ulong_t freehigh;
 __u32 mem_unit;
 char _f[20-2*sizeof(__kernel_ulong_t)-sizeof(__u32)];
};
# 6 "./include/uapi/linux/kernel.h" 2
# 1 "./include/linux/const.h" 1



# 1 "./include/vdso/const.h" 1




# 1 "./include/uapi/linux/const.h" 1
# 6 "./include/vdso/const.h" 2
# 5 "./include/linux/const.h" 2
# 7 "./include/uapi/linux/kernel.h" 2
# 6 "./include/linux/cache.h" 2
# 1 "./arch/mips/include/asm/cache.h" 1
# 12 "./arch/mips/include/asm/cache.h"
# 1 "./arch/mips/include/asm/mach-generic/kmalloc.h" 1
# 13 "./arch/mips/include/asm/cache.h" 2
# 7 "./include/linux/cache.h" 2
# 6 "./include/linux/jiffies.h" 2
# 1 "./include/linux/limits.h" 1




# 1 "./include/uapi/linux/limits.h" 1
# 6 "./include/linux/limits.h" 2

# 1 "./include/vdso/limits.h" 1
# 8 "./include/linux/limits.h" 2
# 7 "./include/linux/jiffies.h" 2
# 1 "./include/linux/math64.h" 1





# 1 "./include/linux/math.h" 1




# 1 "./arch/mips/include/asm/div64.h" 1
# 89 "./arch/mips/include/asm/div64.h"
# 1 "./include/asm-generic/div64.h" 1
# 27 "./include/asm-generic/div64.h"
# 1 "./include/linux/compiler.h" 1
# 250 "./include/linux/compiler.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *offset_to_ptr(const int *off)
{
 return (void *)((unsigned long)off + *off);
}
# 266 "./include/linux/compiler.h"
# 1 "./arch/mips/include/generated/asm/rwonce.h" 1
# 1 "./include/asm-generic/rwonce.h" 1
# 26 "./include/asm-generic/rwonce.h"
# 1 "./include/linux/kasan-checks.h" 1
# 22 "./include/linux/kasan-checks.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __kasan_check_read(const volatile void *p, unsigned int size)
{
 return true;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __kasan_check_write(const volatile void *p, unsigned int size)
{
 return true;
}
# 40 "./include/linux/kasan-checks.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool kasan_check_read(const volatile void *p, unsigned int size)
{
 return true;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool kasan_check_write(const volatile void *p, unsigned int size)
{
 return true;
}
# 27 "./include/asm-generic/rwonce.h" 2
# 1 "./include/linux/kcsan-checks.h" 1
# 151 "./include/linux/kcsan-checks.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __kcsan_check_access(const volatile void *ptr, size_t size,
     int type) { }

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_disable_current(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_enable_current(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_enable_current_nowarn(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_nestable_atomic_begin(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_nestable_atomic_end(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_flat_atomic_begin(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_flat_atomic_end(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_atomic_next(int n) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_set_access_mask(unsigned long mask) { }

struct kcsan_scoped_access { };

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct kcsan_scoped_access *
kcsan_begin_scoped_access(const volatile void *ptr, size_t size, int type,
     struct kcsan_scoped_access *sa) { return sa; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_end_scoped_access(struct kcsan_scoped_access *sa) { }
# 187 "./include/linux/kcsan-checks.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_check_access(const volatile void *ptr, size_t size,
          int type) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __kcsan_enable_current(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __kcsan_disable_current(void) { }
# 28 "./include/asm-generic/rwonce.h" 2
# 64 "./include/asm-generic/rwonce.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__))
unsigned long __read_once_word_nocheck(const void *addr)
{
 return (*(const volatile typeof( _Generic((*(unsigned long *)addr), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*(unsigned long *)addr))) *)&(*(unsigned long *)addr));
}
# 82 "./include/asm-generic/rwonce.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__))
unsigned long read_word_at_a_time(const void *addr)
{
 kasan_check_read(addr, 1);
 return *(unsigned long *)addr;
}
# 2 "./arch/mips/include/generated/asm/rwonce.h" 2
# 267 "./include/linux/compiler.h" 2
# 28 "./include/asm-generic/div64.h" 2
# 55 "./include/asm-generic/div64.h"
# 1 "./include/linux/log2.h" 1
# 12 "./include/linux/log2.h"
# 1 "./include/linux/bitops.h" 1





# 1 "./include/linux/bits.h" 1





# 1 "./include/vdso/bits.h" 1
# 7 "./include/linux/bits.h" 2
# 22 "./include/linux/bits.h"
# 1 "./include/linux/build_bug.h" 1
# 23 "./include/linux/bits.h" 2
# 7 "./include/linux/bitops.h" 2
# 1 "./include/linux/typecheck.h" 1
# 8 "./include/linux/bitops.h" 2
# 24 "./include/linux/bitops.h"
extern unsigned int __sw_hweight8(unsigned int w);
extern unsigned int __sw_hweight16(unsigned int w);
extern unsigned int __sw_hweight32(unsigned int w);
extern unsigned long __sw_hweight64(__u64 w);





# 1 "./arch/mips/include/asm/bitops.h" 1
# 19 "./arch/mips/include/asm/bitops.h"
# 1 "./arch/mips/include/asm/barrier.h" 1
# 11 "./arch/mips/include/asm/barrier.h"
# 1 "./arch/mips/include/asm/addrspace.h" 1
# 13 "./arch/mips/include/asm/addrspace.h"
# 1 "./arch/mips/include/asm/mach-generic/spaces.h" 1
# 15 "./arch/mips/include/asm/mach-generic/spaces.h"
# 1 "./arch/mips/include/asm/mipsregs.h" 1
# 16 "./arch/mips/include/asm/mipsregs.h"
# 1 "./include/linux/linkage.h" 1





# 1 "./include/linux/stringify.h" 1
# 7 "./include/linux/linkage.h" 2
# 1 "./include/linux/export.h" 1
# 72 "./include/linux/export.h"
struct kernel_symbol {
 unsigned long value;
 const char *name;
 const char *namespace;
};
# 8 "./include/linux/linkage.h" 2
# 1 "./arch/mips/include/asm/linkage.h" 1
# 9 "./include/linux/linkage.h" 2
# 17 "./arch/mips/include/asm/mipsregs.h" 2

# 1 "./arch/mips/include/asm/hazards.h" 1
# 418 "./arch/mips/include/asm/hazards.h"
extern void mips_ihb(void);
# 19 "./arch/mips/include/asm/mipsregs.h" 2
# 1 "./arch/mips/include/asm/isa-rev.h" 1
# 20 "./arch/mips/include/asm/mipsregs.h" 2
# 1 "./arch/mips/include/asm/war.h" 1
# 21 "./arch/mips/include/asm/mipsregs.h" 2
# 1239 "./arch/mips/include/asm/mipsregs.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int mm_insn_16bit(u16 insn)
{
 u16 opcode = (insn >> 10) & 0x7;

 return (opcode >= 1 && opcode <= 3) ? 1 : 0;
}
# 1368 "./arch/mips/include/asm/mipsregs.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tlbinvf(void)
{
 __asm__ __volatile__(
  ".set push\n\t"
  ".set noreorder\n\t"
  "# tlbinvf\n\t"
  ".insn\n\t" ".word (" "0x42000004" ")\n\t"

  ".set pop");
}
# 2761 "./arch/mips/include/asm/mipsregs.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tlb_probe(void)
{
 __asm__ __volatile__(
  ".set noreorder\n\t"
  "tlbp\n\t"
  ".set reorder");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tlb_read(void)
{
# 2788 "./arch/mips/include/asm/mipsregs.h"
 __asm__ __volatile__(
  ".set noreorder\n\t"
  "tlbr\n\t"
  ".set reorder");
# 2804 "./arch/mips/include/asm/mipsregs.h"
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tlb_write_indexed(void)
{
 __asm__ __volatile__(
  ".set noreorder\n\t"
  "tlbwi\n\t"
  ".set reorder");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tlb_write_random(void)
{
 __asm__ __volatile__(
  ".set noreorder\n\t"
  "tlbwr\n\t"
  ".set reorder");
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void guest_tlb_probe(void)
{
 __asm__ __volatile__(
  ".set push\n\t"
  ".set noreorder\n\t"
  ".set\tvirt\n\t" "tlbgp\n\t"
  ".set pop");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void guest_tlb_read(void)
{
 __asm__ __volatile__(
  ".set push\n\t"
  ".set noreorder\n\t"
  ".set\tvirt\n\t" "tlbgr\n\t"
  ".set pop");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void guest_tlb_write_indexed(void)
{
 __asm__ __volatile__(
  ".set push\n\t"
  ".set noreorder\n\t"
  ".set\tvirt\n\t" "tlbgwi\n\t"
  ".set pop");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void guest_tlb_write_random(void)
{
 __asm__ __volatile__(
  ".set push\n\t"
  ".set noreorder\n\t"
  ".set\tvirt\n\t" "tlbgwr\n\t"
  ".set pop");
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void guest_tlbinvf(void)
{
 __asm__ __volatile__(
  ".set push\n\t"
  ".set noreorder\n\t"
  ".set\tvirt\n\t" "tlbginvf\n\t"
  ".set pop");
}
# 2921 "./arch/mips/include/asm/mipsregs.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_status(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_status(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_status(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_cause(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$13" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$13" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$13" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$13" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_cause(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$13" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$13" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$13" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$13" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_cause(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$13" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$13" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$13" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$13" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_config(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_config(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_config(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_config5(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_config5(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_config5(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_config6(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_config6(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_config6(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_config7(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (7 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "7" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (7 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "7" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_config7(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (7 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "7" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (7 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "7" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_config7(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (7 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "7" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (7 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "7" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_diag(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_diag(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_diag(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_intcontrol(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; __asm__ __volatile__( "cfc0\t%0, " "$20" "\n\t" : "=r" (__res)); __res; }); new = res | set; do { __asm__ __volatile__( "ctc0\t%z0, " "$20" "\n\t" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_intcontrol(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; __asm__ __volatile__( "cfc0\t%0, " "$20" "\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { __asm__ __volatile__( "ctc0\t%z0, " "$20" "\n\t" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_intcontrol(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; __asm__ __volatile__( "cfc0\t%0, " "$20" "\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { __asm__ __volatile__( "ctc0\t%z0, " "$20" "\n\t" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_intctl(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_intctl(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_intctl(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_srsmap(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (3 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "3" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (3 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "3" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_srsmap(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (3 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "3" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (3 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "3" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_srsmap(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (3 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "3" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (3 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "3" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_pagegrain(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$5" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$5" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$5" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$5" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_pagegrain(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$5" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$5" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$5" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$5" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_pagegrain(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$5" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$5" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$5" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$5" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_guestctl0(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_guestctl0(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_guestctl0(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_guestctl0ext(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$11" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$11" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$11" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$11" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_guestctl0ext(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$11" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$11" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$11" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$11" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_guestctl0ext(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$11" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$11" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$11" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$11" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_guestctl1(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_guestctl1(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_guestctl1(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_guestctl2(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_guestctl2(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_guestctl2(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_guestctl3(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_guestctl3(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_guestctl3(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_config_0(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_config_0(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_config_0(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_bus_pll(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_bus_pll(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_bus_pll(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_reset(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_reset(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_reset(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_cmt_intr(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_cmt_intr(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_cmt_intr(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_cmt_ctrl(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (2 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "2" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (2 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "2" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_cmt_ctrl(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (2 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "2" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (2 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "2" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_cmt_ctrl(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (2 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "2" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (2 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "2" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_config(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_config(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_config(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_mode(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_mode(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_mode(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_gc0_wired(unsigned int set) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$6" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res | set; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$6" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_gc0_wired(unsigned int clear) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$6" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res & ~clear; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$6" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_gc0_wired(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$6" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res & ~change; new |= (val & change); do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$6" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_gc0_status(unsigned int set) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$12" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res | set; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$12" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_gc0_status(unsigned int clear) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$12" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res & ~clear; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$12" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_gc0_status(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$12" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res & ~change; new |= (val & change); do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$12" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_gc0_cause(unsigned int set) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$13" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res | set; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$13" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_gc0_cause(unsigned int clear) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$13" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res & ~clear; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$13" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_gc0_cause(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$13" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res & ~change; new |= (val & change); do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$13" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_gc0_ebase(unsigned int set) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$15" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (1)); __res; }); new = res | set; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$15" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (1)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_gc0_ebase(unsigned int clear) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$15" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (1)); __res; }); new = res & ~clear; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$15" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (1)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_gc0_ebase(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$15" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (1)); __res; }); new = res & ~change; new |= (val & change); do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$15" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (1)); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_gc0_config1(unsigned int set) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$16" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (1)); __res; }); new = res | set; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$16" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (1)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_gc0_config1(unsigned int clear) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$16" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (1)); __res; }); new = res & ~clear; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$16" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (1)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_gc0_config1(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$16" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (1)); __res; }); new = res & ~change; new |= (val & change); do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r5\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$16" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (1)); } while (0); return res; }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int get_ebase_cpunum(void)
{
 return ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$15" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$15" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }) & ((unsigned long)(0x3ff) << 0);
}
# 16 "./arch/mips/include/asm/mach-generic/spaces.h" 2
# 14 "./arch/mips/include/asm/addrspace.h" 2
# 12 "./arch/mips/include/asm/barrier.h" 2
# 1 "./arch/mips/include/asm/sync.h" 1
# 13 "./arch/mips/include/asm/barrier.h" 2

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __sync(void)
{
 asm volatile(".if (( 0x00 ) != -1) && ( (1 << 0) ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" ::: "memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rmb(void)
{
 asm volatile(".if (( 0x00 ) != -1) && ( (1 << 0) ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" ::: "memory");
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void wmb(void)
{
 asm volatile(".if (( 0x00 ) != -1) && ( (1 << 0) ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" ::: "memory");
}
# 135 "./arch/mips/include/asm/barrier.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void sync_ginv(void)
{
 asm volatile(".if (( 0x14 ) != -1) && ( (1 << 0) ); .set push; .set mips64r2; .rept 1; sync 0x14; .endr; .set pop; .else; ; .endif");
}

# 1 "./include/asm-generic/barrier.h" 1
# 17 "./include/asm-generic/barrier.h"
# 1 "./arch/mips/include/generated/asm/rwonce.h" 1
# 18 "./include/asm-generic/barrier.h" 2
# 141 "./arch/mips/include/asm/barrier.h" 2
# 20 "./arch/mips/include/asm/bitops.h" 2
# 1 "./arch/mips/include/uapi/asm/byteorder.h" 1
# 13 "./arch/mips/include/uapi/asm/byteorder.h"
# 1 "./include/linux/byteorder/big_endian.h" 1




# 1 "./include/uapi/linux/byteorder/big_endian.h" 1
# 13 "./include/uapi/linux/byteorder/big_endian.h"
# 1 "./include/linux/swab.h" 1




# 1 "./include/uapi/linux/swab.h" 1







# 1 "./arch/mips/include/uapi/asm/swab.h" 1
# 9 "./include/uapi/linux/swab.h" 2
# 48 "./include/uapi/linux/swab.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__)) __u16 __fswab16(__u16 val)
{



 return ((__u16)( (((__u16)(val) & (__u16)0x00ffU) << 8) | (((__u16)(val) & (__u16)0xff00U) >> 8)));

}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__)) __u32 __fswab32(__u32 val)
{



 return ((__u32)( (((__u32)(val) & (__u32)0x000000ffUL) << 24) | (((__u32)(val) & (__u32)0x0000ff00UL) << 8) | (((__u32)(val) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(val) & (__u32)0xff000000UL) >> 24)));

}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__)) __u64 __fswab64(__u64 val)
{



 __u32 h = val >> 32;
 __u32 l = val & ((1ULL << 32) - 1);
 return (((__u64)__fswab32(l)) << 32) | ((__u64)(__fswab32(h)));



}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__)) __u32 __fswahw32(__u32 val)
{



 return ((__u32)( (((__u32)(val) & (__u32)0x0000ffffUL) << 16) | (((__u32)(val) & (__u32)0xffff0000UL) >> 16)));

}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__)) __u32 __fswahb32(__u32 val)
{



 return ((__u32)( (((__u32)(val) & (__u32)0x00ff00ffUL) << 8) | (((__u32)(val) & (__u32)0xff00ff00UL) >> 8)));

}
# 136 "./include/uapi/linux/swab.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned long __swab(const unsigned long y)
{



 return (__u32)__builtin_bswap32((__u32)(y));

}
# 171 "./include/uapi/linux/swab.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u16 __swab16p(const __u16 *p)
{



 return (__u16)__builtin_bswap16((__u16)(*p));

}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u32 __swab32p(const __u32 *p)
{



 return (__u32)__builtin_bswap32((__u32)(*p));

}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u64 __swab64p(const __u64 *p)
{



 return (__u64)__builtin_bswap64((__u64)(*p));

}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u32 __swahw32p(const __u32 *p)
{



 return (__builtin_constant_p((__u32)(*p)) ? ((__u32)( (((__u32)(*p) & (__u32)0x0000ffffUL) << 16) | (((__u32)(*p) & (__u32)0xffff0000UL) >> 16))) : __fswahw32(*p));

}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u32 __swahb32p(const __u32 *p)
{



 return (__builtin_constant_p((__u32)(*p)) ? ((__u32)( (((__u32)(*p) & (__u32)0x00ff00ffUL) << 8) | (((__u32)(*p) & (__u32)0xff00ff00UL) >> 8))) : __fswahb32(*p));

}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __swab16s(__u16 *p)
{



 *p = __swab16p(p);

}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __swab32s(__u32 *p)
{



 *p = __swab32p(p);

}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __swab64s(__u64 *p)
{



 *p = __swab64p(p);

}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __swahw32s(__u32 *p)
{



 *p = __swahw32p(p);

}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __swahb32s(__u32 *p)
{



 *p = __swahb32p(p);

}
# 6 "./include/linux/swab.h" 2
# 14 "./include/uapi/linux/byteorder/big_endian.h" 2
# 44 "./include/uapi/linux/byteorder/big_endian.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __le64 __cpu_to_le64p(const __u64 *p)
{
 return ( __le64)__swab64p(p);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u64 __le64_to_cpup(const __le64 *p)
{
 return __swab64p((__u64 *)p);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __le32 __cpu_to_le32p(const __u32 *p)
{
 return ( __le32)__swab32p(p);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u32 __le32_to_cpup(const __le32 *p)
{
 return __swab32p((__u32 *)p);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __le16 __cpu_to_le16p(const __u16 *p)
{
 return ( __le16)__swab16p(p);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u16 __le16_to_cpup(const __le16 *p)
{
 return __swab16p((__u16 *)p);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __be64 __cpu_to_be64p(const __u64 *p)
{
 return ( __be64)*p;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u64 __be64_to_cpup(const __be64 *p)
{
 return ( __u64)*p;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __be32 __cpu_to_be32p(const __u32 *p)
{
 return ( __be32)*p;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u32 __be32_to_cpup(const __be32 *p)
{
 return ( __u32)*p;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __be16 __cpu_to_be16p(const __u16 *p)
{
 return ( __be16)*p;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u16 __be16_to_cpup(const __be16 *p)
{
 return ( __u16)*p;
}
# 6 "./include/linux/byteorder/big_endian.h" 2





# 1 "./include/linux/byteorder/generic.h" 1
# 144 "./include/linux/byteorder/generic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void le16_add_cpu(__le16 *var, u16 val)
{
 *var = (( __le16)(__u16)__builtin_bswap16((__u16)(((__u16)__builtin_bswap16((__u16)(( __u16)(__le16)(*var))) + val))));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void le32_add_cpu(__le32 *var, u32 val)
{
 *var = (( __le32)(__u32)__builtin_bswap32((__u32)(((__u32)__builtin_bswap32((__u32)(( __u32)(__le32)(*var))) + val))));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void le64_add_cpu(__le64 *var, u64 val)
{
 *var = (( __le64)(__u64)__builtin_bswap64((__u64)(((__u64)__builtin_bswap64((__u64)(( __u64)(__le64)(*var))) + val))));
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void le32_to_cpu_array(u32 *buf, unsigned int words)
{
 while (words--) {
  __swab32s((buf));
  buf++;
 }
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpu_to_le32_array(u32 *buf, unsigned int words)
{
 while (words--) {
  __swab32s((buf));
  buf++;
 }
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void be16_add_cpu(__be16 *var, u16 val)
{
 *var = (( __be16)(__u16)((( __u16)(__be16)(*var)) + val));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void be32_add_cpu(__be32 *var, u32 val)
{
 *var = (( __be32)(__u32)((( __u32)(__be32)(*var)) + val));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void be64_add_cpu(__be64 *var, u64 val)
{
 *var = (( __be64)(__u64)((( __u64)(__be64)(*var)) + val));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpu_to_be32_array(__be32 *dst, const u32 *src, size_t len)
{
 int i;

 for (i = 0; i < len; i++)
  dst[i] = (( __be32)(__u32)(src[i]));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void be32_to_cpu_array(u32 *dst, const __be32 *src, size_t len)
{
 int i;

 for (i = 0; i < len; i++)
  dst[i] = (( __u32)(__be32)(src[i]));
}
# 12 "./include/linux/byteorder/big_endian.h" 2
# 14 "./arch/mips/include/uapi/asm/byteorder.h" 2
# 21 "./arch/mips/include/asm/bitops.h" 2

# 1 "./arch/mips/include/asm/cpu-features.h" 1
# 12 "./arch/mips/include/asm/cpu-features.h"
# 1 "./arch/mips/include/asm/cpu.h" 1
# 293 "./arch/mips/include/asm/cpu.h"
enum cpu_type_enum {
 CPU_UNKNOWN,




 CPU_R2000, CPU_R3000, CPU_R3000A, CPU_R3041, CPU_R3051, CPU_R3052,
 CPU_R3081, CPU_R3081E,




 CPU_R4000PC, CPU_R4000SC, CPU_R4000MC, CPU_R4200, CPU_R4300, CPU_R4310,
 CPU_R4400PC, CPU_R4400SC, CPU_R4400MC, CPU_R4600, CPU_R4640, CPU_R4650,
 CPU_R4700, CPU_R5000, CPU_R5500, CPU_NEVADA, CPU_R10000,
 CPU_R12000, CPU_R14000, CPU_R16000, CPU_VR41XX, CPU_VR4111, CPU_VR4121,
 CPU_VR4122, CPU_VR4131, CPU_VR4133, CPU_VR4181, CPU_VR4181A, CPU_RM7000,
 CPU_SR71000, CPU_TX49XX,




 CPU_TX3912, CPU_TX3922, CPU_TX3927,




 CPU_4KC, CPU_4KEC, CPU_4KSC, CPU_24K, CPU_34K, CPU_1004K, CPU_74K,
 CPU_ALCHEMY, CPU_PR4450, CPU_BMIPS32, CPU_BMIPS3300, CPU_BMIPS4350,
 CPU_BMIPS4380, CPU_BMIPS5000, CPU_XBURST, CPU_LOONGSON32, CPU_M14KC,
 CPU_M14KEC, CPU_INTERAPTIV, CPU_P5600, CPU_PROAPTIV, CPU_1074K,
 CPU_M5150, CPU_I6400, CPU_P6600, CPU_M6250,




 CPU_5KC, CPU_5KE, CPU_20KC, CPU_25KF, CPU_SB1, CPU_SB1A, CPU_LOONGSON2EF,
 CPU_LOONGSON64, CPU_CAVIUM_OCTEON, CPU_CAVIUM_OCTEON_PLUS,
 CPU_CAVIUM_OCTEON2, CPU_CAVIUM_OCTEON3, CPU_I6500,

 CPU_QEMU_GENERIC,

 CPU_LAST
};
# 13 "./arch/mips/include/asm/cpu-features.h" 2
# 1 "./arch/mips/include/asm/cpu-info.h" 1
# 23 "./arch/mips/include/asm/cpu-info.h"
struct cache_desc {
 unsigned int waysize;
 unsigned short sets;
 unsigned char ways;
 unsigned char linesz;
 unsigned char waybit;
 unsigned char flags;
};

struct guest_info {
 unsigned long ases;
 unsigned long ases_dyn;
 unsigned long long options;
 unsigned long long options_dyn;
 int tlbsize;
 u8 conf;
 u8 kscratch_mask;
};
# 52 "./arch/mips/include/asm/cpu-info.h"
struct cpuinfo_mips {
 u64 asid_cache;







 unsigned long ases;
 unsigned long long options;
 unsigned int udelay_val;
 unsigned int processor_id;
 unsigned int fpu_id;
 unsigned int fpu_csr31;
 unsigned int fpu_msk31;
 unsigned int msa_id;
 unsigned int cputype;
 int isa_level;
 int tlbsize;
 int tlbsizevtlb;
 int tlbsizeftlbsets;
 int tlbsizeftlbways;
 struct cache_desc icache;
 struct cache_desc dcache;
 struct cache_desc vcache;
 struct cache_desc scache;
 struct cache_desc tcache;
 int srsets;
 int package;
 unsigned int globalnumber;



 void *data;
 unsigned int watch_reg_count;
 unsigned int watch_reg_use_cnt;

 u16 watch_reg_masks[4];
 unsigned int kscratch_mask;




 unsigned int writecombine;




 unsigned int htw_seq;


 struct guest_info guest;
 unsigned int gtoffset_mask;
 unsigned int guestid_mask;
 unsigned int guestid_cache;
# 117 "./arch/mips/include/asm/cpu-info.h"
} __attribute__((aligned((1 << 7))));

extern struct cpuinfo_mips cpu_data[];




extern void cpu_probe(void);
extern void cpu_report(void);

extern const char *__cpu_name[];


struct seq_file;
struct notifier_block;

extern int register_proc_cpuinfo_notifier(struct notifier_block *nb);
extern int proc_cpuinfo_notifier_call_chain(unsigned long val, void *v);
# 146 "./arch/mips/include/asm/cpu-info.h"
struct proc_cpuinfo_notifier_args {
 struct seq_file *m;
 unsigned long n;
};

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpu_cluster(struct cpuinfo_mips *cpuinfo)
{

 if (!0 && !0)
  return 0;

 return (cpuinfo->globalnumber & ((unsigned long)(0xf) << 16)) >>
  16;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpu_core(struct cpuinfo_mips *cpuinfo)
{
 return (cpuinfo->globalnumber & ((unsigned long)(0xff) << 8)) >>
  8;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpu_vpe_id(struct cpuinfo_mips *cpuinfo)
{

 if (!1 && !0)
  return 0;

 return (cpuinfo->globalnumber & ((unsigned long)(0xff) << 0)) >>
  0;
}

extern void cpu_set_cluster(struct cpuinfo_mips *cpuinfo, unsigned int cluster);
extern void cpu_set_core(struct cpuinfo_mips *cpuinfo, unsigned int core);
extern void cpu_set_vpe_id(struct cpuinfo_mips *cpuinfo, unsigned int vpe);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpus_are_siblings(int cpua, int cpub)
{
 struct cpuinfo_mips *infoa = &cpu_data[cpua];
 struct cpuinfo_mips *infob = &cpu_data[cpub];
 unsigned int gnuma, gnumb;

 if (infoa->package != infob->package)
  return false;

 gnuma = infoa->globalnumber & ~((unsigned long)(0xff) << 0);
 gnumb = infob->globalnumber & ~((unsigned long)(0xff) << 0);
 if (gnuma != gnumb)
  return false;

 return true;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long cpu_asid_inc(void)
{
 return 1 << 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long cpu_asid_mask(struct cpuinfo_mips *cpuinfo)
{



 return ((1 << 8) - 1) << 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpu_asid_mask(struct cpuinfo_mips *cpuinfo,
         unsigned long asid_mask)
{



}
# 14 "./arch/mips/include/asm/cpu-features.h" 2

# 1 "./arch/mips/include/asm/mach-generic/cpu-feature-overrides.h" 1
# 16 "./arch/mips/include/asm/cpu-features.h" 2
# 23 "./arch/mips/include/asm/bitops.h" 2

# 1 "./arch/mips/include/asm/llsc.h" 1
# 25 "./arch/mips/include/asm/bitops.h" 2
# 69 "./arch/mips/include/asm/bitops.h"
void __mips_set_bit(unsigned long nr, volatile unsigned long *addr);
void __mips_clear_bit(unsigned long nr, volatile unsigned long *addr);
void __mips_change_bit(unsigned long nr, volatile unsigned long *addr);
int __mips_test_and_set_bit_lock(unsigned long nr,
     volatile unsigned long *addr);
int __mips_test_and_clear_bit(unsigned long nr,
         volatile unsigned long *addr);
int __mips_test_and_change_bit(unsigned long nr,
          volatile unsigned long *addr);
# 90 "./arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_bit(unsigned long nr, volatile unsigned long *addr)
{
 volatile unsigned long *m = &addr[((nr) / 32)];
 int bit = nr % 32;

 if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) {
  __mips_set_bit(nr, addr);
  return;
 }

 if ((1 >= 2) && __builtin_constant_p(bit) && (bit >= 16)) {
  do { unsigned long __temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r2" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0, %1			\n" "	" "ins	" "%0, %3, %2, 1" "			\n" "	" "sc	" "%0, %1			\n" "	" "beqz	" "%0, 1b			\n" "	.set		pop			\n" : "=&r"(__temp), "+" "ZC"(*m) : "i"(bit), "r"(~0) : "memory"); } while (0);
  return;
 }

 do { unsigned long __temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r2" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0, %1			\n" "	" "or\t%0, %2" "			\n" "	" "sc	" "%0, %1			\n" "	" "beqz	" "%0, 1b			\n" "	.set		pop			\n" : "=&r"(__temp), "+" "ZC"(*m) : "ir"(((((1UL))) << (bit))) : "memory"); } while (0);
}
# 118 "./arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_bit(unsigned long nr, volatile unsigned long *addr)
{
 volatile unsigned long *m = &addr[((nr) / 32)];
 int bit = nr % 32;

 if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) {
  __mips_clear_bit(nr, addr);
  return;
 }

 if ((1 >= 2) && __builtin_constant_p(bit)) {
  do { unsigned long __temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r2" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0, %1			\n" "	" "ins	" "%0, $0, %2, 1" "			\n" "	" "sc	" "%0, %1			\n" "	" "beqz	" "%0, 1b			\n" "	.set		pop			\n" : "=&r"(__temp), "+" "ZC"(*m) : "i"(bit) : "memory"); } while (0);
  return;
 }

 do { unsigned long __temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r2" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0, %1			\n" "	" "and\t%0, %2" "			\n" "	" "sc	" "%0, %1			\n" "	" "beqz	" "%0, 1b			\n" "	.set		pop			\n" : "=&r"(__temp), "+" "ZC"(*m) : "ir"(~((((1UL))) << (bit))) : "memory"); } while (0);
}
# 144 "./arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_bit_unlock(unsigned long nr, volatile unsigned long *addr)
{
 do { } while (0);
 clear_bit(nr, addr);
}
# 159 "./arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_bit(unsigned long nr, volatile unsigned long *addr)
{
 volatile unsigned long *m = &addr[((nr) / 32)];
 int bit = nr % 32;

 if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) {
  __mips_change_bit(nr, addr);
  return;
 }

 do { unsigned long __temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r2" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0, %1			\n" "	" "xor\t%0, %2" "			\n" "	" "sc	" "%0, %1			\n" "	" "beqz	" "%0, 1b			\n" "	.set		pop			\n" : "=&r"(__temp), "+" "ZC"(*m) : "ir"(((((1UL))) << (bit))) : "memory"); } while (0);
}
# 180 "./arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_set_bit_lock(unsigned long nr,
 volatile unsigned long *addr)
{
 volatile unsigned long *m = &addr[((nr) / 32)];
 int bit = nr % 32;
 unsigned long res, orig;

 if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) {
  res = __mips_test_and_set_bit_lock(nr, addr);
 } else {
  orig = ({ unsigned long __orig, __temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r2" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0" ", %2		\n" "	" "or\t%1, %0, %3" "			\n" "	" "sc	" "%1, %2			\n" "	" "beqz	" "%1, 1b			\n" "	.set		pop			\n" : "=&r"(__orig), "=&r"(__temp), "+" "ZC"(*m) : "ir"(((((1UL))) << (bit))) : "memory"); __orig; });


  res = (orig & ((((1UL))) << (bit))) != 0;
 }

 do { } while (0);

 return res;
}
# 209 "./arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_set_bit(unsigned long nr,
 volatile unsigned long *addr)
{
 do { } while (0);
 return test_and_set_bit_lock(nr, addr);
}
# 224 "./arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_clear_bit(unsigned long nr,
 volatile unsigned long *addr)
{
 volatile unsigned long *m = &addr[((nr) / 32)];
 int bit = nr % 32;
 unsigned long res, orig;

 do { } while (0);

 if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) {
  res = __mips_test_and_clear_bit(nr, addr);
 } else if ((1 >= 2) && __builtin_constant_p(nr)) {
  res = ({ unsigned long __orig, __temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r2" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%1" ", %2		\n" "	" "ext	" "%0, %1, %3, 1;" "ins	" "%1, $0, %3, 1" "			\n" "	" "sc	" "%1, %2			\n" "	" "beqz	" "%1, 1b			\n" "	.set		pop			\n" : "=&r"(__orig), "=&r"(__temp), "+" "ZC"(*m) : "i"(bit) : "memory"); __orig; });



 } else {
  orig = ({ unsigned long __orig, __temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r2" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0" ", %2		\n" "	" "or\t%1, %0, %3;" "xor\t%1, %1, %3" "			\n" "	" "sc	" "%1, %2			\n" "	" "beqz	" "%1, 1b			\n" "	.set		pop			\n" : "=&r"(__orig), "=&r"(__temp), "+" "ZC"(*m) : "ir"(((((1UL))) << (bit))) : "memory"); __orig; });



  res = (orig & ((((1UL))) << (bit))) != 0;
 }

 do { } while (0);

 return res;
}
# 261 "./arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_change_bit(unsigned long nr,
 volatile unsigned long *addr)
{
 volatile unsigned long *m = &addr[((nr) / 32)];
 int bit = nr % 32;
 unsigned long res, orig;

 do { } while (0);

 if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) {
  res = __mips_test_and_change_bit(nr, addr);
 } else {
  orig = ({ unsigned long __orig, __temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r2" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0" ", %2		\n" "	" "xor\t%1, %0, %3" "			\n" "	" "sc	" "%1, %2			\n" "	" "beqz	" "%1, 1b			\n" "	.set		pop			\n" : "=&r"(__orig), "=&r"(__temp), "+" "ZC"(*m) : "ir"(((((1UL))) << (bit))) : "memory"); __orig; });


  res = (orig & ((((1UL))) << (bit))) != 0;
 }

 do { } while (0);

 return res;
}




# 1 "./include/asm-generic/bitops/non-atomic.h" 1
# 16 "./include/asm-generic/bitops/non-atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch___set_bit(unsigned int nr, volatile unsigned long *addr)
{
 unsigned long mask = ((((1UL))) << ((nr) % 32));
 unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);

 *p |= mask;
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch___clear_bit(unsigned int nr, volatile unsigned long *addr)
{
 unsigned long mask = ((((1UL))) << ((nr) % 32));
 unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);

 *p &= ~mask;
}
# 45 "./include/asm-generic/bitops/non-atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__))
void arch___change_bit(unsigned int nr, volatile unsigned long *addr)
{
 unsigned long mask = ((((1UL))) << ((nr) % 32));
 unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);

 *p ^= mask;
}
# 64 "./include/asm-generic/bitops/non-atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch___test_and_set_bit(unsigned int nr, volatile unsigned long *addr)
{
 unsigned long mask = ((((1UL))) << ((nr) % 32));
 unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);
 unsigned long old = *p;

 *p = old | mask;
 return (old & mask) != 0;
}
# 85 "./include/asm-generic/bitops/non-atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch___test_and_clear_bit(unsigned int nr, volatile unsigned long *addr)
{
 unsigned long mask = ((((1UL))) << ((nr) % 32));
 unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);
 unsigned long old = *p;

 *p = old & ~mask;
 return (old & mask) != 0;
}



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch___test_and_change_bit(unsigned int nr, volatile unsigned long *addr)
{
 unsigned long mask = ((((1UL))) << ((nr) % 32));
 unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);
 unsigned long old = *p;

 *p = old ^ mask;
 return (old & mask) != 0;
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_test_bit(unsigned int nr, const volatile unsigned long *addr)
{
 return 1UL & (addr[((nr) / 32)] >> (nr & (32 -1)));
}
# 288 "./arch/mips/include/asm/bitops.h" 2
# 298 "./arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __clear_bit_unlock(unsigned long nr, volatile unsigned long *addr)
{
 do { } while (0);
 arch___clear_bit(nr, addr);
 __sync();
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned long __fls(unsigned long word)
{
 int num;

 if (32 == 32 && !__builtin_constant_p(word) &&
     __builtin_constant_p(((((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((1 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((1 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) && ((((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((1 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((1 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) {
  __asm__(
  "	.set	push					\n"
  "	.set	""mips64r2""			\n"
  "	clz	%0, %1					\n"
  "	.set	pop					\n"
  : "=r" (num)
  : "r" (word));

  return 31 - num;
 }

 if (32 == 64 && !__builtin_constant_p(word) &&
     __builtin_constant_p((((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((1 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) && (((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((1 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) {
  __asm__(
  "	.set	push					\n"
  "	.set	""mips64r2""			\n"
  "	dclz	%0, %1					\n"
  "	.set	pop					\n"
  : "=r" (num)
  : "r" (word));

  return 63 - num;
 }

 num = 32 - 1;







 if (!(word & (~0ul << (32 -16)))) {
  num -= 16;
  word <<= 16;
 }
 if (!(word & (~0ul << (32 -8)))) {
  num -= 8;
  word <<= 8;
 }
 if (!(word & (~0ul << (32 -4)))) {
  num -= 4;
  word <<= 4;
 }
 if (!(word & (~0ul << (32 -2)))) {
  num -= 2;
  word <<= 2;
 }
 if (!(word & (~0ul << (32 -1))))
  num -= 1;
 return num;
}
# 375 "./arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned long __ffs(unsigned long word)
{
 return __fls(word & -word);
}
# 387 "./arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int fls(unsigned int x)
{
 int r;

 if (!__builtin_constant_p(x) &&
     __builtin_constant_p(((((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((1 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((1 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) && ((((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((1 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((1 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) {
  __asm__(
  "	.set	push					\n"
  "	.set	""mips64r2""			\n"
  "	clz	%0, %1					\n"
  "	.set	pop					\n"
  : "=r" (x)
  : "r" (x));

  return 32 - x;
 }

 r = 32;
 if (!x)
  return 0;
 if (!(x & 0xffff0000u)) {
  x <<= 16;
  r -= 16;
 }
 if (!(x & 0xff000000u)) {
  x <<= 8;
  r -= 8;
 }
 if (!(x & 0xf0000000u)) {
  x <<= 4;
  r -= 4;
 }
 if (!(x & 0xc0000000u)) {
  x <<= 2;
  r -= 2;
 }
 if (!(x & 0x80000000u)) {
  x <<= 1;
  r -= 1;
 }
 return r;
}

# 1 "./include/asm-generic/bitops/fls64.h" 1
# 19 "./include/asm-generic/bitops/fls64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int fls64(__u64 x)
{
 __u32 h = x >> 32;
 if (h)
  return fls(h) + 32;
 return fls(x);
}
# 431 "./arch/mips/include/asm/bitops.h" 2
# 440 "./arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int ffs(int word)
{
 if (!word)
  return 0;

 return fls(word & -word);
}

# 1 "./include/asm-generic/bitops/ffz.h" 1
# 449 "./arch/mips/include/asm/bitops.h" 2
# 1 "./include/asm-generic/bitops/find.h" 1




extern unsigned long _find_next_bit(const unsigned long *addr1,
  const unsigned long *addr2, unsigned long nbits,
  unsigned long start, unsigned long invert, unsigned long le);
extern unsigned long _find_first_bit(const unsigned long *addr, unsigned long size);
extern unsigned long _find_first_zero_bit(const unsigned long *addr, unsigned long size);
extern unsigned long _find_last_bit(const unsigned long *addr, unsigned long size);
# 22 "./include/asm-generic/bitops/find.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__))
unsigned long find_next_bit(const unsigned long *addr, unsigned long size,
       unsigned long offset)
{
 if ((__builtin_constant_p(size) && (size) <= 32 && (size) > 0)) {
  unsigned long val;

  if (__builtin_expect(!!(offset >= size), 0))
   return size;

  val = *addr & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((offset) > (size - 1)) * 0l)) : (int *)8))), (offset) > (size - 1), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (offset)) + 1) & (~(((0UL))) >> (32 - 1 - (size - 1)))));
  return val ? __ffs(val) : size;
 }

 return _find_next_bit(addr, ((void *)0), size, offset, 0UL, 0);
}
# 51 "./include/asm-generic/bitops/find.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__))
unsigned long find_next_and_bit(const unsigned long *addr1,
  const unsigned long *addr2, unsigned long size,
  unsigned long offset)
{
 if ((__builtin_constant_p(size) && (size) <= 32 && (size) > 0)) {
  unsigned long val;

  if (__builtin_expect(!!(offset >= size), 0))
   return size;

  val = *addr1 & *addr2 & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((offset) > (size - 1)) * 0l)) : (int *)8))), (offset) > (size - 1), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (offset)) + 1) & (~(((0UL))) >> (32 - 1 - (size - 1)))));
  return val ? __ffs(val) : size;
 }

 return _find_next_bit(addr1, addr2, size, offset, 0UL, 0);
}
# 80 "./include/asm-generic/bitops/find.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__))
unsigned long find_next_zero_bit(const unsigned long *addr, unsigned long size,
     unsigned long offset)
{
 if ((__builtin_constant_p(size) && (size) <= 32 && (size) > 0)) {
  unsigned long val;

  if (__builtin_expect(!!(offset >= size), 0))
   return size;

  val = *addr | ~((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((offset) > (size - 1)) * 0l)) : (int *)8))), (offset) > (size - 1), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (offset)) + 1) & (~(((0UL))) >> (32 - 1 - (size - 1)))));
  return val == ~0UL ? size : __ffs(~(val));
 }

 return _find_next_bit(addr, ((void *)0), size, offset, ~0UL, 0);
}
# 108 "./include/asm-generic/bitops/find.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__))
unsigned long find_first_bit(const unsigned long *addr, unsigned long size)
{
 if ((__builtin_constant_p(size) && (size) <= 32 && (size) > 0)) {
  unsigned long val = *addr & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (size - 1)) * 0l)) : (int *)8))), (0) > (size - 1), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (size - 1)))));

  return val ? __ffs(val) : size;
 }

 return _find_first_bit(addr, size);
}
# 128 "./include/asm-generic/bitops/find.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__))
unsigned long find_first_zero_bit(const unsigned long *addr, unsigned long size)
{
 if ((__builtin_constant_p(size) && (size) <= 32 && (size) > 0)) {
  unsigned long val = *addr | ~((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (size - 1)) * 0l)) : (int *)8))), (0) > (size - 1), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (size - 1)))));

  return val == ~0UL ? size : __ffs(~(val));
 }

 return _find_first_zero_bit(addr, size);
}
# 158 "./include/asm-generic/bitops/find.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__))
unsigned long find_last_bit(const unsigned long *addr, unsigned long size)
{
 if ((__builtin_constant_p(size) && (size) <= 32 && (size) > 0)) {
  unsigned long val = *addr & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (size - 1)) * 0l)) : (int *)8))), (0) > (size - 1), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (size - 1)))));

  return val ? __fls(val) : size;
 }

 return _find_last_bit(addr, size);
}
# 181 "./include/asm-generic/bitops/find.h"
extern unsigned long find_next_clump8(unsigned long *clump,
          const unsigned long *addr,
          unsigned long size, unsigned long offset);
# 450 "./arch/mips/include/asm/bitops.h" 2



# 1 "./include/asm-generic/bitops/sched.h" 1
# 13 "./include/asm-generic/bitops/sched.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int sched_find_first_bit(const unsigned long *b)
{





 if (b[0])
  return __ffs(b[0]);
 if (b[1])
  return __ffs(b[1]) + 32;
 if (b[2])
  return __ffs(b[2]) + 64;
 return __ffs(b[3]) + 96;



}
# 454 "./arch/mips/include/asm/bitops.h" 2

# 1 "./arch/mips/include/asm/arch_hweight.h" 1
# 35 "./arch/mips/include/asm/arch_hweight.h"
# 1 "./include/asm-generic/bitops/arch_hweight.h" 1






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int __arch_hweight32(unsigned int w)
{
 return __sw_hweight32(w);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int __arch_hweight16(unsigned int w)
{
 return __sw_hweight16(w);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int __arch_hweight8(unsigned int w)
{
 return __sw_hweight8(w);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __arch_hweight64(__u64 w)
{
 return __sw_hweight64(w);
}
# 36 "./arch/mips/include/asm/arch_hweight.h" 2
# 456 "./arch/mips/include/asm/bitops.h" 2
# 1 "./include/asm-generic/bitops/const_hweight.h" 1
# 457 "./arch/mips/include/asm/bitops.h" 2

# 1 "./include/asm-generic/bitops/le.h" 1
# 37 "./include/asm-generic/bitops/le.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__))
unsigned long find_next_zero_bit_le(const void *addr, unsigned
  long size, unsigned long offset)
{
 if ((__builtin_constant_p(size) && (size) <= 32 && (size) > 0)) {
  unsigned long val = *(const unsigned long *)addr;

  if (__builtin_expect(!!(offset >= size), 0))
   return size;

  val = __swab(val) | ~((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((offset) > (size - 1)) * 0l)) : (int *)8))), (offset) > (size - 1), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (offset)) + 1) & (~(((0UL))) >> (32 - 1 - (size - 1)))));
  return val == ~0UL ? size : __ffs(~(val));
 }

 return _find_next_bit(addr, ((void *)0), size, offset, ~0UL, 1);
}



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__))
unsigned long find_next_bit_le(const void *addr, unsigned
  long size, unsigned long offset)
{
 if ((__builtin_constant_p(size) && (size) <= 32 && (size) > 0)) {
  unsigned long val = *(const unsigned long *)addr;

  if (__builtin_expect(!!(offset >= size), 0))
   return size;

  val = __swab(val) & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((offset) > (size - 1)) * 0l)) : (int *)8))), (offset) > (size - 1), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (offset)) + 1) & (~(((0UL))) >> (32 - 1 - (size - 1)))));
  return val ? __ffs(val) : size;
 }

 return _find_next_bit(addr, ((void *)0), size, offset, 0UL, 1);
}
# 83 "./include/asm-generic/bitops/le.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_bit_le(int nr, const void *addr)
{
 return arch_test_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_bit_le(int nr, void *addr)
{
 set_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_bit_le(int nr, void *addr)
{
 clear_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __set_bit_le(int nr, void *addr)
{
 arch___set_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __clear_bit_le(int nr, void *addr)
{
 arch___clear_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_set_bit_le(int nr, void *addr)
{
 return test_and_set_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_clear_bit_le(int nr, void *addr)
{
 return test_and_clear_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __test_and_set_bit_le(int nr, void *addr)
{
 return arch___test_and_set_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __test_and_clear_bit_le(int nr, void *addr)
{
 return arch___test_and_clear_bit(nr ^ ((32 -1) & ~0x7), addr);
}
# 459 "./arch/mips/include/asm/bitops.h" 2
# 1 "./include/asm-generic/bitops/ext2-atomic.h" 1
# 460 "./arch/mips/include/asm/bitops.h" 2
# 34 "./include/linux/bitops.h" 2
# 69 "./include/linux/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int get_bitmask_order(unsigned int count)
{
 int order;

 order = fls(count);
 return order;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned long hweight_long(unsigned long w)
{
 return sizeof(w) == 4 ? (__builtin_constant_p(w) ? ((((unsigned int) ((!!((w) & (1ULL << 0))) + (!!((w) & (1ULL << 1))) + (!!((w) & (1ULL << 2))) + (!!((w) & (1ULL << 3))) + (!!((w) & (1ULL << 4))) + (!!((w) & (1ULL << 5))) + (!!((w) & (1ULL << 6))) + (!!((w) & (1ULL << 7))))) + ((unsigned int) ((!!(((w) >> 8) & (1ULL << 0))) + (!!(((w) >> 8) & (1ULL << 1))) + (!!(((w) >> 8) & (1ULL << 2))) + (!!(((w) >> 8) & (1ULL << 3))) + (!!(((w) >> 8) & (1ULL << 4))) + (!!(((w) >> 8) & (1ULL << 5))) + (!!(((w) >> 8) & (1ULL << 6))) + (!!(((w) >> 8) & (1ULL << 7)))))) + (((unsigned int) ((!!(((w) >> 16) & (1ULL << 0))) + (!!(((w) >> 16) & (1ULL << 1))) + (!!(((w) >> 16) & (1ULL << 2))) + (!!(((w) >> 16) & (1ULL << 3))) + (!!(((w) >> 16) & (1ULL << 4))) + (!!(((w) >> 16) & (1ULL << 5))) + (!!(((w) >> 16) & (1ULL << 6))) + (!!(((w) >> 16) & (1ULL << 7))))) + ((unsigned int) ((!!((((w) >> 16) >> 8) & (1ULL << 0))) + (!!((((w) >> 16) >> 8) & (1ULL << 1))) + (!!((((w) >> 16) >> 8) & (1ULL << 2))) + (!!((((w) >> 16) >> 8) & (1ULL << 3))) + (!!((((w) >> 16) >> 8) & (1ULL << 4))) + (!!((((w) >> 16) >> 8) & (1ULL << 5))) + (!!((((w) >> 16) >> 8) & (1ULL << 6))) + (!!((((w) >> 16) >> 8) & (1ULL << 7))))))) : __arch_hweight32(w)) : (__builtin_constant_p((__u64)w) ? (((((unsigned int) ((!!(((__u64)w) & (1ULL << 0))) + (!!(((__u64)w) & (1ULL << 1))) + (!!(((__u64)w) & (1ULL << 2))) + (!!(((__u64)w) & (1ULL << 3))) + (!!(((__u64)w) & (1ULL << 4))) + (!!(((__u64)w) & (1ULL << 5))) + (!!(((__u64)w) & (1ULL << 6))) + (!!(((__u64)w) & (1ULL << 7))))) + ((unsigned int) ((!!((((__u64)w) >> 8) & (1ULL << 0))) + (!!((((__u64)w) >> 8) & (1ULL << 1))) + (!!((((__u64)w) >> 8) & (1ULL << 2))) + (!!((((__u64)w) >> 8) & (1ULL << 3))) + (!!((((__u64)w) >> 8) & (1ULL << 4))) + (!!((((__u64)w) >> 8) & (1ULL << 5))) + (!!((((__u64)w) >> 8) & (1ULL << 6))) + (!!((((__u64)w) >> 8) & (1ULL << 7)))))) + (((unsigned int) ((!!((((__u64)w) >> 16) & (1ULL << 0))) + (!!((((__u64)w) >> 16) & (1ULL << 1))) + (!!((((__u64)w) >> 16) & (1ULL << 2))) + (!!((((__u64)w) >> 16) & (1ULL << 3))) + (!!((((__u64)w) >> 16) & (1ULL << 4))) + (!!((((__u64)w) >> 16) & (1ULL << 5))) + (!!((((__u64)w) >> 16) & (1ULL << 6))) + (!!((((__u64)w) >> 16) & (1ULL << 7))))) + ((unsigned int) ((!!(((((__u64)w) >> 16) >> 8) & (1ULL << 0))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 1))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 2))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 3))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 4))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 5))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 6))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 7))))))) + ((((unsigned int) ((!!((((__u64)w) >> 32) & (1ULL << 0))) + (!!((((__u64)w) >> 32) & (1ULL << 1))) + (!!((((__u64)w) >> 32) & (1ULL << 2))) + (!!((((__u64)w) >> 32) & (1ULL << 3))) + (!!((((__u64)w) >> 32) & (1ULL << 4))) + (!!((((__u64)w) >> 32) & (1ULL << 5))) + (!!((((__u64)w) >> 32) & (1ULL << 6))) + (!!((((__u64)w) >> 32) & (1ULL << 7))))) + ((unsigned int) ((!!(((((__u64)w) >> 32) >> 8) & (1ULL << 0))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 1))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 2))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 3))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 4))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 5))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 6))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 7)))))) + (((unsigned int) ((!!(((((__u64)w) >> 32) >> 16) & (1ULL << 0))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 1))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 2))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 3))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 4))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 5))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 6))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 7))))) + ((unsigned int) ((!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 0))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 1))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 2))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 3))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 4))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 5))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 6))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 7)))))))) : __arch_hweight64((__u64)w));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u64 rol64(__u64 word, unsigned int shift)
{
 return (word << (shift & 63)) | (word >> ((-shift) & 63));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u64 ror64(__u64 word, unsigned int shift)
{
 return (word >> (shift & 63)) | (word << ((-shift) & 63));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u32 rol32(__u32 word, unsigned int shift)
{
 return (word << (shift & 31)) | (word >> ((-shift) & 31));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u32 ror32(__u32 word, unsigned int shift)
{
 return (word >> (shift & 31)) | (word << ((-shift) & 31));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u16 rol16(__u16 word, unsigned int shift)
{
 return (word << (shift & 15)) | (word >> ((-shift) & 15));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u16 ror16(__u16 word, unsigned int shift)
{
 return (word >> (shift & 15)) | (word << ((-shift) & 15));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u8 rol8(__u8 word, unsigned int shift)
{
 return (word << (shift & 7)) | (word >> ((-shift) & 7));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u8 ror8(__u8 word, unsigned int shift)
{
 return (word >> (shift & 7)) | (word << ((-shift) & 7));
}
# 169 "./include/linux/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __s32 sign_extend32(__u32 value, int index)
{
 __u8 shift = 31 - index;
 return (__s32)(value << shift) >> shift;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __s64 sign_extend64(__u64 value, int index)
{
 __u8 shift = 63 - index;
 return (__s64)(value << shift) >> shift;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned fls_long(unsigned long l)
{
 if (sizeof(l) == 4)
  return fls(l);
 return fls64(l);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int get_count_order(unsigned int count)
{
 if (count == 0)
  return -1;

 return fls(--count);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int get_count_order_long(unsigned long l)
{
 if (l == 0UL)
  return -1;
 return (int)fls_long(--l);
}
# 222 "./include/linux/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __ffs64(u64 word)
{

 if (((u32)word) == 0UL)
  return __ffs((u32)(word >> 32)) + 32;



 return __ffs((unsigned long)word);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void assign_bit(long nr, volatile unsigned long *addr,
           bool value)
{
 if (value)
  set_bit(nr, addr);
 else
  clear_bit(nr, addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __assign_bit(long nr, volatile unsigned long *addr,
      bool value)
{
 if (value)
  arch___set_bit(nr, addr);
 else
  arch___clear_bit(nr, addr);
}
# 13 "./include/linux/log2.h" 2








static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((const))
int __ilog2_u32(u32 n)
{
 return fls(n) - 1;
}



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((const))
int __ilog2_u64(u64 n)
{
 return fls64(n) - 1;
}
# 44 "./include/linux/log2.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((const))
bool is_power_of_2(unsigned long n)
{
 return (n != 0 && ((n & (n - 1)) == 0));
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((const))
unsigned long __roundup_pow_of_two(unsigned long n)
{
 return 1UL << fls_long(n - 1);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((const))
unsigned long __rounddown_pow_of_two(unsigned long n)
{
 return 1UL << (fls_long(n) - 1);
}
# 198 "./include/linux/log2.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__))
int __order_base_2(unsigned long n)
{
 return n > 1 ? ( __builtin_constant_p(n - 1) ? ((n - 1) < 2 ? 0 : 63 - __builtin_clzll(n - 1)) : (sizeof(n - 1) <= 4) ? __ilog2_u32(n - 1) : __ilog2_u64(n - 1) ) + 1 : 0;
}
# 225 "./include/linux/log2.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((const))
int __bits_per(unsigned long n)
{
 if (n < 2)
  return 1;
 if (is_power_of_2(n))
  return ( __builtin_constant_p(n) ? ( ((n) == 0 || (n) == 1) ? 0 : ( __builtin_constant_p((n) - 1) ? (((n) - 1) < 2 ? 0 : 63 - __builtin_clzll((n) - 1)) : (sizeof((n) - 1) <= 4) ? __ilog2_u32((n) - 1) : __ilog2_u64((n) - 1) ) + 1) : __order_base_2(n) ) + 1;
 return ( __builtin_constant_p(n) ? ( ((n) == 0 || (n) == 1) ? 0 : ( __builtin_constant_p((n) - 1) ? (((n) - 1) < 2 ? 0 : 63 - __builtin_clzll((n) - 1)) : (sizeof((n) - 1) <= 4) ? __ilog2_u32((n) - 1) : __ilog2_u64((n) - 1) ) + 1) : __order_base_2(n) );
}
# 56 "./include/asm-generic/div64.h" 2
# 171 "./include/asm-generic/div64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t __arch_xprod_64(const uint64_t m, uint64_t n, bool bias)
{
 uint32_t m_lo = m;
 uint32_t m_hi = m >> 32;
 uint32_t n_lo = n;
 uint32_t n_hi = n >> 32;
 uint64_t res;
 uint32_t res_lo, res_hi, tmp;

 if (!bias) {
  res = ((uint64_t)m_lo * n_lo) >> 32;
 } else if (!(m & ((1ULL << 63) | (1ULL << 31)))) {

  res = (m + (uint64_t)m_lo * n_lo) >> 32;
 } else {
  res = m + (uint64_t)m_lo * n_lo;
  res_lo = res >> 32;
  res_hi = (res_lo < m_hi);
  res = res_lo | ((uint64_t)res_hi << 32);
 }

 if (!(m & ((1ULL << 63) | (1ULL << 31)))) {

  res += (uint64_t)m_lo * n_hi;
  res += (uint64_t)m_hi * n_lo;
  res >>= 32;
 } else {
  res += (uint64_t)m_lo * n_hi;
  tmp = res >> 32;
  res += (uint64_t)m_hi * n_lo;
  res_lo = res >> 32;
  res_hi = (res_lo < tmp);
  res = res_lo | ((uint64_t)res_hi << 32);
 }

 res += (uint64_t)m_hi * n_hi;

 return res;
}
# 90 "./arch/mips/include/asm/div64.h" 2
# 6 "./include/linux/math.h" 2
# 160 "./include/linux/math.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 reciprocal_scale(u32 val, u32 ep_ro)
{
 return (u32)(((u64) val * ep_ro) >> 32);
}

u64 int_pow(u64 base, unsigned int exp);
unsigned long int_sqrt(unsigned long);


u32 int_sqrt64(u64 x);
# 7 "./include/linux/math64.h" 2
# 1 "./include/vdso/math64.h" 1




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u32
__iter_div_u64_rem(u64 dividend, u32 divisor, u64 *remainder)
{
 u32 ret = 0;

 while (dividend >= divisor) {


  asm("" : "+rm"(dividend));

  dividend -= divisor;
  ret++;
 }

 *remainder = dividend;

 return ret;
}
# 8 "./include/linux/math64.h" 2
# 90 "./include/linux/math64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)
{
 *remainder = ({ uint32_t __base = (divisor); uint32_t __rem; (void)(((typeof((dividend)) *)0) == ((uint64_t *)0)); if (__builtin_constant_p(__base) && is_power_of_2(__base)) { __rem = (dividend) & (__base - 1); (dividend) >>= ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); } else if (__builtin_constant_p(__base) && __base != 0) { uint32_t __res_lo, __n_lo = (dividend); (dividend) = ({ uint64_t ___res, ___x, ___t, ___m, ___n = (dividend); uint32_t ___p, ___bias; ___p = 1 << ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); ___m = (~0ULL / __base) * ___p; ___m += (((~0ULL % __base + 1) * ___p) + __base - 1) / __base; ___x = ~0ULL / __base * __base - 1; ___res = ((___m & 0xffffffff) * (___x & 0xffffffff)) >> 32; ___t = ___res += (___m & 0xffffffff) * (___x >> 32); ___res += (___x & 0xffffffff) * (___m >> 32); ___t = (___res < ___t) ? (1ULL << 32) : 0; ___res = (___res >> 32) + ___t; ___res += (___m >> 32) * (___x >> 32); ___res /= ___p; if (~0ULL % (__base / (__base & -__base)) == 0) { ___n /= (__base & -__base); ___m = ~0ULL / (__base / (__base & -__base)); ___p = 1; ___bias = 1; } else if (___res != ___x / __base) { ___bias = 1; ___m = (~0ULL / __base) * ___p; ___m += ((~0ULL % __base + 1) * ___p) / __base; } else { uint32_t ___bits = -(___m & -___m); ___bits |= ___m >> 32; ___bits = (~___bits) << 1; if (!___bits) { ___p /= (___m & -___m); ___m /= (___m & -___m); } else { ___p >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); ___m >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); } ___bias = 0; } ___res = __arch_xprod_64(___m, ___n, ___bias); ___res /= ___p; }); __res_lo = (dividend); __rem = __n_lo - __res_lo * __base; } else if (__builtin_expect(!!(((dividend) >> 32) == 0), 1)) { __rem = (uint32_t)(dividend) % __base; (dividend) = (uint32_t)(dividend) / __base; } else { __rem = ({ unsigned long __upper, __low, __high, __radix; unsigned long long __quot; unsigned long long __div; unsigned long __mod; __div = (*&(dividend)); __radix = (__base); __high = __div >> 32; __low = __div; if (__high < __radix) { __upper = __high; __high = 0; } else { __upper = __high % __radix; __high /= __radix; } __mod = ({ unsigned long __cf, __tmp, __tmp2, __i; unsigned long __quot32, __mod32; __asm__( "	.set	push					\n" "	.set	noat					\n" "	.set	noreorder				\n" "	move	%2, $0					\n" "	move	%3, $0					\n" "	b	1f					\n" "	 li	%4, 0x21				\n" "0:							\n" "	sll	$1, %0, 0x1				\n" "	srl	%3, %0, 0x1f				\n" "	or	%0, $1, %5				\n" "	sll	%1, %1, 0x1				\n" "	sll	%2, %2, 0x1				\n" "1:							\n" "	bnez	%3, 2f					\n" "	 sltu	%5, %0, %z6				\n" "	bnez	%5, 3f					\n" "2:							\n" "	 addiu	%4, %4, -1				\n" "	subu	%0, %0, %z6				\n" "	addiu	%2, %2, 1				\n" "3:							\n" "	bnez	%4, 0b					\n" "	 srl	%5, %1, 0x1f				\n" "	.set	pop" : "=&r" (__mod32), "=&r" (__tmp), "=&r" (__quot32), "=&r" (__cf), "=&r" (__i), "=&r" (__tmp2) : "Jr" (__radix), "0" (__upper), "1" (__low)); (__low) = __quot32; __mod32; }); __quot = __high; __quot = __quot << 32 | __low; (*&(dividend)) = __quot; __mod; }); } __rem; });
 return dividend;
}



extern s64 div_s64_rem(s64 dividend, s32 divisor, s32 *remainder);



extern u64 div64_u64_rem(u64 dividend, u64 divisor, u64 *remainder);



extern u64 div64_u64(u64 dividend, u64 divisor);



extern s64 div64_s64(s64 dividend, s64 divisor);
# 125 "./include/linux/math64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 div_u64(u64 dividend, u32 divisor)
{
 u32 remainder;
 return div_u64_rem(dividend, divisor, &remainder);
}
# 138 "./include/linux/math64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 div_s64(s64 dividend, s32 divisor)
{
 s32 remainder;
 return div_s64_rem(dividend, divisor, &remainder);
}


u32 iter_div_u64_rem(u64 dividend, u32 divisor, u64 *remainder);





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 mul_u32_u32(u32 a, u32 b)
{
 return (u64)a * b;
}
# 176 "./include/linux/math64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 mul_u64_u32_shr(u64 a, u32 mul, unsigned int shift)
{
 u32 ah, al;
 u64 ret;

 al = a;
 ah = a >> 32;

 ret = mul_u32_u32(al, mul) >> shift;
 if (ah)
  ret += mul_u32_u32(ah, mul) << (32 - shift);

 return ret;
}



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 mul_u64_u64_shr(u64 a, u64 b, unsigned int shift)
{
 union {
  u64 ll;
  struct {

   u32 high, low;



  } l;
 } rl, rm, rn, rh, a0, b0;
 u64 c;

 a0.ll = a;
 b0.ll = b;

 rl.ll = mul_u32_u32(a0.l.low, b0.l.low);
 rm.ll = mul_u32_u32(a0.l.low, b0.l.high);
 rn.ll = mul_u32_u32(a0.l.high, b0.l.low);
 rh.ll = mul_u32_u32(a0.l.high, b0.l.high);






 rl.l.high = c = (u64)rl.l.high + rm.l.low + rn.l.low;
 rh.l.low = c = (c >> 32) + rm.l.high + rn.l.high + rh.l.low;
 rh.l.high = (c >> 32) + rh.l.high;





 if (shift == 0)
  return rl.ll;
 if (shift < 64)
  return (rl.ll >> shift) | (rh.ll << (64 - shift));
 return rh.ll >> (shift & 63);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 mul_s64_u64_shr(s64 a, u64 b, unsigned int shift)
{
 u64 ret;





 ret = mul_u64_u64_shr(__builtin_choose_expr( __builtin_types_compatible_p(typeof(a), signed long long) || __builtin_types_compatible_p(typeof(a), unsigned long long), ({ signed long long __x = (a); __x < 0 ? -__x : __x; }), __builtin_choose_expr( __builtin_types_compatible_p(typeof(a), signed long) || __builtin_types_compatible_p(typeof(a), unsigned long), ({ signed long __x = (a); __x < 0 ? -__x : __x; }), __builtin_choose_expr( __builtin_types_compatible_p(typeof(a), signed int) || __builtin_types_compatible_p(typeof(a), unsigned int), ({ signed int __x = (a); __x < 0 ? -__x : __x; }), __builtin_choose_expr( __builtin_types_compatible_p(typeof(a), signed short) || __builtin_types_compatible_p(typeof(a), unsigned short), ({ signed short __x = (a); __x < 0 ? -__x : __x; }), __builtin_choose_expr( __builtin_types_compatible_p(typeof(a), signed char) || __builtin_types_compatible_p(typeof(a), unsigned char), ({ signed char __x = (a); __x < 0 ? -__x : __x; }), __builtin_choose_expr( __builtin_types_compatible_p(typeof(a), char), (char)({ signed char __x = (a); __x<0?-__x:__x; }), ((void)0))))))), b, shift);

 if (a < 0)
  ret = -((s64) ret);

 return ret;
}



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 mul_u64_u32_div(u64 a, u32 mul, u32 divisor)
{
 union {
  u64 ll;
  struct {

   u32 high, low;



  } l;
 } u, rl, rh;

 u.ll = a;
 rl.ll = mul_u32_u32(u.l.low, mul);
 rh.ll = mul_u32_u32(u.l.high, mul) + rl.l.high;


 rl.l.high = ({ uint32_t __base = (divisor); uint32_t __rem; (void)(((typeof((rh.ll)) *)0) == ((uint64_t *)0)); if (__builtin_constant_p(__base) && is_power_of_2(__base)) { __rem = (rh.ll) & (__base - 1); (rh.ll) >>= ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); } else if (__builtin_constant_p(__base) && __base != 0) { uint32_t __res_lo, __n_lo = (rh.ll); (rh.ll) = ({ uint64_t ___res, ___x, ___t, ___m, ___n = (rh.ll); uint32_t ___p, ___bias; ___p = 1 << ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); ___m = (~0ULL / __base) * ___p; ___m += (((~0ULL % __base + 1) * ___p) + __base - 1) / __base; ___x = ~0ULL / __base * __base - 1; ___res = ((___m & 0xffffffff) * (___x & 0xffffffff)) >> 32; ___t = ___res += (___m & 0xffffffff) * (___x >> 32); ___res += (___x & 0xffffffff) * (___m >> 32); ___t = (___res < ___t) ? (1ULL << 32) : 0; ___res = (___res >> 32) + ___t; ___res += (___m >> 32) * (___x >> 32); ___res /= ___p; if (~0ULL % (__base / (__base & -__base)) == 0) { ___n /= (__base & -__base); ___m = ~0ULL / (__base / (__base & -__base)); ___p = 1; ___bias = 1; } else if (___res != ___x / __base) { ___bias = 1; ___m = (~0ULL / __base) * ___p; ___m += ((~0ULL % __base + 1) * ___p) / __base; } else { uint32_t ___bits = -(___m & -___m); ___bits |= ___m >> 32; ___bits = (~___bits) << 1; if (!___bits) { ___p /= (___m & -___m); ___m /= (___m & -___m); } else { ___p >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); ___m >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); } ___bias = 0; } ___res = __arch_xprod_64(___m, ___n, ___bias); ___res /= ___p; }); __res_lo = (rh.ll); __rem = __n_lo - __res_lo * __base; } else if (__builtin_expect(!!(((rh.ll) >> 32) == 0), 1)) { __rem = (uint32_t)(rh.ll) % __base; (rh.ll) = (uint32_t)(rh.ll) / __base; } else { __rem = ({ unsigned long __upper, __low, __high, __radix; unsigned long long __quot; unsigned long long __div; unsigned long __mod; __div = (*&(rh.ll)); __radix = (__base); __high = __div >> 32; __low = __div; if (__high < __radix) { __upper = __high; __high = 0; } else { __upper = __high % __radix; __high /= __radix; } __mod = ({ unsigned long __cf, __tmp, __tmp2, __i; unsigned long __quot32, __mod32; __asm__( "	.set	push					\n" "	.set	noat					\n" "	.set	noreorder				\n" "	move	%2, $0					\n" "	move	%3, $0					\n" "	b	1f					\n" "	 li	%4, 0x21				\n" "0:							\n" "	sll	$1, %0, 0x1				\n" "	srl	%3, %0, 0x1f				\n" "	or	%0, $1, %5				\n" "	sll	%1, %1, 0x1				\n" "	sll	%2, %2, 0x1				\n" "1:							\n" "	bnez	%3, 2f					\n" "	 sltu	%5, %0, %z6				\n" "	bnez	%5, 3f					\n" "2:							\n" "	 addiu	%4, %4, -1				\n" "	subu	%0, %0, %z6				\n" "	addiu	%2, %2, 1				\n" "3:							\n" "	bnez	%4, 0b					\n" "	 srl	%5, %1, 0x1f				\n" "	.set	pop" : "=&r" (__mod32), "=&r" (__tmp), "=&r" (__quot32), "=&r" (__cf), "=&r" (__i), "=&r" (__tmp2) : "Jr" (__radix), "0" (__upper), "1" (__low)); (__low) = __quot32; __mod32; }); __quot = __high; __quot = __quot << 32 | __low; (*&(rh.ll)) = __quot; __mod; }); } __rem; });


 ({ uint32_t __base = (divisor); uint32_t __rem; (void)(((typeof((rl.ll)) *)0) == ((uint64_t *)0)); if (__builtin_constant_p(__base) && is_power_of_2(__base)) { __rem = (rl.ll) & (__base - 1); (rl.ll) >>= ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); } else if (__builtin_constant_p(__base) && __base != 0) { uint32_t __res_lo, __n_lo = (rl.ll); (rl.ll) = ({ uint64_t ___res, ___x, ___t, ___m, ___n = (rl.ll); uint32_t ___p, ___bias; ___p = 1 << ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); ___m = (~0ULL / __base) * ___p; ___m += (((~0ULL % __base + 1) * ___p) + __base - 1) / __base; ___x = ~0ULL / __base * __base - 1; ___res = ((___m & 0xffffffff) * (___x & 0xffffffff)) >> 32; ___t = ___res += (___m & 0xffffffff) * (___x >> 32); ___res += (___x & 0xffffffff) * (___m >> 32); ___t = (___res < ___t) ? (1ULL << 32) : 0; ___res = (___res >> 32) + ___t; ___res += (___m >> 32) * (___x >> 32); ___res /= ___p; if (~0ULL % (__base / (__base & -__base)) == 0) { ___n /= (__base & -__base); ___m = ~0ULL / (__base / (__base & -__base)); ___p = 1; ___bias = 1; } else if (___res != ___x / __base) { ___bias = 1; ___m = (~0ULL / __base) * ___p; ___m += ((~0ULL % __base + 1) * ___p) / __base; } else { uint32_t ___bits = -(___m & -___m); ___bits |= ___m >> 32; ___bits = (~___bits) << 1; if (!___bits) { ___p /= (___m & -___m); ___m /= (___m & -___m); } else { ___p >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); ___m >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); } ___bias = 0; } ___res = __arch_xprod_64(___m, ___n, ___bias); ___res /= ___p; }); __res_lo = (rl.ll); __rem = __n_lo - __res_lo * __base; } else if (__builtin_expect(!!(((rl.ll) >> 32) == 0), 1)) { __rem = (uint32_t)(rl.ll) % __base; (rl.ll) = (uint32_t)(rl.ll) / __base; } else { __rem = ({ unsigned long __upper, __low, __high, __radix; unsigned long long __quot; unsigned long long __div; unsigned long __mod; __div = (*&(rl.ll)); __radix = (__base); __high = __div >> 32; __low = __div; if (__high < __radix) { __upper = __high; __high = 0; } else { __upper = __high % __radix; __high /= __radix; } __mod = ({ unsigned long __cf, __tmp, __tmp2, __i; unsigned long __quot32, __mod32; __asm__( "	.set	push					\n" "	.set	noat					\n" "	.set	noreorder				\n" "	move	%2, $0					\n" "	move	%3, $0					\n" "	b	1f					\n" "	 li	%4, 0x21				\n" "0:							\n" "	sll	$1, %0, 0x1				\n" "	srl	%3, %0, 0x1f				\n" "	or	%0, $1, %5				\n" "	sll	%1, %1, 0x1				\n" "	sll	%2, %2, 0x1				\n" "1:							\n" "	bnez	%3, 2f					\n" "	 sltu	%5, %0, %z6				\n" "	bnez	%5, 3f					\n" "2:							\n" "	 addiu	%4, %4, -1				\n" "	subu	%0, %0, %z6				\n" "	addiu	%2, %2, 1				\n" "3:							\n" "	bnez	%4, 0b					\n" "	 srl	%5, %1, 0x1f				\n" "	.set	pop" : "=&r" (__mod32), "=&r" (__tmp), "=&r" (__quot32), "=&r" (__cf), "=&r" (__i), "=&r" (__tmp2) : "Jr" (__radix), "0" (__upper), "1" (__low)); (__low) = __quot32; __mod32; }); __quot = __high; __quot = __quot << 32 | __low; (*&(rl.ll)) = __quot; __mod; }); } __rem; });

 rl.l.high = rh.l.low;
 return rl.ll;
}


u64 mul_u64_u64_div_u64(u64 a, u64 mul, u64 div);
# 8 "./include/linux/jiffies.h" 2
# 1 "./include/linux/minmax.h" 1
# 9 "./include/linux/jiffies.h" 2

# 1 "./include/linux/time.h" 1






# 1 "./include/linux/time64.h" 1





# 1 "./include/vdso/time64.h" 1
# 7 "./include/linux/time64.h" 2

typedef __s64 time64_t;
typedef __u64 timeu64_t;

# 1 "./include/uapi/linux/time.h" 1





# 1 "./include/uapi/linux/time_types.h" 1






struct __kernel_timespec {
 __kernel_time64_t tv_sec;
 long long tv_nsec;
};

struct __kernel_itimerspec {
 struct __kernel_timespec it_interval;
 struct __kernel_timespec it_value;
};
# 25 "./include/uapi/linux/time_types.h"
struct __kernel_old_timeval {
 __kernel_long_t tv_sec;
 __kernel_long_t tv_usec;
};


struct __kernel_old_timespec {
 __kernel_old_time_t tv_sec;
 long tv_nsec;
};

struct __kernel_old_itimerval {
 struct __kernel_old_timeval it_interval;
 struct __kernel_old_timeval it_value;
};

struct __kernel_sock_timeval {
 __s64 tv_sec;
 __s64 tv_usec;
};
# 7 "./include/uapi/linux/time.h" 2
# 33 "./include/uapi/linux/time.h"
struct timezone {
 int tz_minuteswest;
 int tz_dsttime;
};
# 12 "./include/linux/time64.h" 2

struct timespec64 {
 time64_t tv_sec;
 long tv_nsec;
};

struct itimerspec64 {
 struct timespec64 it_interval;
 struct timespec64 it_value;
};
# 43 "./include/linux/time64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int timespec64_equal(const struct timespec64 *a,
       const struct timespec64 *b)
{
 return (a->tv_sec == b->tv_sec) && (a->tv_nsec == b->tv_nsec);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int timespec64_compare(const struct timespec64 *lhs, const struct timespec64 *rhs)
{
 if (lhs->tv_sec < rhs->tv_sec)
  return -1;
 if (lhs->tv_sec > rhs->tv_sec)
  return 1;
 return lhs->tv_nsec - rhs->tv_nsec;
}

extern void set_normalized_timespec64(struct timespec64 *ts, time64_t sec, s64 nsec);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct timespec64 timespec64_add(struct timespec64 lhs,
      struct timespec64 rhs)
{
 struct timespec64 ts_delta;
 set_normalized_timespec64(&ts_delta, lhs.tv_sec + rhs.tv_sec,
    lhs.tv_nsec + rhs.tv_nsec);
 return ts_delta;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct timespec64 timespec64_sub(struct timespec64 lhs,
      struct timespec64 rhs)
{
 struct timespec64 ts_delta;
 set_normalized_timespec64(&ts_delta, lhs.tv_sec - rhs.tv_sec,
    lhs.tv_nsec - rhs.tv_nsec);
 return ts_delta;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool timespec64_valid(const struct timespec64 *ts)
{

 if (ts->tv_sec < 0)
  return false;

 if ((unsigned long)ts->tv_nsec >= 1000000000L)
  return false;
 return true;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool timespec64_valid_strict(const struct timespec64 *ts)
{
 if (!timespec64_valid(ts))
  return false;

 if ((unsigned long long)ts->tv_sec >= (((s64)~((u64)1 << 63)) / 1000000000L))
  return false;
 return true;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool timespec64_valid_settod(const struct timespec64 *ts)
{
 if (!timespec64_valid(ts))
  return false;

 if ((unsigned long long)ts->tv_sec >= ((((s64)~((u64)1 << 63)) / 1000000000L) - (30LL * 365 * 24 *3600)))
  return false;
 return true;
}
# 127 "./include/linux/time64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 timespec64_to_ns(const struct timespec64 *ts)
{

 if (ts->tv_sec >= (((s64)~((u64)1 << 63)) / 1000000000L))
  return ((s64)~((u64)1 << 63));

 if (ts->tv_sec <= ((-((s64)~((u64)1 << 63)) - 1) / 1000000000L))
  return (-((s64)~((u64)1 << 63)) - 1);

 return ((s64) ts->tv_sec * 1000000000L) + ts->tv_nsec;
}







extern struct timespec64 ns_to_timespec64(const s64 nsec);
# 155 "./include/linux/time64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void timespec64_add_ns(struct timespec64 *a, u64 ns)
{
 a->tv_sec += __iter_div_u64_rem(a->tv_nsec + ns, 1000000000L, &ns);
 a->tv_nsec = ns;
}





extern struct timespec64 timespec64_add_safe(const struct timespec64 lhs,
      const struct timespec64 rhs);
# 8 "./include/linux/time.h" 2

extern struct timezone sys_tz;

int get_timespec64(struct timespec64 *ts,
  const struct __kernel_timespec *uts);
int put_timespec64(const struct timespec64 *ts,
  struct __kernel_timespec *uts);
int get_itimerspec64(struct itimerspec64 *it,
   const struct __kernel_itimerspec *uit);
int put_itimerspec64(const struct itimerspec64 *it,
   struct __kernel_itimerspec *uit);

extern time64_t mktime64(const unsigned int year, const unsigned int mon,
   const unsigned int day, const unsigned int hour,
   const unsigned int min, const unsigned int sec);


extern void clear_itimer(void);




extern long do_utimes(int dfd, const char *filename, struct timespec64 *times, int flags);





struct tm {




 int tm_sec;

 int tm_min;

 int tm_hour;

 int tm_mday;

 int tm_mon;

 long tm_year;

 int tm_wday;

 int tm_yday;
};

void time64_to_tm(time64_t totalsecs, int offset, struct tm *result);

# 1 "./include/linux/time32.h" 1
# 13 "./include/linux/time32.h"
# 1 "./include/linux/timex.h" 1
# 56 "./include/linux/timex.h"
# 1 "./include/uapi/linux/timex.h" 1
# 56 "./include/uapi/linux/timex.h"
# 1 "./include/linux/time.h" 1
# 57 "./include/uapi/linux/timex.h" 2
# 97 "./include/uapi/linux/timex.h"
struct __kernel_timex_timeval {
 __kernel_time64_t tv_sec;
 long long tv_usec;
};

struct __kernel_timex {
 unsigned int modes;
 int :32;
 long long offset;
 long long freq;
 long long maxerror;
 long long esterror;
 int status;
 int :32;
 long long constant;
 long long precision;
 long long tolerance;


 struct __kernel_timex_timeval time;
 long long tick;

 long long ppsfreq;
 long long jitter;
 int shift;
 int :32;
 long long stabil;
 long long jitcnt;
 long long calcnt;
 long long errcnt;
 long long stbcnt;

 int tai;

 int :32; int :32; int :32; int :32;
 int :32; int :32; int :32; int :32;
 int :32; int :32; int :32;
};
# 57 "./include/linux/timex.h" 2






# 1 "./include/uapi/linux/param.h" 1




# 1 "./arch/mips/include/uapi/asm/param.h" 1
# 15 "./arch/mips/include/uapi/asm/param.h"
# 1 "./include/asm-generic/param.h" 1




# 1 "./include/uapi/asm-generic/param.h" 1
# 6 "./include/asm-generic/param.h" 2
# 16 "./arch/mips/include/uapi/asm/param.h" 2
# 6 "./include/uapi/linux/param.h" 2
# 64 "./include/linux/timex.h" 2

# 1 "./arch/mips/include/asm/timex.h" 1
# 19 "./arch/mips/include/asm/timex.h"
# 1 "./arch/mips/include/asm/cpu-type.h" 1
# 12 "./arch/mips/include/asm/cpu-type.h"
# 1 "./include/linux/smp.h" 1
# 10 "./include/linux/smp.h"
# 1 "./include/linux/errno.h" 1




# 1 "./include/uapi/linux/errno.h" 1
# 1 "./arch/mips/include/asm/errno.h" 1
# 11 "./arch/mips/include/asm/errno.h"
# 1 "./arch/mips/include/uapi/asm/errno.h" 1
# 16 "./arch/mips/include/uapi/asm/errno.h"
# 1 "./include/uapi/asm-generic/errno-base.h" 1
# 17 "./arch/mips/include/uapi/asm/errno.h" 2
# 12 "./arch/mips/include/asm/errno.h" 2
# 2 "./include/uapi/linux/errno.h" 2
# 6 "./include/linux/errno.h" 2
# 11 "./include/linux/smp.h" 2

# 1 "./include/linux/list.h" 1




# 1 "./include/linux/container_of.h" 1





# 1 "./include/linux/err.h" 1
# 24 "./include/linux/err.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void * __attribute__((__warn_unused_result__)) ERR_PTR(long error)
{
 return (void *) error;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) long __attribute__((__warn_unused_result__)) PTR_ERR( const void *ptr)
{
 return (long) ptr;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __attribute__((__warn_unused_result__)) IS_ERR( const void *ptr)
{
 return __builtin_expect(!!((unsigned long)(void *)((unsigned long)ptr) >= (unsigned long)-4095), 0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __attribute__((__warn_unused_result__)) IS_ERR_OR_NULL( const void *ptr)
{
 return __builtin_expect(!!(!ptr), 0) || __builtin_expect(!!((unsigned long)(void *)((unsigned long)ptr) >= (unsigned long)-4095), 0);
}
# 51 "./include/linux/err.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void * __attribute__((__warn_unused_result__)) ERR_CAST( const void *ptr)
{

 return (void *) ptr;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) PTR_ERR_OR_ZERO( const void *ptr)
{
 if (IS_ERR(ptr))
  return PTR_ERR(ptr);
 else
  return 0;
}
# 7 "./include/linux/container_of.h" 2
# 6 "./include/linux/list.h" 2


# 1 "./include/linux/poison.h" 1
# 9 "./include/linux/list.h" 2
# 35 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void INIT_LIST_HEAD(struct list_head *list)
{
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_0(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(list->next) == sizeof(char) || sizeof(list->next) == sizeof(short) || sizeof(list->next) == sizeof(int) || sizeof(list->next) == sizeof(long)) || sizeof(list->next) == sizeof(long long))) __compiletime_assert_0(); } while (0); do { *(volatile typeof(list->next) *)&(list->next) = (list); } while (0); } while (0);
 list->prev = list;
}


extern bool __list_add_valid(struct list_head *new,
         struct list_head *prev,
         struct list_head *next);
extern bool __list_del_entry_valid(struct list_head *entry);
# 65 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __list_add(struct list_head *new,
         struct list_head *prev,
         struct list_head *next)
{
 if (!__list_add_valid(new, prev, next))
  return;

 next->prev = new;
 new->next = next;
 new->prev = prev;
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_1(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(prev->next) == sizeof(char) || sizeof(prev->next) == sizeof(short) || sizeof(prev->next) == sizeof(int) || sizeof(prev->next) == sizeof(long)) || sizeof(prev->next) == sizeof(long long))) __compiletime_assert_1(); } while (0); do { *(volatile typeof(prev->next) *)&(prev->next) = (new); } while (0); } while (0);
}
# 86 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_add(struct list_head *new, struct list_head *head)
{
 __list_add(new, head, head->next);
}
# 100 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_add_tail(struct list_head *new, struct list_head *head)
{
 __list_add(new, head->prev, head);
}
# 112 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __list_del(struct list_head * prev, struct list_head * next)
{
 next->prev = prev;
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_2(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(prev->next) == sizeof(char) || sizeof(prev->next) == sizeof(short) || sizeof(prev->next) == sizeof(int) || sizeof(prev->next) == sizeof(long)) || sizeof(prev->next) == sizeof(long long))) __compiletime_assert_2(); } while (0); do { *(volatile typeof(prev->next) *)&(prev->next) = (next); } while (0); } while (0);
}
# 126 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __list_del_clearprev(struct list_head *entry)
{
 __list_del(entry->prev, entry->next);
 entry->prev = ((void *)0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __list_del_entry(struct list_head *entry)
{
 if (!__list_del_entry_valid(entry))
  return;

 __list_del(entry->prev, entry->next);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_del(struct list_head *entry)
{
 __list_del_entry(entry);
 entry->next = ((void *) 0x100 + 0);
 entry->prev = ((void *) 0x122 + 0);
}
# 160 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_replace(struct list_head *old,
    struct list_head *new)
{
 new->next = old->next;
 new->next->prev = new;
 new->prev = old->prev;
 new->prev->next = new;
}
# 176 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_replace_init(struct list_head *old,
         struct list_head *new)
{
 list_replace(old, new);
 INIT_LIST_HEAD(old);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_swap(struct list_head *entry1,
        struct list_head *entry2)
{
 struct list_head *pos = entry2->prev;

 list_del(entry2);
 list_replace(entry1, entry2);
 if (pos == entry1)
  pos = entry2;
 list_add(entry1, pos);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_del_init(struct list_head *entry)
{
 __list_del_entry(entry);
 INIT_LIST_HEAD(entry);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_move(struct list_head *list, struct list_head *head)
{
 __list_del_entry(list);
 list_add(list, head);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_move_tail(struct list_head *list,
      struct list_head *head)
{
 __list_del_entry(list);
 list_add_tail(list, head);
}
# 242 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_bulk_move_tail(struct list_head *head,
           struct list_head *first,
           struct list_head *last)
{
 first->prev->next = last->next;
 last->next->prev = first->prev;

 head->prev->next = first;
 first->prev = head->prev;

 last->next = head;
 head->prev = last;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int list_is_first(const struct list_head *list,
     const struct list_head *head)
{
 return list->prev == head;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int list_is_last(const struct list_head *list,
    const struct list_head *head)
{
 return list->next == head;
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int list_empty(const struct list_head *head)
{
 return ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_3(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(head->next) == sizeof(char) || sizeof(head->next) == sizeof(short) || sizeof(head->next) == sizeof(int) || sizeof(head->next) == sizeof(long)) || sizeof(head->next) == sizeof(long long))) __compiletime_assert_3(); } while (0); (*(const volatile typeof( _Generic((head->next), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (head->next))) *)&(head->next)); }) == head;
}
# 298 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_del_init_careful(struct list_head *entry)
{
 __list_del_entry(entry);
 entry->prev = entry;
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_4(void) __attribute__((__error__("Need native word sized stores/loads for atomicity."))); if (!((sizeof(*&entry->next) == sizeof(char) || sizeof(*&entry->next) == sizeof(short) || sizeof(*&entry->next) == sizeof(int) || sizeof(*&entry->next) == sizeof(long)))) __compiletime_assert_4(); } while (0); __sync(); do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_5(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(*&entry->next) == sizeof(char) || sizeof(*&entry->next) == sizeof(short) || sizeof(*&entry->next) == sizeof(int) || sizeof(*&entry->next) == sizeof(long)) || sizeof(*&entry->next) == sizeof(long long))) __compiletime_assert_5(); } while (0); do { *(volatile typeof(*&entry->next) *)&(*&entry->next) = (entry); } while (0); } while (0); } while (0);
}
# 318 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int list_empty_careful(const struct list_head *head)
{
 struct list_head *next = ({ typeof( _Generic((*&head->next), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*&head->next))) ___p1 = ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_6(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(*&head->next) == sizeof(char) || sizeof(*&head->next) == sizeof(short) || sizeof(*&head->next) == sizeof(int) || sizeof(*&head->next) == sizeof(long)) || sizeof(*&head->next) == sizeof(long long))) __compiletime_assert_6(); } while (0); (*(const volatile typeof( _Generic((*&head->next), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*&head->next))) *)&(*&head->next)); }); do { __attribute__((__noreturn__)) extern void __compiletime_assert_7(void) __attribute__((__error__("Need native word sized stores/loads for atomicity."))); if (!((sizeof(*&head->next) == sizeof(char) || sizeof(*&head->next) == sizeof(short) || sizeof(*&head->next) == sizeof(int) || sizeof(*&head->next) == sizeof(long)))) __compiletime_assert_7(); } while (0); __sync(); (typeof(*&head->next))___p1; });
 return (next == head) && (next == head->prev);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_rotate_left(struct list_head *head)
{
 struct list_head *first;

 if (!list_empty(head)) {
  first = head->next;
  list_move_tail(first, head);
 }
}
# 345 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_rotate_to_front(struct list_head *list,
     struct list_head *head)
{





 list_move_tail(head, list);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int list_is_singular(const struct list_head *head)
{
 return !list_empty(head) && (head->next == head->prev);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __list_cut_position(struct list_head *list,
  struct list_head *head, struct list_head *entry)
{
 struct list_head *new_first = entry->next;
 list->next = head->next;
 list->next->prev = list;
 list->prev = entry;
 entry->next = list;
 head->next = new_first;
 new_first->prev = head;
}
# 391 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_cut_position(struct list_head *list,
  struct list_head *head, struct list_head *entry)
{
 if (list_empty(head))
  return;
 if (list_is_singular(head) &&
  (head->next != entry && head != entry))
  return;
 if (entry == head)
  INIT_LIST_HEAD(list);
 else
  __list_cut_position(list, head, entry);
}
# 419 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_cut_before(struct list_head *list,
       struct list_head *head,
       struct list_head *entry)
{
 if (head->next == entry) {
  INIT_LIST_HEAD(list);
  return;
 }
 list->next = head->next;
 list->next->prev = list;
 list->prev = entry->prev;
 list->prev->next = list;
 head->next = entry;
 entry->prev = head;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __list_splice(const struct list_head *list,
     struct list_head *prev,
     struct list_head *next)
{
 struct list_head *first = list->next;
 struct list_head *last = list->prev;

 first->prev = prev;
 prev->next = first;

 last->next = next;
 next->prev = last;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_splice(const struct list_head *list,
    struct list_head *head)
{
 if (!list_empty(list))
  __list_splice(list, head, head->next);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_splice_tail(struct list_head *list,
    struct list_head *head)
{
 if (!list_empty(list))
  __list_splice(list, head->prev, head);
}
# 480 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_splice_init(struct list_head *list,
        struct list_head *head)
{
 if (!list_empty(list)) {
  __list_splice(list, head, head->next);
  INIT_LIST_HEAD(list);
 }
}
# 497 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_splice_tail_init(struct list_head *list,
      struct list_head *head)
{
 if (!list_empty(list)) {
  __list_splice(list, head->prev, head);
  INIT_LIST_HEAD(list);
 }
}
# 794 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void INIT_HLIST_NODE(struct hlist_node *h)
{
 h->next = ((void *)0);
 h->pprev = ((void *)0);
}
# 808 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int hlist_unhashed(const struct hlist_node *h)
{
 return !h->pprev;
}
# 821 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int hlist_unhashed_lockless(const struct hlist_node *h)
{
 return !({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_8(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(h->pprev) == sizeof(char) || sizeof(h->pprev) == sizeof(short) || sizeof(h->pprev) == sizeof(int) || sizeof(h->pprev) == sizeof(long)) || sizeof(h->pprev) == sizeof(long long))) __compiletime_assert_8(); } while (0); (*(const volatile typeof( _Generic((h->pprev), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (h->pprev))) *)&(h->pprev)); });
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int hlist_empty(const struct hlist_head *h)
{
 return !({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_9(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(h->first) == sizeof(char) || sizeof(h->first) == sizeof(short) || sizeof(h->first) == sizeof(int) || sizeof(h->first) == sizeof(long)) || sizeof(h->first) == sizeof(long long))) __compiletime_assert_9(); } while (0); (*(const volatile typeof( _Generic((h->first), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (h->first))) *)&(h->first)); });
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __hlist_del(struct hlist_node *n)
{
 struct hlist_node *next = n->next;
 struct hlist_node **pprev = n->pprev;

 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_10(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(*pprev) == sizeof(char) || sizeof(*pprev) == sizeof(short) || sizeof(*pprev) == sizeof(int) || sizeof(*pprev) == sizeof(long)) || sizeof(*pprev) == sizeof(long long))) __compiletime_assert_10(); } while (0); do { *(volatile typeof(*pprev) *)&(*pprev) = (next); } while (0); } while (0);
 if (next)
  do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_11(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(next->pprev) == sizeof(char) || sizeof(next->pprev) == sizeof(short) || sizeof(next->pprev) == sizeof(int) || sizeof(next->pprev) == sizeof(long)) || sizeof(next->pprev) == sizeof(long long))) __compiletime_assert_11(); } while (0); do { *(volatile typeof(next->pprev) *)&(next->pprev) = (pprev); } while (0); } while (0);
}
# 852 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_del(struct hlist_node *n)
{
 __hlist_del(n);
 n->next = ((void *) 0x100 + 0);
 n->pprev = ((void *) 0x122 + 0);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_del_init(struct hlist_node *n)
{
 if (!hlist_unhashed(n)) {
  __hlist_del(n);
  INIT_HLIST_NODE(n);
 }
}
# 881 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_add_head(struct hlist_node *n, struct hlist_head *h)
{
 struct hlist_node *first = h->first;
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_12(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(n->next) == sizeof(char) || sizeof(n->next) == sizeof(short) || sizeof(n->next) == sizeof(int) || sizeof(n->next) == sizeof(long)) || sizeof(n->next) == sizeof(long long))) __compiletime_assert_12(); } while (0); do { *(volatile typeof(n->next) *)&(n->next) = (first); } while (0); } while (0);
 if (first)
  do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_13(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(first->pprev) == sizeof(char) || sizeof(first->pprev) == sizeof(short) || sizeof(first->pprev) == sizeof(int) || sizeof(first->pprev) == sizeof(long)) || sizeof(first->pprev) == sizeof(long long))) __compiletime_assert_13(); } while (0); do { *(volatile typeof(first->pprev) *)&(first->pprev) = (&n->next); } while (0); } while (0);
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_14(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(h->first) == sizeof(char) || sizeof(h->first) == sizeof(short) || sizeof(h->first) == sizeof(int) || sizeof(h->first) == sizeof(long)) || sizeof(h->first) == sizeof(long long))) __compiletime_assert_14(); } while (0); do { *(volatile typeof(h->first) *)&(h->first) = (n); } while (0); } while (0);
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_15(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(n->pprev) == sizeof(char) || sizeof(n->pprev) == sizeof(short) || sizeof(n->pprev) == sizeof(int) || sizeof(n->pprev) == sizeof(long)) || sizeof(n->pprev) == sizeof(long long))) __compiletime_assert_15(); } while (0); do { *(volatile typeof(n->pprev) *)&(n->pprev) = (&h->first); } while (0); } while (0);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_add_before(struct hlist_node *n,
        struct hlist_node *next)
{
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_16(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(n->pprev) == sizeof(char) || sizeof(n->pprev) == sizeof(short) || sizeof(n->pprev) == sizeof(int) || sizeof(n->pprev) == sizeof(long)) || sizeof(n->pprev) == sizeof(long long))) __compiletime_assert_16(); } while (0); do { *(volatile typeof(n->pprev) *)&(n->pprev) = (next->pprev); } while (0); } while (0);
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_17(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(n->next) == sizeof(char) || sizeof(n->next) == sizeof(short) || sizeof(n->next) == sizeof(int) || sizeof(n->next) == sizeof(long)) || sizeof(n->next) == sizeof(long long))) __compiletime_assert_17(); } while (0); do { *(volatile typeof(n->next) *)&(n->next) = (next); } while (0); } while (0);
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_18(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(next->pprev) == sizeof(char) || sizeof(next->pprev) == sizeof(short) || sizeof(next->pprev) == sizeof(int) || sizeof(next->pprev) == sizeof(long)) || sizeof(next->pprev) == sizeof(long long))) __compiletime_assert_18(); } while (0); do { *(volatile typeof(next->pprev) *)&(next->pprev) = (&n->next); } while (0); } while (0);
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_19(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(*(n->pprev)) == sizeof(char) || sizeof(*(n->pprev)) == sizeof(short) || sizeof(*(n->pprev)) == sizeof(int) || sizeof(*(n->pprev)) == sizeof(long)) || sizeof(*(n->pprev)) == sizeof(long long))) __compiletime_assert_19(); } while (0); do { *(volatile typeof(*(n->pprev)) *)&(*(n->pprev)) = (n); } while (0); } while (0);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_add_behind(struct hlist_node *n,
        struct hlist_node *prev)
{
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_20(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(n->next) == sizeof(char) || sizeof(n->next) == sizeof(short) || sizeof(n->next) == sizeof(int) || sizeof(n->next) == sizeof(long)) || sizeof(n->next) == sizeof(long long))) __compiletime_assert_20(); } while (0); do { *(volatile typeof(n->next) *)&(n->next) = (prev->next); } while (0); } while (0);
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_21(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(prev->next) == sizeof(char) || sizeof(prev->next) == sizeof(short) || sizeof(prev->next) == sizeof(int) || sizeof(prev->next) == sizeof(long)) || sizeof(prev->next) == sizeof(long long))) __compiletime_assert_21(); } while (0); do { *(volatile typeof(prev->next) *)&(prev->next) = (n); } while (0); } while (0);
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_22(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(n->pprev) == sizeof(char) || sizeof(n->pprev) == sizeof(short) || sizeof(n->pprev) == sizeof(int) || sizeof(n->pprev) == sizeof(long)) || sizeof(n->pprev) == sizeof(long long))) __compiletime_assert_22(); } while (0); do { *(volatile typeof(n->pprev) *)&(n->pprev) = (&prev->next); } while (0); } while (0);

 if (n->next)
  do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_23(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(n->next->pprev) == sizeof(char) || sizeof(n->next->pprev) == sizeof(short) || sizeof(n->next->pprev) == sizeof(int) || sizeof(n->next->pprev) == sizeof(long)) || sizeof(n->next->pprev) == sizeof(long long))) __compiletime_assert_23(); } while (0); do { *(volatile typeof(n->next->pprev) *)&(n->next->pprev) = (&n->next); } while (0); } while (0);
}
# 929 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_add_fake(struct hlist_node *n)
{
 n->pprev = &n->next;
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool hlist_fake(struct hlist_node *h)
{
 return h->pprev == &h->next;
}
# 951 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool
hlist_is_singular_node(struct hlist_node *n, struct hlist_head *h)
{
 return !n->next && n->pprev == &h->first;
}
# 965 "./include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_move_list(struct hlist_head *old,
       struct hlist_head *new)
{
 new->first = old->first;
 if (new->first)
  new->first->pprev = &new->first;
 old->first = ((void *)0);
}
# 13 "./include/linux/smp.h" 2
# 1 "./include/linux/cpumask.h" 1
# 10 "./include/linux/cpumask.h"
# 1 "./include/linux/kernel.h" 1




# 1 "./include/linux/stdarg.h" 1




typedef __builtin_va_list va_list;
# 6 "./include/linux/kernel.h" 2
# 1 "./include/linux/align.h" 1
# 7 "./include/linux/kernel.h" 2







# 1 "./include/linux/kstrtox.h" 1








int __attribute__((__warn_unused_result__)) _kstrtoul(const char *s, unsigned int base, unsigned long *res);
int __attribute__((__warn_unused_result__)) _kstrtol(const char *s, unsigned int base, long *res);

int __attribute__((__warn_unused_result__)) kstrtoull(const char *s, unsigned int base, unsigned long long *res);
int __attribute__((__warn_unused_result__)) kstrtoll(const char *s, unsigned int base, long long *res);
# 30 "./include/linux/kstrtox.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtoul(const char *s, unsigned int base, unsigned long *res)
{




 if (sizeof(unsigned long) == sizeof(unsigned long long) &&
     __alignof__(unsigned long) == __alignof__(unsigned long long))
  return kstrtoull(s, base, (unsigned long long *)res);
 else
  return _kstrtoul(s, base, res);
}
# 58 "./include/linux/kstrtox.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtol(const char *s, unsigned int base, long *res)
{




 if (sizeof(long) == sizeof(long long) &&
     __alignof__(long) == __alignof__(long long))
  return kstrtoll(s, base, (long long *)res);
 else
  return _kstrtol(s, base, res);
}

int __attribute__((__warn_unused_result__)) kstrtouint(const char *s, unsigned int base, unsigned int *res);
int __attribute__((__warn_unused_result__)) kstrtoint(const char *s, unsigned int base, int *res);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtou64(const char *s, unsigned int base, u64 *res)
{
 return kstrtoull(s, base, res);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtos64(const char *s, unsigned int base, s64 *res)
{
 return kstrtoll(s, base, res);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtou32(const char *s, unsigned int base, u32 *res)
{
 return kstrtouint(s, base, res);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtos32(const char *s, unsigned int base, s32 *res)
{
 return kstrtoint(s, base, res);
}

int __attribute__((__warn_unused_result__)) kstrtou16(const char *s, unsigned int base, u16 *res);
int __attribute__((__warn_unused_result__)) kstrtos16(const char *s, unsigned int base, s16 *res);
int __attribute__((__warn_unused_result__)) kstrtou8(const char *s, unsigned int base, u8 *res);
int __attribute__((__warn_unused_result__)) kstrtos8(const char *s, unsigned int base, s8 *res);
int __attribute__((__warn_unused_result__)) kstrtobool(const char *s, bool *res);

int __attribute__((__warn_unused_result__)) kstrtoull_from_user(const char *s, size_t count, unsigned int base, unsigned long long *res);
int __attribute__((__warn_unused_result__)) kstrtoll_from_user(const char *s, size_t count, unsigned int base, long long *res);
int __attribute__((__warn_unused_result__)) kstrtoul_from_user(const char *s, size_t count, unsigned int base, unsigned long *res);
int __attribute__((__warn_unused_result__)) kstrtol_from_user(const char *s, size_t count, unsigned int base, long *res);
int __attribute__((__warn_unused_result__)) kstrtouint_from_user(const char *s, size_t count, unsigned int base, unsigned int *res);
int __attribute__((__warn_unused_result__)) kstrtoint_from_user(const char *s, size_t count, unsigned int base, int *res);
int __attribute__((__warn_unused_result__)) kstrtou16_from_user(const char *s, size_t count, unsigned int base, u16 *res);
int __attribute__((__warn_unused_result__)) kstrtos16_from_user(const char *s, size_t count, unsigned int base, s16 *res);
int __attribute__((__warn_unused_result__)) kstrtou8_from_user(const char *s, size_t count, unsigned int base, u8 *res);
int __attribute__((__warn_unused_result__)) kstrtos8_from_user(const char *s, size_t count, unsigned int base, s8 *res);
int __attribute__((__warn_unused_result__)) kstrtobool_from_user(const char *s, size_t count, bool *res);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtou64_from_user(const char *s, size_t count, unsigned int base, u64 *res)
{
 return kstrtoull_from_user(s, count, base, res);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtos64_from_user(const char *s, size_t count, unsigned int base, s64 *res)
{
 return kstrtoll_from_user(s, count, base, res);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtou32_from_user(const char *s, size_t count, unsigned int base, u32 *res)
{
 return kstrtouint_from_user(s, count, base, res);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtos32_from_user(const char *s, size_t count, unsigned int base, s32 *res)
{
 return kstrtoint_from_user(s, count, base, res);
}
# 145 "./include/linux/kstrtox.h"
extern unsigned long simple_strtoul(const char *,char **,unsigned int);
extern long simple_strtol(const char *,char **,unsigned int);
extern unsigned long long simple_strtoull(const char *,char **,unsigned int);
extern long long simple_strtoll(const char *,char **,unsigned int);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int strtobool(const char *s, bool *res)
{
 return kstrtobool(s, res);
}
# 15 "./include/linux/kernel.h" 2




# 1 "./include/linux/panic.h" 1







struct pt_regs;

extern long (*panic_blink)(int state);
__attribute__((__format__(printf, 1, 2)))
void panic(const char *fmt, ...) __attribute__((__noreturn__)) __attribute__((__cold__));
void nmi_panic(struct pt_regs *regs, const char *msg);
extern void oops_enter(void);
extern void oops_exit(void);
extern bool oops_may_print(void);


extern unsigned int sysctl_oops_all_cpu_backtrace;




extern int panic_timeout;
extern unsigned long panic_print;
extern int panic_on_oops;
extern int panic_on_unrecovered_nmi;
extern int panic_on_io_nmi;
extern int panic_on_warn;

extern unsigned long panic_on_taint;
extern bool panic_on_taint_nousertaint;

extern int sysctl_panic_on_rcu_stall;
extern int sysctl_max_rcu_stall_to_panic;
extern int sysctl_panic_on_stackoverflow;

extern bool crash_kexec_post_notifiers;






extern atomic_t panic_cpu;






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_arch_panic_timeout(int timeout, int arch_default_timeout)
{
 if (panic_timeout == arch_default_timeout)
  panic_timeout = timeout;
}
# 80 "./include/linux/panic.h"
struct taint_flag {
 char c_true;
 char c_false;
 bool module;
};

extern const struct taint_flag taint_flags[18];

enum lockdep_ok {
 LOCKDEP_STILL_OK,
 LOCKDEP_NOW_UNRELIABLE,
};

extern const char *print_tainted(void);
extern void add_taint(unsigned flag, enum lockdep_ok);
extern int test_taint(unsigned flag);
extern unsigned long get_taint(void);
# 20 "./include/linux/kernel.h" 2
# 1 "./include/linux/printk.h" 1





# 1 "./include/linux/init.h" 1
# 116 "./include/linux/init.h"
typedef int (*initcall_t)(void);
typedef void (*exitcall_t)(void);
# 127 "./include/linux/init.h"
typedef initcall_t initcall_entry_t;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) initcall_t initcall_from_entry(initcall_entry_t *entry)
{
 return *entry;
}


extern initcall_entry_t __con_initcall_start[], __con_initcall_end[];


typedef void (*ctor_fn_t)(void);

struct file_system_type;


extern int do_one_initcall(initcall_t fn);
extern char __attribute__((__section__(".init.data"))) boot_command_line[];
extern char *saved_command_line;
extern unsigned int reset_devices;


void setup_arch(char **);
void prepare_namespace(void);
void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) __attribute__((__no_sanitize__("cfi"))) init_rootfs(void);
extern struct file_system_type rootfs_fs_type;
# 161 "./include/linux/init.h"
extern void (*late_time_init)(void);

extern bool initcall_debug;
# 303 "./include/linux/init.h"
struct obs_kernel_param {
 const char *str;
 int (*setup_func)(char *);
 int early;
};
# 352 "./include/linux/init.h"
void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) __attribute__((__no_sanitize__("cfi"))) parse_early_param(void);
void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) __attribute__((__no_sanitize__("cfi"))) parse_early_options(char *cmdline);
# 7 "./include/linux/printk.h" 2
# 1 "./include/linux/kern_levels.h" 1
# 8 "./include/linux/printk.h" 2


# 1 "./include/linux/ratelimit_types.h" 1






# 1 "./include/linux/spinlock_types.h" 1
# 12 "./include/linux/spinlock_types.h"
# 1 "./include/linux/spinlock_types_raw.h" 1






# 1 "./arch/mips/include/asm/spinlock_types.h" 1




# 1 "./include/asm-generic/qspinlock_types.h" 1
# 14 "./include/asm-generic/qspinlock_types.h"
typedef struct qspinlock {
 union {
  atomic_t val;
# 33 "./include/asm-generic/qspinlock_types.h"
  struct {
   u16 tail;
   u16 locked_pending;
  };
  struct {
   u8 reserved[2];
   u8 pending;
   u8 locked;
  };

 };
} arch_spinlock_t;
# 6 "./arch/mips/include/asm/spinlock_types.h" 2
# 1 "./include/asm-generic/qrwlock_types.h" 1






# 1 "./arch/mips/include/asm/spinlock_types.h" 1
# 8 "./include/asm-generic/qrwlock_types.h" 2





typedef struct qrwlock {
 union {
  atomic_t cnts;
  struct {




   u8 __lstate[3];
   u8 wlocked;

  };
 };
 arch_spinlock_t wait_lock;
} arch_rwlock_t;
# 7 "./arch/mips/include/asm/spinlock_types.h" 2
# 8 "./include/linux/spinlock_types_raw.h" 2




# 1 "./include/linux/lockdep_types.h" 1
# 17 "./include/linux/lockdep_types.h"
enum lockdep_wait_type {
 LD_WAIT_INV = 0,

 LD_WAIT_FREE,
 LD_WAIT_SPIN,


 LD_WAIT_CONFIG,



 LD_WAIT_SLEEP,

 LD_WAIT_MAX,
};

enum lockdep_lock_type {
 LD_LOCK_NORMAL = 0,
 LD_LOCK_PERCPU,
 LD_LOCK_MAX,
};
# 69 "./include/linux/lockdep_types.h"
struct lockdep_subclass_key {
 char __one_byte;
} __attribute__ ((__packed__));


struct lock_class_key {
 union {
  struct hlist_node hash_entry;
  struct lockdep_subclass_key subkeys[8UL];
 };
};

extern struct lock_class_key __lockdep_no_validate__;

struct lock_trace;







struct lock_class {



 struct hlist_node hash_entry;






 struct list_head lock_entry;






 struct list_head locks_after, locks_before;

 const struct lockdep_subclass_key *key;
 unsigned int subclass;
 unsigned int dep_gen_id;




 unsigned long usage_mask;
 const struct lock_trace *usage_traces[(2*4 + 2)];





 int name_version;
 const char *name;

 u8 wait_type_inner;
 u8 wait_type_outer;
 u8 lock_type;



 unsigned long contention_point[4];
 unsigned long contending_point[4];

} ;


struct lock_time {
 s64 min;
 s64 max;
 s64 total;
 unsigned long nr;
};

enum bounce_type {
 bounce_acquired_write,
 bounce_acquired_read,
 bounce_contended_write,
 bounce_contended_read,
 nr_bounce_types,

 bounce_acquired = bounce_acquired_write,
 bounce_contended = bounce_contended_write,
};

struct lock_class_stats {
 unsigned long contention_point[4];
 unsigned long contending_point[4];
 struct lock_time read_waittime;
 struct lock_time write_waittime;
 struct lock_time read_holdtime;
 struct lock_time write_holdtime;
 unsigned long bounces[nr_bounce_types];
};

struct lock_class_stats lock_stats(struct lock_class *class);
void clear_lock_stats(struct lock_class *class);






struct lockdep_map {
 struct lock_class_key *key;
 struct lock_class *class_cache[2];
 const char *name;
 u8 wait_type_outer;
 u8 wait_type_inner;
 u8 lock_type;


 int cpu;
 unsigned long ip;

};

struct pin_cookie { unsigned int val; };
# 13 "./include/linux/spinlock_types_raw.h" 2

typedef struct raw_spinlock {
 arch_spinlock_t raw_lock;

 unsigned int magic, owner_cpu;
 void *owner;


 struct lockdep_map dep_map;

} raw_spinlock_t;
# 13 "./include/linux/spinlock_types.h" 2




typedef struct spinlock {
 union {
  struct raw_spinlock rlock;



  struct {
   u8 __padding[(__builtin_offsetof(struct raw_spinlock, dep_map))];
   struct lockdep_map dep_map;
  };

 };
} spinlock_t;
# 74 "./include/linux/spinlock_types.h"
# 1 "./include/linux/rwlock_types.h" 1
# 25 "./include/linux/rwlock_types.h"
typedef struct {
 arch_rwlock_t raw_lock;

 unsigned int magic, owner_cpu;
 void *owner;


 struct lockdep_map dep_map;

} rwlock_t;
# 75 "./include/linux/spinlock_types.h" 2
# 8 "./include/linux/ratelimit_types.h" 2







struct ratelimit_state {
 raw_spinlock_t lock;

 int interval;
 int burst;
 int printed;
 int missed;
 unsigned long begin;
 unsigned long flags;
};
# 40 "./include/linux/ratelimit_types.h"
extern int ___ratelimit(struct ratelimit_state *rs, const char *func);
# 11 "./include/linux/printk.h" 2
# 1 "./include/linux/once_lite.h" 1
# 12 "./include/linux/printk.h" 2

extern const char linux_banner[];
extern const char linux_proc_banner[];

extern int oops_in_progress;



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int printk_get_level(const char *buffer)
{
 if (buffer[0] == '\001' && buffer[1]) {
  switch (buffer[1]) {
  case '0' ... '7':
  case 'c':
   return buffer[1];
  }
 }
 return 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) const char *printk_skip_level(const char *buffer)
{
 if (printk_get_level(buffer))
  return buffer + 2;

 return buffer;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) const char *printk_skip_headers(const char *buffer)
{
 while (printk_get_level(buffer))
  buffer = printk_skip_level(buffer);

 return buffer;
}
# 66 "./include/linux/printk.h"
extern int console_printk[];






extern void console_verbose(void);



extern char devkmsg_log_str[];
struct ctl_table;

extern int suppress_printk;

struct va_format {
 const char *fmt;
 va_list *va;
};
# 140 "./include/linux/printk.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__format__(printf, 1, 2))) __attribute__((__cold__))
void early_printk(const char *s, ...) { }


struct dev_printk_info;


           __attribute__((__format__(printf, 4, 0)))
int vprintk_emit(int facility, int level,
   const struct dev_printk_info *dev_info,
   const char *fmt, va_list args);

           __attribute__((__format__(printf, 1, 0)))
int vprintk(const char *fmt, va_list args);

           __attribute__((__format__(printf, 1, 2))) __attribute__((__cold__))
int _printk(const char *fmt, ...);




__attribute__((__format__(printf, 1, 2))) __attribute__((__cold__)) int _printk_deferred(const char *fmt, ...);

extern void __printk_safe_enter(void);
extern void __printk_safe_exit(void);
# 178 "./include/linux/printk.h"
extern int __printk_ratelimit(const char *func);

extern bool printk_timed_ratelimit(unsigned long *caller_jiffies,
       unsigned int interval_msec);

extern int printk_delay_msec;
extern int dmesg_restrict;

extern int
devkmsg_sysctl_set_loglvl(struct ctl_table *table, int write, void *buf,
     size_t *lenp, loff_t *ppos);

extern void wake_up_klogd(void);

char *log_buf_addr_get(void);
u32 log_buf_len_get(void);
void log_buf_vmcoreinfo_setup(void);
void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) __attribute__((__no_sanitize__("cfi"))) setup_log_buf(int early);
__attribute__((__format__(printf, 1, 2))) void dump_stack_set_arch_desc(const char *fmt, ...);
void dump_stack_print_info(const char *log_lvl);
void show_regs_print_info(const char *log_lvl);
extern void dump_stack_lvl(const char *log_lvl) __attribute__((__cold__));
extern void dump_stack(void) __attribute__((__cold__));
void printk_trigger_flush(void);
# 284 "./include/linux/printk.h"
extern int __printk_cpu_trylock(void);
extern void __printk_wait_on_cpu_lock(void);
extern void __printk_cpu_unlock(void);
# 324 "./include/linux/printk.h"
extern int kptr_restrict;
# 343 "./include/linux/printk.h"
struct module;


struct pi_entry {
 const char *fmt;
 const char *func;
 const char *file;
 unsigned int line;
# 360 "./include/linux/printk.h"
 const char *level;
# 369 "./include/linux/printk.h"
 const char *subsys_fmt_prefix;
} __attribute__((__packed__));
# 559 "./include/linux/printk.h"
# 1 "./include/linux/dynamic_debug.h" 1





# 1 "./include/linux/jump_label.h" 1
# 79 "./include/linux/jump_label.h"
extern bool static_key_initialized;







struct static_key {
 atomic_t enabled;
# 102 "./include/linux/jump_label.h"
 union {
  unsigned long type;
  struct jump_entry *entries;
  struct static_key_mod *next;
 };
};
# 117 "./include/linux/jump_label.h"
# 1 "./arch/mips/include/asm/jump_label.h" 1
# 35 "./arch/mips/include/asm/jump_label.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool arch_static_branch(struct static_key *key, bool branch)
{
 asm goto("1:\t" "b" " 2f\n\t" "2:\t.insn\n\t" ".pushsection __jump_table,  \"aw\"\n\t" ".word" " 1b, %l[l_yes], %0\n\t" ".popsection\n\t" : : "i" (&((char *)key)[branch]) : : l_yes);






 return false;
l_yes:
 return true;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool arch_static_branch_jump(struct static_key *key, bool branch)
{
 asm goto("1:\t" "j" " %l[l_yes]\n\t" ".pushsection __jump_table,  \"aw\"\n\t" ".word" " 1b, %l[l_yes], %0\n\t" ".popsection\n\t" : : "i" (&((char *)key)[branch]) : : l_yes);





 return false;
l_yes:
 return true;
}




typedef u32 jump_label_t;


struct jump_entry {
 jump_label_t code;
 jump_label_t target;
 jump_label_t key;
};
# 118 "./include/linux/jump_label.h" 2
# 147 "./include/linux/jump_label.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long jump_entry_code(const struct jump_entry *entry)
{
 return entry->code;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long jump_entry_target(const struct jump_entry *entry)
{
 return entry->target;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct static_key *jump_entry_key(const struct jump_entry *entry)
{
 return (struct static_key *)((unsigned long)entry->key & ~3UL);
}



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool jump_entry_is_branch(const struct jump_entry *entry)
{
 return (unsigned long)entry->key & 1UL;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool jump_entry_is_init(const struct jump_entry *entry)
{
 return (unsigned long)entry->key & 2UL;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void jump_entry_set_init(struct jump_entry *entry, bool set)
{
 if (set)
  entry->key |= 2;
 else
  entry->key &= ~2;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int jump_entry_size(struct jump_entry *entry)
{

 return 4;



}






enum jump_label_type {
 JUMP_LABEL_NOP = 0,
 JUMP_LABEL_JMP,
};

struct module;
# 210 "./include/linux/jump_label.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool static_key_false(struct static_key *key)
{
 return arch_static_branch(key, false);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool static_key_true(struct static_key *key)
{
 return !arch_static_branch(key, true);
}

extern struct jump_entry __start___jump_table[];
extern struct jump_entry __stop___jump_table[];

extern void jump_label_init(void);
extern void jump_label_lock(void);
extern void jump_label_unlock(void);
extern void arch_jump_label_transform(struct jump_entry *entry,
          enum jump_label_type type);
extern void arch_jump_label_transform_static(struct jump_entry *entry,
          enum jump_label_type type);
extern bool arch_jump_label_transform_queue(struct jump_entry *entry,
         enum jump_label_type type);
extern void arch_jump_label_transform_apply(void);
extern int jump_label_text_reserved(void *start, void *end);
extern void static_key_slow_inc(struct static_key *key);
extern void static_key_slow_dec(struct static_key *key);
extern void static_key_slow_inc_cpuslocked(struct static_key *key);
extern void static_key_slow_dec_cpuslocked(struct static_key *key);
extern void jump_label_apply_nops(struct module *mod);
extern int static_key_count(struct static_key *key);
extern void static_key_enable(struct static_key *key);
extern void static_key_disable(struct static_key *key);
extern void static_key_enable_cpuslocked(struct static_key *key);
extern void static_key_disable_cpuslocked(struct static_key *key);
# 358 "./include/linux/jump_label.h"
struct static_key_true {
 struct static_key key;
};

struct static_key_false {
 struct static_key key;
};
# 412 "./include/linux/jump_label.h"
extern bool ____wrong_branch_error(void);
# 7 "./include/linux/dynamic_debug.h" 2







struct _ddebug {




 const char *modname;
 const char *function;
 const char *filename;
 const char *format;
 unsigned int lineno:18;
# 45 "./include/linux/dynamic_debug.h"
 unsigned int flags:8;

 union {
  struct static_key_true dd_key_true;
  struct static_key_false dd_key_false;
 } key;

} __attribute__((aligned(8)));






int dynamic_debug_exec_queries(const char *query, const char *modname);

int ddebug_add_module(struct _ddebug *tab, unsigned int n,
    const char *modname);
extern int ddebug_remove_module(const char *mod_name);
extern __attribute__((__format__(printf, 2, 3)))
void __dynamic_pr_debug(struct _ddebug *descriptor, const char *fmt, ...);

extern int ddebug_dyndbg_module_param_cb(char *param, char *val,
     const char *modname);

struct device;

extern __attribute__((__format__(printf, 3, 4)))
void __dynamic_dev_dbg(struct _ddebug *descriptor, const struct device *dev,
         const char *fmt, ...);

struct net_device;

extern __attribute__((__format__(printf, 3, 4)))
void __dynamic_netdev_dbg(struct _ddebug *descriptor,
     const struct net_device *dev,
     const char *fmt, ...);

struct ib_device;

extern __attribute__((__format__(printf, 3, 4)))
void __dynamic_ibdev_dbg(struct _ddebug *descriptor,
    const struct ib_device *ibdev,
    const char *fmt, ...);
# 560 "./include/linux/printk.h" 2
# 697 "./include/linux/printk.h"
extern const struct file_operations kmsg_fops;

enum {
 DUMP_PREFIX_NONE,
 DUMP_PREFIX_ADDRESS,
 DUMP_PREFIX_OFFSET
};
extern int hex_dump_to_buffer(const void *buf, size_t len, int rowsize,
         int groupsize, char *linebuf, size_t linebuflen,
         bool ascii);

extern void print_hex_dump(const char *level, const char *prefix_str,
      int prefix_type, int rowsize, int groupsize,
      const void *buf, size_t len, bool ascii);
# 21 "./include/linux/kernel.h" 2

# 1 "./include/linux/static_call_types.h" 1
# 32 "./include/linux/static_call_types.h"
struct static_call_site {
 s32 addr;
 s32 key;
};
# 94 "./include/linux/static_call_types.h"
struct static_call_key {
 void *func;
};
# 23 "./include/linux/kernel.h" 2
# 1 "./include/linux/instruction_pointer.h" 1
# 24 "./include/linux/kernel.h" 2
# 85 "./include/linux/kernel.h"
struct completion;
struct user;
# 111 "./include/linux/kernel.h"
extern void __might_resched(const char *file, int line, unsigned int offsets);
extern void __might_sleep(const char *file, int line);
extern void __cant_sleep(const char *file, int line, int preempt_offset);
extern void __cant_migrate(const char *file, int line);
# 184 "./include/linux/kernel.h"
void __might_fault(const char *file, int line);




void do_exit(long error_code) __attribute__((__noreturn__));
void complete_and_exit(struct completion *, long) __attribute__((__noreturn__));

extern int num_to_str(char *buf, int size,
        unsigned long long num, unsigned int width);



extern __attribute__((__format__(printf, 2, 3))) int sprintf(char *buf, const char * fmt, ...);
extern __attribute__((__format__(printf, 2, 0))) int vsprintf(char *buf, const char *, va_list);
extern __attribute__((__format__(printf, 3, 4)))
int snprintf(char *buf, size_t size, const char *fmt, ...);
extern __attribute__((__format__(printf, 3, 0)))
int vsnprintf(char *buf, size_t size, const char *fmt, va_list args);
extern __attribute__((__format__(printf, 3, 4)))
int scnprintf(char *buf, size_t size, const char *fmt, ...);
extern __attribute__((__format__(printf, 3, 0)))
int vscnprintf(char *buf, size_t size, const char *fmt, va_list args);
extern __attribute__((__format__(printf, 2, 3))) __attribute__((__malloc__))
char *kasprintf(gfp_t gfp, const char *fmt, ...);
extern __attribute__((__format__(printf, 2, 0))) __attribute__((__malloc__))
char *kvasprintf(gfp_t gfp, const char *fmt, va_list args);
extern __attribute__((__format__(printf, 2, 0)))
const char *kvasprintf_const(gfp_t gfp, const char *fmt, va_list args);

extern __attribute__((__format__(scanf, 2, 3)))
int sscanf(const char *, const char *, ...);
extern __attribute__((__format__(scanf, 2, 0)))
int vsscanf(const char *, const char *, va_list);

extern int no_hash_pointers_enable(char *str);

extern int get_option(char **str, int *pint);
extern char *get_options(const char *str, int nints, int *ints);
extern unsigned long long memparse(const char *ptr, char **retptr);
extern bool parse_option_str(const char *str, const char *option);
extern char *next_arg(char *args, char **param, char **val);

extern int core_kernel_text(unsigned long addr);
extern int __kernel_text_address(unsigned long addr);
extern int kernel_text_address(unsigned long addr);
extern int func_ptr_is_kernel_text(void *ptr);

extern void bust_spinlocks(int yes);

extern int root_mountflags;

extern bool early_boot_irqs_disabled;





extern enum system_states {
 SYSTEM_BOOTING,
 SYSTEM_SCHEDULING,
 SYSTEM_FREEING_INITMEM,
 SYSTEM_RUNNING,
 SYSTEM_HALT,
 SYSTEM_POWER_OFF,
 SYSTEM_RESTART,
 SYSTEM_SUSPEND,
} system_state;

extern const char hex_asc[];



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) char *hex_byte_pack(char *buf, u8 byte)
{
 *buf++ = hex_asc[((byte) & 0xf0) >> 4];
 *buf++ = hex_asc[((byte) & 0x0f)];
 return buf;
}

extern const char hex_asc_upper[];



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) char *hex_byte_pack_upper(char *buf, u8 byte)
{
 *buf++ = hex_asc_upper[((byte) & 0xf0) >> 4];
 *buf++ = hex_asc_upper[((byte) & 0x0f)];
 return buf;
}

extern int hex_to_bin(char ch);
extern int __attribute__((__warn_unused_result__)) hex2bin(u8 *dst, const char *src, size_t count);
extern char *bin2hex(char *dst, const void *src, size_t count);

bool mac_pton(const char *s, u8 *mac);
# 301 "./include/linux/kernel.h"
enum ftrace_dump_mode {
 DUMP_NONE,
 DUMP_ALL,
 DUMP_ORIG,
};


void tracing_on(void);
void tracing_off(void);
int tracing_is_on(void);
void tracing_snapshot(void);
void tracing_snapshot_alloc(void);

extern void tracing_start(void);
extern void tracing_stop(void);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__format__(printf, 1, 2)))
void ____trace_printk_check_format(const char *fmt, ...)
{
}
# 380 "./include/linux/kernel.h"
extern __attribute__((__format__(printf, 2, 3)))
int __trace_bprintk(unsigned long ip, const char *fmt, ...);

extern __attribute__((__format__(printf, 2, 3)))
int __trace_printk(unsigned long ip, const char *fmt, ...);
# 421 "./include/linux/kernel.h"
extern int __trace_bputs(unsigned long ip, const char *str);
extern int __trace_puts(unsigned long ip, const char *str, int size);

extern void trace_dump_stack(int skip);
# 443 "./include/linux/kernel.h"
extern __attribute__((__format__(printf, 2, 0))) int
__ftrace_vbprintk(unsigned long ip, const char *fmt, va_list ap);

extern __attribute__((__format__(printf, 2, 0))) int
__ftrace_vprintk(unsigned long ip, const char *fmt, va_list ap);

extern void ftrace_dump(enum ftrace_dump_mode oops_dump_mode);
# 11 "./include/linux/cpumask.h" 2
# 1 "./include/linux/threads.h" 1
# 12 "./include/linux/cpumask.h" 2
# 1 "./include/linux/bitmap.h" 1
# 10 "./include/linux/bitmap.h"
# 1 "./include/linux/string.h" 1
# 10 "./include/linux/string.h"
# 1 "./include/uapi/linux/string.h" 1
# 11 "./include/linux/string.h" 2

extern char *strndup_user(const char *, long);
extern void *memdup_user(const void *, size_t);
extern void *vmemdup_user(const void *, size_t);
extern void *memdup_user_nul(const void *, size_t);




# 1 "./arch/mips/include/asm/string.h" 1
# 14 "./arch/mips/include/asm/string.h"
extern void *memset(void *__s, int __c, size_t __count);


extern void *memcpy(void *__to, __const__ void *__from, size_t __n);


extern void *memmove(void *__dest, __const__ void *__src, size_t __n);
# 21 "./include/linux/string.h" 2


extern char * strcpy(char *,const char *);


extern char * strncpy(char *,const char *, __kernel_size_t);


size_t strlcpy(char *, const char *, size_t);


ssize_t strscpy(char *, const char *, size_t);



ssize_t strscpy_pad(char *dest, const char *src, size_t count);


extern char * strcat(char *, const char *);


extern char * strncat(char *, const char *, __kernel_size_t);


extern size_t strlcat(char *, const char *, __kernel_size_t);


extern int strcmp(const char *,const char *);


extern int strncmp(const char *,const char *,__kernel_size_t);


extern int strcasecmp(const char *s1, const char *s2);


extern int strncasecmp(const char *s1, const char *s2, size_t n);


extern char * strchr(const char *,int);


extern char * strchrnul(const char *,int);

extern char * strnchrnul(const char *, size_t, int);

extern char * strnchr(const char *, size_t, int);


extern char * strrchr(const char *,int);

extern char * __attribute__((__warn_unused_result__)) skip_spaces(const char *);

extern char *strim(char *);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__warn_unused_result__)) char *strstrip(char *str)
{
 return strim(str);
}


extern char * strstr(const char *, const char *);


extern char * strnstr(const char *, const char *, size_t);


extern __kernel_size_t strlen(const char *);


extern __kernel_size_t strnlen(const char *,__kernel_size_t);


extern char * strpbrk(const char *,const char *);


extern char * strsep(char **,const char *);


extern __kernel_size_t strspn(const char *,const char *);


extern __kernel_size_t strcspn(const char *,const char *);







extern void *memset16(uint16_t *, uint16_t, __kernel_size_t);



extern void *memset32(uint32_t *, uint32_t, __kernel_size_t);



extern void *memset64(uint64_t *, uint64_t, __kernel_size_t);


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *memset_l(unsigned long *p, unsigned long v,
  __kernel_size_t n)
{
 if (32 == 32)
  return memset32((uint32_t *)p, v, n);
 else
  return memset64((uint64_t *)p, v, n);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *memset_p(void **p, void *v, __kernel_size_t n)
{
 if (32 == 32)
  return memset32((uint32_t *)p, (uintptr_t)v, n);
 else
  return memset64((uint64_t *)p, (uintptr_t)v, n);
}

extern void **__memcat_p(void **a, void **b);
# 153 "./include/linux/string.h"
extern void * memscan(void *,int,__kernel_size_t);


extern int memcmp(const void *,const void *,__kernel_size_t);


extern int bcmp(const void *,const void *,__kernel_size_t);


extern void * memchr(const void *,int,__kernel_size_t);


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void memcpy_flushcache(void *dst, const void *src, size_t cnt)
{
 memcpy(dst, src, cnt);
}


void *memchr_inv(const void *s, int c, size_t n);
char *strreplace(char *s, char old, char new);

extern void kfree_const(const void *x);

extern char *kstrdup(const char *s, gfp_t gfp) __attribute__((__malloc__));
extern const char *kstrdup_const(const char *s, gfp_t gfp);
extern char *kstrndup(const char *s, size_t len, gfp_t gfp);
extern void *kmemdup(const void *src, size_t len, gfp_t gfp);
extern char *kmemdup_nul(const char *s, size_t len, gfp_t gfp);

extern char **argv_split(gfp_t gfp, const char *str, int *argcp);
extern void argv_free(char **argv);

extern bool sysfs_streq(const char *s1, const char *s2);
int match_string(const char * const *array, size_t n, const char *string);
int __sysfs_match_string(const char * const *array, size_t n, const char *s);
# 199 "./include/linux/string.h"
int vbin_printf(u32 *bin_buf, size_t size, const char *fmt, va_list args);
int bstr_printf(char *buf, size_t size, const char *fmt, const u32 *bin_buf);
int bprintf(u32 *bin_buf, size_t size, const char *fmt, ...) __attribute__((__format__(printf, 3, 4)));


extern ssize_t memory_read_from_buffer(void *to, size_t count, loff_t *ppos,
           const void *from, size_t available);

int ptr_to_hashval(const void *ptr, unsigned long *hashval_out);






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool strstarts(const char *str, const char *prefix)
{
 return strncmp(str, prefix, strlen(prefix)) == 0;
}

size_t memweight(const void *ptr, size_t bytes);
# 235 "./include/linux/string.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void memzero_explicit(void *s, size_t count)
{
 memset(s, 0, count);
 __asm__ __volatile__("": :"r"(s) :"memory");
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) const char *kbasename(const char *path)
{
 const char *tail = strrchr(path, '/');
 return tail ? tail + 1 : path;
}





void memcpy_and_pad(void *dest, size_t dest_len, const void *src, size_t count,
      int pad);
# 309 "./include/linux/string.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) size_t str_has_prefix(const char *str, const char *prefix)
{
 size_t len = strlen(prefix);
 return strncmp(str, prefix, len) == 0 ? len : 0;
}
# 11 "./include/linux/bitmap.h" 2


struct device;
# 124 "./include/linux/bitmap.h"
unsigned long *bitmap_alloc(unsigned int nbits, gfp_t flags);
unsigned long *bitmap_zalloc(unsigned int nbits, gfp_t flags);
unsigned long *bitmap_alloc_node(unsigned int nbits, gfp_t flags, int node);
unsigned long *bitmap_zalloc_node(unsigned int nbits, gfp_t flags, int node);
void bitmap_free(const unsigned long *bitmap);


unsigned long *devm_bitmap_alloc(struct device *dev,
     unsigned int nbits, gfp_t flags);
unsigned long *devm_bitmap_zalloc(struct device *dev,
      unsigned int nbits, gfp_t flags);





int __bitmap_equal(const unsigned long *bitmap1,
     const unsigned long *bitmap2, unsigned int nbits);
bool __attribute__((__pure__)) __bitmap_or_equal(const unsigned long *src1,
         const unsigned long *src2,
         const unsigned long *src3,
         unsigned int nbits);
void __bitmap_complement(unsigned long *dst, const unsigned long *src,
    unsigned int nbits);
void __bitmap_shift_right(unsigned long *dst, const unsigned long *src,
     unsigned int shift, unsigned int nbits);
void __bitmap_shift_left(unsigned long *dst, const unsigned long *src,
    unsigned int shift, unsigned int nbits);
void bitmap_cut(unsigned long *dst, const unsigned long *src,
  unsigned int first, unsigned int cut, unsigned int nbits);
int __bitmap_and(unsigned long *dst, const unsigned long *bitmap1,
   const unsigned long *bitmap2, unsigned int nbits);
void __bitmap_or(unsigned long *dst, const unsigned long *bitmap1,
   const unsigned long *bitmap2, unsigned int nbits);
void __bitmap_xor(unsigned long *dst, const unsigned long *bitmap1,
    const unsigned long *bitmap2, unsigned int nbits);
int __bitmap_andnot(unsigned long *dst, const unsigned long *bitmap1,
      const unsigned long *bitmap2, unsigned int nbits);
void __bitmap_replace(unsigned long *dst,
        const unsigned long *old, const unsigned long *new,
        const unsigned long *mask, unsigned int nbits);
int __bitmap_intersects(const unsigned long *bitmap1,
   const unsigned long *bitmap2, unsigned int nbits);
int __bitmap_subset(const unsigned long *bitmap1,
      const unsigned long *bitmap2, unsigned int nbits);
int __bitmap_weight(const unsigned long *bitmap, unsigned int nbits);
void __bitmap_set(unsigned long *map, unsigned int start, int len);
void __bitmap_clear(unsigned long *map, unsigned int start, int len);

unsigned long bitmap_find_next_zero_area_off(unsigned long *map,
          unsigned long size,
          unsigned long start,
          unsigned int nr,
          unsigned long align_mask,
          unsigned long align_offset);
# 192 "./include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long
bitmap_find_next_zero_area(unsigned long *map,
      unsigned long size,
      unsigned long start,
      unsigned int nr,
      unsigned long align_mask)
{
 return bitmap_find_next_zero_area_off(map, size, start, nr,
           align_mask, 0);
}

int bitmap_parse(const char *buf, unsigned int buflen,
   unsigned long *dst, int nbits);
int bitmap_parse_user(const char *ubuf, unsigned int ulen,
   unsigned long *dst, int nbits);
int bitmap_parselist(const char *buf, unsigned long *maskp,
   int nmaskbits);
int bitmap_parselist_user(const char *ubuf, unsigned int ulen,
   unsigned long *dst, int nbits);
void bitmap_remap(unsigned long *dst, const unsigned long *src,
  const unsigned long *old, const unsigned long *new, unsigned int nbits);
int bitmap_bitremap(int oldbit,
  const unsigned long *old, const unsigned long *new, int bits);
void bitmap_onto(unsigned long *dst, const unsigned long *orig,
  const unsigned long *relmap, unsigned int bits);
void bitmap_fold(unsigned long *dst, const unsigned long *orig,
  unsigned int sz, unsigned int nbits);
int bitmap_find_free_region(unsigned long *bitmap, unsigned int bits, int order);
void bitmap_release_region(unsigned long *bitmap, unsigned int pos, int order);
int bitmap_allocate_region(unsigned long *bitmap, unsigned int pos, int order);


void bitmap_copy_le(unsigned long *dst, const unsigned long *src, unsigned int nbits);



unsigned int bitmap_ord_to_pos(const unsigned long *bitmap, unsigned int ord, unsigned int nbits);
int bitmap_print_to_pagebuf(bool list, char *buf,
       const unsigned long *maskp, int nmaskbits);

extern int bitmap_print_bitmask_to_buf(char *buf, const unsigned long *maskp,
          int nmaskbits, loff_t off, size_t count);

extern int bitmap_print_list_to_buf(char *buf, const unsigned long *maskp,
          int nmaskbits, loff_t off, size_t count);




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_zero(unsigned long *dst, unsigned int nbits)
{
 unsigned int len = (((nbits) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8))) * sizeof(unsigned long);
 memset(dst, 0, len);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_fill(unsigned long *dst, unsigned int nbits)
{
 unsigned int len = (((nbits) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8))) * sizeof(unsigned long);
 memset(dst, 0xff, len);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_copy(unsigned long *dst, const unsigned long *src,
   unsigned int nbits)
{
 unsigned int len = (((nbits) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8))) * sizeof(unsigned long);
 memcpy(dst, src, len);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_copy_clear_tail(unsigned long *dst,
  const unsigned long *src, unsigned int nbits)
{
 bitmap_copy(dst, src, nbits);
 if (nbits % 32)
  dst[nbits / 32] &= (~0UL >> (-(nbits) & (32 - 1)));
}
# 289 "./include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int bitmap_and(unsigned long *dst, const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return (*dst = *src1 & *src2 & (~0UL >> (-(nbits) & (32 - 1)))) != 0;
 return __bitmap_and(dst, src1, src2, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_or(unsigned long *dst, const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  *dst = *src1 | *src2;
 else
  __bitmap_or(dst, src1, src2, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_xor(unsigned long *dst, const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  *dst = *src1 ^ *src2;
 else
  __bitmap_xor(dst, src1, src2, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int bitmap_andnot(unsigned long *dst, const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return (*dst = *src1 & ~(*src2) & (~0UL >> (-(nbits) & (32 - 1)))) != 0;
 return __bitmap_andnot(dst, src1, src2, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_complement(unsigned long *dst, const unsigned long *src,
   unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  *dst = ~(*src);
 else
  __bitmap_complement(dst, src, nbits);
}
# 339 "./include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int bitmap_equal(const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return !((*src1 ^ *src2) & (~0UL >> (-(nbits) & (32 - 1))));
 if (__builtin_constant_p(nbits & ((8 * sizeof(unsigned long)) - 1)) &&
     (((nbits) & ((typeof(nbits))((8 * sizeof(unsigned long))) - 1)) == 0))
  return !memcmp(src1, src2, nbits / 8);
 return __bitmap_equal(src1, src2, nbits);
}
# 359 "./include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool bitmap_or_equal(const unsigned long *src1,
       const unsigned long *src2,
       const unsigned long *src3,
       unsigned int nbits)
{
 if (!(__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return __bitmap_or_equal(src1, src2, src3, nbits);

 return !(((*src1 | *src2) ^ *src3) & (~0UL >> (-(nbits) & (32 - 1))));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int bitmap_intersects(const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return ((*src1 & *src2) & (~0UL >> (-(nbits) & (32 - 1)))) != 0;
 else
  return __bitmap_intersects(src1, src2, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int bitmap_subset(const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return ! ((*src1 & ~(*src2)) & (~0UL >> (-(nbits) & (32 - 1))));
 else
  return __bitmap_subset(src1, src2, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool bitmap_empty(const unsigned long *src, unsigned nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return ! (*src & (~0UL >> (-(nbits) & (32 - 1))));

 return find_first_bit(src, nbits) == nbits;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool bitmap_full(const unsigned long *src, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return ! (~(*src) & (~0UL >> (-(nbits) & (32 - 1))));

 return find_first_zero_bit(src, nbits) == nbits;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int bitmap_weight(const unsigned long *src, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return hweight_long(*src & (~0UL >> (-(nbits) & (32 - 1))));
 return __bitmap_weight(src, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void bitmap_set(unsigned long *map, unsigned int start,
  unsigned int nbits)
{
 if (__builtin_constant_p(nbits) && nbits == 1)
  arch___set_bit(start, map);
 else if (__builtin_constant_p(start & ((8 * sizeof(unsigned long)) - 1)) &&
   (((start) & ((typeof(start))((8 * sizeof(unsigned long))) - 1)) == 0) &&
   __builtin_constant_p(nbits & ((8 * sizeof(unsigned long)) - 1)) &&
   (((nbits) & ((typeof(nbits))((8 * sizeof(unsigned long))) - 1)) == 0))
  memset((char *)map + start / 8, 0xff, nbits / 8);
 else
  __bitmap_set(map, start, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void bitmap_clear(unsigned long *map, unsigned int start,
  unsigned int nbits)
{
 if (__builtin_constant_p(nbits) && nbits == 1)
  arch___clear_bit(start, map);
 else if (__builtin_constant_p(start & ((8 * sizeof(unsigned long)) - 1)) &&
   (((start) & ((typeof(start))((8 * sizeof(unsigned long))) - 1)) == 0) &&
   __builtin_constant_p(nbits & ((8 * sizeof(unsigned long)) - 1)) &&
   (((nbits) & ((typeof(nbits))((8 * sizeof(unsigned long))) - 1)) == 0))
  memset((char *)map + start / 8, 0, nbits / 8);
 else
  __bitmap_clear(map, start, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_shift_right(unsigned long *dst, const unsigned long *src,
    unsigned int shift, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  *dst = (*src & (~0UL >> (-(nbits) & (32 - 1)))) >> shift;
 else
  __bitmap_shift_right(dst, src, shift, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_shift_left(unsigned long *dst, const unsigned long *src,
    unsigned int shift, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  *dst = (*src << shift) & (~0UL >> (-(nbits) & (32 - 1)));
 else
  __bitmap_shift_left(dst, src, shift, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_replace(unsigned long *dst,
      const unsigned long *old,
      const unsigned long *new,
      const unsigned long *mask,
      unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  *dst = (*old & ~(*mask)) | (*new & *mask);
 else
  __bitmap_replace(dst, old, new, mask, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_next_clear_region(unsigned long *bitmap,
         unsigned int *rs, unsigned int *re,
         unsigned int end)
{
 *rs = find_next_zero_bit(bitmap, end, *rs);
 *re = find_next_bit(bitmap, end, *rs + 1);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_next_set_region(unsigned long *bitmap,
       unsigned int *rs, unsigned int *re,
       unsigned int end)
{
 *rs = find_next_bit(bitmap, end, *rs);
 *re = find_next_zero_bit(bitmap, end, *rs + 1);
}
# 547 "./include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_from_u64(unsigned long *dst, u64 mask)
{
 dst[0] = mask & (~0UL);

 if (sizeof(mask) > sizeof(unsigned long))
  dst[1] = mask >> 32;
}
# 563 "./include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long bitmap_get_value8(const unsigned long *map,
           unsigned long start)
{
 const size_t index = ((start) / 32);
 const unsigned long offset = start % 32;

 return (map[index] >> offset) & 0xFF;
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_set_value8(unsigned long *map, unsigned long value,
         unsigned long start)
{
 const size_t index = ((start) / 32);
 const unsigned long offset = start % 32;

 map[index] &= ~(0xFFUL << offset);
 map[index] |= value << offset;
}
# 13 "./include/linux/cpumask.h" 2
# 1 "./include/linux/atomic.h" 1






# 1 "./arch/mips/include/asm/atomic.h" 1
# 17 "./arch/mips/include/asm/atomic.h"
# 1 "./include/linux/irqflags.h" 1
# 16 "./include/linux/irqflags.h"
# 1 "./arch/mips/include/asm/irqflags.h" 1
# 94 "./arch/mips/include/asm/irqflags.h"
void arch_local_irq_disable(void);
unsigned long arch_local_irq_save(void);
void arch_local_irq_restore(unsigned long flags);


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_local_irq_enable(void)
{
 __asm__ __volatile__(
 "	.set	push						\n"
 "	.set	reorder						\n"
 "	.set	noat						\n"



 "	mfc0	$1,$12						\n"
 "	ori	$1,0x1f						\n"
 "	xori	$1,0x1e						\n"
 "	mtc0	$1,$12						\n"

 "	" "sll $0, $0, 1; sll $0, $0, 1; sll $0, $0, 1; sll $0, $0, 3" "			\n"
 "	.set	pop						\n"
 :
 :
 : "memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long arch_local_save_flags(void)
{
 unsigned long flags;

 asm __volatile__(
 "	.set	push						\n"
 "	.set	reorder						\n"
 "	mfc0	%[flags], $12					\n"
 "	.set	pop						\n"
 : [flags] "=r" (flags));

 return flags;
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_irqs_disabled_flags(unsigned long flags)
{
 return !(flags & 1);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_irqs_disabled(void)
{
 return arch_irqs_disabled_flags(arch_local_save_flags());
}
# 17 "./include/linux/irqflags.h" 2
# 1 "./arch/mips/include/generated/asm/percpu.h" 1
# 1 "./include/asm-generic/percpu.h" 1






# 1 "./include/linux/percpu-defs.h" 1
# 308 "./include/linux/percpu-defs.h"
extern void __bad_size_call_parameter(void);




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __this_cpu_preempt_check(const char *op) { }
# 8 "./include/asm-generic/percpu.h" 2
# 19 "./include/asm-generic/percpu.h"
extern unsigned long __per_cpu_offset[2];
# 2 "./arch/mips/include/generated/asm/percpu.h" 2
# 18 "./include/linux/irqflags.h" 2



  extern void lockdep_softirqs_on(unsigned long ip);
  extern void lockdep_softirqs_off(unsigned long ip);
  extern void lockdep_hardirqs_on_prepare(unsigned long ip);
  extern void lockdep_hardirqs_on(unsigned long ip);
  extern void lockdep_hardirqs_off(unsigned long ip);
# 37 "./include/linux/irqflags.h"
struct irqtrace_events {
 unsigned int irq_events;
 unsigned long hardirq_enable_ip;
 unsigned long hardirq_disable_ip;
 unsigned int hardirq_enable_event;
 unsigned int hardirq_disable_event;
 unsigned long softirq_disable_ip;
 unsigned long softirq_enable_ip;
 unsigned int softirq_disable_event;
 unsigned int softirq_enable_event;
};

extern __attribute__((__section__(".discard"))) __attribute__((unused)) char __pcpu_scope_hardirqs_enabled; extern __attribute__((section(".data..percpu" ""))) __typeof__(int) hardirqs_enabled;
extern __attribute__((__section__(".discard"))) __attribute__((unused)) char __pcpu_scope_hardirq_context; extern __attribute__((section(".data..percpu" ""))) __typeof__(int) hardirq_context;

extern void trace_hardirqs_on_prepare(void);
extern void trace_hardirqs_off_finish(void);
extern void trace_hardirqs_on(void);
extern void trace_hardirqs_off(void);
# 145 "./include/linux/irqflags.h"
 extern void stop_critical_timings(void);
 extern void start_critical_timings(void);






extern void warn_bogus_irq_restore(void);
# 18 "./arch/mips/include/asm/atomic.h" 2




# 1 "./arch/mips/include/asm/cmpxchg.h" 1
# 11 "./arch/mips/include/asm/cmpxchg.h"
# 1 "./include/linux/bug.h" 1




# 1 "./arch/mips/include/asm/bug.h" 1
# 10 "./arch/mips/include/asm/bug.h"
# 1 "./arch/mips/include/asm/break.h" 1
# 15 "./arch/mips/include/asm/break.h"
# 1 "./arch/mips/include/uapi/asm/break.h" 1
# 16 "./arch/mips/include/asm/break.h" 2
# 11 "./arch/mips/include/asm/bug.h" 2

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __attribute__((__noreturn__)) BUG(void)
{
 __asm__ __volatile__("break %0" : : "i" (12));
 do { ; __builtin_unreachable(); } while (0);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __BUG_ON(unsigned long condition)
{
 if (__builtin_constant_p(condition)) {
  if (condition)
   BUG();
  else
   return;
 }
 __asm__ __volatile__("tne $0, %0, %1"
        : : "r" (condition), "i" (12));
}
# 42 "./arch/mips/include/asm/bug.h"
# 1 "./include/asm-generic/bug.h" 1





# 1 "./include/linux/instrumentation.h" 1
# 7 "./include/asm-generic/bug.h" 2
# 85 "./include/asm-generic/bug.h"
extern __attribute__((__format__(printf, 4, 5)))
void warn_slowpath_fmt(const char *file, const int line, unsigned taint,
         const char *fmt, ...);
# 113 "./include/asm-generic/bug.h"
struct warn_args;
struct pt_regs;

void __warn(const char *file, int line, void *caller, unsigned taint,
     struct pt_regs *regs, struct warn_args *args);
# 43 "./arch/mips/include/asm/bug.h" 2
# 6 "./include/linux/bug.h" 2



enum bug_trap_type {
 BUG_TRAP_TYPE_NONE = 0,
 BUG_TRAP_TYPE_WARN = 1,
 BUG_TRAP_TYPE_BUG = 2,
};

struct pt_regs;
# 53 "./include/linux/bug.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *find_bug(unsigned long bugaddr)
{
 return ((void *)0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) enum bug_trap_type report_bug(unsigned long bug_addr,
         struct pt_regs *regs)
{
 return BUG_TRAP_TYPE_BUG;
}

struct bug_entry;
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bug_get_file_line(struct bug_entry *bug, const char **file,
         unsigned int *line)
{
 *file = ((void *)0);
 *line = 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void generic_bug_clear_once(void) {}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__warn_unused_result__)) bool check_data_corruption(bool v) { return v; }
# 12 "./arch/mips/include/asm/cmpxchg.h" 2
# 28 "./arch/mips/include/asm/cmpxchg.h"
extern unsigned long __cmpxchg_called_with_bad_pointer(void)
 __attribute__((__error__("Bad argument size for cmpxchg")));
extern unsigned long __cmpxchg64_unsupported(void)
 __attribute__((__error__("cmpxchg64 not available; cpu_has_64bits may be false")));
extern unsigned long __xchg_called_with_bad_pointer(void)
 __attribute__((__error__("Bad argument size for xchg")));
# 68 "./arch/mips/include/asm/cmpxchg.h"
extern unsigned long __xchg_small(volatile void *ptr, unsigned long val,
      unsigned int size);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__))
unsigned long __xchg(volatile void *ptr, unsigned long x, int size)
{
 switch (size) {
 case 1:
 case 2:
  return __xchg_small(ptr, x, size);

 case 4:
  return ({ __typeof(*((volatile u32 *)ptr)) __ret; if (((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { __asm__ __volatile__( "	.set	push				\n" "	.set	noat				\n" "	.set	push				\n" "	.set	" "arch=r4000" "		\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll" "	%0, %2		# __xchg_asm	\n" "	.set	pop				\n" "	move	$1, %z3				\n" "	.set	" "arch=r4000" "		\n" "	" "sc" "	$1, %1				\n" "\t" "beqz	" "$1, 1b				\n" "	.set	pop				\n" : "=&r" (__ret), "=" "ZC" (*(volatile u32 *)ptr) : "ZC" (*(volatile u32 *)ptr), "Jr" (x) : "memory"); } else { unsigned long __flags; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); __ret = *(volatile u32 *)ptr; *(volatile u32 *)ptr = x; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } __ret; });

 case 8:
  if (!0)
   return __xchg_called_with_bad_pointer();

  return ({ __typeof(*((volatile u64 *)ptr)) __ret; if (((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { __asm__ __volatile__( "	.set	push				\n" "	.set	noat				\n" "	.set	push				\n" "	.set	" "arch=r4000" "		\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "lld" "	%0, %2		# __xchg_asm	\n" "	.set	pop				\n" "	move	$1, %z3				\n" "	.set	" "arch=r4000" "		\n" "	" "scd" "	$1, %1				\n" "\t" "beqz	" "$1, 1b				\n" "	.set	pop				\n" : "=&r" (__ret), "=" "ZC" (*(volatile u64 *)ptr) : "ZC" (*(volatile u64 *)ptr), "Jr" (x) : "memory"); } else { unsigned long __flags; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); __ret = *(volatile u64 *)ptr; *(volatile u64 *)ptr = x; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } __ret; });

 default:
  return __xchg_called_with_bad_pointer();
 }
}
# 149 "./arch/mips/include/asm/cmpxchg.h"
extern unsigned long __cmpxchg_small(volatile void *ptr, unsigned long old,
         unsigned long new, unsigned int size);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__))
unsigned long __cmpxchg(volatile void *ptr, unsigned long old,
   unsigned long new, unsigned int size)
{
 switch (size) {
 case 1:
 case 2:
  return __cmpxchg_small(ptr, old, new, size);

 case 4:
  return ({ __typeof(*((volatile u32 *)ptr)) __ret; if (((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { __asm__ __volatile__( "	.set	push				\n" "	.set	noat				\n" "	.set	push				\n" "	.set	""arch=r4000""		\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll" "	%0, %2		# __cmpxchg_asm \n" "	bne	%0, %z3, 2f			\n" "	.set	pop				\n" "	move	$1, %z4				\n" "	.set	""arch=r4000""		\n" "	" "sc" "	$1, %1				\n" "\t" "beqz	" "$1, 1b				\n" "	.set	pop				\n" "2:	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" : "=&r" (__ret), "=" "ZC" (*(volatile u32 *)ptr) : "ZC" (*(volatile u32 *)ptr), "Jr" ((u32)old), "Jr" (new) : "memory"); } else { unsigned long __flags; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); __ret = *(volatile u32 *)ptr; if (__ret == (u32)old) *(volatile u32 *)ptr = new; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } __ret; });


 case 8:

  if (!0)
   return __cmpxchg_called_with_bad_pointer();

  return ({ __typeof(*((volatile u64 *)ptr)) __ret; if (((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { __asm__ __volatile__( "	.set	push				\n" "	.set	noat				\n" "	.set	push				\n" "	.set	""arch=r4000""		\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "lld" "	%0, %2		# __cmpxchg_asm \n" "	bne	%0, %z3, 2f			\n" "	.set	pop				\n" "	move	$1, %z4				\n" "	.set	""arch=r4000""		\n" "	" "scd" "	$1, %1				\n" "\t" "beqz	" "$1, 1b				\n" "	.set	pop				\n" "2:	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" : "=&r" (__ret), "=" "ZC" (*(volatile u64 *)ptr) : "ZC" (*(volatile u64 *)ptr), "Jr" ((u64)old), "Jr" (new) : "memory"); } else { unsigned long __flags; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); __ret = *(volatile u64 *)ptr; if (__ret == (u64)old) *(volatile u64 *)ptr = new; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } __ret; });


 default:
  return __cmpxchg_called_with_bad_pointer();
 }
}
# 224 "./arch/mips/include/asm/cmpxchg.h"
# 1 "./include/asm-generic/cmpxchg-local.h" 1







extern unsigned long wrong_size_cmpxchg(volatile void *ptr)
 __attribute__((__noreturn__));





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __generic_cmpxchg_local(volatile void *ptr,
  unsigned long old, unsigned long new, int size)
{
 unsigned long flags, prev;




 if (size == 8 && sizeof(unsigned long) != 8)
  wrong_size_cmpxchg(ptr);

 do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0);
 switch (size) {
 case 1: prev = *(u8 *)ptr;
  if (prev == old)
   *(u8 *)ptr = (u8)new;
  break;
 case 2: prev = *(u16 *)ptr;
  if (prev == old)
   *(u16 *)ptr = (u16)new;
  break;
 case 4: prev = *(u32 *)ptr;
  if (prev == old)
   *(u32 *)ptr = (u32)new;
  break;
 case 8: prev = *(u64 *)ptr;
  if (prev == old)
   *(u64 *)ptr = (u64)new;
  break;
 default:
  wrong_size_cmpxchg(ptr);
 }
 do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0);
 return prev;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 __generic_cmpxchg64_local(volatile void *ptr,
  u64 old, u64 new)
{
 u64 prev;
 unsigned long flags;

 do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0);
 prev = *(u64 *)ptr;
 if (prev == old)
  *(u64 *)ptr = new;
 do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0);
 return prev;
}
# 225 "./arch/mips/include/asm/cmpxchg.h" 2




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __cmpxchg64(volatile void *ptr,
     unsigned long long old,
     unsigned long long new)
{
 unsigned long long tmp, ret;
 unsigned long flags;
# 244 "./arch/mips/include/asm/cmpxchg.h"
 do { do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(flags); })) trace_hardirqs_off(); } while (0);

 asm volatile(
 "	.set	push				\n"
 "	.set	" "arch=r4000" "		\n"

 "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n"
 "1:	lld	%L0, %3		# __cmpxchg64	\n"
 "	.set	pop				\n"




 "	dsra	%M0, %L0, 32			\n"
 "	sll	%L0, %L0, 0			\n"




 "	bne	%M0, %M4, 2f			\n"
 "	bne	%L0, %L4, 2f			\n"
# 273 "./arch/mips/include/asm/cmpxchg.h"
 "	dsll	%L1, %L5, 32			\n"
 "	dsrl	%L1, %L1, 32			\n"
 "	.set	noat				\n"
 "	dsll	$at, %M5, 32			\n"
 "	or	%L1, %L1, $at			\n"
 "	.set	at				\n"

 "	.set	push				\n"
 "	.set	" "arch=r4000" "		\n"

 "	scd	%L1, %2				\n"

 "\t" "beqz	" "%L1, 1b				\n"
 "2:	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n"
 "	.set	pop				\n"
 : "=&r"(ret),
   "=&r"(tmp),
   "=" "ZC" (*(unsigned long long *)ptr)
 : "ZC" (*(unsigned long long *)ptr),
   "r" (old),
   "r" (new)
 : "memory");

 do { if (!({ ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); } while (0);
 return ret;
}
# 23 "./arch/mips/include/asm/atomic.h" 2
# 49 "./arch/mips/include/asm/atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int arch_atomic_read(const atomic_t *v) { return ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_24(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(v->counter) == sizeof(char) || sizeof(v->counter) == sizeof(short) || sizeof(v->counter) == sizeof(int) || sizeof(v->counter) == sizeof(long)) || sizeof(v->counter) == sizeof(long long))) __compiletime_assert_24(); } while (0); (*(const volatile typeof( _Generic((v->counter), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (v->counter))) *)&(v->counter)); }); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void arch_atomic_set(atomic_t *v, int i) { do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_25(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(v->counter) == sizeof(char) || sizeof(v->counter) == sizeof(short) || sizeof(v->counter) == sizeof(int) || sizeof(v->counter) == sizeof(long)) || sizeof(v->counter) == sizeof(long long))) __compiletime_assert_25(); } while (0); do { *(volatile typeof(v->counter) *)&(v->counter) = (i); } while (0); } while (0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int arch_atomic_cmpxchg(atomic_t *v, int o, int n) { return ({ __typeof__(*(&v->counter)) __res; if (0 == 0) do { } while (0); __res = ((__typeof__(*((&v->counter)))) __cmpxchg(((&v->counter)), (unsigned long)(__typeof__(*((&v->counter))))((o)), (unsigned long)(__typeof__(*((&v->counter))))((n)), sizeof(*((&v->counter))))); if (0 == 0) do { } while (0); __res; }); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int arch_atomic_xchg(atomic_t *v, int n) { return ({ __typeof__(*(&v->counter)) __res; if (0 == 0) do { } while (0); __res = (__typeof__(*(&v->counter))) __xchg((&v->counter), (unsigned long)(n), sizeof(*(&v->counter))); do { } while (0); __res; }); }
# 156 "./arch/mips/include/asm/atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_atomic_add(int i, atomic_t * v) { int temp; if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); v->counter += i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); return; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%0, %1		# " "atomic" "_" "add" "	\n" "	" "addu" " %0, %2				\n" "	" "sc" "	%0, %1					\n" "\t" "beqz	" "%0, 1b					\n" "	.set	pop					\n" : "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_atomic_add_return_relaxed(int i, atomic_t * v) { int temp, result; if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; result += i; v->counter = result; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_" "add" "_return\n" "	" "addu" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqz	" "%0, 1b					\n" "	" "addu" " %0, %1, %3				\n" "	.set	pop					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_atomic_fetch_add_relaxed(int i, atomic_t * v) { int temp, result; if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; v->counter += i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_fetch_" "add" "\n" "	" "addu" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqz	" "%0, 1b					\n" "	.set	pop					\n" "	move	%0, %1					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_atomic_sub(int i, atomic_t * v) { int temp; if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); v->counter -= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); return; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%0, %1		# " "atomic" "_" "sub" "	\n" "	" "subu" " %0, %2				\n" "	" "sc" "	%0, %1					\n" "\t" "beqz	" "%0, 1b					\n" "	.set	pop					\n" : "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_atomic_sub_return_relaxed(int i, atomic_t * v) { int temp, result; if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; result -= i; v->counter = result; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_" "sub" "_return\n" "	" "subu" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqz	" "%0, 1b					\n" "	" "subu" " %0, %1, %3				\n" "	.set	pop					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_atomic_fetch_sub_relaxed(int i, atomic_t * v) { int temp, result; if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; v->counter -= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_fetch_" "sub" "\n" "	" "subu" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqz	" "%0, 1b					\n" "	.set	pop					\n" "	move	%0, %1					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; }
# 178 "./arch/mips/include/asm/atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_atomic_and(int i, atomic_t * v) { int temp; if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); v->counter &= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); return; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%0, %1		# " "atomic" "_" "and" "	\n" "	" "and" " %0, %2				\n" "	" "sc" "	%0, %1					\n" "\t" "beqz	" "%0, 1b					\n" "	.set	pop					\n" : "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_atomic_fetch_and_relaxed(int i, atomic_t * v) { int temp, result; if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; v->counter &= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_fetch_" "and" "\n" "	" "and" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqz	" "%0, 1b					\n" "	.set	pop					\n" "	move	%0, %1					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_atomic_or(int i, atomic_t * v) { int temp; if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); v->counter |= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); return; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%0, %1		# " "atomic" "_" "or" "	\n" "	" "or" " %0, %2				\n" "	" "sc" "	%0, %1					\n" "\t" "beqz	" "%0, 1b					\n" "	.set	pop					\n" : "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_atomic_fetch_or_relaxed(int i, atomic_t * v) { int temp, result; if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; v->counter |= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_fetch_" "or" "\n" "	" "or" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqz	" "%0, 1b					\n" "	.set	pop					\n" "	move	%0, %1					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_atomic_xor(int i, atomic_t * v) { int temp; if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); v->counter ^= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); return; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%0, %1		# " "atomic" "_" "xor" "	\n" "	" "xor" " %0, %2				\n" "	" "sc" "	%0, %1					\n" "\t" "beqz	" "%0, 1b					\n" "	.set	pop					\n" : "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_atomic_fetch_xor_relaxed(int i, atomic_t * v) { int temp, result; if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; v->counter ^= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_fetch_" "xor" "\n" "	" "xor" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqz	" "%0, 1b					\n" "	.set	pop					\n" "	move	%0, %1					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; }
# 260 "./arch/mips/include/asm/atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_atomic_sub_if_positive(int i, atomic_t * v) { int temp, result; do { } while (0); if (!((1 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; result -= i; if (result >= 0) v->counter = result; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(flags); } while (0); do { } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# atomic_sub_if_positive\n" "	.set	pop					\n" "	" "subu" "	%0, %1, %3				\n" "	move	%1, %0					\n" "	bltz	%0, 2f					\n" "	.set	push					\n" "	.set	" "mips64r2" "			\n" "	" "sc" "	%1, %2					\n" "	" "beqz	" "%1, 1b				\n" "2:	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r2; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "	.set	pop					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); if (0 == 0) do { } while (0); return result; }
# 8 "./include/linux/atomic.h" 2
# 80 "./include/linux/atomic.h"
# 1 "./include/linux/atomic/atomic-arch-fallback.h" 1
# 151 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_read_acquire(const atomic_t *v)
{
 return ({ typeof( _Generic((*&(v)->counter), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*&(v)->counter))) ___p1 = ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_26(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(*&(v)->counter) == sizeof(char) || sizeof(*&(v)->counter) == sizeof(short) || sizeof(*&(v)->counter) == sizeof(int) || sizeof(*&(v)->counter) == sizeof(long)) || sizeof(*&(v)->counter) == sizeof(long long))) __compiletime_assert_26(); } while (0); (*(const volatile typeof( _Generic((*&(v)->counter), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*&(v)->counter))) *)&(*&(v)->counter)); }); do { __attribute__((__noreturn__)) extern void __compiletime_assert_27(void) __attribute__((__error__("Need native word sized stores/loads for atomicity."))); if (!((sizeof(*&(v)->counter) == sizeof(char) || sizeof(*&(v)->counter) == sizeof(short) || sizeof(*&(v)->counter) == sizeof(int) || sizeof(*&(v)->counter) == sizeof(long)))) __compiletime_assert_27(); } while (0); __sync(); (typeof(*&(v)->counter))___p1; });
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_set_release(atomic_t *v, int i)
{
 do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_28(void) __attribute__((__error__("Need native word sized stores/loads for atomicity."))); if (!((sizeof(*&(v)->counter) == sizeof(char) || sizeof(*&(v)->counter) == sizeof(short) || sizeof(*&(v)->counter) == sizeof(int) || sizeof(*&(v)->counter) == sizeof(long)))) __compiletime_assert_28(); } while (0); __sync(); do { do { __attribute__((__noreturn__)) extern void __compiletime_assert_29(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(*&(v)->counter) == sizeof(char) || sizeof(*&(v)->counter) == sizeof(short) || sizeof(*&(v)->counter) == sizeof(int) || sizeof(*&(v)->counter) == sizeof(long)) || sizeof(*&(v)->counter) == sizeof(long long))) __compiletime_assert_29(); } while (0); do { *(volatile typeof(*&(v)->counter) *)&(*&(v)->counter) = (i); } while (0); } while (0); } while (0);
}
# 175 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_add_return_acquire(int i, atomic_t *v)
{
 int ret = arch_atomic_add_return_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_add_return_release(int i, atomic_t *v)
{
 do { } while (0);
 return arch_atomic_add_return_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_add_return(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = arch_atomic_add_return_relaxed(i, v);
 do { } while (0);
 return ret;
}
# 217 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_add_acquire(int i, atomic_t *v)
{
 int ret = arch_atomic_fetch_add_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_add_release(int i, atomic_t *v)
{
 do { } while (0);
 return arch_atomic_fetch_add_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_add(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = arch_atomic_fetch_add_relaxed(i, v);
 do { } while (0);
 return ret;
}
# 259 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_sub_return_acquire(int i, atomic_t *v)
{
 int ret = arch_atomic_sub_return_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_sub_return_release(int i, atomic_t *v)
{
 do { } while (0);
 return arch_atomic_sub_return_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_sub_return(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = arch_atomic_sub_return_relaxed(i, v);
 do { } while (0);
 return ret;
}
# 301 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_sub_acquire(int i, atomic_t *v)
{
 int ret = arch_atomic_fetch_sub_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_sub_release(int i, atomic_t *v)
{
 do { } while (0);
 return arch_atomic_fetch_sub_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_sub(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = arch_atomic_fetch_sub_relaxed(i, v);
 do { } while (0);
 return ret;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_inc(atomic_t *v)
{
 arch_atomic_add(1, v);
}
# 353 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_inc_return(atomic_t *v)
{
 return arch_atomic_add_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_inc_return_acquire(atomic_t *v)
{
 return arch_atomic_add_return_acquire(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_inc_return_release(atomic_t *v)
{
 return arch_atomic_add_return_release(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_inc_return_relaxed(atomic_t *v)
{
 return arch_atomic_add_return_relaxed(1, v);
}
# 434 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_inc(atomic_t *v)
{
 return arch_atomic_fetch_add(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_inc_acquire(atomic_t *v)
{
 return arch_atomic_fetch_add_acquire(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_inc_release(atomic_t *v)
{
 return arch_atomic_fetch_add_release(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_inc_relaxed(atomic_t *v)
{
 return arch_atomic_fetch_add_relaxed(1, v);
}
# 508 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_dec(atomic_t *v)
{
 arch_atomic_sub(1, v);
}
# 524 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_dec_return(atomic_t *v)
{
 return arch_atomic_sub_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_dec_return_acquire(atomic_t *v)
{
 return arch_atomic_sub_return_acquire(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_dec_return_release(atomic_t *v)
{
 return arch_atomic_sub_return_release(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_dec_return_relaxed(atomic_t *v)
{
 return arch_atomic_sub_return_relaxed(1, v);
}
# 605 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_dec(atomic_t *v)
{
 return arch_atomic_fetch_sub(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_dec_acquire(atomic_t *v)
{
 return arch_atomic_fetch_sub_acquire(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_dec_release(atomic_t *v)
{
 return arch_atomic_fetch_sub_release(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_dec_relaxed(atomic_t *v)
{
 return arch_atomic_fetch_sub_relaxed(1, v);
}
# 685 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_and_acquire(int i, atomic_t *v)
{
 int ret = arch_atomic_fetch_and_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_and_release(int i, atomic_t *v)
{
 do { } while (0);
 return arch_atomic_fetch_and_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_and(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = arch_atomic_fetch_and_relaxed(i, v);
 do { } while (0);
 return ret;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_andnot(int i, atomic_t *v)
{
 arch_atomic_and(~i, v);
}
# 737 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_andnot(int i, atomic_t *v)
{
 return arch_atomic_fetch_and(~i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_andnot_acquire(int i, atomic_t *v)
{
 return arch_atomic_fetch_and_acquire(~i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_andnot_release(int i, atomic_t *v)
{
 return arch_atomic_fetch_and_release(~i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_andnot_relaxed(int i, atomic_t *v)
{
 return arch_atomic_fetch_and_relaxed(~i, v);
}
# 817 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_or_acquire(int i, atomic_t *v)
{
 int ret = arch_atomic_fetch_or_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_or_release(int i, atomic_t *v)
{
 do { } while (0);
 return arch_atomic_fetch_or_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_or(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = arch_atomic_fetch_or_relaxed(i, v);
 do { } while (0);
 return ret;
}
# 859 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_xor_acquire(int i, atomic_t *v)
{
 int ret = arch_atomic_fetch_xor_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_xor_release(int i, atomic_t *v)
{
 do { } while (0);
 return arch_atomic_fetch_xor_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_xor(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = arch_atomic_fetch_xor_relaxed(i, v);
 do { } while (0);
 return ret;
}
# 986 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_try_cmpxchg(atomic_t *v, int *old, int new)
{
 int r, o = *old;
 r = arch_atomic_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)
{
 int r, o = *old;
 r = arch_atomic_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_try_cmpxchg_release(atomic_t *v, int *old, int new)
{
 int r, o = *old;
 r = arch_atomic_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_try_cmpxchg_relaxed(atomic_t *v, int *old, int new)
{
 int r, o = *old;
 r = arch_atomic_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}
# 1085 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_sub_and_test(int i, atomic_t *v)
{
 return arch_atomic_sub_return(i, v) == 0;
}
# 1102 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_dec_and_test(atomic_t *v)
{
 return arch_atomic_dec_return(v) == 0;
}
# 1119 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_inc_and_test(atomic_t *v)
{
 return arch_atomic_inc_return(v) == 0;
}
# 1137 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_add_negative(int i, atomic_t *v)
{
 return arch_atomic_add_return(i, v) < 0;
}
# 1155 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
arch_atomic_fetch_add_unless(atomic_t *v, int a, int u)
{
 int c = arch_atomic_read(v);

 do {
  if (__builtin_expect(!!(c == u), 0))
   break;
 } while (!arch_atomic_try_cmpxchg(v, &c, c + a));

 return c;
}
# 1180 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_add_unless(atomic_t *v, int a, int u)
{
 return arch_atomic_fetch_add_unless(v, a, u) != u;
}
# 1196 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_inc_not_zero(atomic_t *v)
{
 return arch_atomic_add_unless(v, 1, 0);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_inc_unless_negative(atomic_t *v)
{
 int c = arch_atomic_read(v);

 do {
  if (__builtin_expect(!!(c < 0), 0))
   return false;
 } while (!arch_atomic_try_cmpxchg(v, &c, c + 1));

 return true;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_dec_unless_positive(atomic_t *v)
{
 int c = arch_atomic_read(v);

 do {
  if (__builtin_expect(!!(c > 0), 0))
   return false;
 } while (!arch_atomic_try_cmpxchg(v, &c, c - 1));

 return true;
}
# 1254 "./include/linux/atomic/atomic-arch-fallback.h"
# 1 "./include/asm-generic/atomic64.h" 1
# 12 "./include/asm-generic/atomic64.h"
typedef struct {
 s64 counter;
} atomic64_t;



extern s64 generic_atomic64_read(const atomic64_t *v);
extern void generic_atomic64_set(atomic64_t *v, s64 i);
# 32 "./include/asm-generic/atomic64.h"
extern void generic_atomic64_add(s64 a, atomic64_t *v); extern s64 generic_atomic64_add_return(s64 a, atomic64_t *v); extern s64 generic_atomic64_fetch_add(s64 a, atomic64_t *v);
extern void generic_atomic64_sub(s64 a, atomic64_t *v); extern s64 generic_atomic64_sub_return(s64 a, atomic64_t *v); extern s64 generic_atomic64_fetch_sub(s64 a, atomic64_t *v);




extern void generic_atomic64_and(s64 a, atomic64_t *v); extern s64 generic_atomic64_fetch_and(s64 a, atomic64_t *v);
extern void generic_atomic64_or(s64 a, atomic64_t *v); extern s64 generic_atomic64_fetch_or(s64 a, atomic64_t *v);
extern void generic_atomic64_xor(s64 a, atomic64_t *v); extern s64 generic_atomic64_fetch_xor(s64 a, atomic64_t *v);






extern s64 generic_atomic64_dec_if_positive(atomic64_t *v);
extern s64 generic_atomic64_cmpxchg(atomic64_t *v, s64 o, s64 n);
extern s64 generic_atomic64_xchg(atomic64_t *v, s64 new);
extern s64 generic_atomic64_fetch_add_unless(atomic64_t *v, s64 a, s64 u);
# 1255 "./include/linux/atomic/atomic-arch-fallback.h" 2



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_read_acquire(const atomic64_t *v)
{
 return ({ typeof( _Generic((*&(v)->counter), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*&(v)->counter))) ___p1 = ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_30(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(*&(v)->counter) == sizeof(char) || sizeof(*&(v)->counter) == sizeof(short) || sizeof(*&(v)->counter) == sizeof(int) || sizeof(*&(v)->counter) == sizeof(long)) || sizeof(*&(v)->counter) == sizeof(long long))) __compiletime_assert_30(); } while (0); (*(const volatile typeof( _Generic((*&(v)->counter), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*&(v)->counter))) *)&(*&(v)->counter)); }); do { __attribute__((__noreturn__)) extern void __compiletime_assert_31(void) __attribute__((__error__("Need native word sized stores/loads for atomicity."))); if (!((sizeof(*&(v)->counter) == sizeof(char) || sizeof(*&(v)->counter) == sizeof(short) || sizeof(*&(v)->counter) == sizeof(int) || sizeof(*&(v)->counter) == sizeof(long)))) __compiletime_assert_31(); } while (0); __sync(); (typeof(*&(v)->counter))___p1; });
}
# 1444 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic64_inc(atomic64_t *v)
{
 generic_atomic64_add(1, v);
}
# 1460 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_inc_return(atomic64_t *v)
{
 return generic_atomic64_add_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_inc_return_acquire(atomic64_t *v)
{
 return generic_atomic64_add_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_inc_return_release(atomic64_t *v)
{
 return generic_atomic64_add_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_inc_return_relaxed(atomic64_t *v)
{
 return generic_atomic64_add_return(1, v);
}
# 1541 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_fetch_inc(atomic64_t *v)
{
 return generic_atomic64_fetch_add(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_fetch_inc_acquire(atomic64_t *v)
{
 return generic_atomic64_fetch_add(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_fetch_inc_release(atomic64_t *v)
{
 return generic_atomic64_fetch_add(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_fetch_inc_relaxed(atomic64_t *v)
{
 return generic_atomic64_fetch_add(1, v);
}
# 1615 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic64_dec(atomic64_t *v)
{
 generic_atomic64_sub(1, v);
}
# 1631 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_dec_return(atomic64_t *v)
{
 return generic_atomic64_sub_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_dec_return_acquire(atomic64_t *v)
{
 return generic_atomic64_sub_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_dec_return_release(atomic64_t *v)
{
 return generic_atomic64_sub_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_dec_return_relaxed(atomic64_t *v)
{
 return generic_atomic64_sub_return(1, v);
}
# 1712 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_fetch_dec(atomic64_t *v)
{
 return generic_atomic64_fetch_sub(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_fetch_dec_acquire(atomic64_t *v)
{
 return generic_atomic64_fetch_sub(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_fetch_dec_release(atomic64_t *v)
{
 return generic_atomic64_fetch_sub(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_fetch_dec_relaxed(atomic64_t *v)
{
 return generic_atomic64_fetch_sub(1, v);
}
# 1828 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic64_andnot(s64 i, atomic64_t *v)
{
 generic_atomic64_and(~i, v);
}
# 1844 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_fetch_andnot(s64 i, atomic64_t *v)
{
 return generic_atomic64_fetch_and(~i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_fetch_andnot_acquire(s64 i, atomic64_t *v)
{
 return generic_atomic64_fetch_and(~i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_fetch_andnot_release(s64 i, atomic64_t *v)
{
 return generic_atomic64_fetch_and(~i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
arch_atomic64_fetch_andnot_relaxed(s64 i, atomic64_t *v)
{
 return generic_atomic64_fetch_and(~i, v);
}
# 2093 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic64_try_cmpxchg(atomic64_t *v, s64 *old, s64 new)
{
 s64 r, o = *old;
 r = generic_atomic64_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic64_try_cmpxchg_acquire(atomic64_t *v, s64 *old, s64 new)
{
 s64 r, o = *old;
 r = generic_atomic64_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic64_try_cmpxchg_release(atomic64_t *v, s64 *old, s64 new)
{
 s64 r, o = *old;
 r = generic_atomic64_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic64_try_cmpxchg_relaxed(atomic64_t *v, s64 *old, s64 new)
{
 s64 r, o = *old;
 r = generic_atomic64_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}
# 2192 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic64_sub_and_test(s64 i, atomic64_t *v)
{
 return generic_atomic64_sub_return(i, v) == 0;
}
# 2209 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic64_dec_and_test(atomic64_t *v)
{
 return arch_atomic64_dec_return(v) == 0;
}
# 2226 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic64_inc_and_test(atomic64_t *v)
{
 return arch_atomic64_inc_return(v) == 0;
}
# 2244 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic64_add_negative(s64 i, atomic64_t *v)
{
 return generic_atomic64_add_return(i, v) < 0;
}
# 2287 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic64_add_unless(atomic64_t *v, s64 a, s64 u)
{
 return generic_atomic64_fetch_add_unless(v, a, u) != u;
}
# 2303 "./include/linux/atomic/atomic-arch-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic64_inc_not_zero(atomic64_t *v)
{
 return arch_atomic64_add_unless(v, 1, 0);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic64_inc_unless_negative(atomic64_t *v)
{
 s64 c = generic_atomic64_read(v);

 do {
  if (__builtin_expect(!!(c < 0), 0))
   return false;
 } while (!arch_atomic64_try_cmpxchg(v, &c, c + 1));

 return true;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic64_dec_unless_positive(atomic64_t *v)
{
 s64 c = generic_atomic64_read(v);

 do {
  if (__builtin_expect(!!(c > 0), 0))
   return false;
 } while (!arch_atomic64_try_cmpxchg(v, &c, c - 1));

 return true;
}
# 81 "./include/linux/atomic.h" 2
# 1 "./include/linux/atomic/atomic-long.h" 1
# 18 "./include/linux/atomic/atomic-long.h"
typedef atomic_t atomic_long_t;
# 520 "./include/linux/atomic/atomic-long.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_read(const atomic_long_t *v)
{
 return arch_atomic_read(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_read_acquire(const atomic_long_t *v)
{
 return arch_atomic_read_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_long_set(atomic_long_t *v, long i)
{
 arch_atomic_set(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_long_set_release(atomic_long_t *v, long i)
{
 arch_atomic_set_release(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_long_add(long i, atomic_long_t *v)
{
 arch_atomic_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_add_return(long i, atomic_long_t *v)
{
 return arch_atomic_add_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_add_return_acquire(long i, atomic_long_t *v)
{
 return arch_atomic_add_return_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_add_return_release(long i, atomic_long_t *v)
{
 return arch_atomic_add_return_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_add_return_relaxed(long i, atomic_long_t *v)
{
 return arch_atomic_add_return_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_add(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_add_acquire(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_add_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_add_release(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_add_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_add_relaxed(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_add_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_long_sub(long i, atomic_long_t *v)
{
 arch_atomic_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_sub_return(long i, atomic_long_t *v)
{
 return arch_atomic_sub_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_sub_return_acquire(long i, atomic_long_t *v)
{
 return arch_atomic_sub_return_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_sub_return_release(long i, atomic_long_t *v)
{
 return arch_atomic_sub_return_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_sub_return_relaxed(long i, atomic_long_t *v)
{
 return arch_atomic_sub_return_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_sub(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_sub_acquire(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_sub_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_sub_release(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_sub_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_sub_relaxed(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_sub_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_long_inc(atomic_long_t *v)
{
 arch_atomic_inc(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_inc_return(atomic_long_t *v)
{
 return arch_atomic_inc_return(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_inc_return_acquire(atomic_long_t *v)
{
 return arch_atomic_inc_return_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_inc_return_release(atomic_long_t *v)
{
 return arch_atomic_inc_return_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_inc_return_relaxed(atomic_long_t *v)
{
 return arch_atomic_inc_return_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_inc(atomic_long_t *v)
{
 return arch_atomic_fetch_inc(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_inc_acquire(atomic_long_t *v)
{
 return arch_atomic_fetch_inc_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_inc_release(atomic_long_t *v)
{
 return arch_atomic_fetch_inc_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_inc_relaxed(atomic_long_t *v)
{
 return arch_atomic_fetch_inc_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_long_dec(atomic_long_t *v)
{
 arch_atomic_dec(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_dec_return(atomic_long_t *v)
{
 return arch_atomic_dec_return(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_dec_return_acquire(atomic_long_t *v)
{
 return arch_atomic_dec_return_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_dec_return_release(atomic_long_t *v)
{
 return arch_atomic_dec_return_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_dec_return_relaxed(atomic_long_t *v)
{
 return arch_atomic_dec_return_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_dec(atomic_long_t *v)
{
 return arch_atomic_fetch_dec(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_dec_acquire(atomic_long_t *v)
{
 return arch_atomic_fetch_dec_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_dec_release(atomic_long_t *v)
{
 return arch_atomic_fetch_dec_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_dec_relaxed(atomic_long_t *v)
{
 return arch_atomic_fetch_dec_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_long_and(long i, atomic_long_t *v)
{
 arch_atomic_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_and(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_and_acquire(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_and_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_and_release(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_and_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_and_relaxed(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_and_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_long_andnot(long i, atomic_long_t *v)
{
 arch_atomic_andnot(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_andnot(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_andnot(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_andnot_acquire(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_andnot_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_andnot_release(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_andnot_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_andnot_relaxed(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_andnot_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_long_or(long i, atomic_long_t *v)
{
 arch_atomic_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_or(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_or_acquire(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_or_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_or_release(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_or_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_or_relaxed(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_or_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
arch_atomic_long_xor(long i, atomic_long_t *v)
{
 arch_atomic_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_xor(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_xor_acquire(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_xor_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_xor_release(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_xor_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_xor_relaxed(long i, atomic_long_t *v)
{
 return arch_atomic_fetch_xor_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_xchg(atomic_long_t *v, long i)
{
 return arch_atomic_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_xchg_acquire(atomic_long_t *v, long i)
{
 return arch_atomic_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_xchg_release(atomic_long_t *v, long i)
{
 return arch_atomic_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_xchg_relaxed(atomic_long_t *v, long i)
{
 return arch_atomic_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_cmpxchg(atomic_long_t *v, long old, long new)
{
 return arch_atomic_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_cmpxchg_acquire(atomic_long_t *v, long old, long new)
{
 return arch_atomic_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_cmpxchg_release(atomic_long_t *v, long old, long new)
{
 return arch_atomic_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_cmpxchg_relaxed(atomic_long_t *v, long old, long new)
{
 return arch_atomic_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_long_try_cmpxchg(atomic_long_t *v, long *old, long new)
{
 return arch_atomic_try_cmpxchg(v, (int *)old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_long_try_cmpxchg_acquire(atomic_long_t *v, long *old, long new)
{
 return arch_atomic_try_cmpxchg_acquire(v, (int *)old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_long_try_cmpxchg_release(atomic_long_t *v, long *old, long new)
{
 return arch_atomic_try_cmpxchg_release(v, (int *)old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_long_try_cmpxchg_relaxed(atomic_long_t *v, long *old, long new)
{
 return arch_atomic_try_cmpxchg_relaxed(v, (int *)old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_long_sub_and_test(long i, atomic_long_t *v)
{
 return arch_atomic_sub_and_test(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_long_dec_and_test(atomic_long_t *v)
{
 return arch_atomic_dec_and_test(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_long_inc_and_test(atomic_long_t *v)
{
 return arch_atomic_inc_and_test(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_long_add_negative(long i, atomic_long_t *v)
{
 return arch_atomic_add_negative(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_fetch_add_unless(atomic_long_t *v, long a, long u)
{
 return arch_atomic_fetch_add_unless(v, a, u);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_long_add_unless(atomic_long_t *v, long a, long u)
{
 return arch_atomic_add_unless(v, a, u);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_long_inc_not_zero(atomic_long_t *v)
{
 return arch_atomic_inc_not_zero(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_long_inc_unless_negative(atomic_long_t *v)
{
 return arch_atomic_inc_unless_negative(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
arch_atomic_long_dec_unless_positive(atomic_long_t *v)
{
 return arch_atomic_dec_unless_positive(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
arch_atomic_long_dec_if_positive(atomic_long_t *v)
{
 return arch_atomic_sub_if_positive(1, v);
}
# 82 "./include/linux/atomic.h" 2
# 1 "./include/linux/atomic/atomic-instrumented.h" 1
# 22 "./include/linux/atomic/atomic-instrumented.h"
# 1 "./include/linux/instrumented.h" 1
# 24 "./include/linux/instrumented.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void instrument_read(const volatile void *v, size_t size)
{
 kasan_check_read(v, size);
 kcsan_check_access(v, size, 0);
}
# 39 "./include/linux/instrumented.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void instrument_write(const volatile void *v, size_t size)
{
 kasan_check_write(v, size);
 kcsan_check_access(v, size, (1 << 0));
}
# 54 "./include/linux/instrumented.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void instrument_read_write(const volatile void *v, size_t size)
{
 kasan_check_write(v, size);
 kcsan_check_access(v, size, (1 << 1) | (1 << 0));
}
# 69 "./include/linux/instrumented.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void instrument_atomic_read(const volatile void *v, size_t size)
{
 kasan_check_read(v, size);
 kcsan_check_access(v, size, (1 << 2));
}
# 84 "./include/linux/instrumented.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void instrument_atomic_write(const volatile void *v, size_t size)
{
 kasan_check_write(v, size);
 kcsan_check_access(v, size, (1 << 2) | (1 << 0));
}
# 99 "./include/linux/instrumented.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void instrument_atomic_read_write(const volatile void *v, size_t size)
{
 kasan_check_write(v, size);
 kcsan_check_access(v, size, (1 << 2) | (1 << 0) | (1 << 1));
}
# 115 "./include/linux/instrumented.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
instrument_copy_to_user(void *to, const void *from, unsigned long n)
{
 kasan_check_read(from, n);
 kcsan_check_access(from, n, 0);
}
# 132 "./include/linux/instrumented.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
instrument_copy_from_user(const void *to, const void *from, unsigned long n)
{
 kasan_check_write(to, n);
 kcsan_check_access(to, n, (1 << 0));
}
# 23 "./include/linux/atomic/atomic-instrumented.h" 2

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_read(const atomic_t *v)
{
 instrument_atomic_read(v, sizeof(*v));
 return arch_atomic_read(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_read_acquire(const atomic_t *v)
{
 instrument_atomic_read(v, sizeof(*v));
 return arch_atomic_read_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_set(atomic_t *v, int i)
{
 instrument_atomic_write(v, sizeof(*v));
 arch_atomic_set(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_set_release(atomic_t *v, int i)
{
 instrument_atomic_write(v, sizeof(*v));
 arch_atomic_set_release(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_add(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_add_return(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_add_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_add_return_acquire(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_add_return_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_add_return_release(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_add_return_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_add_return_relaxed(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_add_return_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_add(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_add_acquire(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_add_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_add_release(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_add_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_add_relaxed(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_add_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_sub(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_sub_return(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_sub_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_sub_return_acquire(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_sub_return_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_sub_return_release(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_sub_return_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_sub_return_relaxed(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_sub_return_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_sub(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_sub_acquire(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_sub_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_sub_release(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_sub_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_sub_relaxed(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_sub_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_inc(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_inc(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_inc_return(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_inc_return(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_inc_return_acquire(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_inc_return_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_inc_return_release(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_inc_return_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_inc_return_relaxed(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_inc_return_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_inc(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_inc(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_inc_acquire(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_inc_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_inc_release(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_inc_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_inc_relaxed(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_inc_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_dec(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_dec(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_dec_return(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_dec_return(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_dec_return_acquire(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_dec_return_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_dec_return_release(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_dec_return_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_dec_return_relaxed(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_dec_return_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_dec(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_dec(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_dec_acquire(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_dec_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_dec_release(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_dec_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_dec_relaxed(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_dec_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_and(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_and(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_and_acquire(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_and_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_and_release(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_and_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_and_relaxed(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_and_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_andnot(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_andnot(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_andnot(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_andnot(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_andnot_acquire(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_andnot_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_andnot_release(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_andnot_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_andnot_relaxed(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_andnot_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_or(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_or(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_or_acquire(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_or_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_or_release(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_or_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_or_relaxed(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_or_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_xor(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_xor(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_xor_acquire(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_xor_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_xor_release(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_xor_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_xor_relaxed(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_xor_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_xchg(atomic_t *v, int i)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_xchg_acquire(atomic_t *v, int i)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_xchg_release(atomic_t *v, int i)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_xchg_relaxed(atomic_t *v, int i)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_cmpxchg(atomic_t *v, int old, int new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_cmpxchg_acquire(atomic_t *v, int old, int new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_cmpxchg_release(atomic_t *v, int old, int new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_cmpxchg_relaxed(atomic_t *v, int old, int new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_try_cmpxchg(atomic_t *v, int *old, int new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 instrument_atomic_read_write(old, sizeof(*old));
 return arch_atomic_try_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 instrument_atomic_read_write(old, sizeof(*old));
 return arch_atomic_try_cmpxchg_acquire(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_try_cmpxchg_release(atomic_t *v, int *old, int new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 instrument_atomic_read_write(old, sizeof(*old));
 return arch_atomic_try_cmpxchg_release(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_try_cmpxchg_relaxed(atomic_t *v, int *old, int new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 instrument_atomic_read_write(old, sizeof(*old));
 return arch_atomic_try_cmpxchg_relaxed(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_sub_and_test(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_sub_and_test(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_dec_and_test(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_dec_and_test(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_inc_and_test(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_inc_and_test(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_add_negative(int i, atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_add_negative(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_add_unless(atomic_t *v, int a, int u)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_fetch_add_unless(v, a, u);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_add_unless(atomic_t *v, int a, int u)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_add_unless(v, a, u);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_inc_not_zero(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_inc_not_zero(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_inc_unless_negative(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_inc_unless_negative(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_dec_unless_positive(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_dec_unless_positive(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_dec_if_positive(atomic_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_sub_if_positive(1, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_read(const atomic64_t *v)
{
 instrument_atomic_read(v, sizeof(*v));
 return generic_atomic64_read(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_read_acquire(const atomic64_t *v)
{
 instrument_atomic_read(v, sizeof(*v));
 return arch_atomic64_read_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_set(atomic64_t *v, s64 i)
{
 instrument_atomic_write(v, sizeof(*v));
 generic_atomic64_set(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_set_release(atomic64_t *v, s64 i)
{
 instrument_atomic_write(v, sizeof(*v));
 generic_atomic64_set(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_add(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 generic_atomic64_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_add_return(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_add_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_add_return_acquire(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_add_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_add_return_release(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_add_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_add_return_relaxed(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_add_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_add(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_add_acquire(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_add_release(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_add_relaxed(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_sub(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 generic_atomic64_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_sub_return(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_sub_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_sub_return_acquire(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_sub_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_sub_return_release(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_sub_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_sub_return_relaxed(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_sub_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_sub(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_sub_acquire(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_sub_release(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_sub_relaxed(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_inc(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic64_inc(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_inc_return(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_inc_return(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_inc_return_acquire(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_inc_return_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_inc_return_release(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_inc_return_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_inc_return_relaxed(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_inc_return_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_inc(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_fetch_inc(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_inc_acquire(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_fetch_inc_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_inc_release(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_fetch_inc_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_inc_relaxed(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_fetch_inc_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_dec(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic64_dec(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_dec_return(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_dec_return(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_dec_return_acquire(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_dec_return_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_dec_return_release(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_dec_return_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_dec_return_relaxed(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_dec_return_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_dec(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_fetch_dec(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_dec_acquire(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_fetch_dec_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_dec_release(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_fetch_dec_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_dec_relaxed(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_fetch_dec_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_and(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 generic_atomic64_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_and(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_and_acquire(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_and_release(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_and_relaxed(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_andnot(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic64_andnot(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_andnot(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_fetch_andnot(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_andnot_acquire(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_fetch_andnot_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_andnot_release(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_fetch_andnot_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_andnot_relaxed(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_fetch_andnot_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_or(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 generic_atomic64_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_or(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_or_acquire(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_or_release(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_or_relaxed(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_xor(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 generic_atomic64_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_xor(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_xor_acquire(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_xor_release(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_xor_relaxed(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_xchg(atomic64_t *v, s64 i)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_xchg_acquire(atomic64_t *v, s64 i)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_xchg_release(atomic64_t *v, s64 i)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_xchg_relaxed(atomic64_t *v, s64 i)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_cmpxchg(atomic64_t *v, s64 old, s64 new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_cmpxchg_acquire(atomic64_t *v, s64 old, s64 new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_cmpxchg_release(atomic64_t *v, s64 old, s64 new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_cmpxchg_relaxed(atomic64_t *v, s64 old, s64 new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_try_cmpxchg(atomic64_t *v, s64 *old, s64 new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 instrument_atomic_read_write(old, sizeof(*old));
 return arch_atomic64_try_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_try_cmpxchg_acquire(atomic64_t *v, s64 *old, s64 new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 instrument_atomic_read_write(old, sizeof(*old));
 return arch_atomic64_try_cmpxchg_acquire(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_try_cmpxchg_release(atomic64_t *v, s64 *old, s64 new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 instrument_atomic_read_write(old, sizeof(*old));
 return arch_atomic64_try_cmpxchg_release(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_try_cmpxchg_relaxed(atomic64_t *v, s64 *old, s64 new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 instrument_atomic_read_write(old, sizeof(*old));
 return arch_atomic64_try_cmpxchg_relaxed(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_sub_and_test(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_sub_and_test(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_dec_and_test(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_dec_and_test(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_inc_and_test(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_inc_and_test(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_add_negative(s64 i, atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_add_negative(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_add_unless(atomic64_t *v, s64 a, s64 u)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_fetch_add_unless(v, a, u);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_add_unless(atomic64_t *v, s64 a, s64 u)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_add_unless(v, a, u);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_inc_not_zero(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_inc_not_zero(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_inc_unless_negative(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_inc_unless_negative(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_dec_unless_positive(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic64_dec_unless_positive(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_dec_if_positive(atomic64_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return generic_atomic64_dec_if_positive(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_read(const atomic_long_t *v)
{
 instrument_atomic_read(v, sizeof(*v));
 return arch_atomic_long_read(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_read_acquire(const atomic_long_t *v)
{
 instrument_atomic_read(v, sizeof(*v));
 return arch_atomic_long_read_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_set(atomic_long_t *v, long i)
{
 instrument_atomic_write(v, sizeof(*v));
 arch_atomic_long_set(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_set_release(atomic_long_t *v, long i)
{
 instrument_atomic_write(v, sizeof(*v));
 arch_atomic_long_set_release(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_add(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_long_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_add_return(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_add_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_add_return_acquire(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_add_return_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_add_return_release(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_add_return_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_add_return_relaxed(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_add_return_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_add(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_add_acquire(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_add_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_add_release(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_add_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_add_relaxed(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_add_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_sub(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_long_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_sub_return(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_sub_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_sub_return_acquire(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_sub_return_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_sub_return_release(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_sub_return_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_sub_return_relaxed(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_sub_return_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_sub(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_sub_acquire(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_sub_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_sub_release(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_sub_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_sub_relaxed(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_sub_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_inc(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_long_inc(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_inc_return(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_inc_return(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_inc_return_acquire(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_inc_return_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_inc_return_release(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_inc_return_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_inc_return_relaxed(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_inc_return_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_inc(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_inc(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_inc_acquire(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_inc_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_inc_release(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_inc_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_inc_relaxed(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_inc_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_dec(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_long_dec(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_dec_return(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_dec_return(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_dec_return_acquire(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_dec_return_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_dec_return_release(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_dec_return_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_dec_return_relaxed(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_dec_return_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_dec(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_dec(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_dec_acquire(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_dec_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_dec_release(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_dec_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_dec_relaxed(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_dec_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_and(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_long_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_and(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_and_acquire(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_and_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_and_release(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_and_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_and_relaxed(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_and_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_andnot(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_long_andnot(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_andnot(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_andnot(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_andnot_acquire(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_andnot_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_andnot_release(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_andnot_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_andnot_relaxed(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_andnot_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_or(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_long_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_or(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_or_acquire(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_or_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_or_release(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_or_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_or_relaxed(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_or_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_xor(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 arch_atomic_long_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_xor(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_xor_acquire(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_xor_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_xor_release(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_xor_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_xor_relaxed(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_xor_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_xchg(atomic_long_t *v, long i)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_xchg_acquire(atomic_long_t *v, long i)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_xchg_acquire(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_xchg_release(atomic_long_t *v, long i)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_xchg_release(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_xchg_relaxed(atomic_long_t *v, long i)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_xchg_relaxed(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_cmpxchg(atomic_long_t *v, long old, long new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_cmpxchg_acquire(atomic_long_t *v, long old, long new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_cmpxchg_acquire(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_cmpxchg_release(atomic_long_t *v, long old, long new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_cmpxchg_release(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_cmpxchg_relaxed(atomic_long_t *v, long old, long new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_cmpxchg_relaxed(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_try_cmpxchg(atomic_long_t *v, long *old, long new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 instrument_atomic_read_write(old, sizeof(*old));
 return arch_atomic_long_try_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_try_cmpxchg_acquire(atomic_long_t *v, long *old, long new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 instrument_atomic_read_write(old, sizeof(*old));
 return arch_atomic_long_try_cmpxchg_acquire(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_try_cmpxchg_release(atomic_long_t *v, long *old, long new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 instrument_atomic_read_write(old, sizeof(*old));
 return arch_atomic_long_try_cmpxchg_release(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_try_cmpxchg_relaxed(atomic_long_t *v, long *old, long new)
{
 instrument_atomic_read_write(v, sizeof(*v));
 instrument_atomic_read_write(old, sizeof(*old));
 return arch_atomic_long_try_cmpxchg_relaxed(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_sub_and_test(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_sub_and_test(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_dec_and_test(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_dec_and_test(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_inc_and_test(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_inc_and_test(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_add_negative(long i, atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_add_negative(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_add_unless(atomic_long_t *v, long a, long u)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_fetch_add_unless(v, a, u);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_add_unless(atomic_long_t *v, long a, long u)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_add_unless(v, a, u);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_inc_not_zero(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_inc_not_zero(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_inc_unless_negative(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_inc_unless_negative(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_dec_unless_positive(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_dec_unless_positive(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_dec_if_positive(atomic_long_t *v)
{
 instrument_atomic_read_write(v, sizeof(*v));
 return arch_atomic_long_dec_if_positive(v);
}
# 83 "./include/linux/atomic.h" 2
# 14 "./include/linux/cpumask.h" 2



typedef struct cpumask { unsigned long bits[(((2) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8)))]; } cpumask_t;
# 39 "./include/linux/cpumask.h"
extern unsigned int nr_cpu_ids;
# 90 "./include/linux/cpumask.h"
extern struct cpumask __cpu_possible_mask;
extern struct cpumask __cpu_online_mask;
extern struct cpumask __cpu_present_mask;
extern struct cpumask __cpu_active_mask;
extern struct cpumask __cpu_dying_mask;






extern atomic_t __num_online_cpus;

extern cpumask_t cpus_booted_once_mask;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpu_max_bits_warn(unsigned int cpu, unsigned int bits)
{

 ({ static bool __attribute__((__section__(".data.once"))) __already_done; bool __ret_do_once = !!(cpu >= bits); if (__builtin_expect(!!(__ret_do_once && !__already_done), 0)) { __already_done = true; ({ int __ret_warn_on = !!(1); if (__builtin_expect(!!(__ret_warn_on), 0)) do { do { } while(0); warn_slowpath_fmt("include/linux/cpumask.h", 108, 9, ((void *)0)); do { } while(0); } while (0); __builtin_expect(!!(__ret_warn_on), 0); }); } __builtin_expect(!!(__ret_do_once), 0); });

}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpumask_check(unsigned int cpu)
{
 cpu_max_bits_warn(cpu, nr_cpu_ids);
 return cpu;
}
# 193 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpumask_first(const struct cpumask *srcp)
{
 return find_first_bit(((srcp)->bits), nr_cpu_ids);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpumask_last(const struct cpumask *srcp)
{
 return find_last_bit(((srcp)->bits), nr_cpu_ids);
}

unsigned int __attribute__((__pure__)) cpumask_next(int n, const struct cpumask *srcp);
# 218 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpumask_next_zero(int n, const struct cpumask *srcp)
{

 if (n != -1)
  cpumask_check(n);
 return find_next_zero_bit(((srcp)->bits), nr_cpu_ids, n+1);
}

int __attribute__((__pure__)) cpumask_next_and(int n, const struct cpumask *, const struct cpumask *);
int __attribute__((__pure__)) cpumask_any_but(const struct cpumask *mask, unsigned int cpu);
unsigned int cpumask_local_spread(unsigned int i, int node);
int cpumask_any_and_distribute(const struct cpumask *src1p,
          const struct cpumask *src2p);
int cpumask_any_distribute(const struct cpumask *srcp);
# 257 "./include/linux/cpumask.h"
extern int cpumask_next_wrap(int n, const struct cpumask *mask, int start, bool wrap);
# 309 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_set_cpu(unsigned int cpu, struct cpumask *dstp)
{
 set_bit(cpumask_check(cpu), ((dstp)->bits));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __cpumask_set_cpu(unsigned int cpu, struct cpumask *dstp)
{
 arch___set_bit(cpumask_check(cpu), ((dstp)->bits));
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_clear_cpu(int cpu, struct cpumask *dstp)
{
 clear_bit(cpumask_check(cpu), ((dstp)->bits));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __cpumask_clear_cpu(int cpu, struct cpumask *dstp)
{
 arch___clear_bit(cpumask_check(cpu), ((dstp)->bits));
}
# 342 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_test_cpu(int cpu, const struct cpumask *cpumask)
{
 return arch_test_bit(cpumask_check(cpu), (((cpumask))->bits));
}
# 356 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_test_and_set_cpu(int cpu, struct cpumask *cpumask)
{
 return test_and_set_bit(cpumask_check(cpu), ((cpumask)->bits));
}
# 370 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_test_and_clear_cpu(int cpu, struct cpumask *cpumask)
{
 return test_and_clear_bit(cpumask_check(cpu), ((cpumask)->bits));
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_setall(struct cpumask *dstp)
{
 bitmap_fill(((dstp)->bits), nr_cpu_ids);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_clear(struct cpumask *dstp)
{
 bitmap_zero(((dstp)->bits), nr_cpu_ids);
}
# 401 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_and(struct cpumask *dstp,
          const struct cpumask *src1p,
          const struct cpumask *src2p)
{
 return bitmap_and(((dstp)->bits), ((src1p)->bits),
           ((src2p)->bits), nr_cpu_ids);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_or(struct cpumask *dstp, const struct cpumask *src1p,
         const struct cpumask *src2p)
{
 bitmap_or(((dstp)->bits), ((src1p)->bits),
          ((src2p)->bits), nr_cpu_ids);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_xor(struct cpumask *dstp,
          const struct cpumask *src1p,
          const struct cpumask *src2p)
{
 bitmap_xor(((dstp)->bits), ((src1p)->bits),
           ((src2p)->bits), nr_cpu_ids);
}
# 444 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_andnot(struct cpumask *dstp,
      const struct cpumask *src1p,
      const struct cpumask *src2p)
{
 return bitmap_andnot(((dstp)->bits), ((src1p)->bits),
       ((src2p)->bits), nr_cpu_ids);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_complement(struct cpumask *dstp,
          const struct cpumask *srcp)
{
 bitmap_complement(((dstp)->bits), ((srcp)->bits),
           nr_cpu_ids);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpumask_equal(const struct cpumask *src1p,
    const struct cpumask *src2p)
{
 return bitmap_equal(((src1p)->bits), ((src2p)->bits),
       nr_cpu_ids);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpumask_or_equal(const struct cpumask *src1p,
        const struct cpumask *src2p,
        const struct cpumask *src3p)
{
 return bitmap_or_equal(((src1p)->bits), ((src2p)->bits),
          ((src3p)->bits), nr_cpu_ids);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpumask_intersects(const struct cpumask *src1p,
         const struct cpumask *src2p)
{
 return bitmap_intersects(((src1p)->bits), ((src2p)->bits),
            nr_cpu_ids);
}
# 509 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_subset(const struct cpumask *src1p,
     const struct cpumask *src2p)
{
 return bitmap_subset(((src1p)->bits), ((src2p)->bits),
        nr_cpu_ids);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpumask_empty(const struct cpumask *srcp)
{
 return bitmap_empty(((srcp)->bits), nr_cpu_ids);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpumask_full(const struct cpumask *srcp)
{
 return bitmap_full(((srcp)->bits), nr_cpu_ids);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpumask_weight(const struct cpumask *srcp)
{
 return bitmap_weight(((srcp)->bits), nr_cpu_ids);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_shift_right(struct cpumask *dstp,
           const struct cpumask *srcp, int n)
{
 bitmap_shift_right(((dstp)->bits), ((srcp)->bits), n,
            nr_cpu_ids);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_shift_left(struct cpumask *dstp,
          const struct cpumask *srcp, int n)
{
 bitmap_shift_left(((dstp)->bits), ((srcp)->bits), n,
           nr_cpu_ids);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_copy(struct cpumask *dstp,
    const struct cpumask *srcp)
{
 bitmap_copy(((dstp)->bits), ((srcp)->bits), nr_cpu_ids);
}
# 620 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_parse_user(const char *buf, int len,
         struct cpumask *dstp)
{
 return bitmap_parse_user(buf, len, ((dstp)->bits), nr_cpu_ids);
}
# 634 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_parselist_user(const char *buf, int len,
         struct cpumask *dstp)
{
 return bitmap_parselist_user(buf, len, ((dstp)->bits),
         nr_cpu_ids);
}
# 648 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_parse(const char *buf, struct cpumask *dstp)
{
 return bitmap_parse(buf, (~0U), ((dstp)->bits), nr_cpu_ids);
}
# 660 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpulist_parse(const char *buf, struct cpumask *dstp)
{
 return bitmap_parselist(buf, ((dstp)->bits), nr_cpu_ids);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpumask_size(void)
{
 return (((nr_cpu_ids) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8))) * sizeof(long);
}
# 714 "./include/linux/cpumask.h"
typedef struct cpumask *cpumask_var_t;




bool alloc_cpumask_var_node(cpumask_var_t *mask, gfp_t flags, int node);
bool alloc_cpumask_var(cpumask_var_t *mask, gfp_t flags);
bool zalloc_cpumask_var_node(cpumask_var_t *mask, gfp_t flags, int node);
bool zalloc_cpumask_var(cpumask_var_t *mask, gfp_t flags);
void alloc_bootmem_cpumask_var(cpumask_var_t *mask);
void free_cpumask_var(cpumask_var_t mask);
void free_bootmem_cpumask_var(cpumask_var_t mask);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpumask_available(cpumask_var_t mask)
{
 return mask != ((void *)0);
}
# 782 "./include/linux/cpumask.h"
extern const unsigned long cpu_all_bits[(((2) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8)))];
# 793 "./include/linux/cpumask.h"
void init_cpu_present(const struct cpumask *src);
void init_cpu_possible(const struct cpumask *src);
void init_cpu_online(const struct cpumask *src);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void reset_cpu_possible_mask(void)
{
 bitmap_zero(((&__cpu_possible_mask)->bits), 2);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
set_cpu_possible(unsigned int cpu, bool possible)
{
 if (possible)
  cpumask_set_cpu(cpu, &__cpu_possible_mask);
 else
  cpumask_clear_cpu(cpu, &__cpu_possible_mask);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
set_cpu_present(unsigned int cpu, bool present)
{
 if (present)
  cpumask_set_cpu(cpu, &__cpu_present_mask);
 else
  cpumask_clear_cpu(cpu, &__cpu_present_mask);
}

void set_cpu_online(unsigned int cpu, bool online);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
set_cpu_active(unsigned int cpu, bool active)
{
 if (active)
  cpumask_set_cpu(cpu, &__cpu_active_mask);
 else
  cpumask_clear_cpu(cpu, &__cpu_active_mask);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
set_cpu_dying(unsigned int cpu, bool dying)
{
 if (dying)
  cpumask_set_cpu(cpu, &__cpu_dying_mask);
 else
  cpumask_clear_cpu(cpu, &__cpu_dying_mask);
}
# 854 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __check_is_bitmap(const unsigned long *bitmap)
{
 return 1;
}
# 866 "./include/linux/cpumask.h"
extern const unsigned long
 cpu_bit_bitmap[32 +1][(((2) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8)))];

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) const struct cpumask *get_cpu_mask(unsigned int cpu)
{
 const unsigned long *p = cpu_bit_bitmap[1 + cpu % 32];
 p -= cpu / 32;
 return ((struct cpumask *)(1 ? (p) : (void *)sizeof(__check_is_bitmap(p))));
}
# 885 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int num_online_cpus(void)
{
 return atomic_read(&__num_online_cpus);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpu_online(unsigned int cpu)
{
 return cpumask_test_cpu(cpu, ((const struct cpumask *)&__cpu_online_mask));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpu_possible(unsigned int cpu)
{
 return cpumask_test_cpu(cpu, ((const struct cpumask *)&__cpu_possible_mask));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpu_present(unsigned int cpu)
{
 return cpumask_test_cpu(cpu, ((const struct cpumask *)&__cpu_present_mask));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpu_active(unsigned int cpu)
{
 return cpumask_test_cpu(cpu, ((const struct cpumask *)&__cpu_active_mask));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpu_dying(unsigned int cpu)
{
 return cpumask_test_cpu(cpu, ((const struct cpumask *)&__cpu_dying_mask));
}
# 979 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ssize_t
cpumap_print_to_pagebuf(bool list, char *buf, const struct cpumask *mask)
{
 return bitmap_print_to_pagebuf(list, buf, ((mask)->bits),
          nr_cpu_ids);
}
# 1002 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ssize_t
cpumap_print_bitmask_to_buf(char *buf, const struct cpumask *mask,
  loff_t off, size_t count)
{
 return bitmap_print_bitmask_to_buf(buf, ((mask)->bits),
       nr_cpu_ids, off, count) - 1;
}
# 1017 "./include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ssize_t
cpumap_print_list_to_buf(char *buf, const struct cpumask *mask,
  loff_t off, size_t count)
{
 return bitmap_print_list_to_buf(buf, ((mask)->bits),
       nr_cpu_ids, off, count) - 1;
}
# 14 "./include/linux/smp.h" 2

# 1 "./include/linux/smp_types.h" 1




# 1 "./include/linux/llist.h" 1
# 56 "./include/linux/llist.h"
struct llist_head {
 struct llist_node *first;
};

struct llist_node {
 struct llist_node *next;
};
# 71 "./include/linux/llist.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void init_llist_head(struct llist_head *list)
{
 list->first = ((void *)0);
}
# 189 "./include/linux/llist.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool llist_empty(const struct llist_head *head)
{
 return ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_32(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(head->first) == sizeof(char) || sizeof(head->first) == sizeof(short) || sizeof(head->first) == sizeof(int) || sizeof(head->first) == sizeof(long)) || sizeof(head->first) == sizeof(long long))) __compiletime_assert_32(); } while (0); (*(const volatile typeof( _Generic((head->first), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (head->first))) *)&(head->first)); }) == ((void *)0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct llist_node *llist_next(struct llist_node *node)
{
 return node->next;
}

extern bool llist_add_batch(struct llist_node *new_first,
       struct llist_node *new_last,
       struct llist_head *head);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __llist_add_batch(struct llist_node *new_first,
         struct llist_node *new_last,
         struct llist_head *head)
{
 new_last->next = head->first;
 head->first = new_first;
 return new_last->next == ((void *)0);
}
# 219 "./include/linux/llist.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool llist_add(struct llist_node *new, struct llist_head *head)
{
 return llist_add_batch(new, new, head);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __llist_add(struct llist_node *new, struct llist_head *head)
{
 return __llist_add_batch(new, new, head);
}
# 237 "./include/linux/llist.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct llist_node *llist_del_all(struct llist_head *head)
{
 return ({ typeof(&head->first) __ai_ptr = (&head->first); instrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); ({ __typeof__(*(__ai_ptr)) __res; if (0 == 0) do { } while (0); __res = (__typeof__(*(__ai_ptr))) __xchg((__ai_ptr), (unsigned long)(((void *)0)), sizeof(*(__ai_ptr))); do { } while (0); __res; }); });
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct llist_node *__llist_del_all(struct llist_head *head)
{
 struct llist_node *first = head->first;

 head->first = ((void *)0);
 return first;
}

extern struct llist_node *llist_del_first(struct llist_head *head);

struct llist_node *llist_reverse_order(struct llist_node *head);
# 6 "./include/linux/smp_types.h" 2

enum {
 CSD_FLAG_LOCK = 0x01,

 IRQ_WORK_PENDING = 0x01,
 IRQ_WORK_BUSY = 0x02,
 IRQ_WORK_LAZY = 0x04,
 IRQ_WORK_HARD_IRQ = 0x08,

 IRQ_WORK_CLAIMED = (IRQ_WORK_PENDING | IRQ_WORK_BUSY),

 CSD_TYPE_ASYNC = 0x00,
 CSD_TYPE_SYNC = 0x10,
 CSD_TYPE_IRQ_WORK = 0x20,
 CSD_TYPE_TTWU = 0x30,

 CSD_FLAG_TYPE_MASK = 0xF0,
};
# 58 "./include/linux/smp_types.h"
struct __call_single_node {
 struct llist_node llist;
 union {
  unsigned int u_flags;
  atomic_t a_flags;
 };



};
# 16 "./include/linux/smp.h" 2

typedef void (*smp_call_func_t)(void *info);
typedef bool (*smp_cond_func_t)(int cpu, void *info);




struct __call_single_data {
 struct __call_single_node node;
 smp_call_func_t func;
 void *info;
};





typedef struct __call_single_data call_single_data_t
 __attribute__((__aligned__(sizeof(struct __call_single_data))));
# 45 "./include/linux/smp.h"
extern void __smp_call_single_queue(int cpu, struct llist_node *node);


extern unsigned int total_cpus;

int smp_call_function_single(int cpuid, smp_call_func_t func, void *info,
        int wait);

void on_each_cpu_cond_mask(smp_cond_func_t cond_func, smp_call_func_t func,
      void *info, bool wait, const struct cpumask *mask);

int smp_call_function_single_async(int cpu, struct __call_single_data *csd);





void panic_smp_self_stop(void);
void nmi_panic_self_stop(struct pt_regs *regs);
void crash_smp_send_stop(void);




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void on_each_cpu(smp_call_func_t func, void *info, int wait)
{
 on_each_cpu_cond_mask(((void *)0), func, info, wait, ((const struct cpumask *)&__cpu_online_mask));
}
# 90 "./include/linux/smp.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void on_each_cpu_mask(const struct cpumask *mask,
        smp_call_func_t func, void *info, bool wait)
{
 on_each_cpu_cond_mask(((void *)0), func, info, wait, mask);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void on_each_cpu_cond(smp_cond_func_t cond_func,
        smp_call_func_t func, void *info, bool wait)
{
 on_each_cpu_cond_mask(cond_func, func, info, wait, ((const struct cpumask *)&__cpu_online_mask));
}



# 1 "./include/linux/preempt.h" 1
# 78 "./include/linux/preempt.h"
# 1 "./arch/mips/include/generated/asm/preempt.h" 1
# 1 "./include/asm-generic/preempt.h" 1




# 1 "./include/linux/thread_info.h" 1
# 14 "./include/linux/thread_info.h"
# 1 "./include/linux/restart_block.h" 1
# 12 "./include/linux/restart_block.h"
struct timespec;
struct old_timespec32;
struct pollfd;

enum timespec_type {
 TT_NONE = 0,
 TT_NATIVE = 1,
 TT_COMPAT = 2,
};




struct restart_block {
 unsigned long arch_data;
 long (*fn)(struct restart_block *);
 union {

  struct {
   u32 *uaddr;
   u32 val;
   u32 flags;
   u32 bitset;
   u64 time;
   u32 *uaddr2;
  } futex;

  struct {
   clockid_t clockid;
   enum timespec_type type;
   union {
    struct __kernel_timespec *rmtp;
    struct old_timespec32 *compat_rmtp;
   };
   u64 expires;
  } nanosleep;

  struct {
   struct pollfd *ufds;
   int nfds;
   int has_timeout;
   unsigned long tv_sec;
   unsigned long tv_nsec;
  } poll;
 };
};

extern long do_no_restart_syscall(struct restart_block *parm);
# 15 "./include/linux/thread_info.h" 2
# 33 "./include/linux/thread_info.h"
enum {
 BAD_STACK = -1,
 NOT_STACK = 0,
 GOOD_FRAME,
 GOOD_STACK,
};
# 60 "./include/linux/thread_info.h"
# 1 "./arch/mips/include/asm/thread_info.h" 1
# 16 "./arch/mips/include/asm/thread_info.h"
# 1 "./arch/mips/include/asm/processor.h" 1
# 16 "./arch/mips/include/asm/processor.h"
# 1 "./include/linux/sizes.h" 1
# 17 "./arch/mips/include/asm/processor.h" 2


# 1 "./arch/mips/include/uapi/asm/cachectl.h" 1
# 20 "./arch/mips/include/asm/processor.h" 2


# 1 "./arch/mips/include/asm/dsemul.h" 1
# 11 "./arch/mips/include/asm/dsemul.h"
# 1 "./arch/mips/include/asm/inst.h" 1
# 14 "./arch/mips/include/asm/inst.h"
# 1 "./arch/mips/include/uapi/asm/inst.h" 1
# 17 "./arch/mips/include/uapi/asm/inst.h"
# 1 "./arch/mips/include/uapi/asm/bitfield.h" 1
# 18 "./arch/mips/include/uapi/asm/inst.h" 2




enum major_op {
 spec_op, bcond_op, j_op, jal_op,
 beq_op, bne_op, blez_op, bgtz_op,
 addi_op, pop10_op = addi_op, addiu_op, slti_op, sltiu_op,
 andi_op, ori_op, xori_op, lui_op,
 cop0_op, cop1_op, cop2_op, cop1x_op,
 beql_op, bnel_op, blezl_op, bgtzl_op,
 daddi_op, pop30_op = daddi_op, daddiu_op, ldl_op, ldr_op,
 spec2_op, jalx_op, mdmx_op, msa_op = mdmx_op, spec3_op,
 lb_op, lh_op, lwl_op, lw_op,
 lbu_op, lhu_op, lwr_op, lwu_op,
 sb_op, sh_op, swl_op, sw_op,
 sdl_op, sdr_op, swr_op, cache_op,
 ll_op, lwc1_op, lwc2_op, bc6_op = lwc2_op, pref_op,
 lld_op, ldc1_op, ldc2_op, pop66_op = ldc2_op, ld_op,
 sc_op, swc1_op, swc2_op, balc6_op = swc2_op, major_3b_op,
 scd_op, sdc1_op, sdc2_op, pop76_op = sdc2_op, sd_op
};




enum spec_op {
 sll_op, movc_op, srl_op, sra_op,
 sllv_op, pmon_op, srlv_op, srav_op,
 jr_op, jalr_op, movz_op, movn_op,
 syscall_op, break_op, spim_op, sync_op,
 mfhi_op, mthi_op, mflo_op, mtlo_op,
 dsllv_op, spec2_unused_op, dsrlv_op, dsrav_op,
 mult_op, multu_op, div_op, divu_op,
 dmult_op, dmultu_op, ddiv_op, ddivu_op,
 add_op, addu_op, sub_op, subu_op,
 and_op, or_op, xor_op, nor_op,
 spec3_unused_op, spec4_unused_op, slt_op, sltu_op,
 dadd_op, daddu_op, dsub_op, dsubu_op,
 tge_op, tgeu_op, tlt_op, tltu_op,
 teq_op, seleqz_op, tne_op, selnez_op,
 dsll_op, spec5_unused_op, dsrl_op, dsra_op,
 dsll32_op, spec6_unused_op, dsrl32_op, dsra32_op
};




enum spec2_op {
 madd_op, maddu_op, mul_op, spec2_3_unused_op,
 msub_op, msubu_op,
 clz_op = 0x20, clo_op,
 dclz_op = 0x24, dclo_op,
 sdbpp_op = 0x3f
};




enum spec3_op {
 ext_op, dextm_op, dextu_op, dext_op,
 ins_op, dinsm_op, dinsu_op, dins_op,
 yield_op = 0x09, lx_op = 0x0a,
 lwle_op = 0x19, lwre_op = 0x1a,
 cachee_op = 0x1b, sbe_op = 0x1c,
 she_op = 0x1d, sce_op = 0x1e,
 swe_op = 0x1f, bshfl_op = 0x20,
 swle_op = 0x21, swre_op = 0x22,
 prefe_op = 0x23, dbshfl_op = 0x24,
 cache6_op = 0x25, sc6_op = 0x26,
 scd6_op = 0x27, lbue_op = 0x28,
 lhue_op = 0x29, lbe_op = 0x2c,
 lhe_op = 0x2d, lle_op = 0x2e,
 lwe_op = 0x2f, pref6_op = 0x35,
 ll6_op = 0x36, lld6_op = 0x37,
 rdhwr_op = 0x3b
};




enum mult_op {
 mult_mult_op = 0x0,
 mult_mul_op = 0x2,
 mult_muh_op = 0x3,
};
enum multu_op {
 multu_multu_op = 0x0,
 multu_mulu_op = 0x2,
 multu_muhu_op = 0x3,
};
enum div_op {
 div_div_op = 0x0,
 div_div6_op = 0x2,
 div_mod_op = 0x3,
};
enum divu_op {
 divu_divu_op = 0x0,
 divu_divu6_op = 0x2,
 divu_modu_op = 0x3,
};
enum dmult_op {
 dmult_dmult_op = 0x0,
 dmult_dmul_op = 0x2,
 dmult_dmuh_op = 0x3,
};
enum dmultu_op {
 dmultu_dmultu_op = 0x0,
 dmultu_dmulu_op = 0x2,
 dmultu_dmuhu_op = 0x3,
};
enum ddiv_op {
 ddiv_ddiv_op = 0x0,
 ddiv_ddiv6_op = 0x2,
 ddiv_dmod_op = 0x3,
};
enum ddivu_op {
 ddivu_ddivu_op = 0x0,
 ddivu_ddivu6_op = 0x2,
 ddivu_dmodu_op = 0x3,
};




enum rt_op {
 bltz_op, bgez_op, bltzl_op, bgezl_op,
 spimi_op, unused_rt_op_0x05, unused_rt_op_0x06, unused_rt_op_0x07,
 tgei_op, tgeiu_op, tlti_op, tltiu_op,
 teqi_op, unused_0x0d_rt_op, tnei_op, unused_0x0f_rt_op,
 bltzal_op, bgezal_op, bltzall_op, bgezall_op,
 rt_op_0x14, rt_op_0x15, rt_op_0x16, rt_op_0x17,
 rt_op_0x18, rt_op_0x19, rt_op_0x1a, rt_op_0x1b,
 bposge32_op, rt_op_0x1d, rt_op_0x1e, synci_op
};




enum cop_op {
 mfc_op = 0x00, dmfc_op = 0x01,
 cfc_op = 0x02, mfhc0_op = 0x02,
 mfhc_op = 0x03, mtc_op = 0x04,
 dmtc_op = 0x05, ctc_op = 0x06,
 mthc0_op = 0x06, mthc_op = 0x07,
 bc_op = 0x08, bc1eqz_op = 0x09,
 mfmc0_op = 0x0b, bc1nez_op = 0x0d,
 wrpgpr_op = 0x0e, cop_op = 0x10,
 copm_op = 0x18
};




enum bcop_op {
 bcf_op, bct_op, bcfl_op, bctl_op
};




enum cop0_coi_func {
 tlbr_op = 0x01, tlbwi_op = 0x02,
 tlbwr_op = 0x06, tlbp_op = 0x08,
 rfe_op = 0x10, eret_op = 0x18,
 wait_op = 0x20, hypcall_op = 0x28
};




enum cop0_com_func {
 tlbr1_op = 0x01, tlbw_op = 0x02,
 tlbp1_op = 0x08, dctr_op = 0x09,
 dctw_op = 0x0a
};




enum cop1_fmt {
 s_fmt, d_fmt, e_fmt, q_fmt,
 w_fmt, l_fmt
};




enum cop1_sdw_func {
 fadd_op = 0x00, fsub_op = 0x01,
 fmul_op = 0x02, fdiv_op = 0x03,
 fsqrt_op = 0x04, fabs_op = 0x05,
 fmov_op = 0x06, fneg_op = 0x07,
 froundl_op = 0x08, ftruncl_op = 0x09,
 fceill_op = 0x0a, ffloorl_op = 0x0b,
 fround_op = 0x0c, ftrunc_op = 0x0d,
 fceil_op = 0x0e, ffloor_op = 0x0f,
 fsel_op = 0x10,
 fmovc_op = 0x11, fmovz_op = 0x12,
 fmovn_op = 0x13, fseleqz_op = 0x14,
 frecip_op = 0x15, frsqrt_op = 0x16,
 fselnez_op = 0x17, fmaddf_op = 0x18,
 fmsubf_op = 0x19, frint_op = 0x1a,
 fclass_op = 0x1b, fmin_op = 0x1c,
 fmina_op = 0x1d, fmax_op = 0x1e,
 fmaxa_op = 0x1f, fcvts_op = 0x20,
 fcvtd_op = 0x21, fcvte_op = 0x22,
 fcvtw_op = 0x24, fcvtl_op = 0x25,
 fcmp_op = 0x30
};




enum cop1x_func {
 lwxc1_op = 0x00, ldxc1_op = 0x01,
 swxc1_op = 0x08, sdxc1_op = 0x09,
 pfetch_op = 0x0f, madd_s_op = 0x20,
 madd_d_op = 0x21, madd_e_op = 0x22,
 msub_s_op = 0x28, msub_d_op = 0x29,
 msub_e_op = 0x2a, nmadd_s_op = 0x30,
 nmadd_d_op = 0x31, nmadd_e_op = 0x32,
 nmsub_s_op = 0x38, nmsub_d_op = 0x39,
 nmsub_e_op = 0x3a
};




enum mad_func {
 madd_fp_op = 0x08, msub_fp_op = 0x0a,
 nmadd_fp_op = 0x0c, nmsub_fp_op = 0x0e
};




enum ptw_func {
 lwdir_op = 0x00,
 lwpte_op = 0x01,
 lddir_op = 0x02,
 ldpte_op = 0x03,
};




enum lx_func {
 lwx_op = 0x00,
 lhx_op = 0x04,
 lbux_op = 0x06,
 ldx_op = 0x08,
 lwux_op = 0x10,
 lhux_op = 0x14,
 lbx_op = 0x16,
};




enum bshfl_func {
 wsbh_op = 0x2,
 seb_op = 0x10,
 seh_op = 0x18,
};




enum dbshfl_func {
 dsbh_op = 0x2,
 dshd_op = 0x5,
};




enum msa_func {
 msa_elm_op = 0x19,
};




enum msa_elm {
 msa_ctc_op = 0x3e,
 msa_cfc_op = 0x7e,
};




enum msa_mi10_func {
 msa_ld_op = 8,
 msa_st_op = 9,
};




enum msa_2b_fmt {
 msa_fmt_b = 0,
 msa_fmt_h = 1,
 msa_fmt_w = 2,
 msa_fmt_d = 3,
};




enum mm_major_op {
 mm_pool32a_op, mm_pool16a_op, mm_lbu16_op, mm_move16_op,
 mm_addi32_op, mm_lbu32_op, mm_sb32_op, mm_lb32_op,
 mm_pool32b_op, mm_pool16b_op, mm_lhu16_op, mm_andi16_op,
 mm_addiu32_op, mm_lhu32_op, mm_sh32_op, mm_lh32_op,
 mm_pool32i_op, mm_pool16c_op, mm_lwsp16_op, mm_pool16d_op,
 mm_ori32_op, mm_pool32f_op, mm_pool32s_op, mm_reserved2_op,
 mm_pool32c_op, mm_lwgp16_op, mm_lw16_op, mm_pool16e_op,
 mm_xori32_op, mm_jals32_op, mm_addiupc_op, mm_reserved3_op,
 mm_reserved4_op, mm_pool16f_op, mm_sb16_op, mm_beqz16_op,
 mm_slti32_op, mm_beq32_op, mm_swc132_op, mm_lwc132_op,
 mm_reserved5_op, mm_reserved6_op, mm_sh16_op, mm_bnez16_op,
 mm_sltiu32_op, mm_bne32_op, mm_sdc132_op, mm_ldc132_op,
 mm_reserved7_op, mm_reserved8_op, mm_swsp16_op, mm_b16_op,
 mm_andi32_op, mm_j32_op, mm_sd32_op, mm_ld32_op,
 mm_reserved11_op, mm_reserved12_op, mm_sw16_op, mm_li16_op,
 mm_jalx32_op, mm_jal32_op, mm_sw32_op, mm_lw32_op,
};




enum mm_32i_minor_op {
 mm_bltz_op, mm_bltzal_op, mm_bgez_op, mm_bgezal_op,
 mm_blez_op, mm_bnezc_op, mm_bgtz_op, mm_beqzc_op,
 mm_tlti_op, mm_tgei_op, mm_tltiu_op, mm_tgeiu_op,
 mm_tnei_op, mm_lui_op, mm_teqi_op, mm_reserved13_op,
 mm_synci_op, mm_bltzals_op, mm_reserved14_op, mm_bgezals_op,
 mm_bc2f_op, mm_bc2t_op, mm_reserved15_op, mm_reserved16_op,
 mm_reserved17_op, mm_reserved18_op, mm_bposge64_op, mm_bposge32_op,
 mm_bc1f_op, mm_bc1t_op, mm_reserved19_op, mm_reserved20_op,
 mm_bc1any2f_op, mm_bc1any2t_op, mm_bc1any4f_op, mm_bc1any4t_op,
};




enum mm_32a_minor_op {
 mm_sll32_op = 0x000,
 mm_ins_op = 0x00c,
 mm_sllv32_op = 0x010,
 mm_ext_op = 0x02c,
 mm_pool32axf_op = 0x03c,
 mm_srl32_op = 0x040,
 mm_srlv32_op = 0x050,
 mm_sra_op = 0x080,
 mm_srav_op = 0x090,
 mm_rotr_op = 0x0c0,
 mm_lwxs_op = 0x118,
 mm_addu32_op = 0x150,
 mm_subu32_op = 0x1d0,
 mm_wsbh_op = 0x1ec,
 mm_mul_op = 0x210,
 mm_and_op = 0x250,
 mm_or32_op = 0x290,
 mm_xor32_op = 0x310,
 mm_slt_op = 0x350,
 mm_sltu_op = 0x390,
};




enum mm_32b_func {
 mm_lwc2_func = 0x0,
 mm_lwp_func = 0x1,
 mm_ldc2_func = 0x2,
 mm_ldp_func = 0x4,
 mm_lwm32_func = 0x5,
 mm_cache_func = 0x6,
 mm_ldm_func = 0x7,
 mm_swc2_func = 0x8,
 mm_swp_func = 0x9,
 mm_sdc2_func = 0xa,
 mm_sdp_func = 0xc,
 mm_swm32_func = 0xd,
 mm_sdm_func = 0xf,
};




enum mm_32c_func {
 mm_pref_func = 0x2,
 mm_ll_func = 0x3,
 mm_swr_func = 0x9,
 mm_sc_func = 0xb,
 mm_lwu_func = 0xe,
};




enum mm_32axf_minor_op {
 mm_mfc0_op = 0x003,
 mm_mtc0_op = 0x00b,
 mm_tlbp_op = 0x00d,
 mm_mfhi32_op = 0x035,
 mm_jalr_op = 0x03c,
 mm_tlbr_op = 0x04d,
 mm_mflo32_op = 0x075,
 mm_jalrhb_op = 0x07c,
 mm_tlbwi_op = 0x08d,
 mm_mthi32_op = 0x0b5,
 mm_tlbwr_op = 0x0cd,
 mm_mtlo32_op = 0x0f5,
 mm_di_op = 0x11d,
 mm_jalrs_op = 0x13c,
 mm_jalrshb_op = 0x17c,
 mm_sync_op = 0x1ad,
 mm_syscall_op = 0x22d,
 mm_wait_op = 0x24d,
 mm_eret_op = 0x3cd,
 mm_divu_op = 0x5dc,
};




enum mm_32f_minor_op {
 mm_32f_00_op = 0x00,
 mm_32f_01_op = 0x01,
 mm_32f_02_op = 0x02,
 mm_32f_10_op = 0x08,
 mm_32f_11_op = 0x09,
 mm_32f_12_op = 0x0a,
 mm_32f_20_op = 0x10,
 mm_32f_30_op = 0x18,
 mm_32f_40_op = 0x20,
 mm_32f_41_op = 0x21,
 mm_32f_42_op = 0x22,
 mm_32f_50_op = 0x28,
 mm_32f_51_op = 0x29,
 mm_32f_52_op = 0x2a,
 mm_32f_60_op = 0x30,
 mm_32f_70_op = 0x38,
 mm_32f_73_op = 0x3b,
 mm_32f_74_op = 0x3c,
};




enum mm_32f_10_minor_op {
 mm_lwxc1_op = 0x1,
 mm_swxc1_op,
 mm_ldxc1_op,
 mm_sdxc1_op,
 mm_luxc1_op,
 mm_suxc1_op,
};

enum mm_32f_func {
 mm_lwxc1_func = 0x048,
 mm_swxc1_func = 0x088,
 mm_ldxc1_func = 0x0c8,
 mm_sdxc1_func = 0x108,
};




enum mm_32f_40_minor_op {
 mm_fmovf_op,
 mm_fmovt_op,
};




enum mm_32f_60_minor_op {
 mm_fadd_op,
 mm_fsub_op,
 mm_fmul_op,
 mm_fdiv_op,
};




enum mm_32f_70_minor_op {
 mm_fmovn_op,
 mm_fmovz_op,
};




enum mm_32f_73_minor_op {
 mm_fmov0_op = 0x01,
 mm_fcvtl_op = 0x04,
 mm_movf0_op = 0x05,
 mm_frsqrt_op = 0x08,
 mm_ffloorl_op = 0x0c,
 mm_fabs0_op = 0x0d,
 mm_fcvtw_op = 0x24,
 mm_movt0_op = 0x25,
 mm_fsqrt_op = 0x28,
 mm_ffloorw_op = 0x2c,
 mm_fneg0_op = 0x2d,
 mm_cfc1_op = 0x40,
 mm_frecip_op = 0x48,
 mm_fceill_op = 0x4c,
 mm_fcvtd0_op = 0x4d,
 mm_ctc1_op = 0x60,
 mm_fceilw_op = 0x6c,
 mm_fcvts0_op = 0x6d,
 mm_mfc1_op = 0x80,
 mm_fmov1_op = 0x81,
 mm_movf1_op = 0x85,
 mm_ftruncl_op = 0x8c,
 mm_fabs1_op = 0x8d,
 mm_mtc1_op = 0xa0,
 mm_movt1_op = 0xa5,
 mm_ftruncw_op = 0xac,
 mm_fneg1_op = 0xad,
 mm_mfhc1_op = 0xc0,
 mm_froundl_op = 0xcc,
 mm_fcvtd1_op = 0xcd,
 mm_mthc1_op = 0xe0,
 mm_froundw_op = 0xec,
 mm_fcvts1_op = 0xed,
};




enum mm_32s_minor_op {
 mm_32s_elm_op = 0x16,
};




enum mm_16c_minor_op {
 mm_lwm16_op = 0x04,
 mm_swm16_op = 0x05,
 mm_jr16_op = 0x0c,
 mm_jrc_op = 0x0d,
 mm_jalr16_op = 0x0e,
 mm_jalrs16_op = 0x0f,
 mm_jraddiusp_op = 0x18,
};




enum mm_16d_minor_op {
 mm_addius5_func,
 mm_addiusp_func,
};




enum MIPS16e_ops {
 MIPS16e_jal_op = 003,
 MIPS16e_ld_op = 007,
 MIPS16e_i8_op = 014,
 MIPS16e_sd_op = 017,
 MIPS16e_lb_op = 020,
 MIPS16e_lh_op = 021,
 MIPS16e_lwsp_op = 022,
 MIPS16e_lw_op = 023,
 MIPS16e_lbu_op = 024,
 MIPS16e_lhu_op = 025,
 MIPS16e_lwpc_op = 026,
 MIPS16e_lwu_op = 027,
 MIPS16e_sb_op = 030,
 MIPS16e_sh_op = 031,
 MIPS16e_swsp_op = 032,
 MIPS16e_sw_op = 033,
 MIPS16e_rr_op = 035,
 MIPS16e_extend_op = 036,
 MIPS16e_i64_op = 037,
};

enum MIPS16e_i64_func {
 MIPS16e_ldsp_func,
 MIPS16e_sdsp_func,
 MIPS16e_sdrasp_func,
 MIPS16e_dadjsp_func,
 MIPS16e_ldpc_func,
};

enum MIPS16e_rr_func {
 MIPS16e_jr_func,
};

enum MIPS6e_i8_func {
 MIPS16e_swrasp_func = 02,
};






struct j_format {
 unsigned int opcode : 6; unsigned int target : 26; ;


};

struct i_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int rt : 5; signed int simmediate : 16; ;




};

struct u_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int rt : 5; unsigned int uimmediate : 16; ;




};

struct c_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int c_op : 3; unsigned int cache : 2; unsigned int simmediate : 16; ;





};

struct r_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int rt : 5; unsigned int rd : 5; unsigned int re : 5; unsigned int func : 6; ;






};

struct c0r_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int rt : 5; unsigned int rd : 5; unsigned int z: 8; unsigned int sel : 3; ;






};

struct mfmc0_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int rt : 5; unsigned int rd : 5; unsigned int re : 5; unsigned int sc : 1; unsigned int : 2; unsigned int sel : 3; ;
# 687 "./arch/mips/include/uapi/asm/inst.h"
};

struct co_format {
 unsigned int opcode : 6; unsigned int co : 1; unsigned int code : 19; unsigned int func : 6; ;




};

struct p_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int rt : 5; unsigned int rd : 5; unsigned int re : 5; unsigned int func : 6; ;






};

struct f_format {
 unsigned int opcode : 6; unsigned int : 1; unsigned int fmt : 4; unsigned int rt : 5; unsigned int rd : 5; unsigned int re : 5; unsigned int func : 6; ;







};

struct ma_format {
 unsigned int opcode : 6; unsigned int fr : 5; unsigned int ft : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int func : 4; unsigned int fmt : 2; ;







};

struct b_format {
 unsigned int opcode : 6; unsigned int code : 20; unsigned int func : 6; ;



};

struct ps_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int ft : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int func : 6; ;






};

struct v_format {
 unsigned int opcode : 6; unsigned int sel : 4; unsigned int fmt : 1; unsigned int vt : 5; unsigned int vs : 5; unsigned int vd : 5; unsigned int func : 6; ;







};

struct msa_mi10_format {
 unsigned int opcode : 6; signed int s10 : 10; unsigned int rs : 5; unsigned int wd : 5; unsigned int func : 4; unsigned int df : 2; ;






};

struct dsp_format {
 unsigned int opcode : 6; unsigned int base : 5; unsigned int index : 5; unsigned int rd : 5; unsigned int op : 5; unsigned int func : 6; ;






};

struct spec3_format {
 unsigned int opcode:6; unsigned int rs:5; unsigned int rt:5; signed int simmediate:9; unsigned int func:7; ;





};
# 793 "./arch/mips/include/uapi/asm/inst.h"
struct fb_format {
 unsigned int opcode : 6; unsigned int bc : 5; unsigned int cc : 3; unsigned int flag : 2; signed int simmediate : 16; ;





};

struct fp0_format {
 unsigned int opcode : 6; unsigned int fmt : 5; unsigned int ft : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int func : 6; ;






};

struct mm_fp0_format {
 unsigned int opcode : 6; unsigned int ft : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int fmt : 3; unsigned int op : 2; unsigned int func : 6; ;







};

struct fp1_format {
 unsigned int opcode : 6; unsigned int op : 5; unsigned int rt : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int func : 6; ;






};

struct mm_fp1_format {
 unsigned int opcode : 6; unsigned int rt : 5; unsigned int fs : 5; unsigned int fmt : 2; unsigned int op : 8; unsigned int func : 6; ;






};

struct mm_fp2_format {
 unsigned int opcode : 6; unsigned int fd : 5; unsigned int fs : 5; unsigned int cc : 3; unsigned int zero : 2; unsigned int fmt : 2; unsigned int op : 3; unsigned int func : 6; ;
# 853 "./arch/mips/include/uapi/asm/inst.h"
};

struct mm_fp3_format {
 unsigned int opcode : 6; unsigned int rt : 5; unsigned int fs : 5; unsigned int fmt : 3; unsigned int op : 7; unsigned int func : 6; ;






};

struct mm_fp4_format {
 unsigned int opcode : 6; unsigned int rt : 5; unsigned int fs : 5; unsigned int cc : 3; unsigned int fmt : 3; unsigned int cond : 4; unsigned int func : 6; ;







};

struct mm_fp5_format {
 unsigned int opcode : 6; unsigned int index : 5; unsigned int base : 5; unsigned int fd : 5; unsigned int op : 5; unsigned int func : 6; ;






};

struct fp6_format {
 unsigned int opcode : 6; unsigned int fr : 5; unsigned int ft : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int func : 6; ;






};

struct mm_fp6_format {
 unsigned int opcode : 6; unsigned int ft : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int fr : 5; unsigned int func : 6; ;






};

struct mm_i_format {
 unsigned int opcode : 6; unsigned int rt : 5; unsigned int rs : 5; signed int simmediate : 16; ;




};

struct mm_m_format {
 unsigned int opcode : 6; unsigned int rd : 5; unsigned int base : 5; unsigned int func : 4; signed int simmediate : 12; ;





};

struct mm_x_format {
 unsigned int opcode : 6; unsigned int index : 5; unsigned int base : 5; unsigned int rd : 5; unsigned int func : 11; ;





};

struct mm_a_format {
 unsigned int opcode : 6; unsigned int rs : 3; signed int simmediate : 23; ;



};




struct mm_b0_format {
 unsigned int opcode : 6; signed int simmediate : 10; unsigned int : 16; ;



};

struct mm_b1_format {
 unsigned int opcode : 6; unsigned int rs : 3; signed int simmediate : 7; unsigned int : 16; ;




};

struct mm16_m_format {
 unsigned int opcode : 6; unsigned int func : 4; unsigned int rlist : 2; unsigned int imm : 4; unsigned int : 16; ;





};

struct mm16_rb_format {
 unsigned int opcode : 6; unsigned int rt : 3; unsigned int base : 3; signed int simmediate : 4; unsigned int : 16; ;





};

struct mm16_r3_format {
 unsigned int opcode : 6; unsigned int rt : 3; signed int simmediate : 7; unsigned int : 16; ;




};

struct mm16_r5_format {
 unsigned int opcode : 6; unsigned int rt : 5; unsigned int imm : 5; unsigned int : 16; ;




};




struct loongson3_lswc2_format {
 unsigned int opcode : 6; unsigned int base : 5; unsigned int rt : 5; unsigned int fr : 1; unsigned int offset : 9; unsigned int ls : 1; unsigned int rq : 5; ;







};

struct loongson3_lsdc2_format {
 unsigned int opcode : 6; unsigned int base : 5; unsigned int rt : 5; unsigned int index : 5; unsigned int offset : 8; unsigned int opcode1 : 3; ;






};

struct loongson3_lscsr_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int fr : 5; unsigned int rd : 5; unsigned int fd : 5; unsigned int func : 6; ;






};




struct m16e_rr {
 unsigned int opcode : 5; unsigned int rx : 3; unsigned int nd : 1; unsigned int l : 1; unsigned int ra : 1; unsigned int func : 5; ;






};

struct m16e_jal {
 unsigned int opcode : 5; unsigned int x : 1; unsigned int imm20_16 : 5; signed int imm25_21 : 5; ;




};

struct m16e_i64 {
 unsigned int opcode : 5; unsigned int func : 3; unsigned int imm : 8; ;



};

struct m16e_ri64 {
 unsigned int opcode : 5; unsigned int func : 3; unsigned int ry : 3; unsigned int imm : 5; ;




};

struct m16e_ri {
 unsigned int opcode : 5; unsigned int rx : 3; unsigned int imm : 8; ;



};

struct m16e_rri {
 unsigned int opcode : 5; unsigned int rx : 3; unsigned int ry : 3; unsigned int imm : 5; ;




};

struct m16e_i8 {
 unsigned int opcode : 5; unsigned int func : 3; unsigned int imm : 8; ;



};

union mips_instruction {
 unsigned int word;
 unsigned short halfword[2];
 unsigned char byte[4];
 struct j_format j_format;
 struct i_format i_format;
 struct u_format u_format;
 struct c_format c_format;
 struct r_format r_format;
 struct c0r_format c0r_format;
 struct mfmc0_format mfmc0_format;
 struct co_format co_format;
 struct p_format p_format;
 struct f_format f_format;
 struct ma_format ma_format;
 struct msa_mi10_format msa_mi10_format;
 struct b_format b_format;
 struct ps_format ps_format;
 struct v_format v_format;
 struct dsp_format dsp_format;
 struct spec3_format spec3_format;
 struct fb_format fb_format;
 struct fp0_format fp0_format;
 struct mm_fp0_format mm_fp0_format;
 struct fp1_format fp1_format;
 struct mm_fp1_format mm_fp1_format;
 struct mm_fp2_format mm_fp2_format;
 struct mm_fp3_format mm_fp3_format;
 struct mm_fp4_format mm_fp4_format;
 struct mm_fp5_format mm_fp5_format;
 struct fp6_format fp6_format;
 struct mm_fp6_format mm_fp6_format;
 struct mm_i_format mm_i_format;
 struct mm_m_format mm_m_format;
 struct mm_x_format mm_x_format;
 struct mm_a_format mm_a_format;
 struct mm_b0_format mm_b0_format;
 struct mm_b1_format mm_b1_format;
 struct mm16_m_format mm16_m_format ;
 struct mm16_rb_format mm16_rb_format;
 struct mm16_r3_format mm16_r3_format;
 struct mm16_r5_format mm16_r5_format;
 struct loongson3_lswc2_format loongson3_lswc2_format;
 struct loongson3_lsdc2_format loongson3_lsdc2_format;
 struct loongson3_lscsr_format loongson3_lscsr_format;
};

union mips16e_instruction {
 unsigned int full : 16;
 struct m16e_rr rr;
 struct m16e_jal jal;
 struct m16e_i64 i64;
 struct m16e_ri64 ri64;
 struct m16e_ri ri;
 struct m16e_rri rri;
 struct m16e_i8 i8;
};
# 15 "./arch/mips/include/asm/inst.h" 2
# 74 "./arch/mips/include/asm/inst.h"
typedef unsigned int mips_instruction;


struct mm_decoded_insn {
 mips_instruction insn;
 mips_instruction next_insn;
 int pc_inc;
 int next_pc_inc;
 int micro_mips_mode;
};


extern const int reg16to32[];
# 12 "./arch/mips/include/asm/dsemul.h" 2







struct mm_struct;
struct pt_regs;
struct task_struct;
# 37 "./arch/mips/include/asm/dsemul.h"
extern int mips_dsemul(struct pt_regs *regs, mips_instruction ir,
         unsigned long branch_pc, unsigned long cont_pc);
# 52 "./arch/mips/include/asm/dsemul.h"
extern bool do_dsemulret(struct pt_regs *xcp);
# 70 "./arch/mips/include/asm/dsemul.h"
extern bool dsemul_thread_cleanup(struct task_struct *tsk);
# 90 "./arch/mips/include/asm/dsemul.h"
extern bool dsemul_thread_rollback(struct pt_regs *regs);
# 107 "./arch/mips/include/asm/dsemul.h"
extern void dsemul_mm_cleanup(struct mm_struct *mm);
# 23 "./arch/mips/include/asm/processor.h" 2

# 1 "./arch/mips/include/asm/prefetch.h" 1
# 25 "./arch/mips/include/asm/processor.h" 2
# 1 "./arch/mips/include/asm/vdso/processor.h" 1
# 26 "./arch/mips/include/asm/processor.h" 2





extern unsigned int vced_count, vcei_count;
extern int arch_dup_task_struct(struct task_struct *dst, struct task_struct *src);
# 73 "./arch/mips/include/asm/processor.h"
extern unsigned long mips_stack_top(void);
# 91 "./arch/mips/include/asm/processor.h"
union fpureg {
 __u32 val32[64 / 32];
 __u64 val64[64 / 64];
};
# 114 "./arch/mips/include/asm/processor.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 get_fpr32(union fpureg *fpr, unsigned idx) { return fpr->val32[((idx) ^ ((64 / (32)) - 1))]; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_fpr32(union fpureg *fpr, unsigned idx, u32 val) { fpr->val32[((idx) ^ ((64 / (32)) - 1))] = val; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 get_fpr64(union fpureg *fpr, unsigned idx) { return fpr->val64[((idx) ^ ((64 / (64)) - 1))]; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_fpr64(union fpureg *fpr, unsigned idx, u64 val) { fpr->val64[((idx) ^ ((64 / (64)) - 1))] = val; }







struct mips_fpu_struct {
 union fpureg fpr[32];
 unsigned int fcr31;
 unsigned int msacsr;
};



typedef unsigned long dspreg_t;

struct mips_dsp_state {
 dspreg_t dspr[6];
 unsigned int dspcontrol;
};





struct mips3264_watch_reg_state {



 unsigned long watchlo[4];

 u16 watchhi[4];
};

union mips_watch_reg_state {
 struct mips3264_watch_reg_state mips3264;
};
# 222 "./arch/mips/include/asm/processor.h"
struct mips_abi;




struct thread_struct {

 unsigned long reg16;
 unsigned long reg17, reg18, reg19, reg20, reg21, reg22, reg23;
 unsigned long reg29, reg30, reg31;


 unsigned long cp0_status;



 struct mips_fpu_struct fpu ;

 atomic_t bd_emu_frame;

 unsigned long bd_emu_branch_pc;

 unsigned long bd_emu_cont_pc;



 unsigned long emulated_fp;

 cpumask_t user_cpus_allowed;



 struct mips_dsp_state dsp;


 union mips_watch_reg_state watch;


 unsigned long cp0_badvaddr;
 unsigned long cp0_baduaddr;
 unsigned long error_code;
 unsigned long trap_nr;




 struct mips_abi *abi;
};
# 345 "./arch/mips/include/asm/processor.h"
struct task_struct;







extern void start_thread(struct pt_regs * regs, unsigned long pc, unsigned long sp);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void flush_thread(void)
{
}

unsigned long __get_wchan(struct task_struct *p);
# 396 "./arch/mips/include/asm/processor.h"
extern int mips_get_process_fp_mode(struct task_struct *task);
extern int mips_set_process_fp_mode(struct task_struct *task,
        unsigned int value);
# 17 "./arch/mips/include/asm/thread_info.h" 2








struct thread_info {
 struct task_struct *task;
 unsigned long flags;
 unsigned long tp_value;
 __u32 cpu;
 int preempt_count;
 struct pt_regs *regs;
 long syscall;
};
# 64 "./arch/mips/include/asm/thread_info.h"
register struct thread_info *__current_thread_info __asm__("$28");


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct thread_info *current_thread_info(void)
{
 return __current_thread_info;
}
# 61 "./include/linux/thread_info.h" 2







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) long set_restart_fn(struct restart_block *restart,
     long (*fn)(struct restart_block *))
{
 restart->fn = fn;
 do { } while (0);
 return -516;
}
# 87 "./include/linux/thread_info.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_ti_thread_flag(struct thread_info *ti, int flag)
{
 set_bit(flag, (unsigned long *)&ti->flags);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_ti_thread_flag(struct thread_info *ti, int flag)
{
 clear_bit(flag, (unsigned long *)&ti->flags);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void update_ti_thread_flag(struct thread_info *ti, int flag,
      bool value)
{
 if (value)
  set_ti_thread_flag(ti, flag);
 else
  clear_ti_thread_flag(ti, flag);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_set_ti_thread_flag(struct thread_info *ti, int flag)
{
 return test_and_set_bit(flag, (unsigned long *)&ti->flags);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_clear_ti_thread_flag(struct thread_info *ti, int flag)
{
 return test_and_clear_bit(flag, (unsigned long *)&ti->flags);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_ti_thread_flag(struct thread_info *ti, int flag)
{
 return arch_test_bit(flag, (unsigned long *)&ti->flags);
}
# 169 "./include/linux/thread_info.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_within_stack_frames(const void * const stack,
        const void * const stackend,
        const void *obj, unsigned long len)
{
 return 0;
}



extern void __check_object_size(const void *ptr, unsigned long n,
     bool to_user);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void check_object_size(const void *ptr, unsigned long n,
           bool to_user)
{
 if (!__builtin_constant_p(n))
  __check_object_size(ptr, n, to_user);
}






extern void __attribute__((__error__("copy source size is too small")))
__bad_copy_from(void);
extern void __attribute__((__error__("copy destination size is too small")))
__bad_copy_to(void);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void copy_overflow(int size, unsigned long count)
{
 ({ int __ret_warn_on = !!(1); if (__builtin_expect(!!(__ret_warn_on), 0)) do { do { } while(0); warn_slowpath_fmt("include/linux/thread_info.h", 200, 9, "Buffer overflow detected (%d < %lu)!\n", size, count); do { } while(0); } while (0); __builtin_expect(!!(__ret_warn_on), 0); });
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __attribute__((__warn_unused_result__)) bool
check_copy_size(const void *addr, size_t bytes, bool is_source)
{
 int sz = __builtin_object_size(addr, 0);
 if (__builtin_expect(!!(sz >= 0 && sz < bytes), 0)) {
  if (!__builtin_constant_p(bytes))
   copy_overflow(sz, bytes);
  else if (is_source)
   __bad_copy_from();
  else
   __bad_copy_to();
  return false;
 }
 if (({ static bool __attribute__((__section__(".data.once"))) __already_done; bool __ret_do_once = !!(bytes > ((int)(~0U >> 1))); if (__builtin_expect(!!(__ret_do_once && !__already_done), 0)) { __already_done = true; ({ int __ret_warn_on = !!(1); if (__builtin_expect(!!(__ret_warn_on), 0)) do { do { } while(0); warn_slowpath_fmt("include/linux/thread_info.h", 216, 9, ((void *)0)); do { } while(0); } while (0); __builtin_expect(!!(__ret_warn_on), 0); }); } __builtin_expect(!!(__ret_do_once), 0); }))
  return false;
 check_object_size(addr, bytes, is_source);
 return true;
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_setup_new_exec(void) { }
# 6 "./include/asm-generic/preempt.h" 2



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int preempt_count(void)
{
 return ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_33(void) __attribute__((__error__("Unsupported access size for {READ,WRITE}_ONCE()."))); if (!((sizeof(current_thread_info()->preempt_count) == sizeof(char) || sizeof(current_thread_info()->preempt_count) == sizeof(short) || sizeof(current_thread_info()->preempt_count) == sizeof(int) || sizeof(current_thread_info()->preempt_count) == sizeof(long)) || sizeof(current_thread_info()->preempt_count) == sizeof(long long))) __compiletime_assert_33(); } while (0); (*(const volatile typeof( _Generic((current_thread_info()->preempt_count), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (current_thread_info()->preempt_count))) *)&(current_thread_info()->preempt_count)); });
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) volatile int *preempt_count_ptr(void)
{
 return &current_thread_info()->preempt_count;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void preempt_count_set(int pc)
{
 *preempt_count_ptr() = pc;
}
# 35 "./include/asm-generic/preempt.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void set_preempt_need_resched(void)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void clear_preempt_need_resched(void)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool test_preempt_need_resched(void)
{
 return false;
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __preempt_count_add(int val)
{
 *preempt_count_ptr() += val;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __preempt_count_sub(int val)
{
 *preempt_count_ptr() -= val;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool __preempt_count_dec_and_test(void)
{





 return !--*preempt_count_ptr() && test_ti_thread_flag(current_thread_info(), 2);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool should_resched(int preempt_offset)
{
 return __builtin_expect(!!(preempt_count() == preempt_offset && test_ti_thread_flag(current_thread_info(), 2)), 0);

}
# 2 "./arch/mips/include/generated/asm/preempt.h" 2
# 79 "./include/linux/preempt.h" 2
# 89 "./include/linux/preempt.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned char interrupt_context_level(void)
{
 unsigned long pc = preempt_count();
 unsigned char level = 0;

 level += !!(pc & ((((1UL << (4))-1) << (((0 + 8) + 8) + 4))));
 level += !!(pc & ((((1UL << (4))-1) << (((0 + 8) + 8) + 4)) | (((1UL << (4))-1) << ((0 + 8) + 8))));
 level += !!(pc & ((((1UL << (4))-1) << (((0 + 8) + 8) + 4)) | (((1UL << (4))-1) << ((0 + 8) + 8)) | (1UL << (0 + 8))));

 return level;
}
# 414 "./include/linux/preempt.h"
extern void migrate_disable(void);
extern void migrate_enable(void);
# 111 "./include/linux/smp.h" 2


# 1 "./arch/mips/include/asm/smp.h" 1
# 16 "./arch/mips/include/asm/smp.h"
# 1 "./include/linux/smp.h" 1
# 17 "./arch/mips/include/asm/smp.h" 2




# 1 "./arch/mips/include/asm/smp-ops.h" 1
# 16 "./arch/mips/include/asm/smp-ops.h"
# 1 "./arch/mips/include/asm/mips-cps.h" 1
# 10 "./arch/mips/include/asm/mips-cps.h"
# 1 "./include/linux/io.h" 1
# 13 "./include/linux/io.h"
# 1 "./arch/mips/include/asm/io.h" 1
# 28 "./arch/mips/include/asm/io.h"
# 1 "./include/asm-generic/iomap.h" 1
# 29 "./include/asm-generic/iomap.h"
extern unsigned int ioread8(const void *);
extern unsigned int ioread16(const void *);
extern unsigned int ioread16be(const void *);
extern unsigned int ioread32(const void *);
extern unsigned int ioread32be(const void *);
# 50 "./include/asm-generic/iomap.h"
extern void iowrite8(u8, void *);
extern void iowrite16(u16, void *);
extern void iowrite16be(u16, void *);
extern void iowrite32(u32, void *);
extern void iowrite32be(u32, void *);
# 82 "./include/asm-generic/iomap.h"
extern void ioread8_rep(const void *port, void *buf, unsigned long count);
extern void ioread16_rep(const void *port, void *buf, unsigned long count);
extern void ioread32_rep(const void *port, void *buf, unsigned long count);

extern void iowrite8_rep(void *port, const void *buf, unsigned long count);
extern void iowrite16_rep(void *port, const void *buf, unsigned long count);
extern void iowrite32_rep(void *port, const void *buf, unsigned long count);



extern void *ioport_map(unsigned long port, unsigned int nr);
extern void ioport_unmap(void *);
# 107 "./include/asm-generic/iomap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *ioremap_np(phys_addr_t offset, size_t size)
{
 return ((void *)0);
}


# 1 "./include/asm-generic/pci_iomap.h" 1
# 10 "./include/asm-generic/pci_iomap.h"
struct pci_dev;


extern void *pci_iomap(struct pci_dev *dev, int bar, unsigned long max);
extern void *pci_iomap_wc(struct pci_dev *dev, int bar, unsigned long max);
extern void *pci_iomap_range(struct pci_dev *dev, int bar,
         unsigned long offset,
         unsigned long maxlen);
extern void *pci_iomap_wc_range(struct pci_dev *dev, int bar,
     unsigned long offset,
     unsigned long maxlen);
extern void pci_iounmap(struct pci_dev *dev, void *);
# 114 "./include/asm-generic/iomap.h" 2
# 29 "./arch/mips/include/asm/io.h" 2
# 1 "./arch/mips/include/asm/page.h" 1
# 42 "./arch/mips/include/asm/page.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int page_size_ftlb(unsigned int mmuextdef)
{
 switch (mmuextdef) {
 case ((unsigned long)(2) << 14):
  if (((1UL) << 12) == (1 << 30))
   return 5;
  if (((1UL) << 12) == (1llu << 32))
   return 6;
  if (((1UL) << 12) > (256 << 10))
   return 7;
  __attribute__((__fallthrough__));
 case ((unsigned long)(3) << 14):
  return (12 - 10) / 2;
 default:
  panic("Invalid FTLB configuration with Conf4_mmuextdef=%d value\n",
        mmuextdef >> 14);
 }
}
# 73 "./arch/mips/include/asm/page.h"
# 1 "./include/linux/pfn.h" 1
# 13 "./include/linux/pfn.h"
typedef struct {
 u64 val;
} pfn_t;
# 74 "./arch/mips/include/asm/page.h" 2

extern void build_clear_page(void);
extern void build_copy_page(void);







extern unsigned long ARCH_PFN_OFFSET;





extern void clear_page(void * page);
extern void copy_page(void * to, void * from);

extern unsigned long shm_align_mask;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long pages_do_alias(unsigned long addr1,
 unsigned long addr2)
{
 return (addr1 ^ addr2) & shm_align_mask;
}

struct page;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_user_page(void *addr, unsigned long vaddr,
 struct page *page)
{
 extern void (*flush_data_cache_page)(unsigned long addr);

 clear_page(addr);
 if (pages_do_alias((unsigned long) addr, vaddr & (~((1 << 12) - 1))))
  flush_data_cache_page((unsigned long)addr);
}

struct vm_area_struct;
extern void copy_user_highpage(struct page *to, struct page *from,
 unsigned long vaddr, struct vm_area_struct *vma);
# 133 "./arch/mips/include/asm/page.h"
typedef struct { unsigned long pte; } pte_t;



typedef struct page *pgtable_t;
# 147 "./arch/mips/include/asm/page.h"
typedef struct { unsigned long pgd; } pgd_t;






typedef struct { unsigned long pgprot; } pgprot_t;
# 171 "./arch/mips/include/asm/page.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long ___pa(unsigned long x)
{
 if (0) {





  return x < 0x80000000 ? (((__s64)(x)) & 0x0000ffffffffffffLL) : (((int)(int)(x)) & 0x1fffffff);
 }

 if (!0) {






  return (((int)(int)(x)) & 0x1fffffff);
 }





 return x - ((0x80000000UL) + ((unsigned long)((phys_addr_t)(ARCH_PFN_OFFSET) << 12))) + ((unsigned long)((phys_addr_t)(ARCH_PFN_OFFSET) << 12));
}


# 1 "./arch/mips/include/asm/io.h" 1
# 201 "./arch/mips/include/asm/page.h" 2
# 216 "./arch/mips/include/asm/page.h"
extern phys_addr_t __phys_addr_symbol(unsigned long x);
# 229 "./arch/mips/include/asm/page.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int pfn_valid(unsigned long pfn)
{

 extern unsigned long max_mapnr;
 unsigned long pfn_offset = ARCH_PFN_OFFSET;

 return pfn >= pfn_offset && pfn < max_mapnr;
}
# 258 "./arch/mips/include/asm/page.h"
extern bool __virt_addr_valid(const volatile void *kaddr);





extern unsigned long __kaslr_offset;
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long kaslr_offset(void)
{
 return __kaslr_offset;
}

# 1 "./include/asm-generic/memory_model.h" 1
# 271 "./arch/mips/include/asm/page.h" 2
# 1 "./include/asm-generic/getorder.h" 1
# 29 "./include/asm-generic/getorder.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __attribute__((__const__)) int get_order(unsigned long size)
{
 if (__builtin_constant_p(size)) {
  if (!size)
   return 32 - 12;

  if (size < (1UL << 12))
   return 0;

  return ( __builtin_constant_p((size) - 1) ? (((size) - 1) < 2 ? 0 : 63 - __builtin_clzll((size) - 1)) : (sizeof((size) - 1) <= 4) ? __ilog2_u32((size) - 1) : __ilog2_u64((size) - 1) ) - 12 + 1;
 }

 size--;
 size >>= 12;

 return fls(size);



}
# 272 "./arch/mips/include/asm/page.h" 2
# 30 "./arch/mips/include/asm/io.h" 2
# 1 "./arch/mips/include/asm/pgtable-bits.h" 1
# 122 "./arch/mips/include/asm/pgtable-bits.h"
enum pgtable_bits {

 _PAGE_PRESENT_SHIFT,

 _PAGE_NO_READ_SHIFT,

 _PAGE_WRITE_SHIFT,
 _PAGE_ACCESSED_SHIFT,
 _PAGE_MODIFIED_SHIFT,




 _PAGE_SPECIAL_SHIFT,
# 145 "./arch/mips/include/asm/pgtable-bits.h"
 _PAGE_GLOBAL_SHIFT,
 _PAGE_VALID_SHIFT,
 _PAGE_DIRTY_SHIFT,
 _CACHE_SHIFT,
};
# 214 "./arch/mips/include/asm/pgtable-bits.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t pte_to_entrylo(unsigned long pte_val)
{
# 234 "./arch/mips/include/asm/pgtable-bits.h"
 return pte_val >> _PAGE_GLOBAL_SHIFT;
}
# 31 "./arch/mips/include/asm/io.h" 2


# 1 "./arch/mips/include/asm/mach-generic/mangle-port.h" 1
# 34 "./arch/mips/include/asm/io.h" 2
# 62 "./arch/mips/include/asm/io.h"
extern unsigned long mips_io_port_base;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_io_port_base(unsigned long base)
{
 mips_io_port_base = base;
}
# 103 "./arch/mips/include/asm/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __virt_to_phys_nodebug(volatile const void *address)
{
 return ___pa((unsigned long)(address));
}


extern phys_addr_t __virt_to_phys(volatile const void *x);





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) phys_addr_t virt_to_phys(const volatile void *x)
{
 return __virt_to_phys(x);
}
# 132 "./arch/mips/include/asm/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void * phys_to_virt(unsigned long address)
{
 return (void *)(address + ((0x80000000UL) + ((unsigned long)((phys_addr_t)(ARCH_PFN_OFFSET) << 12))) - ((unsigned long)((phys_addr_t)(ARCH_PFN_OFFSET) << 12)));
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long isa_virt_to_bus(volatile void *address)
{
 return virt_to_phys(address);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *isa_bus_to_virt(unsigned long address)
{
 return phys_to_virt(address);
}
# 164 "./arch/mips/include/asm/io.h"
void *ioremap_prot(phys_addr_t offset, unsigned long size,
  unsigned long prot_val);
void iounmap(const volatile void *addr);
# 362 "./arch/mips/include/asm/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_writeb(u8 val, volatile void *mem) { volatile u8 *__mem; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u8 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 __raw_readb(const volatile void *mem) { volatile u8 *__mem; u8 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __relaxed_writeb(u8 val, volatile void *mem) { volatile u8 *__mem; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u8 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 __relaxed_readb(const volatile void *mem) { volatile u8 *__mem; u8 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!1) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_writeb(u8 val, volatile void *mem) { volatile u8 *__mem; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u8 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 __mem_readb(const volatile void *mem) { volatile u8 *__mem; u8 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void writeb(u8 val, volatile void *mem) { volatile u8 *__mem; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u8 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 readb(const volatile void *mem) { volatile u8 *__mem; u8 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_writew(u16 val, volatile void *mem) { volatile u16 *__mem; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u16 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 __raw_readw(const volatile void *mem) { volatile u16 *__mem; u16 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __relaxed_writew(u16 val, volatile void *mem) { volatile u16 *__mem; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (__u16)__builtin_bswap16((__u16)(( __u16)(__le16)(( __le16)(val)))); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u16 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 __relaxed_readw(const volatile void *mem) { volatile u16 *__mem; u16 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!1) rmb(); return (__u16)__builtin_bswap16((__u16)(( __u16)(__le16)(( __le16)(__val)))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_writew(u16 val, volatile void *mem) { volatile u16 *__mem; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u16 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 __mem_readw(const volatile void *mem) { volatile u16 *__mem; u16 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void writew(u16 val, volatile void *mem) { volatile u16 *__mem; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (__u16)__builtin_bswap16((__u16)(( __u16)(__le16)(( __le16)(val)))); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u16 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 readw(const volatile void *mem) { volatile u16 *__mem; u16 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__u16)__builtin_bswap16((__u16)(( __u16)(__le16)(( __le16)(__val)))); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_writel(u32 val, volatile void *mem) { volatile u32 *__mem; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u32 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 __raw_readl(const volatile void *mem) { volatile u32 *__mem; u32 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __relaxed_writel(u32 val, volatile void *mem) { volatile u32 *__mem; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (__u32)__builtin_bswap32((__u32)(( __u32)(__le32)(( __le32)(val)))); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u32 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 __relaxed_readl(const volatile void *mem) { volatile u32 *__mem; u32 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!1) rmb(); return (__u32)__builtin_bswap32((__u32)(( __u32)(__le32)(( __le32)(__val)))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_writel(u32 val, volatile void *mem) { volatile u32 *__mem; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u32 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 __mem_readl(const volatile void *mem) { volatile u32 *__mem; u32 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void writel(u32 val, volatile void *mem) { volatile u32 *__mem; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (__u32)__builtin_bswap32((__u32)(( __u32)(__le32)(( __le32)(val)))); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u32 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 readl(const volatile void *mem) { volatile u32 *__mem; u32 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__u32)__builtin_bswap32((__u32)(( __u32)(__le32)(( __le32)(__val)))); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_writeq(u64 val, volatile void *mem) { volatile u64 *__mem; u64 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u64) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u64 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 __raw_readq(const volatile void *mem) { volatile u64 *__mem; u64 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u64) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_writeq(u64 val, volatile void *mem) { volatile u64 *__mem; u64 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u64) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u64 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 __mem_readq(const volatile void *mem) { volatile u64 *__mem; u64 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u64) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); }
# 380 "./arch/mips/include/asm/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outb(u8 val, unsigned long port) { volatile u8 *__addr; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { __attribute__((__noreturn__)) extern void __compiletime_assert_34(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u8) > sizeof(unsigned long)"))); if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_34(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 inb(unsigned long port) { volatile u8 *__addr; u8 __val; __addr = (void *)(mips_io_port_base + port); do { __attribute__((__noreturn__)) extern void __compiletime_assert_35(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u8) > sizeof(unsigned long)"))); if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_35(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outb_p(u8 val, unsigned long port) { volatile u8 *__addr; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { __attribute__((__noreturn__)) extern void __compiletime_assert_36(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u8) > sizeof(unsigned long)"))); if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_36(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 inb_p(unsigned long port) { volatile u8 *__addr; u8 __val; __addr = (void *)(mips_io_port_base + port); do { __attribute__((__noreturn__)) extern void __compiletime_assert_37(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u8) > sizeof(unsigned long)"))); if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_37(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_outb(u8 val, unsigned long port) { volatile u8 *__addr; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { __attribute__((__noreturn__)) extern void __compiletime_assert_38(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u8) > sizeof(unsigned long)"))); if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_38(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 __mem_inb(unsigned long port) { volatile u8 *__addr; u8 __val; __addr = (void *)(mips_io_port_base + port); do { __attribute__((__noreturn__)) extern void __compiletime_assert_39(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u8) > sizeof(unsigned long)"))); if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_39(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_outb_p(u8 val, unsigned long port) { volatile u8 *__addr; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { __attribute__((__noreturn__)) extern void __compiletime_assert_40(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u8) > sizeof(unsigned long)"))); if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_40(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 __mem_inb_p(unsigned long port) { volatile u8 *__addr; u8 __val; __addr = (void *)(mips_io_port_base + port); do { __attribute__((__noreturn__)) extern void __compiletime_assert_41(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u8) > sizeof(unsigned long)"))); if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_41(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outw(u16 val, unsigned long port) { volatile u16 *__addr; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (__u16)__builtin_bswap16((__u16)(( __u16)(__le16)(( __le16)(val)))); do { __attribute__((__noreturn__)) extern void __compiletime_assert_42(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u16) > sizeof(unsigned long)"))); if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_42(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 inw(unsigned long port) { volatile u16 *__addr; u16 __val; __addr = (void *)(mips_io_port_base + port); do { __attribute__((__noreturn__)) extern void __compiletime_assert_43(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u16) > sizeof(unsigned long)"))); if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_43(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__u16)__builtin_bswap16((__u16)(( __u16)(__le16)(( __le16)(__val)))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outw_p(u16 val, unsigned long port) { volatile u16 *__addr; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (__u16)__builtin_bswap16((__u16)(( __u16)(__le16)(( __le16)(val)))); do { __attribute__((__noreturn__)) extern void __compiletime_assert_44(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u16) > sizeof(unsigned long)"))); if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_44(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 inw_p(unsigned long port) { volatile u16 *__addr; u16 __val; __addr = (void *)(mips_io_port_base + port); do { __attribute__((__noreturn__)) extern void __compiletime_assert_45(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u16) > sizeof(unsigned long)"))); if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_45(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__u16)__builtin_bswap16((__u16)(( __u16)(__le16)(( __le16)(__val)))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_outw(u16 val, unsigned long port) { volatile u16 *__addr; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { __attribute__((__noreturn__)) extern void __compiletime_assert_46(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u16) > sizeof(unsigned long)"))); if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_46(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 __mem_inw(unsigned long port) { volatile u16 *__addr; u16 __val; __addr = (void *)(mips_io_port_base + port); do { __attribute__((__noreturn__)) extern void __compiletime_assert_47(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u16) > sizeof(unsigned long)"))); if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_47(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_outw_p(u16 val, unsigned long port) { volatile u16 *__addr; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { __attribute__((__noreturn__)) extern void __compiletime_assert_48(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u16) > sizeof(unsigned long)"))); if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_48(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 __mem_inw_p(unsigned long port) { volatile u16 *__addr; u16 __val; __addr = (void *)(mips_io_port_base + port); do { __attribute__((__noreturn__)) extern void __compiletime_assert_49(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u16) > sizeof(unsigned long)"))); if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_49(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outl(u32 val, unsigned long port) { volatile u32 *__addr; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (__u32)__builtin_bswap32((__u32)(( __u32)(__le32)(( __le32)(val)))); do { __attribute__((__noreturn__)) extern void __compiletime_assert_50(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u32) > sizeof(unsigned long)"))); if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_50(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 inl(unsigned long port) { volatile u32 *__addr; u32 __val; __addr = (void *)(mips_io_port_base + port); do { __attribute__((__noreturn__)) extern void __compiletime_assert_51(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u32) > sizeof(unsigned long)"))); if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_51(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__u32)__builtin_bswap32((__u32)(( __u32)(__le32)(( __le32)(__val)))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outl_p(u32 val, unsigned long port) { volatile u32 *__addr; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (__u32)__builtin_bswap32((__u32)(( __u32)(__le32)(( __le32)(val)))); do { __attribute__((__noreturn__)) extern void __compiletime_assert_52(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u32) > sizeof(unsigned long)"))); if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_52(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 inl_p(unsigned long port) { volatile u32 *__addr; u32 __val; __addr = (void *)(mips_io_port_base + port); do { __attribute__((__noreturn__)) extern void __compiletime_assert_53(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u32) > sizeof(unsigned long)"))); if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_53(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__u32)__builtin_bswap32((__u32)(( __u32)(__le32)(( __le32)(__val)))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_outl(u32 val, unsigned long port) { volatile u32 *__addr; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { __attribute__((__noreturn__)) extern void __compiletime_assert_54(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u32) > sizeof(unsigned long)"))); if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_54(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 __mem_inl(unsigned long port) { volatile u32 *__addr; u32 __val; __addr = (void *)(mips_io_port_base + port); do { __attribute__((__noreturn__)) extern void __compiletime_assert_55(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u32) > sizeof(unsigned long)"))); if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_55(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_outl_p(u32 val, unsigned long port) { volatile u32 *__addr; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { __attribute__((__noreturn__)) extern void __compiletime_assert_56(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u32) > sizeof(unsigned long)"))); if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_56(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 __mem_inl_p(unsigned long port) { volatile u32 *__addr; u32 __val; __addr = (void *)(mips_io_port_base + port); do { __attribute__((__noreturn__)) extern void __compiletime_assert_57(void) __attribute__((__error__("BUILD_BUG_ON failed: " "sizeof(u32) > sizeof(unsigned long)"))); if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_57(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); }
# 391 "./arch/mips/include/asm/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ____raw_writeq(u64 val, volatile void *mem) { volatile u64 *__mem; u64 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u64) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u64 __tmp; if (0) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (0) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 ____raw_readq(const volatile void *mem) { volatile u64 *__mem; u64 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u64) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (0) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_off(); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (0) do { if (!({ ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_irqs_disabled_flags(__flags); })) trace_hardirqs_on(); do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); do { if (__builtin_expect(!!(!arch_irqs_disabled()), 0)) warn_bogus_irq_restore(); } while (0); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); }
# 486 "./arch/mips/include/asm/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void writesb(volatile void *mem, const void *addr, unsigned int count) { const volatile u8 *__addr = addr; while (count--) { __mem_writeb(*__addr, mem); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void readsb(volatile void *mem, void *addr, unsigned int count) { volatile u8 *__addr = addr; while (count--) { *__addr = __mem_readb(mem); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outsb(unsigned long port, const void *addr, unsigned int count) { const volatile u8 *__addr = addr; while (count--) { __mem_outb(*__addr, port); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void insb(unsigned long port, void *addr, unsigned int count) { volatile u8 *__addr = addr; while (count--) { *__addr = __mem_inb(port); __addr++; } }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void writesw(volatile void *mem, const void *addr, unsigned int count) { const volatile u16 *__addr = addr; while (count--) { __mem_writew(*__addr, mem); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void readsw(volatile void *mem, void *addr, unsigned int count) { volatile u16 *__addr = addr; while (count--) { *__addr = __mem_readw(mem); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outsw(unsigned long port, const void *addr, unsigned int count) { const volatile u16 *__addr = addr; while (count--) { __mem_outw(*__addr, port); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void insw(unsigned long port, void *addr, unsigned int count) { volatile u16 *__addr = addr; while (count--) { *__addr = __mem_inw(port); __addr++; } }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void writesl(volatile void *mem, const void *addr, unsigned int count) { const volatile u32 *__addr = addr; while (count--) { __mem_writel(*__addr, mem); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void readsl(volatile void *mem, void *addr, unsigned int count) { volatile u32 *__addr = addr; while (count--) { *__addr = __mem_readl(mem); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outsl(unsigned long port, const void *addr, unsigned int count) { const volatile u32 *__addr = addr; while (count--) { __mem_outl(*__addr, port); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void insl(unsigned long port, void *addr, unsigned int count) { volatile u32 *__addr = addr; while (count--) { *__addr = __mem_inl(port); __addr++; } }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void memset_io(volatile void *addr, unsigned char val, int count)
{
 memset((void *) addr, val, count);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void memcpy_fromio(void *dst, const volatile void *src, int count)
{
 memcpy(dst, (void *) src, count);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void memcpy_toio(volatile void *dst, const void *src, int count)
{
 memcpy((void *) dst, src, count);
}
# 528 "./arch/mips/include/asm/io.h"
extern void (*_dma_cache_wback_inv)(unsigned long start, unsigned long size);
extern void (*_dma_cache_wback)(unsigned long start, unsigned long size);
extern void (*_dma_cache_inv)(unsigned long start, unsigned long size);
# 567 "./arch/mips/include/asm/io.h"
void __ioread64_copy(void *to, const void *from, size_t count);
# 14 "./include/linux/io.h" 2


struct device;
struct resource;

          void __iowrite32_copy(void *to, const void *from, size_t count);
void __ioread32_copy(void *to, const void *from, size_t count);
void __iowrite64_copy(void *to, const void *from, size_t count);


int ioremap_page_range(unsigned long addr, unsigned long end,
         phys_addr_t phys_addr, pgprot_t prot);
# 38 "./include/linux/io.h"
void * devm_ioport_map(struct device *dev, unsigned long port,
          unsigned int nr);
void devm_ioport_unmap(struct device *dev, void *addr);
# 56 "./include/linux/io.h"
void *devm_ioremap(struct device *dev, resource_size_t offset,
      resource_size_t size);
void *devm_ioremap_uc(struct device *dev, resource_size_t offset,
       resource_size_t size);
void *devm_ioremap_wc(struct device *dev, resource_size_t offset,
       resource_size_t size);
void *devm_ioremap_np(struct device *dev, resource_size_t offset,
       resource_size_t size);
void devm_iounmap(struct device *dev, void *addr);
int check_signature(const volatile void *io_addr,
   const unsigned char *signature, int length);
void devm_ioremap_release(struct device *dev, void *res);

void *devm_memremap(struct device *dev, resource_size_t offset,
  size_t size, unsigned long flags);
void devm_memunmap(struct device *dev, void *addr);
# 86 "./include/linux/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *pci_remap_cfgspace(phys_addr_t offset,
            size_t size)
{
 return ioremap_np(offset, size) ?: ioremap_prot((offset), (size), (2<<_CACHE_SHIFT));
}
# 115 "./include/linux/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) arch_phys_wc_add(unsigned long base,
      unsigned long size)
{
 return 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_phys_wc_del(int handle)
{
}



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_phys_wc_index(int handle)
{
 return -1;
}




int devm_arch_phys_wc_add(struct device *dev, unsigned long base, unsigned long size);

enum {

 MEMREMAP_WB = 1 << 0,
 MEMREMAP_WT = 1 << 1,
 MEMREMAP_WC = 1 << 2,
 MEMREMAP_ENC = 1 << 3,
 MEMREMAP_DEC = 1 << 4,
};

void *memremap(resource_size_t offset, size_t size, unsigned long flags);
void memunmap(void *addr);
# 159 "./include/linux/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_io_reserve_memtype_wc(resource_size_t base,
          resource_size_t size)
{
 return 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_io_free_memtype_wc(resource_size_t base,
        resource_size_t size)
{
}


int devm_arch_io_reserve_memtype_wc(struct device *dev, resource_size_t start,
        resource_size_t size);
# 11 "./arch/mips/include/asm/mips-cps.h" 2


extern unsigned long __cps_access_bad_size(void)
 __attribute__((__error__("Bad size for CPS accessor")));
# 104 "./arch/mips/include/asm/mips-cps.h"
# 1 "./arch/mips/include/asm/mips-cm.h" 1
# 14 "./arch/mips/include/asm/mips-cm.h"
# 1 "./include/linux/bitfield.h" 1
# 112 "./include/linux/bitfield.h"
extern void __attribute__((__error__("value doesn't fit into mask")))
__field_overflow(void);
extern void __attribute__((__error__("bad bitfield mask")))
__bad_mask(void);
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u64 field_multiplier(u64 field)
{
 if ((field | (field - 1)) & ((field | (field - 1)) + 1))
  __bad_mask();
 return field & -field;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u64 field_mask(u64 field)
{
 return field / field_multiplier(field);
}
# 152 "./include/linux/bitfield.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u8 u8_encode_bits(u8 v, u8 field) { if (__builtin_constant_p(v) && (v & ~field_mask(field))) __field_overflow(); return ((v & field_mask(field)) * field_multiplier(field)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u8 u8_replace_bits(__u8 old, u8 val, u8 field) { return (old & ~(field)) | u8_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void u8p_replace_bits(__u8 *p, u8 val, u8 field) { *p = (*p & ~(field)) | u8_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u8 u8_get_bits(__u8 v, u8 field) { return ((v) & field)/field_multiplier(field); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __le16 le16_encode_bits(u16 v, u16 field) { if (__builtin_constant_p(v) && (v & ~field_mask(field))) __field_overflow(); return (( __le16)(__u16)__builtin_bswap16((__u16)(((v & field_mask(field)) * field_multiplier(field))))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __le16 le16_replace_bits(__le16 old, u16 val, u16 field) { return (old & ~(( __le16)(__u16)__builtin_bswap16((__u16)((field))))) | le16_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void le16p_replace_bits(__le16 *p, u16 val, u16 field) { *p = (*p & ~(( __le16)(__u16)__builtin_bswap16((__u16)((field))))) | le16_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u16 le16_get_bits(__le16 v, u16 field) { return ((__u16)__builtin_bswap16((__u16)(( __u16)(__le16)(v))) & field)/field_multiplier(field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __be16 be16_encode_bits(u16 v, u16 field) { if (__builtin_constant_p(v) && (v & ~field_mask(field))) __field_overflow(); return (( __be16)(__u16)((v & field_mask(field)) * field_multiplier(field))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __be16 be16_replace_bits(__be16 old, u16 val, u16 field) { return (old & ~(( __be16)(__u16)(field))) | be16_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void be16p_replace_bits(__be16 *p, u16 val, u16 field) { *p = (*p & ~(( __be16)(__u16)(field))) | be16_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u16 be16_get_bits(__be16 v, u16 field) { return ((( __u16)(__be16)(v)) & field)/field_multiplier(field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u16 u16_encode_bits(u16 v, u16 field) { if (__builtin_constant_p(v) && (v & ~field_mask(field))) __field_overflow(); return ((v & field_mask(field)) * field_multiplier(field)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u16 u16_replace_bits(__u16 old, u16 val, u16 field) { return (old & ~(field)) | u16_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void u16p_replace_bits(__u16 *p, u16 val, u16 field) { *p = (*p & ~(field)) | u16_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u16 u16_get_bits(__u16 v, u16 field) { return ((v) & field)/field_multiplier(field); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __le32 le32_encode_bits(u32 v, u32 field) { if (__builtin_constant_p(v) && (v & ~field_mask(field))) __field_overflow(); return (( __le32)(__u32)__builtin_bswap32((__u32)(((v & field_mask(field)) * field_multiplier(field))))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __le32 le32_replace_bits(__le32 old, u32 val, u32 field) { return (old & ~(( __le32)(__u32)__builtin_bswap32((__u32)((field))))) | le32_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void le32p_replace_bits(__le32 *p, u32 val, u32 field) { *p = (*p & ~(( __le32)(__u32)__builtin_bswap32((__u32)((field))))) | le32_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u32 le32_get_bits(__le32 v, u32 field) { return ((__u32)__builtin_bswap32((__u32)(( __u32)(__le32)(v))) & field)/field_multiplier(field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __be32 be32_encode_bits(u32 v, u32 field) { if (__builtin_constant_p(v) && (v & ~field_mask(field))) __field_overflow(); return (( __be32)(__u32)((v & field_mask(field)) * field_multiplier(field))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __be32 be32_replace_bits(__be32 old, u32 val, u32 field) { return (old & ~(( __be32)(__u32)(field))) | be32_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void be32p_replace_bits(__be32 *p, u32 val, u32 field) { *p = (*p & ~(( __be32)(__u32)(field))) | be32_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u32 be32_get_bits(__be32 v, u32 field) { return ((( __u32)(__be32)(v)) & field)/field_multiplier(field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u32 u32_encode_bits(u32 v, u32 field) { if (__builtin_constant_p(v) && (v & ~field_mask(field))) __field_overflow(); return ((v & field_mask(field)) * field_multiplier(field)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u32 u32_replace_bits(__u32 old, u32 val, u32 field) { return (old & ~(field)) | u32_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void u32p_replace_bits(__u32 *p, u32 val, u32 field) { *p = (*p & ~(field)) | u32_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u32 u32_get_bits(__u32 v, u32 field) { return ((v) & field)/field_multiplier(field); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __le64 le64_encode_bits(u64 v, u64 field) { if (__builtin_constant_p(v) && (v & ~field_mask(field))) __field_overflow(); return (( __le64)(__u64)__builtin_bswap64((__u64)(((v & field_mask(field)) * field_multiplier(field))))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __le64 le64_replace_bits(__le64 old, u64 val, u64 field) { return (old & ~(( __le64)(__u64)__builtin_bswap64((__u64)((field))))) | le64_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void le64p_replace_bits(__le64 *p, u64 val, u64 field) { *p = (*p & ~(( __le64)(__u64)__builtin_bswap64((__u64)((field))))) | le64_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u64 le64_get_bits(__le64 v, u64 field) { return ((__u64)__builtin_bswap64((__u64)(( __u64)(__le64)(v))) & field)/field_multiplier(field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __be64 be64_encode_bits(u64 v, u64 field) { if (__builtin_constant_p(v) && (v & ~field_mask(field))) __field_overflow(); return (( __be64)(__u64)((v & field_mask(field)) * field_multiplier(field))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __be64 be64_replace_bits(__be64 old, u64 val, u64 field) { return (old & ~(( __be64)(__u64)(field))) | be64_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void be64p_replace_bits(__be64 *p, u64 val, u64 field) { *p = (*p & ~(( __be64)(__u64)(field))) | be64_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u64 be64_get_bits(__be64 v, u64 field) { return ((( __u64)(__be64)(v)) & field)/field_multiplier(field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u64 u64_encode_bits(u64 v, u64 field) { if (__builtin_constant_p(v) && (v & ~field_mask(field))) __field_overflow(); return ((v & field_mask(field)) * field_multiplier(field)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u64 u64_replace_bits(__u64 old, u64 val, u64 field) { return (old & ~(field)) | u64_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void u64p_replace_bits(__u64 *p, u64 val, u64 field) { *p = (*p & ~(field)) | u64_encode_bits(val, field); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u64 u64_get_bits(__u64 v, u64 field) { return ((v) & field)/field_multiplier(field); }
# 15 "./arch/mips/include/asm/mips-cm.h" 2




extern void *mips_gcr_base;


extern void *mips_cm_l2sync_base;
# 34 "./arch/mips/include/asm/mips-cm.h"
extern phys_addr_t __mips_cm_phys_base(void);
# 48 "./arch/mips/include/asm/mips-cm.h"
extern int mips_cm_is64;





extern void mips_cm_error_report(void);
# 66 "./arch/mips/include/asm/mips-cm.h"
extern int mips_cm_probe(void);
# 79 "./arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool mips_cm_present(void)
{

 return mips_gcr_base != ((void *)0);



}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool mips_cm_has_l2sync(void)
{

 return mips_cm_l2sync_base != ((void *)0);



}
# 131 "./arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_config(void) { return mips_gcr_base + (0x0000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_config(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_config()); val64 = __raw_readl(addr_gcr_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_config(void) { return mips_gcr_base + (0x4000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_config(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_config()); val64 = __raw_readl(addr_gcr_redir_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_config()); return val64; default: return __cps_access_bad_size(); } }







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_base(void) { return mips_gcr_base + (0x0000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_base()); val64 = __raw_readl(addr_gcr_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_base() + 4); __raw_writel(val, addr_gcr_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_base(); reg_val &= ~mask; reg_val |= val; write_gcr_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_base(uint64_t val) { change_gcr_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_base(uint64_t val) { change_gcr_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_base(void) { return mips_gcr_base + (0x4000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_base()); val64 = __raw_readl(addr_gcr_redir_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_base() + 4); __raw_writel(val, addr_gcr_redir_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_base(uint64_t val) { change_gcr_redir_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_base(uint64_t val) { change_gcr_redir_base(val, 0); }
# 148 "./arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_access(void) { return mips_gcr_base + (0x0000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_access(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_access()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_access()); val64 = __raw_readl(addr_gcr_access() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_access()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_access(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_access()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_access()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_access() + 4); __raw_writel(val, addr_gcr_access()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_access(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_access(); reg_val &= ~mask; reg_val |= val; write_gcr_access(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_access(uint32_t val) { change_gcr_access(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_access(uint32_t val) { change_gcr_access(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_access(void) { return mips_gcr_base + (0x4000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_access(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_access()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_access()); val64 = __raw_readl(addr_gcr_redir_access() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_access()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_access(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_redir_access()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_access()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_access() + 4); __raw_writel(val, addr_gcr_redir_access()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_access(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_redir_access(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_access(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_access(uint32_t val) { change_gcr_redir_access(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_access(uint32_t val) { change_gcr_redir_access(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_rev(void) { return mips_gcr_base + (0x0000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_rev(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_rev()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_rev()); val64 = __raw_readl(addr_gcr_rev() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_rev()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_rev(void) { return mips_gcr_base + (0x4000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_rev(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_rev()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_rev()); val64 = __raw_readl(addr_gcr_redir_rev() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_rev()); return val64; default: return __cps_access_bad_size(); } }
# 166 "./arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_err_control(void) { return mips_gcr_base + (0x0000 + 0x038); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_err_control(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_err_control()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_err_control()); val64 = __raw_readl(addr_gcr_err_control() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_err_control()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_err_control(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_err_control()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_err_control()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_err_control() + 4); __raw_writel(val, addr_gcr_err_control()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_err_control(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_err_control(); reg_val &= ~mask; reg_val |= val; write_gcr_err_control(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_err_control(uint32_t val) { change_gcr_err_control(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_err_control(uint32_t val) { change_gcr_err_control(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_err_control(void) { return mips_gcr_base + (0x4000 + 0x038); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_err_control(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_err_control()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_err_control()); val64 = __raw_readl(addr_gcr_redir_err_control() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_err_control()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_err_control(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_redir_err_control()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_err_control()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_err_control() + 4); __raw_writel(val, addr_gcr_redir_err_control()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_err_control(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_redir_err_control(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_err_control(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_err_control(uint32_t val) { change_gcr_redir_err_control(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_err_control(uint32_t val) { change_gcr_redir_err_control(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_error_mask(void) { return mips_gcr_base + (0x0000 + 0x040); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_error_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_error_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_error_mask()); val64 = __raw_readl(addr_gcr_error_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_error_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_error_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_error_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_error_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_error_mask() + 4); __raw_writel(val, addr_gcr_error_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_error_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_error_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_error_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_error_mask(uint64_t val) { change_gcr_error_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_error_mask(uint64_t val) { change_gcr_error_mask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_error_mask(void) { return mips_gcr_base + (0x4000 + 0x040); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_error_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_error_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_error_mask()); val64 = __raw_readl(addr_gcr_redir_error_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_error_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_error_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_error_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_error_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_error_mask() + 4); __raw_writel(val, addr_gcr_redir_error_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_error_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_error_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_error_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_error_mask(uint64_t val) { change_gcr_redir_error_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_error_mask(uint64_t val) { change_gcr_redir_error_mask(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_error_cause(void) { return mips_gcr_base + (0x0000 + 0x048); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_error_cause(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_error_cause()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_error_cause()); val64 = __raw_readl(addr_gcr_error_cause() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_error_cause()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_error_cause(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_error_cause()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_error_cause()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_error_cause() + 4); __raw_writel(val, addr_gcr_error_cause()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_error_cause(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_error_cause(); reg_val &= ~mask; reg_val |= val; write_gcr_error_cause(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_error_cause(uint64_t val) { change_gcr_error_cause(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_error_cause(uint64_t val) { change_gcr_error_cause(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_error_cause(void) { return mips_gcr_base + (0x4000 + 0x048); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_error_cause(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_error_cause()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_error_cause()); val64 = __raw_readl(addr_gcr_redir_error_cause() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_error_cause()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_error_cause(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_error_cause()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_error_cause()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_error_cause() + 4); __raw_writel(val, addr_gcr_redir_error_cause()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_error_cause(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_error_cause(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_error_cause(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_error_cause(uint64_t val) { change_gcr_redir_error_cause(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_error_cause(uint64_t val) { change_gcr_redir_error_cause(val, 0); }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_error_addr(void) { return mips_gcr_base + (0x0000 + 0x050); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_error_addr(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_error_addr()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_error_addr()); val64 = __raw_readl(addr_gcr_error_addr() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_error_addr()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_error_addr(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_error_addr()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_error_addr()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_error_addr() + 4); __raw_writel(val, addr_gcr_error_addr()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_error_addr(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_error_addr(); reg_val &= ~mask; reg_val |= val; write_gcr_error_addr(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_error_addr(uint64_t val) { change_gcr_error_addr(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_error_addr(uint64_t val) { change_gcr_error_addr(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_error_addr(void) { return mips_gcr_base + (0x4000 + 0x050); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_error_addr(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_error_addr()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_error_addr()); val64 = __raw_readl(addr_gcr_redir_error_addr() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_error_addr()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_error_addr(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_error_addr()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_error_addr()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_error_addr() + 4); __raw_writel(val, addr_gcr_redir_error_addr()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_error_addr(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_error_addr(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_error_addr(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_error_addr(uint64_t val) { change_gcr_redir_error_addr(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_error_addr(uint64_t val) { change_gcr_redir_error_addr(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_error_mult(void) { return mips_gcr_base + (0x0000 + 0x058); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_error_mult(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_error_mult()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_error_mult()); val64 = __raw_readl(addr_gcr_error_mult() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_error_mult()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_error_mult(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_error_mult()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_error_mult()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_error_mult() + 4); __raw_writel(val, addr_gcr_error_mult()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_error_mult(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_error_mult(); reg_val &= ~mask; reg_val |= val; write_gcr_error_mult(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_error_mult(uint64_t val) { change_gcr_error_mult(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_error_mult(uint64_t val) { change_gcr_error_mult(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_error_mult(void) { return mips_gcr_base + (0x4000 + 0x058); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_error_mult(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_error_mult()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_error_mult()); val64 = __raw_readl(addr_gcr_redir_error_mult() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_error_mult()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_error_mult(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_error_mult()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_error_mult()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_error_mult() + 4); __raw_writel(val, addr_gcr_redir_error_mult()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_error_mult(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_error_mult(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_error_mult(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_error_mult(uint64_t val) { change_gcr_redir_error_mult(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_error_mult(uint64_t val) { change_gcr_redir_error_mult(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_l2_only_sync_base(void) { return mips_gcr_base + (0x0000 + 0x070); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_l2_only_sync_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_l2_only_sync_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_l2_only_sync_base()); val64 = __raw_readl(addr_gcr_l2_only_sync_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_l2_only_sync_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_l2_only_sync_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_l2_only_sync_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_l2_only_sync_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_l2_only_sync_base() + 4); __raw_writel(val, addr_gcr_l2_only_sync_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_l2_only_sync_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_l2_only_sync_base(); reg_val &= ~mask; reg_val |= val; write_gcr_l2_only_sync_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_l2_only_sync_base(uint64_t val) { change_gcr_l2_only_sync_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_l2_only_sync_base(uint64_t val) { change_gcr_l2_only_sync_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_l2_only_sync_base(void) { return mips_gcr_base + (0x4000 + 0x070); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_l2_only_sync_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_l2_only_sync_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_l2_only_sync_base()); val64 = __raw_readl(addr_gcr_redir_l2_only_sync_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_l2_only_sync_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_l2_only_sync_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_l2_only_sync_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_l2_only_sync_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_l2_only_sync_base() + 4); __raw_writel(val, addr_gcr_redir_l2_only_sync_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_l2_only_sync_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_l2_only_sync_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_l2_only_sync_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_l2_only_sync_base(uint64_t val) { change_gcr_redir_l2_only_sync_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_l2_only_sync_base(uint64_t val) { change_gcr_redir_l2_only_sync_base(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_gic_base(void) { return mips_gcr_base + (0x0000 + 0x080); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_gic_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_gic_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_gic_base()); val64 = __raw_readl(addr_gcr_gic_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_gic_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_gic_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_gic_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_gic_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_gic_base() + 4); __raw_writel(val, addr_gcr_gic_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_gic_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_gic_base(); reg_val &= ~mask; reg_val |= val; write_gcr_gic_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_gic_base(uint64_t val) { change_gcr_gic_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_gic_base(uint64_t val) { change_gcr_gic_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_gic_base(void) { return mips_gcr_base + (0x4000 + 0x080); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_gic_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_gic_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_gic_base()); val64 = __raw_readl(addr_gcr_redir_gic_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_gic_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_gic_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_gic_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_gic_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_gic_base() + 4); __raw_writel(val, addr_gcr_redir_gic_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_gic_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_gic_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_gic_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_gic_base(uint64_t val) { change_gcr_redir_gic_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_gic_base(uint64_t val) { change_gcr_redir_gic_base(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cpc_base(void) { return mips_gcr_base + (0x0000 + 0x088); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_cpc_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_cpc_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cpc_base()); val64 = __raw_readl(addr_gcr_cpc_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cpc_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_cpc_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_cpc_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_cpc_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_cpc_base() + 4); __raw_writel(val, addr_gcr_cpc_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_cpc_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_cpc_base(); reg_val &= ~mask; reg_val |= val; write_gcr_cpc_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_cpc_base(uint64_t val) { change_gcr_cpc_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_cpc_base(uint64_t val) { change_gcr_cpc_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_cpc_base(void) { return mips_gcr_base + (0x4000 + 0x088); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_cpc_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_cpc_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_cpc_base()); val64 = __raw_readl(addr_gcr_redir_cpc_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_cpc_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_cpc_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_cpc_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_cpc_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_cpc_base() + 4); __raw_writel(val, addr_gcr_redir_cpc_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_cpc_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_cpc_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_cpc_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_cpc_base(uint64_t val) { change_gcr_redir_cpc_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_cpc_base(uint64_t val) { change_gcr_redir_cpc_base(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg0_base(void) { return mips_gcr_base + (0x0000 + 0x090); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg0_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg0_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg0_base()); val64 = __raw_readl(addr_gcr_reg0_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg0_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg0_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg0_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg0_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg0_base() + 4); __raw_writel(val, addr_gcr_reg0_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg0_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg0_base(); reg_val &= ~mask; reg_val |= val; write_gcr_reg0_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg0_base(uint64_t val) { change_gcr_reg0_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg0_base(uint64_t val) { change_gcr_reg0_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg0_base(void) { return mips_gcr_base + (0x4000 + 0x090); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg0_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg0_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg0_base()); val64 = __raw_readl(addr_gcr_redir_reg0_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg0_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg0_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg0_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg0_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg0_base() + 4); __raw_writel(val, addr_gcr_redir_reg0_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg0_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg0_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg0_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg0_base(uint64_t val) { change_gcr_redir_reg0_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg0_base(uint64_t val) { change_gcr_redir_reg0_base(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg1_base(void) { return mips_gcr_base + (0x0000 + 0x0a0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg1_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg1_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg1_base()); val64 = __raw_readl(addr_gcr_reg1_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg1_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg1_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg1_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg1_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg1_base() + 4); __raw_writel(val, addr_gcr_reg1_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg1_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg1_base(); reg_val &= ~mask; reg_val |= val; write_gcr_reg1_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg1_base(uint64_t val) { change_gcr_reg1_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg1_base(uint64_t val) { change_gcr_reg1_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg1_base(void) { return mips_gcr_base + (0x4000 + 0x0a0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg1_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg1_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg1_base()); val64 = __raw_readl(addr_gcr_redir_reg1_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg1_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg1_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg1_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg1_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg1_base() + 4); __raw_writel(val, addr_gcr_redir_reg1_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg1_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg1_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg1_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg1_base(uint64_t val) { change_gcr_redir_reg1_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg1_base(uint64_t val) { change_gcr_redir_reg1_base(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg2_base(void) { return mips_gcr_base + (0x0000 + 0x0b0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg2_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg2_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg2_base()); val64 = __raw_readl(addr_gcr_reg2_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg2_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg2_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg2_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg2_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg2_base() + 4); __raw_writel(val, addr_gcr_reg2_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg2_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg2_base(); reg_val &= ~mask; reg_val |= val; write_gcr_reg2_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg2_base(uint64_t val) { change_gcr_reg2_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg2_base(uint64_t val) { change_gcr_reg2_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg2_base(void) { return mips_gcr_base + (0x4000 + 0x0b0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg2_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg2_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg2_base()); val64 = __raw_readl(addr_gcr_redir_reg2_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg2_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg2_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg2_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg2_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg2_base() + 4); __raw_writel(val, addr_gcr_redir_reg2_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg2_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg2_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg2_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg2_base(uint64_t val) { change_gcr_redir_reg2_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg2_base(uint64_t val) { change_gcr_redir_reg2_base(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg3_base(void) { return mips_gcr_base + (0x0000 + 0x0c0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg3_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg3_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg3_base()); val64 = __raw_readl(addr_gcr_reg3_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg3_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg3_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg3_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg3_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg3_base() + 4); __raw_writel(val, addr_gcr_reg3_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg3_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg3_base(); reg_val &= ~mask; reg_val |= val; write_gcr_reg3_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg3_base(uint64_t val) { change_gcr_reg3_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg3_base(uint64_t val) { change_gcr_reg3_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg3_base(void) { return mips_gcr_base + (0x4000 + 0x0c0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg3_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg3_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg3_base()); val64 = __raw_readl(addr_gcr_redir_reg3_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg3_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg3_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg3_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg3_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg3_base() + 4); __raw_writel(val, addr_gcr_redir_reg3_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg3_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg3_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg3_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg3_base(uint64_t val) { change_gcr_redir_reg3_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg3_base(uint64_t val) { change_gcr_redir_reg3_base(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg0_mask(void) { return mips_gcr_base + (0x0000 + 0x098); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg0_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg0_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg0_mask()); val64 = __raw_readl(addr_gcr_reg0_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg0_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg0_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg0_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg0_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg0_mask() + 4); __raw_writel(val, addr_gcr_reg0_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg0_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg0_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_reg0_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg0_mask(uint64_t val) { change_gcr_reg0_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg0_mask(uint64_t val) { change_gcr_reg0_mask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg0_mask(void) { return mips_gcr_base + (0x4000 + 0x098); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg0_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg0_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg0_mask()); val64 = __raw_readl(addr_gcr_redir_reg0_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg0_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg0_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg0_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg0_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg0_mask() + 4); __raw_writel(val, addr_gcr_redir_reg0_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg0_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg0_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg0_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg0_mask(uint64_t val) { change_gcr_redir_reg0_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg0_mask(uint64_t val) { change_gcr_redir_reg0_mask(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg1_mask(void) { return mips_gcr_base + (0x0000 + 0x0a8); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg1_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg1_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg1_mask()); val64 = __raw_readl(addr_gcr_reg1_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg1_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg1_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg1_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg1_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg1_mask() + 4); __raw_writel(val, addr_gcr_reg1_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg1_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg1_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_reg1_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg1_mask(uint64_t val) { change_gcr_reg1_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg1_mask(uint64_t val) { change_gcr_reg1_mask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg1_mask(void) { return mips_gcr_base + (0x4000 + 0x0a8); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg1_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg1_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg1_mask()); val64 = __raw_readl(addr_gcr_redir_reg1_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg1_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg1_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg1_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg1_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg1_mask() + 4); __raw_writel(val, addr_gcr_redir_reg1_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg1_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg1_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg1_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg1_mask(uint64_t val) { change_gcr_redir_reg1_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg1_mask(uint64_t val) { change_gcr_redir_reg1_mask(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg2_mask(void) { return mips_gcr_base + (0x0000 + 0x0b8); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg2_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg2_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg2_mask()); val64 = __raw_readl(addr_gcr_reg2_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg2_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg2_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg2_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg2_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg2_mask() + 4); __raw_writel(val, addr_gcr_reg2_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg2_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg2_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_reg2_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg2_mask(uint64_t val) { change_gcr_reg2_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg2_mask(uint64_t val) { change_gcr_reg2_mask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg2_mask(void) { return mips_gcr_base + (0x4000 + 0x0b8); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg2_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg2_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg2_mask()); val64 = __raw_readl(addr_gcr_redir_reg2_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg2_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg2_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg2_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg2_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg2_mask() + 4); __raw_writel(val, addr_gcr_redir_reg2_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg2_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg2_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg2_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg2_mask(uint64_t val) { change_gcr_redir_reg2_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg2_mask(uint64_t val) { change_gcr_redir_reg2_mask(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg3_mask(void) { return mips_gcr_base + (0x0000 + 0x0c8); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg3_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg3_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg3_mask()); val64 = __raw_readl(addr_gcr_reg3_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg3_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg3_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg3_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg3_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg3_mask() + 4); __raw_writel(val, addr_gcr_reg3_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg3_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg3_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_reg3_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg3_mask(uint64_t val) { change_gcr_reg3_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg3_mask(uint64_t val) { change_gcr_reg3_mask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg3_mask(void) { return mips_gcr_base + (0x4000 + 0x0c8); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg3_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg3_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg3_mask()); val64 = __raw_readl(addr_gcr_redir_reg3_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg3_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg3_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg3_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg3_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg3_mask() + 4); __raw_writel(val, addr_gcr_redir_reg3_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg3_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg3_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg3_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg3_mask(uint64_t val) { change_gcr_redir_reg3_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg3_mask(uint64_t val) { change_gcr_redir_reg3_mask(val, 0); }
# 224 "./arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_gic_status(void) { return mips_gcr_base + (0x0000 + 0x0d0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_gic_status(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_gic_status()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_gic_status()); val64 = __raw_readl(addr_gcr_gic_status() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_gic_status()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_gic_status(void) { return mips_gcr_base + (0x4000 + 0x0d0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_gic_status(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_gic_status()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_gic_status()); val64 = __raw_readl(addr_gcr_redir_gic_status() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_gic_status()); return val64; default: return __cps_access_bad_size(); } }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cpc_status(void) { return mips_gcr_base + (0x0000 + 0x0f0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cpc_status(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cpc_status()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cpc_status()); val64 = __raw_readl(addr_gcr_cpc_status() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cpc_status()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_cpc_status(void) { return mips_gcr_base + (0x4000 + 0x0f0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_cpc_status(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_cpc_status()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_cpc_status()); val64 = __raw_readl(addr_gcr_redir_cpc_status() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_cpc_status()); return val64; default: return __cps_access_bad_size(); } }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_l2_config(void) { return mips_gcr_base + (0x0000 + 0x130); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_l2_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_l2_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_l2_config()); val64 = __raw_readl(addr_gcr_l2_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_l2_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_l2_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_l2_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_l2_config()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_l2_config() + 4); __raw_writel(val, addr_gcr_l2_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_l2_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_l2_config(); reg_val &= ~mask; reg_val |= val; write_gcr_l2_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_l2_config(uint32_t val) { change_gcr_l2_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_l2_config(uint32_t val) { change_gcr_l2_config(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_l2_config(void) { return mips_gcr_base + (0x4000 + 0x130); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_l2_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_l2_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_l2_config()); val64 = __raw_readl(addr_gcr_redir_l2_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_l2_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_l2_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_redir_l2_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_l2_config()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_l2_config() + 4); __raw_writel(val, addr_gcr_redir_l2_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_l2_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_redir_l2_config(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_l2_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_l2_config(uint32_t val) { change_gcr_redir_l2_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_l2_config(uint32_t val) { change_gcr_redir_l2_config(val, 0); }






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_sys_config2(void) { return mips_gcr_base + (0x0000 + 0x150); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_sys_config2(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_sys_config2()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_sys_config2()); val64 = __raw_readl(addr_gcr_sys_config2() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_sys_config2()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_sys_config2(void) { return mips_gcr_base + (0x4000 + 0x150); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_sys_config2(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_sys_config2()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_sys_config2()); val64 = __raw_readl(addr_gcr_redir_sys_config2() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_sys_config2()); return val64; default: return __cps_access_bad_size(); } }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_l2_pft_control(void) { return mips_gcr_base + (0x0000 + 0x300); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_l2_pft_control(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_l2_pft_control()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_l2_pft_control()); val64 = __raw_readl(addr_gcr_l2_pft_control() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_l2_pft_control()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_l2_pft_control(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_l2_pft_control()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_l2_pft_control()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_l2_pft_control() + 4); __raw_writel(val, addr_gcr_l2_pft_control()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_l2_pft_control(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_l2_pft_control(); reg_val &= ~mask; reg_val |= val; write_gcr_l2_pft_control(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_l2_pft_control(uint32_t val) { change_gcr_l2_pft_control(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_l2_pft_control(uint32_t val) { change_gcr_l2_pft_control(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_l2_pft_control(void) { return mips_gcr_base + (0x4000 + 0x300); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_l2_pft_control(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_l2_pft_control()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_l2_pft_control()); val64 = __raw_readl(addr_gcr_redir_l2_pft_control() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_l2_pft_control()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_l2_pft_control(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_redir_l2_pft_control()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_l2_pft_control()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_l2_pft_control() + 4); __raw_writel(val, addr_gcr_redir_l2_pft_control()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_l2_pft_control(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_redir_l2_pft_control(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_l2_pft_control(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_l2_pft_control(uint32_t val) { change_gcr_redir_l2_pft_control(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_l2_pft_control(uint32_t val) { change_gcr_redir_l2_pft_control(val, 0); }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_l2_pft_control_b(void) { return mips_gcr_base + (0x0000 + 0x308); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_l2_pft_control_b(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_l2_pft_control_b()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_l2_pft_control_b()); val64 = __raw_readl(addr_gcr_l2_pft_control_b() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_l2_pft_control_b()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_l2_pft_control_b(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_l2_pft_control_b()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_l2_pft_control_b()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_l2_pft_control_b() + 4); __raw_writel(val, addr_gcr_l2_pft_control_b()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_l2_pft_control_b(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_l2_pft_control_b(); reg_val &= ~mask; reg_val |= val; write_gcr_l2_pft_control_b(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_l2_pft_control_b(uint32_t val) { change_gcr_l2_pft_control_b(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_l2_pft_control_b(uint32_t val) { change_gcr_l2_pft_control_b(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_l2_pft_control_b(void) { return mips_gcr_base + (0x4000 + 0x308); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_l2_pft_control_b(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_l2_pft_control_b()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_l2_pft_control_b()); val64 = __raw_readl(addr_gcr_redir_l2_pft_control_b() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_l2_pft_control_b()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_l2_pft_control_b(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_redir_l2_pft_control_b()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_l2_pft_control_b()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_l2_pft_control_b() + 4); __raw_writel(val, addr_gcr_redir_l2_pft_control_b()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_l2_pft_control_b(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_redir_l2_pft_control_b(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_l2_pft_control_b(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_l2_pft_control_b(uint32_t val) { change_gcr_redir_l2_pft_control_b(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_l2_pft_control_b(uint32_t val) { change_gcr_redir_l2_pft_control_b(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_l2sm_cop(void) { return mips_gcr_base + (0x0000 + 0x620); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_l2sm_cop(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_l2sm_cop()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_l2sm_cop()); val64 = __raw_readl(addr_gcr_l2sm_cop() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_l2sm_cop()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_l2sm_cop(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_l2sm_cop()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_l2sm_cop()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_l2sm_cop() + 4); __raw_writel(val, addr_gcr_l2sm_cop()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_l2sm_cop(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_l2sm_cop(); reg_val &= ~mask; reg_val |= val; write_gcr_l2sm_cop(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_l2sm_cop(uint32_t val) { change_gcr_l2sm_cop(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_l2sm_cop(uint32_t val) { change_gcr_l2sm_cop(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_l2sm_cop(void) { return mips_gcr_base + (0x4000 + 0x620); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_l2sm_cop(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_l2sm_cop()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_l2sm_cop()); val64 = __raw_readl(addr_gcr_redir_l2sm_cop() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_l2sm_cop()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_l2sm_cop(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_redir_l2sm_cop()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_l2sm_cop()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_l2sm_cop() + 4); __raw_writel(val, addr_gcr_redir_l2sm_cop()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_l2sm_cop(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_redir_l2sm_cop(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_l2sm_cop(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_l2sm_cop(uint32_t val) { change_gcr_redir_l2sm_cop(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_l2sm_cop(uint32_t val) { change_gcr_redir_l2sm_cop(val, 0); }
# 276 "./arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_l2sm_tag_addr_cop(void) { return mips_gcr_base + (0x0000 + 0x628); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_l2sm_tag_addr_cop(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_l2sm_tag_addr_cop()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_l2sm_tag_addr_cop()); val64 = __raw_readl(addr_gcr_l2sm_tag_addr_cop() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_l2sm_tag_addr_cop()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_l2sm_tag_addr_cop(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_l2sm_tag_addr_cop()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_l2sm_tag_addr_cop()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_l2sm_tag_addr_cop() + 4); __raw_writel(val, addr_gcr_l2sm_tag_addr_cop()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_l2sm_tag_addr_cop(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_l2sm_tag_addr_cop(); reg_val &= ~mask; reg_val |= val; write_gcr_l2sm_tag_addr_cop(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_l2sm_tag_addr_cop(uint64_t val) { change_gcr_l2sm_tag_addr_cop(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_l2sm_tag_addr_cop(uint64_t val) { change_gcr_l2sm_tag_addr_cop(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_l2sm_tag_addr_cop(void) { return mips_gcr_base + (0x4000 + 0x628); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_l2sm_tag_addr_cop(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_l2sm_tag_addr_cop()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_l2sm_tag_addr_cop()); val64 = __raw_readl(addr_gcr_redir_l2sm_tag_addr_cop() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_l2sm_tag_addr_cop()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_l2sm_tag_addr_cop(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_l2sm_tag_addr_cop()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_l2sm_tag_addr_cop()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_l2sm_tag_addr_cop() + 4); __raw_writel(val, addr_gcr_redir_l2sm_tag_addr_cop()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_l2sm_tag_addr_cop(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_l2sm_tag_addr_cop(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_l2sm_tag_addr_cop(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_l2sm_tag_addr_cop(uint64_t val) { change_gcr_redir_l2sm_tag_addr_cop(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_l2sm_tag_addr_cop(uint64_t val) { change_gcr_redir_l2sm_tag_addr_cop(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_bev_base(void) { return mips_gcr_base + (0x0000 + 0x680); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_bev_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_bev_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_bev_base()); val64 = __raw_readl(addr_gcr_bev_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_bev_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_bev_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_bev_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_bev_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_bev_base() + 4); __raw_writel(val, addr_gcr_bev_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_bev_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_bev_base(); reg_val &= ~mask; reg_val |= val; write_gcr_bev_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_bev_base(uint64_t val) { change_gcr_bev_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_bev_base(uint64_t val) { change_gcr_bev_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_bev_base(void) { return mips_gcr_base + (0x4000 + 0x680); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_bev_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_bev_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_bev_base()); val64 = __raw_readl(addr_gcr_redir_bev_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_bev_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_bev_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_bev_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_bev_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_bev_base() + 4); __raw_writel(val, addr_gcr_redir_bev_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_bev_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_bev_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_bev_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_bev_base(uint64_t val) { change_gcr_redir_bev_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_bev_base(uint64_t val) { change_gcr_redir_bev_base(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_reset_release(void) { return mips_gcr_base + (0x2000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_reset_release(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_reset_release()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_reset_release()); val64 = __raw_readl(addr_gcr_cl_reset_release() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_reset_release()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_cl_reset_release(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_cl_reset_release()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_cl_reset_release()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_cl_reset_release() + 4); __raw_writel(val, addr_gcr_cl_reset_release()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_cl_reset_release(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_cl_reset_release(); reg_val &= ~mask; reg_val |= val; write_gcr_cl_reset_release(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_cl_reset_release(uint32_t val) { change_gcr_cl_reset_release(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_cl_reset_release(uint32_t val) { change_gcr_cl_reset_release(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_reset_release(void) { return mips_gcr_base + (0x4000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_reset_release(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_reset_release()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_reset_release()); val64 = __raw_readl(addr_gcr_co_reset_release() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_reset_release()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_co_reset_release(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_co_reset_release()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_co_reset_release()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_co_reset_release() + 4); __raw_writel(val, addr_gcr_co_reset_release()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_co_reset_release(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_co_reset_release(); reg_val &= ~mask; reg_val |= val; write_gcr_co_reset_release(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_co_reset_release(uint32_t val) { change_gcr_co_reset_release(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_co_reset_release(uint32_t val) { change_gcr_co_reset_release(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_coherence(void) { return mips_gcr_base + (0x2000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_coherence(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_coherence()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_coherence()); val64 = __raw_readl(addr_gcr_cl_coherence() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_coherence()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_cl_coherence(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_cl_coherence()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_cl_coherence()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_cl_coherence() + 4); __raw_writel(val, addr_gcr_cl_coherence()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_cl_coherence(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_cl_coherence(); reg_val &= ~mask; reg_val |= val; write_gcr_cl_coherence(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_cl_coherence(uint32_t val) { change_gcr_cl_coherence(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_cl_coherence(uint32_t val) { change_gcr_cl_coherence(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_coherence(void) { return mips_gcr_base + (0x4000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_coherence(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_coherence()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_coherence()); val64 = __raw_readl(addr_gcr_co_coherence() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_coherence()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_co_coherence(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_co_coherence()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_co_coherence()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_co_coherence() + 4); __raw_writel(val, addr_gcr_co_coherence()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_co_coherence(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_co_coherence(); reg_val &= ~mask; reg_val |= val; write_gcr_co_coherence(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_co_coherence(uint32_t val) { change_gcr_co_coherence(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_co_coherence(uint32_t val) { change_gcr_co_coherence(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_config(void) { return mips_gcr_base + (0x2000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_config()); val64 = __raw_readl(addr_gcr_cl_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_config(void) { return mips_gcr_base + (0x4000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_config()); val64 = __raw_readl(addr_gcr_co_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_config()); return val64; default: return __cps_access_bad_size(); } }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_other(void) { return mips_gcr_base + (0x2000 + 0x018); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_other(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_other()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_other()); val64 = __raw_readl(addr_gcr_cl_other() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_other()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_cl_other(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_cl_other()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_cl_other()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_cl_other() + 4); __raw_writel(val, addr_gcr_cl_other()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_cl_other(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_cl_other(); reg_val &= ~mask; reg_val |= val; write_gcr_cl_other(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_cl_other(uint32_t val) { change_gcr_cl_other(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_cl_other(uint32_t val) { change_gcr_cl_other(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_other(void) { return mips_gcr_base + (0x4000 + 0x018); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_other(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_other()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_other()); val64 = __raw_readl(addr_gcr_co_other() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_other()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_co_other(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_co_other()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_co_other()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_co_other() + 4); __raw_writel(val, addr_gcr_co_other()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_co_other(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_co_other(); reg_val &= ~mask; reg_val |= val; write_gcr_co_other(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_co_other(uint32_t val) { change_gcr_co_other(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_co_other(uint32_t val) { change_gcr_co_other(val, 0); }
# 312 "./arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_reset_base(void) { return mips_gcr_base + (0x2000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_reset_base(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_reset_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_reset_base()); val64 = __raw_readl(addr_gcr_cl_reset_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_reset_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_cl_reset_base(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_cl_reset_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_cl_reset_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_cl_reset_base() + 4); __raw_writel(val, addr_gcr_cl_reset_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_cl_reset_base(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_cl_reset_base(); reg_val &= ~mask; reg_val |= val; write_gcr_cl_reset_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_cl_reset_base(uint32_t val) { change_gcr_cl_reset_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_cl_reset_base(uint32_t val) { change_gcr_cl_reset_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_reset_base(void) { return mips_gcr_base + (0x4000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_reset_base(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_reset_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_reset_base()); val64 = __raw_readl(addr_gcr_co_reset_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_reset_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_co_reset_base(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_co_reset_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_co_reset_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_co_reset_base() + 4); __raw_writel(val, addr_gcr_co_reset_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_co_reset_base(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_co_reset_base(); reg_val &= ~mask; reg_val |= val; write_gcr_co_reset_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_co_reset_base(uint32_t val) { change_gcr_co_reset_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_co_reset_base(uint32_t val) { change_gcr_co_reset_base(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_id(void) { return mips_gcr_base + (0x2000 + 0x028); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_id(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_id()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_id()); val64 = __raw_readl(addr_gcr_cl_id() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_id()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_id(void) { return mips_gcr_base + (0x4000 + 0x028); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_id(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_id()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_id()); val64 = __raw_readl(addr_gcr_co_id() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_id()); return val64; default: return __cps_access_bad_size(); } }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_reset_ext_base(void) { return mips_gcr_base + (0x2000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_reset_ext_base(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_reset_ext_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_reset_ext_base()); val64 = __raw_readl(addr_gcr_cl_reset_ext_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_reset_ext_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_cl_reset_ext_base(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_cl_reset_ext_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_cl_reset_ext_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_cl_reset_ext_base() + 4); __raw_writel(val, addr_gcr_cl_reset_ext_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_cl_reset_ext_base(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_cl_reset_ext_base(); reg_val &= ~mask; reg_val |= val; write_gcr_cl_reset_ext_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_cl_reset_ext_base(uint32_t val) { change_gcr_cl_reset_ext_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_cl_reset_ext_base(uint32_t val) { change_gcr_cl_reset_ext_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_reset_ext_base(void) { return mips_gcr_base + (0x4000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_reset_ext_base(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_reset_ext_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_reset_ext_base()); val64 = __raw_readl(addr_gcr_co_reset_ext_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_reset_ext_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_co_reset_ext_base(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_co_reset_ext_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_co_reset_ext_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_co_reset_ext_base() + 4); __raw_writel(val, addr_gcr_co_reset_ext_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_co_reset_ext_base(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_co_reset_ext_base(); reg_val &= ~mask; reg_val |= val; write_gcr_co_reset_ext_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_co_reset_ext_base(uint32_t val) { change_gcr_co_reset_ext_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_co_reset_ext_base(uint32_t val) { change_gcr_co_reset_ext_base(val, 0); }
# 334 "./arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int mips_cm_l2sync(void)
{
 if (!mips_cm_has_l2sync())
  return -19;

 writel(0, mips_cm_l2sync_base);
 return 0;
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int mips_cm_revision(void)
{
 if (!mips_cm_present())
  return 0;

 return read_gcr_rev();
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int mips_cm_max_vp_width(void)
{
 extern int smp_num_siblings;

 if (mips_cm_revision() >= (({ ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_58(void) __attribute__((__error__("FIELD_PREP: " "mask is not constant"))); if (!(!(!__builtin_constant_p(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15))))))))) __compiletime_assert_58(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_59(void) __attribute__((__error__("FIELD_PREP: " "mask is zero"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) == 0))) __compiletime_assert_59(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_60(void) __attribute__((__error__("FIELD_PREP: " "value too large for the field"))); if (!(!(__builtin_constant_p(8) ? ~((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) >> (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1)) & (8) : 0))) __compiletime_assert_60(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_61(void) __attribute__((__error__("FIELD_PREP: " "type of reg too small for mask"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) > (typeof(0ULL))~0ull))) __compiletime_assert_61(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_62(void) __attribute__((__error__("BUILD_BUG_ON failed: " "(((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) - 1)) != 0"))); if (!(!((((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) - 1)) != 0))) __compiletime_assert_62(); } while (0); }); ((typeof(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))))(8) << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1)) & (((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))); }) | ({ ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_63(void) __attribute__((__error__("FIELD_PREP: " "mask is not constant"))); if (!(!(!__builtin_constant_p(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7))))))))) __compiletime_assert_63(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_64(void) __attribute__((__error__("FIELD_PREP: " "mask is zero"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) == 0))) __compiletime_assert_64(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_65(void) __attribute__((__error__("FIELD_PREP: " "value too large for the field"))); if (!(!(__builtin_constant_p(0) ? ~((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) >> (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1)) & (0) : 0))) __compiletime_assert_65(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_66(void) __attribute__((__error__("FIELD_PREP: " "type of reg too small for mask"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) > (typeof(0ULL))~0ull))) __compiletime_assert_66(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_67(void) __attribute__((__error__("BUILD_BUG_ON failed: " "(((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) - 1)) != 0"))); if (!(!((((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) - 1)) != 0))) __compiletime_assert_67(); } while (0); }); ((typeof(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))))(0) << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1)) & (((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))); })))
  return ({ ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_68(void) __attribute__((__error__("FIELD_GET: " "mask is not constant"))); if (!(!(!__builtin_constant_p(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3))))))))) __compiletime_assert_68(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_69(void) __attribute__((__error__("FIELD_GET: " "mask is zero"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) == 0))) __compiletime_assert_69(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_70(void) __attribute__((__error__("FIELD_GET: " "value too large for the field"))); if (!(!(__builtin_constant_p(0U) ? ~((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) >> (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) - 1)) & (0U) : 0))) __compiletime_assert_70(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_71(void) __attribute__((__error__("FIELD_GET: " "type of reg too small for mask"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) > (typeof(read_gcr_sys_config2()))~0ull))) __compiletime_assert_71(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_72(void) __attribute__((__error__("BUILD_BUG_ON failed: " "(((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) - 1))) - 1)) != 0"))); if (!(!((((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) - 1))) - 1)) != 0))) __compiletime_assert_72(); } while (0); }); (typeof(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))))(((read_gcr_sys_config2()) & (((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3))))))) >> (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (3)) * 0l)) : (int *)8))), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))))) - 1)); });


 if (mips_cm_present()) {





  return ({ ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_73(void) __attribute__((__error__("FIELD_GET: " "mask is not constant"))); if (!(!(!__builtin_constant_p(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9))))))))) __compiletime_assert_73(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_74(void) __attribute__((__error__("FIELD_GET: " "mask is zero"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) == 0))) __compiletime_assert_74(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_75(void) __attribute__((__error__("FIELD_GET: " "value too large for the field"))); if (!(!(__builtin_constant_p(0U) ? ~((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) >> (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) - 1)) & (0U) : 0))) __compiletime_assert_75(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_76(void) __attribute__((__error__("FIELD_GET: " "type of reg too small for mask"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) > (typeof(read_gcr_cl_config()))~0ull))) __compiletime_assert_76(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_77(void) __attribute__((__error__("BUILD_BUG_ON failed: " "(((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) - 1))) - 1)) != 0"))); if (!(!((((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) - 1))) - 1)) != 0))) __compiletime_assert_77(); } while (0); }); (typeof(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))))(((read_gcr_cl_config()) & (((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9))))))) >> (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))))) - 1)); }) + 1;
 }

 if (1)
  return smp_num_siblings;

 return 1;
}
# 396 "./arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int mips_cm_vp_id(unsigned int cpu)
{
 unsigned int core = cpu_core(&cpu_data[cpu]);
 unsigned int vp = cpu_vpe_id(&cpu_data[cpu]);

 return (core * mips_cm_max_vp_width()) + vp;
}
# 424 "./arch/mips/include/asm/mips-cm.h"
extern void mips_cm_lock_other(unsigned int cluster, unsigned int core,
          unsigned int vp, unsigned int block);







extern void mips_cm_unlock_other(void);
# 452 "./arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void mips_cm_lock_other_cpu(unsigned int cpu, unsigned int block)
{
 struct cpuinfo_mips *d = &cpu_data[cpu];

 mips_cm_lock_other(cpu_cluster(d), cpu_core(d), cpu_vpe_id(d), block);
}
# 105 "./arch/mips/include/asm/mips-cps.h" 2
# 1 "./arch/mips/include/asm/mips-cpc.h" 1
# 18 "./arch/mips/include/asm/mips-cpc.h"
extern void *mips_cpc_base;
# 28 "./arch/mips/include/asm/mips-cpc.h"
extern phys_addr_t mips_cpc_default_phys_base(void);
# 37 "./arch/mips/include/asm/mips-cpc.h"
extern int mips_cpc_probe(void);
# 50 "./arch/mips/include/asm/mips-cpc.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool mips_cpc_present(void)
{

 return mips_cpc_base != ((void *)0);



}
# 81 "./arch/mips/include/asm/mips-cpc.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_access(void) { return mips_cpc_base + (0x0000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_access(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_access()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_access()); val64 = __raw_readl(addr_cpc_access() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_access()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_access(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_access()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_access()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_access() + 4); __raw_writel(val, addr_cpc_access()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_access(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_access(); reg_val &= ~mask; reg_val |= val; write_cpc_access(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_access(uint32_t val) { change_cpc_access(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_access(uint32_t val) { change_cpc_access(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_access(void) { return mips_cpc_base + (0x4000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_access(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_access()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_access()); val64 = __raw_readl(addr_cpc_redir_access() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_access()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_access(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_redir_access()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_access()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_access() + 4); __raw_writel(val, addr_cpc_redir_access()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_access(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_redir_access(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_access(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_access(uint32_t val) { change_cpc_redir_access(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_access(uint32_t val) { change_cpc_redir_access(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_seqdel(void) { return mips_cpc_base + (0x0000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_seqdel(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_seqdel()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_seqdel()); val64 = __raw_readl(addr_cpc_seqdel() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_seqdel()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_seqdel(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_seqdel()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_seqdel()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_seqdel() + 4); __raw_writel(val, addr_cpc_seqdel()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_seqdel(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_seqdel(); reg_val &= ~mask; reg_val |= val; write_cpc_seqdel(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_seqdel(uint32_t val) { change_cpc_seqdel(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_seqdel(uint32_t val) { change_cpc_seqdel(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_seqdel(void) { return mips_cpc_base + (0x4000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_seqdel(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_seqdel()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_seqdel()); val64 = __raw_readl(addr_cpc_redir_seqdel() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_seqdel()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_seqdel(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_redir_seqdel()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_seqdel()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_seqdel() + 4); __raw_writel(val, addr_cpc_redir_seqdel()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_seqdel(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_redir_seqdel(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_seqdel(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_seqdel(uint32_t val) { change_cpc_redir_seqdel(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_seqdel(uint32_t val) { change_cpc_redir_seqdel(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_rail(void) { return mips_cpc_base + (0x0000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_rail(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_rail()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_rail()); val64 = __raw_readl(addr_cpc_rail() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_rail()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_rail(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_rail()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_rail()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_rail() + 4); __raw_writel(val, addr_cpc_rail()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_rail(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_rail(); reg_val &= ~mask; reg_val |= val; write_cpc_rail(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_rail(uint32_t val) { change_cpc_rail(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_rail(uint32_t val) { change_cpc_rail(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_rail(void) { return mips_cpc_base + (0x4000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_rail(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_rail()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_rail()); val64 = __raw_readl(addr_cpc_redir_rail() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_rail()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_rail(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_redir_rail()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_rail()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_rail() + 4); __raw_writel(val, addr_cpc_redir_rail()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_rail(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_redir_rail(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_rail(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_rail(uint32_t val) { change_cpc_redir_rail(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_rail(uint32_t val) { change_cpc_redir_rail(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_resetlen(void) { return mips_cpc_base + (0x0000 + 0x018); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_resetlen(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_resetlen()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_resetlen()); val64 = __raw_readl(addr_cpc_resetlen() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_resetlen()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_resetlen(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_resetlen()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_resetlen()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_resetlen() + 4); __raw_writel(val, addr_cpc_resetlen()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_resetlen(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_resetlen(); reg_val &= ~mask; reg_val |= val; write_cpc_resetlen(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_resetlen(uint32_t val) { change_cpc_resetlen(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_resetlen(uint32_t val) { change_cpc_resetlen(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_resetlen(void) { return mips_cpc_base + (0x4000 + 0x018); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_resetlen(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_resetlen()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_resetlen()); val64 = __raw_readl(addr_cpc_redir_resetlen() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_resetlen()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_resetlen(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_redir_resetlen()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_resetlen()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_resetlen() + 4); __raw_writel(val, addr_cpc_redir_resetlen()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_resetlen(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_redir_resetlen(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_resetlen(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_resetlen(uint32_t val) { change_cpc_redir_resetlen(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_resetlen(uint32_t val) { change_cpc_redir_resetlen(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_revision(void) { return mips_cpc_base + (0x0000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_revision(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_revision()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_revision()); val64 = __raw_readl(addr_cpc_revision() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_revision()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_revision(void) { return mips_cpc_base + (0x4000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_revision(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_revision()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_revision()); val64 = __raw_readl(addr_cpc_redir_revision() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_revision()); return val64; default: return __cps_access_bad_size(); } }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_pwrup_ctl(void) { return mips_cpc_base + (0x0000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_pwrup_ctl(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_pwrup_ctl()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_pwrup_ctl()); val64 = __raw_readl(addr_cpc_pwrup_ctl() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_pwrup_ctl()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_pwrup_ctl(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_pwrup_ctl()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_pwrup_ctl()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_pwrup_ctl() + 4); __raw_writel(val, addr_cpc_pwrup_ctl()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_pwrup_ctl(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_pwrup_ctl(); reg_val &= ~mask; reg_val |= val; write_cpc_pwrup_ctl(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_pwrup_ctl(uint32_t val) { change_cpc_pwrup_ctl(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_pwrup_ctl(uint32_t val) { change_cpc_pwrup_ctl(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_pwrup_ctl(void) { return mips_cpc_base + (0x4000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_pwrup_ctl(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_pwrup_ctl()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_pwrup_ctl()); val64 = __raw_readl(addr_cpc_redir_pwrup_ctl() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_pwrup_ctl()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_pwrup_ctl(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_redir_pwrup_ctl()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_pwrup_ctl()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_pwrup_ctl() + 4); __raw_writel(val, addr_cpc_redir_pwrup_ctl()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_pwrup_ctl(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_redir_pwrup_ctl(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_pwrup_ctl(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_pwrup_ctl(uint32_t val) { change_cpc_redir_pwrup_ctl(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_pwrup_ctl(uint32_t val) { change_cpc_redir_pwrup_ctl(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_config(void) { return mips_cpc_base + (0x0000 + 0x138); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_cpc_config(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_cpc_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_config()); val64 = __raw_readl(addr_cpc_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_config(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_cpc_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_config()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_config() + 4); __raw_writel(val, addr_cpc_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_config(uint64_t mask, uint64_t val) { uint64_t reg_val = read_cpc_config(); reg_val &= ~mask; reg_val |= val; write_cpc_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_config(uint64_t val) { change_cpc_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_config(uint64_t val) { change_cpc_config(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_config(void) { return mips_cpc_base + (0x4000 + 0x138); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_cpc_redir_config(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_cpc_redir_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_config()); val64 = __raw_readl(addr_cpc_redir_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_config(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_cpc_redir_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_config()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_config() + 4); __raw_writel(val, addr_cpc_redir_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_config(uint64_t mask, uint64_t val) { uint64_t reg_val = read_cpc_redir_config(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_config(uint64_t val) { change_cpc_redir_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_config(uint64_t val) { change_cpc_redir_config(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_sys_config(void) { return mips_cpc_base + (0x0000 + 0x140); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_sys_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_sys_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_sys_config()); val64 = __raw_readl(addr_cpc_sys_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_sys_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_sys_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_sys_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_sys_config()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_sys_config() + 4); __raw_writel(val, addr_cpc_sys_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_sys_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_sys_config(); reg_val &= ~mask; reg_val |= val; write_cpc_sys_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_sys_config(uint32_t val) { change_cpc_sys_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_sys_config(uint32_t val) { change_cpc_sys_config(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_sys_config(void) { return mips_cpc_base + (0x4000 + 0x140); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_sys_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_sys_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_sys_config()); val64 = __raw_readl(addr_cpc_redir_sys_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_sys_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_sys_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_redir_sys_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_sys_config()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_sys_config() + 4); __raw_writel(val, addr_cpc_redir_sys_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_sys_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_redir_sys_config(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_sys_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_sys_config(uint32_t val) { change_cpc_redir_sys_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_sys_config(uint32_t val) { change_cpc_redir_sys_config(val, 0); }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_cmd(void) { return mips_cpc_base + (0x2000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_cmd(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_cmd()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_cmd()); val64 = __raw_readl(addr_cpc_cl_cmd() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_cmd()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_cmd(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_cmd()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_cmd()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_cmd() + 4); __raw_writel(val, addr_cpc_cl_cmd()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_cmd(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_cmd(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_cmd(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_cmd(uint32_t val) { change_cpc_cl_cmd(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_cmd(uint32_t val) { change_cpc_cl_cmd(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_cmd(void) { return mips_cpc_base + (0x4000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_cmd(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_cmd()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_cmd()); val64 = __raw_readl(addr_cpc_co_cmd() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_cmd()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_cmd(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_cmd()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_cmd()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_cmd() + 4); __raw_writel(val, addr_cpc_co_cmd()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_cmd(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_cmd(); reg_val &= ~mask; reg_val |= val; write_cpc_co_cmd(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_cmd(uint32_t val) { change_cpc_co_cmd(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_cmd(uint32_t val) { change_cpc_co_cmd(val, 0); }







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_stat_conf(void) { return mips_cpc_base + (0x2000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_stat_conf(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_stat_conf()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_stat_conf()); val64 = __raw_readl(addr_cpc_cl_stat_conf() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_stat_conf()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_stat_conf(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_stat_conf()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_stat_conf()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_stat_conf() + 4); __raw_writel(val, addr_cpc_cl_stat_conf()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_stat_conf(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_stat_conf(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_stat_conf(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_stat_conf(uint32_t val) { change_cpc_cl_stat_conf(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_stat_conf(uint32_t val) { change_cpc_cl_stat_conf(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_stat_conf(void) { return mips_cpc_base + (0x4000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_stat_conf(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_stat_conf()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_stat_conf()); val64 = __raw_readl(addr_cpc_co_stat_conf() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_stat_conf()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_stat_conf(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_stat_conf()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_stat_conf()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_stat_conf() + 4); __raw_writel(val, addr_cpc_co_stat_conf()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_stat_conf(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_stat_conf(); reg_val &= ~mask; reg_val |= val; write_cpc_co_stat_conf(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_stat_conf(uint32_t val) { change_cpc_co_stat_conf(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_stat_conf(uint32_t val) { change_cpc_co_stat_conf(val, 0); }
# 136 "./arch/mips/include/asm/mips-cpc.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_other(void) { return mips_cpc_base + (0x2000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_other(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_other()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_other()); val64 = __raw_readl(addr_cpc_cl_other() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_other()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_other(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_other()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_other()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_other() + 4); __raw_writel(val, addr_cpc_cl_other()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_other(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_other(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_other(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_other(uint32_t val) { change_cpc_cl_other(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_other(uint32_t val) { change_cpc_cl_other(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_other(void) { return mips_cpc_base + (0x4000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_other(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_other()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_other()); val64 = __raw_readl(addr_cpc_co_other() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_other()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_other(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_other()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_other()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_other() + 4); __raw_writel(val, addr_cpc_co_other()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_other(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_other(); reg_val &= ~mask; reg_val |= val; write_cpc_co_other(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_other(uint32_t val) { change_cpc_co_other(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_other(uint32_t val) { change_cpc_co_other(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_vp_stop(void) { return mips_cpc_base + (0x2000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_vp_stop(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_vp_stop()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_vp_stop()); val64 = __raw_readl(addr_cpc_cl_vp_stop() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_vp_stop()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_vp_stop(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_vp_stop()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_vp_stop()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_vp_stop() + 4); __raw_writel(val, addr_cpc_cl_vp_stop()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_vp_stop(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_vp_stop(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_vp_stop(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_vp_stop(uint32_t val) { change_cpc_cl_vp_stop(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_vp_stop(uint32_t val) { change_cpc_cl_vp_stop(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_vp_stop(void) { return mips_cpc_base + (0x4000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_vp_stop(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_vp_stop()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_vp_stop()); val64 = __raw_readl(addr_cpc_co_vp_stop() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_vp_stop()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_vp_stop(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_vp_stop()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_vp_stop()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_vp_stop() + 4); __raw_writel(val, addr_cpc_co_vp_stop()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_vp_stop(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_vp_stop(); reg_val &= ~mask; reg_val |= val; write_cpc_co_vp_stop(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_vp_stop(uint32_t val) { change_cpc_co_vp_stop(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_vp_stop(uint32_t val) { change_cpc_co_vp_stop(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_vp_run(void) { return mips_cpc_base + (0x2000 + 0x028); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_vp_run(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_vp_run()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_vp_run()); val64 = __raw_readl(addr_cpc_cl_vp_run() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_vp_run()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_vp_run(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_vp_run()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_vp_run()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_vp_run() + 4); __raw_writel(val, addr_cpc_cl_vp_run()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_vp_run(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_vp_run(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_vp_run(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_vp_run(uint32_t val) { change_cpc_cl_vp_run(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_vp_run(uint32_t val) { change_cpc_cl_vp_run(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_vp_run(void) { return mips_cpc_base + (0x4000 + 0x028); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_vp_run(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_vp_run()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_vp_run()); val64 = __raw_readl(addr_cpc_co_vp_run() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_vp_run()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_vp_run(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_vp_run()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_vp_run()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_vp_run() + 4); __raw_writel(val, addr_cpc_co_vp_run()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_vp_run(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_vp_run(); reg_val &= ~mask; reg_val |= val; write_cpc_co_vp_run(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_vp_run(uint32_t val) { change_cpc_co_vp_run(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_vp_run(uint32_t val) { change_cpc_co_vp_run(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_vp_running(void) { return mips_cpc_base + (0x2000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_vp_running(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_vp_running()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_vp_running()); val64 = __raw_readl(addr_cpc_cl_vp_running() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_vp_running()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_vp_running(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_vp_running()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_vp_running()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_vp_running() + 4); __raw_writel(val, addr_cpc_cl_vp_running()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_vp_running(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_vp_running(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_vp_running(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_vp_running(uint32_t val) { change_cpc_cl_vp_running(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_vp_running(uint32_t val) { change_cpc_cl_vp_running(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_vp_running(void) { return mips_cpc_base + (0x4000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_vp_running(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_vp_running()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_vp_running()); val64 = __raw_readl(addr_cpc_co_vp_running() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_vp_running()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_vp_running(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_vp_running()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_vp_running()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_vp_running() + 4); __raw_writel(val, addr_cpc_co_vp_running()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_vp_running(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_vp_running(); reg_val &= ~mask; reg_val |= val; write_cpc_co_vp_running(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_vp_running(uint32_t val) { change_cpc_co_vp_running(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_vp_running(uint32_t val) { change_cpc_co_vp_running(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_config(void) { return mips_cpc_base + (0x2000 + 0x090); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_config()); val64 = __raw_readl(addr_cpc_cl_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_config()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_config() + 4); __raw_writel(val, addr_cpc_cl_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_config(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_config(uint32_t val) { change_cpc_cl_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_config(uint32_t val) { change_cpc_cl_config(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_config(void) { return mips_cpc_base + (0x4000 + 0x090); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_config()); val64 = __raw_readl(addr_cpc_co_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_config()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_config() + 4); __raw_writel(val, addr_cpc_co_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_config(); reg_val &= ~mask; reg_val |= val; write_cpc_co_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_config(uint32_t val) { change_cpc_co_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_config(uint32_t val) { change_cpc_co_config(val, 0); }
# 162 "./arch/mips/include/asm/mips-cpc.h"
extern void mips_cpc_lock_other(unsigned int core);







extern void mips_cpc_unlock_other(void);
# 106 "./arch/mips/include/asm/mips-cps.h" 2
# 1 "./arch/mips/include/asm/mips-gic.h" 1
# 17 "./arch/mips/include/asm/mips-gic.h"
extern void *mips_gic_base;
# 164 "./arch/mips/include/asm/mips-gic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_config(void) { return mips_gic_base + (0x00000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_config()); val64 = __raw_readl(addr_gic_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_config()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_config() + 4); __raw_writel(val, addr_gic_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_config(); reg_val &= ~mask; reg_val |= val; write_gic_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_config(uint32_t val) { change_gic_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_config(uint32_t val) { change_gic_config(val, 0); }






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_counter(void) { return mips_gic_base + (0x00000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gic_counter(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gic_counter()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_counter()); val64 = __raw_readl(addr_gic_counter() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_counter()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_counter(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gic_counter()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_counter()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_counter() + 4); __raw_writel(val, addr_gic_counter()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_counter(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gic_counter(); reg_val &= ~mask; reg_val |= val; write_gic_counter(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_counter(uint64_t val) { change_gic_counter(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_counter(uint64_t val) { change_gic_counter(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_counter_32l(void) { return mips_gic_base + (0x00000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_counter_32l(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_counter_32l()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_counter_32l()); val64 = __raw_readl(addr_gic_counter_32l() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_counter_32l()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_counter_32l(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_counter_32l()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_counter_32l()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_counter_32l() + 4); __raw_writel(val, addr_gic_counter_32l()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_counter_32l(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_counter_32l(); reg_val &= ~mask; reg_val |= val; write_gic_counter_32l(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_counter_32l(uint32_t val) { change_gic_counter_32l(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_counter_32l(uint32_t val) { change_gic_counter_32l(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_counter_32h(void) { return mips_gic_base + (0x00000 + 0x014); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_counter_32h(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_counter_32h()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_counter_32h()); val64 = __raw_readl(addr_gic_counter_32h() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_counter_32h()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_counter_32h(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_counter_32h()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_counter_32h()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_counter_32h() + 4); __raw_writel(val, addr_gic_counter_32h()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_counter_32h(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_counter_32h(); reg_val &= ~mask; reg_val |= val; write_gic_counter_32h(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_counter_32h(uint32_t val) { change_gic_counter_32h(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_counter_32h(uint32_t val) { change_gic_counter_32h(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_pol(void) { return mips_gic_base + (0x100); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_pol(unsigned int intr) { void *addr = addr_gic_pol(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_pol(unsigned int intr) { void *addr = addr_gic_pol(); if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); __raw_writeq(((((1UL))) << (intr % 64)), addr); } else { addr += (intr / 32) * sizeof(uint32_t); __raw_writel(((((1UL))) << (intr % 32)), addr); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_pol(unsigned int intr, unsigned int val) { void *addr = addr_gic_pol(); if (mips_cm_is64) { uint64_t _val; addr += (intr / 64) * sizeof(uint64_t); _val = __raw_readq(addr); _val &= ~((((1ULL))) << (intr % 64)); _val |= (uint64_t)val << (intr % 64); __raw_writeq(_val, addr); } else { uint32_t _val; addr += (intr / 32) * sizeof(uint32_t); _val = __raw_readl(addr); _val &= ~((((1UL))) << (intr % 32)); _val |= val << (intr % 32); __raw_writel(_val, addr); } }






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_trig(void) { return mips_gic_base + (0x180); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_trig(unsigned int intr) { void *addr = addr_gic_trig(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_trig(unsigned int intr) { void *addr = addr_gic_trig(); if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); __raw_writeq(((((1UL))) << (intr % 64)), addr); } else { addr += (intr / 32) * sizeof(uint32_t); __raw_writel(((((1UL))) << (intr % 32)), addr); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_trig(unsigned int intr, unsigned int val) { void *addr = addr_gic_trig(); if (mips_cm_is64) { uint64_t _val; addr += (intr / 64) * sizeof(uint64_t); _val = __raw_readq(addr); _val &= ~((((1ULL))) << (intr % 64)); _val |= (uint64_t)val << (intr % 64); __raw_writeq(_val, addr); } else { uint32_t _val; addr += (intr / 32) * sizeof(uint32_t); _val = __raw_readl(addr); _val &= ~((((1UL))) << (intr % 32)); _val |= val << (intr % 32); __raw_writel(_val, addr); } }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_dual(void) { return mips_gic_base + (0x200); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_dual(unsigned int intr) { void *addr = addr_gic_dual(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_dual(unsigned int intr) { void *addr = addr_gic_dual(); if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); __raw_writeq(((((1UL))) << (intr % 64)), addr); } else { addr += (intr / 32) * sizeof(uint32_t); __raw_writel(((((1UL))) << (intr % 32)), addr); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_dual(unsigned int intr, unsigned int val) { void *addr = addr_gic_dual(); if (mips_cm_is64) { uint64_t _val; addr += (intr / 64) * sizeof(uint64_t); _val = __raw_readq(addr); _val &= ~((((1ULL))) << (intr % 64)); _val |= (uint64_t)val << (intr % 64); __raw_writeq(_val, addr); } else { uint32_t _val; addr += (intr / 32) * sizeof(uint32_t); _val = __raw_readl(addr); _val &= ~((((1UL))) << (intr % 32)); _val |= val << (intr % 32); __raw_writel(_val, addr); } }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_wedge(void) { return mips_gic_base + (0x00000 + 0x280); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_wedge(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_wedge()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_wedge()); val64 = __raw_readl(addr_gic_wedge() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_wedge()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_wedge(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_wedge()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_wedge()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_wedge() + 4); __raw_writel(val, addr_gic_wedge()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_wedge(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_wedge(); reg_val &= ~mask; reg_val |= val; write_gic_wedge(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_wedge(uint32_t val) { change_gic_wedge(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_wedge(uint32_t val) { change_gic_wedge(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_rmask(void) { return mips_gic_base + (0x300); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_rmask(unsigned int intr) { void *addr = addr_gic_rmask(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_rmask(unsigned int intr) { void *addr = addr_gic_rmask(); if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); __raw_writeq(((((1UL))) << (intr % 64)), addr); } else { addr += (intr / 32) * sizeof(uint32_t); __raw_writel(((((1UL))) << (intr % 32)), addr); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_rmask(unsigned int intr, unsigned int val) { void *addr = addr_gic_rmask(); if (mips_cm_is64) { uint64_t _val; addr += (intr / 64) * sizeof(uint64_t); _val = __raw_readq(addr); _val &= ~((((1ULL))) << (intr % 64)); _val |= (uint64_t)val << (intr % 64); __raw_writeq(_val, addr); } else { uint32_t _val; addr += (intr / 32) * sizeof(uint32_t); _val = __raw_readl(addr); _val &= ~((((1UL))) << (intr % 32)); _val |= val << (intr % 32); __raw_writel(_val, addr); } }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_smask(void) { return mips_gic_base + (0x380); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_smask(unsigned int intr) { void *addr = addr_gic_smask(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_smask(unsigned int intr) { void *addr = addr_gic_smask(); if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); __raw_writeq(((((1UL))) << (intr % 64)), addr); } else { addr += (intr / 32) * sizeof(uint32_t); __raw_writel(((((1UL))) << (intr % 32)), addr); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_smask(unsigned int intr, unsigned int val) { void *addr = addr_gic_smask(); if (mips_cm_is64) { uint64_t _val; addr += (intr / 64) * sizeof(uint64_t); _val = __raw_readq(addr); _val &= ~((((1ULL))) << (intr % 64)); _val |= (uint64_t)val << (intr % 64); __raw_writeq(_val, addr); } else { uint32_t _val; addr += (intr / 32) * sizeof(uint32_t); _val = __raw_readl(addr); _val &= ~((((1UL))) << (intr % 32)); _val |= val << (intr % 32); __raw_writel(_val, addr); } }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_mask(void) { return mips_gic_base + (0x400); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_mask(unsigned int intr) { void *addr = addr_gic_mask(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_pend(void) { return mips_gic_base + (0x480); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_pend(unsigned int intr) { void *addr = addr_gic_pend(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_map_pin(unsigned int intr) { return mips_gic_base + (0x500) + (intr * (0x4)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_map_pin(unsigned int intr) { do { __attribute__((__noreturn__)) extern void __compiletime_assert_78(void) __attribute__((__error__("BUILD_BUG_ON failed: " "32 != 32"))); if (!(!(32 != 32))) __compiletime_assert_78(); } while (0); return __raw_readl(addr_gic_map_pin(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_map_pin(unsigned int intr, unsigned int val) { do { __attribute__((__noreturn__)) extern void __compiletime_assert_79(void) __attribute__((__error__("BUILD_BUG_ON failed: " "32 != 32"))); if (!(!(32 != 32))) __compiletime_assert_79(); } while (0); __raw_writel(val, addr_gic_map_pin(intr)); }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_map_vp(unsigned int intr) { return mips_gic_base + (0x2000) + (intr * (0x20)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_map_vp(unsigned int intr) { do { __attribute__((__noreturn__)) extern void __compiletime_assert_80(void) __attribute__((__error__("BUILD_BUG_ON failed: " "32 != 32"))); if (!(!(32 != 32))) __compiletime_assert_80(); } while (0); return __raw_readl(addr_gic_map_vp(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_map_vp(unsigned int intr, unsigned int val) { do { __attribute__((__noreturn__)) extern void __compiletime_assert_81(void) __attribute__((__error__("BUILD_BUG_ON failed: " "32 != 32"))); if (!(!(32 != 32))) __compiletime_assert_81(); } while (0); __raw_writel(val, addr_gic_map_vp(intr)); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_ctl(void) { return mips_gic_base + (0x08000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_ctl(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_ctl()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_ctl()); val64 = __raw_readl(addr_gic_vl_ctl() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_ctl()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_ctl(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_ctl()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_ctl()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_ctl() + 4); __raw_writel(val, addr_gic_vl_ctl()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_ctl(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_ctl(); reg_val &= ~mask; reg_val |= val; write_gic_vl_ctl(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_ctl(uint32_t val) { change_gic_vl_ctl(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_ctl(uint32_t val) { change_gic_vl_ctl(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_ctl(void) { return mips_gic_base + (0x0c000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_ctl(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_ctl()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_ctl()); val64 = __raw_readl(addr_gic_vo_ctl() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_ctl()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_ctl(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_ctl()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_ctl()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_ctl() + 4); __raw_writel(val, addr_gic_vo_ctl()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_ctl(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_ctl(); reg_val &= ~mask; reg_val |= val; write_gic_vo_ctl(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_ctl(uint32_t val) { change_gic_vo_ctl(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_ctl(uint32_t val) { change_gic_vo_ctl(val, 0); }







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_pend(void) { return mips_gic_base + (0x08000 + 0x004); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_pend(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_pend()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_pend()); val64 = __raw_readl(addr_gic_vl_pend() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_pend()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_pend(void) { return mips_gic_base + (0x0c000 + 0x004); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_pend(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_pend()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_pend()); val64 = __raw_readl(addr_gic_vo_pend() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_pend()); return val64; default: return __cps_access_bad_size(); } }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_mask(void) { return mips_gic_base + (0x08000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_mask(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_mask()); val64 = __raw_readl(addr_gic_vl_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_mask(void) { return mips_gic_base + (0x0c000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_mask(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_mask()); val64 = __raw_readl(addr_gic_vo_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_mask()); return val64; default: return __cps_access_bad_size(); } }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_rmask(void) { return mips_gic_base + (0x08000 + 0x00c); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_rmask(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_rmask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_rmask()); val64 = __raw_readl(addr_gic_vl_rmask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_rmask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_rmask(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_rmask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_rmask()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_rmask() + 4); __raw_writel(val, addr_gic_vl_rmask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_rmask(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_rmask(); reg_val &= ~mask; reg_val |= val; write_gic_vl_rmask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_rmask(uint32_t val) { change_gic_vl_rmask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_rmask(uint32_t val) { change_gic_vl_rmask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_rmask(void) { return mips_gic_base + (0x0c000 + 0x00c); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_rmask(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_rmask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_rmask()); val64 = __raw_readl(addr_gic_vo_rmask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_rmask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_rmask(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_rmask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_rmask()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_rmask() + 4); __raw_writel(val, addr_gic_vo_rmask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_rmask(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_rmask(); reg_val &= ~mask; reg_val |= val; write_gic_vo_rmask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_rmask(uint32_t val) { change_gic_vo_rmask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_rmask(uint32_t val) { change_gic_vo_rmask(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_smask(void) { return mips_gic_base + (0x08000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_smask(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_smask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_smask()); val64 = __raw_readl(addr_gic_vl_smask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_smask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_smask(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_smask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_smask()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_smask() + 4); __raw_writel(val, addr_gic_vl_smask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_smask(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_smask(); reg_val &= ~mask; reg_val |= val; write_gic_vl_smask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_smask(uint32_t val) { change_gic_vl_smask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_smask(uint32_t val) { change_gic_vl_smask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_smask(void) { return mips_gic_base + (0x0c000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_smask(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_smask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_smask()); val64 = __raw_readl(addr_gic_vo_smask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_smask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_smask(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_smask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_smask()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_smask() + 4); __raw_writel(val, addr_gic_vo_smask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_smask(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_smask(); reg_val &= ~mask; reg_val |= val; write_gic_vo_smask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_smask(uint32_t val) { change_gic_vo_smask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_smask(uint32_t val) { change_gic_vo_smask(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_map(unsigned int intr) { return mips_gic_base + (0x08000 + 0x040) + (intr * (0x4)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_vl_map(unsigned int intr) { do { __attribute__((__noreturn__)) extern void __compiletime_assert_82(void) __attribute__((__error__("BUILD_BUG_ON failed: " "32 != 32"))); if (!(!(32 != 32))) __compiletime_assert_82(); } while (0); return __raw_readl(addr_gic_vl_map(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_map(unsigned int intr, unsigned int val) { do { __attribute__((__noreturn__)) extern void __compiletime_assert_83(void) __attribute__((__error__("BUILD_BUG_ON failed: " "32 != 32"))); if (!(!(32 != 32))) __compiletime_assert_83(); } while (0); __raw_writel(val, addr_gic_vl_map(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_map(unsigned int intr) { return mips_gic_base + (0x0c000 + 0x040) + (intr * (0x4)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_vo_map(unsigned int intr) { do { __attribute__((__noreturn__)) extern void __compiletime_assert_84(void) __attribute__((__error__("BUILD_BUG_ON failed: " "32 != 32"))); if (!(!(32 != 32))) __compiletime_assert_84(); } while (0); return __raw_readl(addr_gic_vo_map(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_map(unsigned int intr, unsigned int val) { do { __attribute__((__noreturn__)) extern void __compiletime_assert_85(void) __attribute__((__error__("BUILD_BUG_ON failed: " "32 != 32"))); if (!(!(32 != 32))) __compiletime_assert_85(); } while (0); __raw_writel(val, addr_gic_vo_map(intr)); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_wd_map(void) { return mips_gic_base + (0x08000 + 0x040); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_wd_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_wd_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_wd_map()); val64 = __raw_readl(addr_gic_vl_wd_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_wd_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_wd_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_wd_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_wd_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_wd_map() + 4); __raw_writel(val, addr_gic_vl_wd_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_wd_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_wd_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_wd_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_wd_map(uint32_t val) { change_gic_vl_wd_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_wd_map(uint32_t val) { change_gic_vl_wd_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_wd_map(void) { return mips_gic_base + (0x0c000 + 0x040); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_wd_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_wd_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_wd_map()); val64 = __raw_readl(addr_gic_vo_wd_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_wd_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_wd_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_wd_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_wd_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_wd_map() + 4); __raw_writel(val, addr_gic_vo_wd_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_wd_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_wd_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_wd_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_wd_map(uint32_t val) { change_gic_vo_wd_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_wd_map(uint32_t val) { change_gic_vo_wd_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_compare_map(void) { return mips_gic_base + (0x08000 + 0x044); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_compare_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_compare_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_compare_map()); val64 = __raw_readl(addr_gic_vl_compare_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_compare_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_compare_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_compare_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_compare_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_compare_map() + 4); __raw_writel(val, addr_gic_vl_compare_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_compare_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_compare_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_compare_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_compare_map(uint32_t val) { change_gic_vl_compare_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_compare_map(uint32_t val) { change_gic_vl_compare_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_compare_map(void) { return mips_gic_base + (0x0c000 + 0x044); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_compare_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_compare_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_compare_map()); val64 = __raw_readl(addr_gic_vo_compare_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_compare_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_compare_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_compare_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_compare_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_compare_map() + 4); __raw_writel(val, addr_gic_vo_compare_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_compare_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_compare_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_compare_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_compare_map(uint32_t val) { change_gic_vo_compare_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_compare_map(uint32_t val) { change_gic_vo_compare_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_timer_map(void) { return mips_gic_base + (0x08000 + 0x048); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_timer_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_timer_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_timer_map()); val64 = __raw_readl(addr_gic_vl_timer_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_timer_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_timer_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_timer_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_timer_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_timer_map() + 4); __raw_writel(val, addr_gic_vl_timer_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_timer_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_timer_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_timer_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_timer_map(uint32_t val) { change_gic_vl_timer_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_timer_map(uint32_t val) { change_gic_vl_timer_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_timer_map(void) { return mips_gic_base + (0x0c000 + 0x048); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_timer_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_timer_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_timer_map()); val64 = __raw_readl(addr_gic_vo_timer_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_timer_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_timer_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_timer_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_timer_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_timer_map() + 4); __raw_writel(val, addr_gic_vo_timer_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_timer_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_timer_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_timer_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_timer_map(uint32_t val) { change_gic_vo_timer_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_timer_map(uint32_t val) { change_gic_vo_timer_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_fdc_map(void) { return mips_gic_base + (0x08000 + 0x04c); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_fdc_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_fdc_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_fdc_map()); val64 = __raw_readl(addr_gic_vl_fdc_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_fdc_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_fdc_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_fdc_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_fdc_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_fdc_map() + 4); __raw_writel(val, addr_gic_vl_fdc_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_fdc_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_fdc_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_fdc_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_fdc_map(uint32_t val) { change_gic_vl_fdc_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_fdc_map(uint32_t val) { change_gic_vl_fdc_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_fdc_map(void) { return mips_gic_base + (0x0c000 + 0x04c); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_fdc_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_fdc_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_fdc_map()); val64 = __raw_readl(addr_gic_vo_fdc_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_fdc_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_fdc_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_fdc_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_fdc_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_fdc_map() + 4); __raw_writel(val, addr_gic_vo_fdc_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_fdc_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_fdc_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_fdc_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_fdc_map(uint32_t val) { change_gic_vo_fdc_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_fdc_map(uint32_t val) { change_gic_vo_fdc_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_perfctr_map(void) { return mips_gic_base + (0x08000 + 0x050); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_perfctr_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_perfctr_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_perfctr_map()); val64 = __raw_readl(addr_gic_vl_perfctr_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_perfctr_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_perfctr_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_perfctr_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_perfctr_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_perfctr_map() + 4); __raw_writel(val, addr_gic_vl_perfctr_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_perfctr_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_perfctr_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_perfctr_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_perfctr_map(uint32_t val) { change_gic_vl_perfctr_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_perfctr_map(uint32_t val) { change_gic_vl_perfctr_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_perfctr_map(void) { return mips_gic_base + (0x0c000 + 0x050); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_perfctr_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_perfctr_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_perfctr_map()); val64 = __raw_readl(addr_gic_vo_perfctr_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_perfctr_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_perfctr_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_perfctr_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_perfctr_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_perfctr_map() + 4); __raw_writel(val, addr_gic_vo_perfctr_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_perfctr_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_perfctr_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_perfctr_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_perfctr_map(uint32_t val) { change_gic_vo_perfctr_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_perfctr_map(uint32_t val) { change_gic_vo_perfctr_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_swint0_map(void) { return mips_gic_base + (0x08000 + 0x054); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_swint0_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_swint0_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_swint0_map()); val64 = __raw_readl(addr_gic_vl_swint0_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_swint0_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_swint0_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_swint0_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_swint0_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_swint0_map() + 4); __raw_writel(val, addr_gic_vl_swint0_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_swint0_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_swint0_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_swint0_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_swint0_map(uint32_t val) { change_gic_vl_swint0_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_swint0_map(uint32_t val) { change_gic_vl_swint0_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_swint0_map(void) { return mips_gic_base + (0x0c000 + 0x054); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_swint0_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_swint0_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_swint0_map()); val64 = __raw_readl(addr_gic_vo_swint0_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_swint0_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_swint0_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_swint0_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_swint0_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_swint0_map() + 4); __raw_writel(val, addr_gic_vo_swint0_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_swint0_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_swint0_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_swint0_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_swint0_map(uint32_t val) { change_gic_vo_swint0_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_swint0_map(uint32_t val) { change_gic_vo_swint0_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_swint1_map(void) { return mips_gic_base + (0x08000 + 0x058); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_swint1_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_swint1_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_swint1_map()); val64 = __raw_readl(addr_gic_vl_swint1_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_swint1_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_swint1_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_swint1_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_swint1_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_swint1_map() + 4); __raw_writel(val, addr_gic_vl_swint1_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_swint1_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_swint1_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_swint1_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_swint1_map(uint32_t val) { change_gic_vl_swint1_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_swint1_map(uint32_t val) { change_gic_vl_swint1_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_swint1_map(void) { return mips_gic_base + (0x0c000 + 0x058); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_swint1_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_swint1_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_swint1_map()); val64 = __raw_readl(addr_gic_vo_swint1_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_swint1_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_swint1_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_swint1_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_swint1_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_swint1_map() + 4); __raw_writel(val, addr_gic_vo_swint1_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_swint1_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_swint1_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_swint1_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_swint1_map(uint32_t val) { change_gic_vo_swint1_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_swint1_map(uint32_t val) { change_gic_vo_swint1_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_other(void) { return mips_gic_base + (0x08000 + 0x080); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_other(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_other()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_other()); val64 = __raw_readl(addr_gic_vl_other() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_other()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_other(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_other()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_other()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_other() + 4); __raw_writel(val, addr_gic_vl_other()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_other(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_other(); reg_val &= ~mask; reg_val |= val; write_gic_vl_other(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_other(uint32_t val) { change_gic_vl_other(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_other(uint32_t val) { change_gic_vl_other(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_other(void) { return mips_gic_base + (0x0c000 + 0x080); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_other(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_other()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_other()); val64 = __raw_readl(addr_gic_vo_other() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_other()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_other(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_other()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_other()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_other() + 4); __raw_writel(val, addr_gic_vo_other()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_other(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_other(); reg_val &= ~mask; reg_val |= val; write_gic_vo_other(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_other(uint32_t val) { change_gic_vo_other(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_other(uint32_t val) { change_gic_vo_other(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_ident(void) { return mips_gic_base + (0x08000 + 0x088); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_ident(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_ident()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_ident()); val64 = __raw_readl(addr_gic_vl_ident() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_ident()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_ident(void) { return mips_gic_base + (0x0c000 + 0x088); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_ident(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_ident()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_ident()); val64 = __raw_readl(addr_gic_vo_ident() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_ident()); return val64; default: return __cps_access_bad_size(); } }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_compare(void) { return mips_gic_base + (0x08000 + 0x0a0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gic_vl_compare(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gic_vl_compare()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_compare()); val64 = __raw_readl(addr_gic_vl_compare() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_compare()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_compare(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gic_vl_compare()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_compare()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_compare() + 4); __raw_writel(val, addr_gic_vl_compare()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_compare(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gic_vl_compare(); reg_val &= ~mask; reg_val |= val; write_gic_vl_compare(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_compare(uint64_t val) { change_gic_vl_compare(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_compare(uint64_t val) { change_gic_vl_compare(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_compare(void) { return mips_gic_base + (0x0c000 + 0x0a0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gic_vo_compare(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gic_vo_compare()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_compare()); val64 = __raw_readl(addr_gic_vo_compare() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_compare()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_compare(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gic_vo_compare()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_compare()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_compare() + 4); __raw_writel(val, addr_gic_vo_compare()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_compare(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gic_vo_compare(); reg_val &= ~mask; reg_val |= val; write_gic_vo_compare(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_compare(uint64_t val) { change_gic_vo_compare(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_compare(uint64_t val) { change_gic_vo_compare(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_eic_shadow_set(unsigned int intr) { return mips_gic_base + (0x08000 + 0x100) + (intr * (0x4)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_vl_eic_shadow_set(unsigned int intr) { do { __attribute__((__noreturn__)) extern void __compiletime_assert_86(void) __attribute__((__error__("BUILD_BUG_ON failed: " "32 != 32"))); if (!(!(32 != 32))) __compiletime_assert_86(); } while (0); return __raw_readl(addr_gic_vl_eic_shadow_set(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_eic_shadow_set(unsigned int intr, unsigned int val) { do { __attribute__((__noreturn__)) extern void __compiletime_assert_87(void) __attribute__((__error__("BUILD_BUG_ON failed: " "32 != 32"))); if (!(!(32 != 32))) __compiletime_assert_87(); } while (0); __raw_writel(val, addr_gic_vl_eic_shadow_set(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_eic_shadow_set(unsigned int intr) { return mips_gic_base + (0x0c000 + 0x100) + (intr * (0x4)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_vo_eic_shadow_set(unsigned int intr) { do { __attribute__((__noreturn__)) extern void __compiletime_assert_88(void) __attribute__((__error__("BUILD_BUG_ON failed: " "32 != 32"))); if (!(!(32 != 32))) __compiletime_assert_88(); } while (0); return __raw_readl(addr_gic_vo_eic_shadow_set(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_eic_shadow_set(unsigned int intr, unsigned int val) { do { __attribute__((__noreturn__)) extern void __compiletime_assert_89(void) __attribute__((__error__("BUILD_BUG_ON failed: " "32 != 32"))); if (!(!(32 != 32))) __compiletime_assert_89(); } while (0); __raw_writel(val, addr_gic_vo_eic_shadow_set(intr)); }
# 289 "./arch/mips/include/asm/mips-gic.h"
enum mips_gic_local_interrupt {
 GIC_LOCAL_INT_WD,
 GIC_LOCAL_INT_COMPARE,
 GIC_LOCAL_INT_TIMER,
 GIC_LOCAL_INT_PERFCTR,
 GIC_LOCAL_INT_SWINT0,
 GIC_LOCAL_INT_SWINT1,
 GIC_LOCAL_INT_FDC,
 GIC_NUM_LOCAL_INTRS
};
# 308 "./arch/mips/include/asm/mips-gic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool mips_gic_present(void)
{
 return 1 && mips_gic_base;
}
# 328 "./arch/mips/include/asm/mips-gic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int
mips_gic_vx_map_reg(enum mips_gic_local_interrupt intr)
{

 if (intr <= GIC_LOCAL_INT_TIMER)
  return intr;


 if (intr == GIC_LOCAL_INT_FDC)
  return GIC_LOCAL_INT_TIMER + 1;


 return intr + 1;
}
# 351 "./arch/mips/include/asm/mips-gic.h"
extern int gic_get_c0_compare_int(void);
# 361 "./arch/mips/include/asm/mips-gic.h"
extern int gic_get_c0_perfcount_int(void);
# 371 "./arch/mips/include/asm/mips-gic.h"
extern int gic_get_c0_fdc_int(void);
# 107 "./arch/mips/include/asm/mips-cps.h" 2






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int mips_cps_numclusters(void)
{
 unsigned int num_clusters;

 if (mips_cm_revision() < (({ ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_90(void) __attribute__((__error__("FIELD_PREP: " "mask is not constant"))); if (!(!(!__builtin_constant_p(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15))))))))) __compiletime_assert_90(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_91(void) __attribute__((__error__("FIELD_PREP: " "mask is zero"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) == 0))) __compiletime_assert_91(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_92(void) __attribute__((__error__("FIELD_PREP: " "value too large for the field"))); if (!(!(__builtin_constant_p(9) ? ~((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) >> (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1)) & (9) : 0))) __compiletime_assert_92(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_93(void) __attribute__((__error__("FIELD_PREP: " "type of reg too small for mask"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) > (typeof(0ULL))~0ull))) __compiletime_assert_93(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_94(void) __attribute__((__error__("BUILD_BUG_ON failed: " "(((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) - 1)) != 0"))); if (!(!((((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) - 1)) != 0))) __compiletime_assert_94(); } while (0); }); ((typeof(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))))(9) << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1)) & (((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))); }) | ({ ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_95(void) __attribute__((__error__("FIELD_PREP: " "mask is not constant"))); if (!(!(!__builtin_constant_p(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7))))))))) __compiletime_assert_95(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_96(void) __attribute__((__error__("FIELD_PREP: " "mask is zero"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) == 0))) __compiletime_assert_96(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_97(void) __attribute__((__error__("FIELD_PREP: " "value too large for the field"))); if (!(!(__builtin_constant_p(0) ? ~((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) >> (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1)) & (0) : 0))) __compiletime_assert_97(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_98(void) __attribute__((__error__("FIELD_PREP: " "type of reg too small for mask"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) > (typeof(0ULL))~0ull))) __compiletime_assert_98(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_99(void) __attribute__((__error__("BUILD_BUG_ON failed: " "(((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) - 1)) != 0"))); if (!(!((((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) - 1)) != 0))) __compiletime_assert_99(); } while (0); }); ((typeof(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))))(0) << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1)) & (((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))); })))
  return 1;

 num_clusters = read_gcr_config() & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((23) > (29)) * 0l)) : (int *)8))), (23) > (29), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (23)) + 1) & (~(((0UL))) >> (32 - 1 - (29)))));
 num_clusters >>= __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((23) > (29)) * 0l)) : (int *)8))), (23) > (29), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (23)) + 1) & (~(((0UL))) >> (32 - 1 - (29))))));
 return num_clusters;
}
# 133 "./arch/mips/include/asm/mips-cps.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t mips_cps_cluster_config(unsigned int cluster)
{
 uint64_t config;

 if (mips_cm_revision() < (({ ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_100(void) __attribute__((__error__("FIELD_PREP: " "mask is not constant"))); if (!(!(!__builtin_constant_p(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15))))))))) __compiletime_assert_100(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_101(void) __attribute__((__error__("FIELD_PREP: " "mask is zero"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) == 0))) __compiletime_assert_101(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_102(void) __attribute__((__error__("FIELD_PREP: " "value too large for the field"))); if (!(!(__builtin_constant_p(9) ? ~((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) >> (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1)) & (9) : 0))) __compiletime_assert_102(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_103(void) __attribute__((__error__("FIELD_PREP: " "type of reg too small for mask"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) > (typeof(0ULL))~0ull))) __compiletime_assert_103(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_104(void) __attribute__((__error__("BUILD_BUG_ON failed: " "(((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) - 1)) != 0"))); if (!(!((((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) - 1)) != 0))) __compiletime_assert_104(); } while (0); }); ((typeof(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))))(9) << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1)) & (((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))); }) | ({ ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_105(void) __attribute__((__error__("FIELD_PREP: " "mask is not constant"))); if (!(!(!__builtin_constant_p(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7))))))))) __compiletime_assert_105(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_106(void) __attribute__((__error__("FIELD_PREP: " "mask is zero"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) == 0))) __compiletime_assert_106(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_107(void) __attribute__((__error__("FIELD_PREP: " "value too large for the field"))); if (!(!(__builtin_constant_p(0) ? ~((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) >> (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1)) & (0) : 0))) __compiletime_assert_107(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_108(void) __attribute__((__error__("FIELD_PREP: " "type of reg too small for mask"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) > (typeof(0ULL))~0ull))) __compiletime_assert_108(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_109(void) __attribute__((__error__("BUILD_BUG_ON failed: " "(((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) - 1)) != 0"))); if (!(!((((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) - 1)) != 0))) __compiletime_assert_109(); } while (0); }); ((typeof(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))))(0) << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1)) & (((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))); }))) {





  ({ int __ret_warn_on = !!(cluster != 0); if (__builtin_expect(!!(__ret_warn_on), 0)) do { do { } while(0); warn_slowpath_fmt("arch/mips/include/asm/mips-cps.h", 143, 9, ((void *)0)); do { } while(0); } while (0); __builtin_expect(!!(__ret_warn_on), 0); });
  config = read_gcr_config();
 } else {





  mips_cm_lock_other(cluster, 0, 0, 1);
  config = read_cpc_redir_config();
  mips_cm_unlock_other();
 }

 return config;
}
# 166 "./arch/mips/include/asm/mips-cps.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int mips_cps_numcores(unsigned int cluster)
{
 if (!mips_cm_present())
  return 0;


 return (mips_cps_cluster_config(cluster) + 1) & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))));
}
# 182 "./arch/mips/include/asm/mips-cps.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int mips_cps_numiocu(unsigned int cluster)
{
 unsigned int num_iocu;

 if (!mips_cm_present())
  return 0;

 num_iocu = mips_cps_cluster_config(cluster) & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))));
 num_iocu >>= __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15))))));
 return num_iocu;
}
# 203 "./arch/mips/include/asm/mips-cps.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int mips_cps_numvps(unsigned int cluster, unsigned int core)
{
 unsigned int cfg;

 if (!mips_cm_present())
  return 1;

 if ((!1 || !(((1 >= (2)) && (1 < (6))) && (cpu_data[0].ases & (0x00000020))))
  && (!0 || !((1 >= (6)) && (cpu_data[0].options & (((((1ULL))) << (40)))))))
  return 1;

 mips_cm_lock_other(cluster, core, 0, 0);

 if (mips_cm_revision() < (({ ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_110(void) __attribute__((__error__("FIELD_PREP: " "mask is not constant"))); if (!(!(!__builtin_constant_p(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15))))))))) __compiletime_assert_110(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_111(void) __attribute__((__error__("FIELD_PREP: " "mask is zero"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) == 0))) __compiletime_assert_111(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_112(void) __attribute__((__error__("FIELD_PREP: " "value too large for the field"))); if (!(!(__builtin_constant_p(9) ? ~((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) >> (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1)) & (9) : 0))) __compiletime_assert_112(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_113(void) __attribute__((__error__("FIELD_PREP: " "type of reg too small for mask"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) > (typeof(0ULL))~0ull))) __compiletime_assert_113(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_114(void) __attribute__((__error__("BUILD_BUG_ON failed: " "(((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) - 1)) != 0"))); if (!(!((((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1))) - 1)) != 0))) __compiletime_assert_114(); } while (0); }); ((typeof(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))))(9) << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))) - 1)) & (((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((8) > (15)) * 0l)) : (int *)8))), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))))); }) | ({ ({ do { __attribute__((__noreturn__)) extern void __compiletime_assert_115(void) __attribute__((__error__("FIELD_PREP: " "mask is not constant"))); if (!(!(!__builtin_constant_p(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7))))))))) __compiletime_assert_115(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_116(void) __attribute__((__error__("FIELD_PREP: " "mask is zero"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) == 0))) __compiletime_assert_116(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_117(void) __attribute__((__error__("FIELD_PREP: " "value too large for the field"))); if (!(!(__builtin_constant_p(0) ? ~((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) >> (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1)) & (0) : 0))) __compiletime_assert_117(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_118(void) __attribute__((__error__("FIELD_PREP: " "type of reg too small for mask"))); if (!(!((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) > (typeof(0ULL))~0ull))) __compiletime_assert_118(); } while (0); do { __attribute__((__noreturn__)) extern void __compiletime_assert_119(void) __attribute__((__error__("BUILD_BUG_ON failed: " "(((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) - 1)) != 0"))); if (!(!((((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) & (((((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) + (1ULL << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1))) - 1)) != 0))) __compiletime_assert_119(); } while (0); }); ((typeof(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))))(0) << (__builtin_ffsll(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))) - 1)) & (((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (7)) * 0l)) : (int *)8))), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))); }))) {




  cfg = read_gcr_co_config();
 } else {





  cfg = read_cpc_co_config();
 }

 mips_cm_unlock_other();

 return (cfg + 1) & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( (sizeof(int) == sizeof(*(8 ? ((void *)((long)((0) > (9)) * 0l)) : (int *)8))), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))));
}
# 17 "./arch/mips/include/asm/smp-ops.h" 2





struct task_struct;

struct plat_smp_ops {
 void (*send_ipi_single)(int cpu, unsigned int action);
 void (*send_ipi_mask)(const struct cpumask *mask, unsigned int action);
 void (*init_secondary)(void);
 void (*smp_finish)(void);
 int (*boot_secondary)(int cpu, struct task_struct *idle);
 void (*smp_setup)(void);
 void (*prepare_cpus)(unsigned int max_cpus);
 void (*prepare_boot_cpu)(void);

 int (*cpu_disable)(void);
 void (*cpu_die)(unsigned int cpu);


 void (*kexec_nonboot_cpu)(void);

};

extern void register_smp_ops(const struct plat_smp_ops *ops);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void plat_smp_setup(void)
{
 extern const struct plat_smp_ops *mp_ops;

 mp_ops->smp_setup();
}

extern void mips_smp_send_ipi_single(int cpu, unsigned int action);
extern void mips_smp_send_ipi_mask(const struct cpumask *mask,
          unsigned int action);
# 70 "./arch/mips/include/asm/smp-ops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int register_up_smp_ops(void)
{

 extern const struct plat_smp_ops up_smp_ops;

 register_smp_ops(&up_smp_ops);

 return 0;



}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int register_cmp_smp_ops(void)
{
# 95 "./arch/mips/include/asm/smp-ops.h"
 return -19;

}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int register_vsmp_smp_ops(void)
{

 extern const struct plat_smp_ops vsmp_smp_ops;

 register_smp_ops(&vsmp_smp_ops);

 return 0;



}


extern int register_cps_smp_ops(void);
# 22 "./arch/mips/include/asm/smp.h" 2

extern int smp_num_siblings;
extern cpumask_t cpu_sibling_map[];
extern cpumask_t cpu_core_map[];
extern cpumask_t cpu_foreign_map[];

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int raw_smp_processor_id(void)
{





 return current_thread_info()->cpu;

}




extern int __cpu_number_map[2];



extern int __cpu_logical_map[2];
# 58 "./arch/mips/include/asm/smp.h"
extern cpumask_t cpu_coherent_mask;

extern void smp_bootstrap(void);

extern void calculate_cpu_foreign_map(void);






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void smp_send_reschedule(int cpu)
{
 extern const struct plat_smp_ops *mp_ops;

 mp_ops->send_ipi_single(cpu, 0x1);
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __cpu_disable(void)
{
 extern const struct plat_smp_ops *mp_ops;

 return mp_ops->cpu_disable();
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __cpu_die(unsigned int cpu)
{
 extern const struct plat_smp_ops *mp_ops;

 mp_ops->cpu_die(cpu);
}

extern void play_dead(void);



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kexec_nonboot_cpu(void)
{
 extern const struct plat_smp_ops *mp_ops;

 return mp_ops->kexec_nonboot_cpu();
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *kexec_nonboot_cpu_func(void)
{
 extern const struct plat_smp_ops *mp_ops;

 return mp_ops->kexec_nonboot_cpu;
}







int mips_smp_ipi_allocate(const struct cpumask *mask);






int mips_smp_ipi_free(const struct cpumask *mask);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_send_call_function_single_ipi(int cpu)
{
 extern const struct plat_smp_ops *mp_ops;

 mp_ops->send_ipi_single(cpu, 0x2);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_send_call_function_ipi_mask(const struct cpumask *mask)
{
 extern const struct plat_smp_ops *mp_ops;

 mp_ops->send_ipi_mask(mask, 0x2);
}
# 114 "./include/linux/smp.h" 2
# 123 "./include/linux/smp.h"
extern void smp_send_stop(void);




extern void smp_send_reschedule(int cpu);





extern void smp_prepare_cpus(unsigned int max_cpus);




extern int __cpu_up(unsigned int cpunum, struct task_struct *tidle);




extern void smp_cpus_done(unsigned int max_cpus);




void smp_call_function(smp_call_func_t func, void *info, int wait);
void smp_call_function_many(const struct cpumask *mask,
       smp_call_func_t func, void *info, bool wait);

int smp_call_function_any(const struct cpumask *mask,
     smp_call_func_t func, void *info, int wait);

void kick_all_cpus_sync(void);
void wake_up_all_idle_cpus(void);




void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) __attribute__((__no_sanitize__("cfi"))) call_function_init(void);
void generic_smp_call_function_single_interrupt(void);







void smp_prepare_boot_cpu(void);

extern unsigned int setup_max_cpus;
extern void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) __attribute__((__no_sanitize__("cfi"))) setup_nr_cpu_ids(void);
extern void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) __attribute__((__no_sanitize__("cfi"))) smp_init(void);

extern int __boot_cpu_id;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int get_boot_cpu_id(void)
{
 return __boot_cpu_id;
}
# 274 "./include/linux/smp.h"
extern void arch_disable_smp_support(void);

extern void arch_thaw_secondary_cpus_begin(void);
extern void arch_thaw_secondary_cpus_end(void);

void smp_setup_processor_id(void);

int smp_call_on_cpu(unsigned int cpu, int (*func)(void *), void *par,
      bool phys);


int smpcfd_prepare_cpu(unsigned int cpu);
int smpcfd_dead_cpu(unsigned int cpu);
int smpcfd_dying_cpu(unsigned int cpu);
# 13 "./arch/mips/include/asm/cpu-type.h" 2


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__pure__)) __get_cpu_type(const int cpu_type)
{
 switch (cpu_type) {
# 33 "./arch/mips/include/asm/cpu-type.h"
 case CPU_4KC:
 case CPU_ALCHEMY:
 case CPU_PR4450:




 case CPU_4KEC:
 case CPU_XBURST:



 case CPU_4KSC:
 case CPU_24K:
 case CPU_34K:
 case CPU_1004K:
 case CPU_74K:
 case CPU_1074K:
 case CPU_M14KC:
 case CPU_M14KEC:
 case CPU_INTERAPTIV:
 case CPU_PROAPTIV:
# 68 "./arch/mips/include/asm/cpu-type.h"
 case CPU_QEMU_GENERIC:



 case CPU_5KC:
 case CPU_5KE:
 case CPU_20KC:
 case CPU_25KF:
 case CPU_SB1:
 case CPU_SB1A:
# 88 "./arch/mips/include/asm/cpu-type.h"
 case CPU_M6250:



 case CPU_I6400:
 case CPU_I6500:
 case CPU_P6600:
# 183 "./arch/mips/include/asm/cpu-type.h"
 case CPU_BMIPS32:
 case CPU_BMIPS3300:
# 198 "./arch/mips/include/asm/cpu-type.h"
  break;
 default:
  do { ; __builtin_unreachable(); } while (0);
 }

 return cpu_type;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__pure__)) current_cpu_type(void)
{
 const int cpu_type = cpu_data[raw_smp_processor_id()].cputype;

 return __get_cpu_type(cpu_type);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__pure__)) boot_cpu_type(void)
{
 const int cpu_type = cpu_data[0].cputype;

 return __get_cpu_type(cpu_type);
}
# 20 "./arch/mips/include/asm/timex.h" 2
# 40 "./arch/mips/include/asm/timex.h"
typedef unsigned int cycles_t;
# 52 "./arch/mips/include/asm/timex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int can_use_mips_counter(unsigned int prid)
{
 int comp = (prid & 0xff0000) != 0x000000;

 if (__builtin_constant_p((cpu_data[0].options & (((((1ULL))) << (7))))) && !(cpu_data[0].options & (((((1ULL))) << (7)))))
  return 0;
 else if (__builtin_constant_p(((((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((1 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((1 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) && ((((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((1 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((1 >= (6)) && (cpu_data[0].isa_level & (0x00000800)))))
  return 1;
 else if (__builtin_expect(!!(!__builtin_constant_p(((((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((1 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (1)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (2)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((1 >= (5)) && (1 < (6))) || ((1 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((1 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) && comp), 1))
  return 1;

 if (!__builtin_constant_p((cpu_data[0].options & (((((1ULL))) << (7))))))
  asm volatile("" : "=m" (cpu_data[0].options));
 if (__builtin_expect(!!((cpu_data[0].options & (((((1ULL))) << (7)))) && prid >= (0x0400 | ((5) << 4 | (0)))), 1))

  return 1;
 else
  return 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) cycles_t get_cycles(void)
{
 if (can_use_mips_counter(({ unsigned int __res; if (0 == 0) __asm__ ( "mfc0\t%0, " "$15" "\n\t" : "=r" (__res)); else __asm__ ( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$15" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; })))
  return ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$9" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$9" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; });
 else
  return 0;
}
# 87 "./arch/mips/include/asm/timex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long random_get_entropy(void)
{
 unsigned int prid = ({ unsigned int __res; if (0 == 0) __asm__ ( "mfc0\t%0, " "$15" "\n\t" : "=r" (__res)); else __asm__ ( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$15" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; });
 unsigned int imp = prid & 0xff00;

 if (can_use_mips_counter(prid))
  return ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$9" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$9" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; });
 else if (__builtin_expect(!!(imp != 0x0300 && imp != 0x0600), 1))
  return ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$1" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$1" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; });
 else
  return 0;
}
# 66 "./include/linux/timex.h" 2
# 139 "./include/linux/timex.h"
extern unsigned long tick_usec;
extern unsigned long tick_nsec;
# 154 "./include/linux/timex.h"
extern int do_adjtimex(struct __kernel_timex *);
extern int do_clock_adjtime(const clockid_t which_clock, struct __kernel_timex * ktx);

extern void hardpps(const struct timespec64 *, const struct timespec64 *);

int read_current_timer(unsigned long *timer_val);
# 14 "./include/linux/time32.h" 2

# 1 "./include/vdso/time32.h" 1




typedef s32 old_time32_t;

struct old_timespec32 {
 old_time32_t tv_sec;
 s32 tv_nsec;
};

struct old_timeval32 {
 old_time32_t tv_sec;
 s32 tv_usec;
};
# 16 "./include/linux/time32.h" 2

struct old_itimerspec32 {
 struct old_timespec32 it_interval;
 struct old_timespec32 it_value;
};

struct old_utimbuf32 {
 old_time32_t actime;
 old_time32_t modtime;
};

struct old_timex32 {
 u32 modes;
 s32 offset;
 s32 freq;
 s32 maxerror;
 s32 esterror;
 s32 status;
 s32 constant;
 s32 precision;
 s32 tolerance;
 struct old_timeval32 time;
 s32 tick;
 s32 ppsfreq;
 s32 jitter;
 s32 shift;
 s32 stabil;
 s32 jitcnt;
 s32 calcnt;
 s32 errcnt;
 s32 stbcnt;
 s32 tai;

 s32:32; s32:32; s32:32; s32:32;
 s32:32; s32:32; s32:32; s32:32;
 s32:32; s32:32; s32:32;
};

extern int get_old_timespec32(struct timespec64 *, const void *);
extern int put_old_timespec32(const struct timespec64 *, void *);
extern int get_old_itimerspec32(struct itimerspec64 *its,
   const struct old_itimerspec32 *uits);
extern int put_old_itimerspec32(const struct itimerspec64 *its,
   struct old_itimerspec32 *uits);
struct __kernel_timex;
int get_old_timex32(struct __kernel_timex *, const struct old_timex32 *);
int put_old_timex32(struct old_timex32 *, const struct __kernel_timex *);







extern struct __kernel_old_timeval ns_to_kernel_old_timeval(s64 nsec);
# 61 "./include/linux/time.h" 2

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool itimerspec64_valid(const struct itimerspec64 *its)
{
 if (!timespec64_valid(&(its->it_interval)) ||
  !timespec64_valid(&(its->it_value)))
  return false;

 return true;
}
# 100 "./include/linux/time.h"
# 1 "./include/vdso/time.h" 1






struct timens_offset {
 s64 sec;
 u64 nsec;
};
# 101 "./include/linux/time.h" 2
# 11 "./include/linux/jiffies.h" 2

# 1 "./include/vdso/jiffies.h" 1
# 13 "./include/linux/jiffies.h" 2

# 1 "./include/generated/timeconst.h" 1
# 15 "./include/linux/jiffies.h" 2
# 62 "./include/linux/jiffies.h"
extern int register_refined_jiffies(long clock_tick_rate);
# 79 "./include/linux/jiffies.h"
extern u64 __attribute__((__aligned__((1 << 7)), __section__(".data..cacheline_aligned"))) jiffies_64;
extern unsigned long volatile __attribute__((__aligned__((1 << 7)), __section__(".data..cacheline_aligned"))) jiffies;


u64 get_jiffies_64(void);
# 189 "./include/linux/jiffies.h"
extern unsigned long preset_lpj;
# 290 "./include/linux/jiffies.h"
extern unsigned int jiffies_to_msecs(const unsigned long j);
extern unsigned int jiffies_to_usecs(const unsigned long j);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 jiffies_to_nsecs(const unsigned long j)
{
 return (u64)jiffies_to_usecs(j) * 1000L;
}

extern u64 jiffies64_to_nsecs(u64 j);
extern u64 jiffies64_to_msecs(u64 j);

extern unsigned long __msecs_to_jiffies(const unsigned int m);






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long _msecs_to_jiffies(const unsigned int m)
{
 return (m + (1000L / 250) - 1) / (1000L / 250);
}
# 363 "./include/linux/jiffies.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned long msecs_to_jiffies(const unsigned int m)
{
 if (__builtin_constant_p(m)) {
  if ((int)m < 0)
   return ((((long)(~0UL >> 1)) >> 1)-1);
  return _msecs_to_jiffies(m);
 } else {
  return __msecs_to_jiffies(m);
 }
}

extern unsigned long __usecs_to_jiffies(const unsigned int u);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long _usecs_to_jiffies(const unsigned int u)
{
 return (u + (1000000L / 250) - 1) / (1000000L / 250);
}
# 410 "./include/linux/jiffies.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned long usecs_to_jiffies(const unsigned int u)
{
 if (__builtin_constant_p(u)) {
  if (u > jiffies_to_usecs(((((long)(~0UL >> 1)) >> 1)-1)))
   return ((((long)(~0UL >> 1)) >> 1)-1);
  return _usecs_to_jiffies(u);
 } else {
  return __usecs_to_jiffies(u);
 }
}

extern unsigned long timespec64_to_jiffies(const struct timespec64 *value);
extern void jiffies_to_timespec64(const unsigned long jiffies,
      struct timespec64 *value);
extern clock_t jiffies_to_clock_t(unsigned long x);
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) clock_t jiffies_delta_to_clock_t(long delta)
{
 return jiffies_to_clock_t(__builtin_choose_expr(((!!(sizeof((typeof(0L) *)1 == (typeof(delta) *)1))) && ((sizeof(int) == sizeof(*(8 ? ((void *)((long)(0L) * 0l)) : (int *)8))) && (sizeof(int) == sizeof(*(8 ? ((void *)((long)(delta) * 0l)) : (int *)8))))), ((0L) > (delta) ? (0L) : (delta)), ({ typeof(0L) __UNIQUE_ID___x120 = (0L); typeof(delta) __UNIQUE_ID___y121 = (delta); ((__UNIQUE_ID___x120) > (__UNIQUE_ID___y121) ? (__UNIQUE_ID___x120) : (__UNIQUE_ID___y121)); })));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int jiffies_delta_to_msecs(long delta)
{
 return jiffies_to_msecs(__builtin_choose_expr(((!!(sizeof((typeof(0L) *)1 == (typeof(delta) *)1))) && ((sizeof(int) == sizeof(*(8 ? ((void *)((long)(0L) * 0l)) : (int *)8))) && (sizeof(int) == sizeof(*(8 ? ((void *)((long)(delta) * 0l)) : (int *)8))))), ((0L) > (delta) ? (0L) : (delta)), ({ typeof(0L) __UNIQUE_ID___x122 = (0L); typeof(delta) __UNIQUE_ID___y123 = (delta); ((__UNIQUE_ID___x122) > (__UNIQUE_ID___y123) ? (__UNIQUE_ID___x122) : (__UNIQUE_ID___y123)); })));
}

extern unsigned long clock_t_to_jiffies(unsigned long x);
extern u64 jiffies_64_to_clock_t(u64 x);
extern u64 nsec_to_clock_t(u64 x);
extern u64 nsecs_to_jiffies64(u64 n);
extern unsigned long nsecs_to_jiffies(u64 n);
# 9 "init/calibrate.c" 2
# 1 "./include/linux/delay.h" 1
# 24 "./include/linux/delay.h"
extern unsigned long loops_per_jiffy;

# 1 "./arch/mips/include/asm/delay.h" 1
# 16 "./arch/mips/include/asm/delay.h"
extern void __delay(unsigned long loops);
extern void __ndelay(unsigned long ns);
extern void __udelay(unsigned long us);
# 27 "./include/linux/delay.h" 2
# 56 "./include/linux/delay.h"
extern unsigned long lpj_fine;
void calibrate_delay(void);
void __attribute__((weak)) calibration_delay_done(void);
void msleep(unsigned int msecs);
unsigned long msleep_interruptible(unsigned int msecs);
void usleep_range(unsigned long min, unsigned long max);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ssleep(unsigned int seconds)
{
 msleep(seconds * 1000);
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void fsleep(unsigned long usecs)
{
 if (usecs <= 10)
  __udelay(usecs);
 else if (usecs <= 20000)
  usleep_range(usecs, 2 * usecs);
 else
  msleep((((usecs) + (1000) - 1) / (1000)));
}
# 10 "init/calibrate.c" 2



# 1 "./include/linux/percpu.h" 1




# 1 "./include/linux/mmdebug.h" 1







struct page;
struct vm_area_struct;
struct mm_struct;

void dump_page(struct page *page, const char *reason);
void dump_vma(const struct vm_area_struct *vma);
void dump_mm(const struct mm_struct *mm);
# 6 "./include/linux/percpu.h" 2






# 1 "./arch/mips/include/generated/asm/percpu.h" 1
# 13 "./include/linux/percpu.h" 2
# 64 "./include/linux/percpu.h"
extern void *pcpu_base_addr;
extern const unsigned long *pcpu_unit_offsets;

struct pcpu_group_info {
 int nr_units;
 unsigned long base_offset;
 unsigned int *cpu_map;

};

struct pcpu_alloc_info {
 size_t static_size;
 size_t reserved_size;
 size_t dyn_size;
 size_t unit_size;
 size_t atom_size;
 size_t alloc_size;
 size_t __ai_size;
 int nr_groups;
 struct pcpu_group_info groups[];
};

enum pcpu_fc {
 PCPU_FC_AUTO,
 PCPU_FC_EMBED,
 PCPU_FC_PAGE,

 PCPU_FC_NR,
};
extern const char * const pcpu_fc_names[PCPU_FC_NR];

extern enum pcpu_fc pcpu_chosen_fc;

typedef void * (*pcpu_fc_alloc_fn_t)(unsigned int cpu, size_t size,
         size_t align);
typedef void (*pcpu_fc_free_fn_t)(void *ptr, size_t size);
typedef void (*pcpu_fc_populate_pte_fn_t)(unsigned long addr);
typedef int (pcpu_fc_cpu_distance_fn_t)(unsigned int from, unsigned int to);

extern struct pcpu_alloc_info * __attribute__((__section__(".init.text"))) __attribute__((__cold__)) __attribute__((__no_sanitize__("cfi"))) pcpu_alloc_alloc_info(int nr_groups,
            int nr_units);
extern void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) __attribute__((__no_sanitize__("cfi"))) pcpu_free_alloc_info(struct pcpu_alloc_info *ai);

extern void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) __attribute__((__no_sanitize__("cfi"))) pcpu_setup_first_chunk(const struct pcpu_alloc_info *ai,
      void *base_addr);
# 125 "./include/linux/percpu.h"
extern void *__alloc_reserved_percpu(size_t size, size_t align) __attribute__((__alloc_size__(1))) __attribute__((__malloc__));
extern bool __is_kernel_percpu_address(unsigned long addr, unsigned long *can_addr);
extern bool is_kernel_percpu_address(unsigned long addr);


extern void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) __attribute__((__no_sanitize__("cfi"))) setup_per_cpu_areas(void);


extern void *__alloc_percpu_gfp(size_t size, size_t align, gfp_t gfp) __attribute__((__alloc_size__(1))) __attribute__((__malloc__));
extern void *__alloc_percpu(size_t size, size_t align) __attribute__((__alloc_size__(1))) __attribute__((__malloc__));
extern void free_percpu(void *__pdata);
extern phys_addr_t per_cpu_ptr_to_phys(void *addr);
# 145 "./include/linux/percpu.h"
extern unsigned long pcpu_nr_pages(void);
# 14 "init/calibrate.c" 2

unsigned long lpj_fine;
unsigned long preset_lpj;
static int __attribute__((__section__(".init.text"))) __attribute__((__cold__)) __attribute__((__no_sanitize__("cfi"))) lpj_setup(char *str)
{
 preset_lpj = simple_strtoul(str,((void *)0),0);
 return 1;
}

static const char __setup_str_lpj_setup[] __attribute__((__section__(".init.rodata"))) __attribute__((__aligned__(1))) = "lpj="; static struct obs_kernel_param __setup_lpj_setup __attribute__((__used__)) __attribute__((__section__(".init.setup"))) __attribute__((__aligned__(__alignof__(struct obs_kernel_param)))) = { __setup_str_lpj_setup, lpj_setup, 0 };
# 170 "init/calibrate.c"
static unsigned long calibrate_delay_direct(void)
{
 return 0;
}
# 187 "init/calibrate.c"
static unsigned long calibrate_delay_converge(void)
{

 unsigned long lpj, lpj_base, ticks, loopadd, loopadd_base, chop_limit;
 int trials = 0, band = 0, trial_in_band = 0;

 lpj = (1<<12);


 ticks = jiffies;
 while (ticks == jiffies)
  ;

 ticks = jiffies;
 do {
  if (++trial_in_band == (1<<band)) {
   ++band;
   trial_in_band = 0;
  }
  __delay(lpj * band);
  trials += band;
 } while (ticks == jiffies);




 trials -= band;
 loopadd_base = lpj * band;
 lpj_base = lpj * trials;

recalibrate:
 lpj = lpj_base;
 loopadd = loopadd_base;





 chop_limit = lpj >> 8;
 while (loopadd > chop_limit) {
  lpj += loopadd;
  ticks = jiffies;
  while (ticks == jiffies)
   ;
  ticks = jiffies;
  __delay(lpj);
  if (jiffies != ticks)
   lpj -= loopadd;
  loopadd >>= 1;
 }





 if (lpj + loopadd * 2 == lpj_base + loopadd_base * 2) {
  lpj_base = lpj;
  loopadd_base <<= 2;
  goto recalibrate;
 }

 return lpj;
}

static __attribute__((__section__(".discard"))) __attribute__((unused)) char __pcpu_scope_cpu_loops_per_jiffy; extern __attribute__((__section__(".discard"))) __attribute__((unused)) char __pcpu_unique_cpu_loops_per_jiffy; __attribute__((__section__(".discard"))) __attribute__((unused)) char __pcpu_unique_cpu_loops_per_jiffy; extern __attribute__((section(".data..percpu" ""))) __typeof__(unsigned long) cpu_loops_per_jiffy; __attribute__((section(".data..percpu" ""))) __attribute__((__weak__)) __typeof__(unsigned long) cpu_loops_per_jiffy = { 0 };
# 261 "init/calibrate.c"
unsigned long __attribute__((weak)) calibrate_delay_is_known(void)
{
 return 0;
}






void __attribute__((weak)) calibration_delay_done(void)
{
}

void calibrate_delay(void)
{
 unsigned long lpj;
 static bool printed;
 int this_cpu = raw_smp_processor_id();

 if ((*({ do { const void *__vpp_verify = (typeof((&(cpu_loops_per_jiffy)) + 0))((void *)0); (void)__vpp_verify; } while (0); ({ unsigned long __ptr; __ptr = (unsigned long) ((typeof(*((&(cpu_loops_per_jiffy)))) *)((&(cpu_loops_per_jiffy)))); (typeof((typeof(*((&(cpu_loops_per_jiffy)))) *)((&(cpu_loops_per_jiffy))))) (__ptr + (((__per_cpu_offset[(this_cpu)])))); }); }))) {
  lpj = (*({ do { const void *__vpp_verify = (typeof((&(cpu_loops_per_jiffy)) + 0))((void *)0); (void)__vpp_verify; } while (0); ({ unsigned long __ptr; __ptr = (unsigned long) ((typeof(*((&(cpu_loops_per_jiffy)))) *)((&(cpu_loops_per_jiffy)))); (typeof((typeof(*((&(cpu_loops_per_jiffy)))) *)((&(cpu_loops_per_jiffy))))) (__ptr + (((__per_cpu_offset[(this_cpu)])))); }); }));
  if (!printed)
   ({ do { if (__builtin_constant_p("\001" "6" "Calibrating delay loop (skipped) " "already calibrated this CPU") && __builtin_constant_p(((void *)0))) { static const struct pi_entry _entry __attribute__((__used__)) = { .fmt = __builtin_constant_p("\001" "6" "Calibrating delay loop (skipped) " "already calibrated this CPU") ? ("\001" "6" "Calibrating delay loop (skipped) " "already calibrated this CPU") : ((void *)0), .func = __func__, .file = "init/calibrate.c", .line = 285, .level = __builtin_constant_p(((void *)0)) ? (((void *)0)) : ((void *)0), .subsys_fmt_prefix = ((void *)0), }; static const struct pi_entry *_entry_ptr __attribute__((__used__)) __attribute__((__section__(".printk_index"))) = &_entry; } } while (0); _printk("\001" "6" "Calibrating delay loop (skipped) " "already calibrated this CPU"); });

 } else if (preset_lpj) {
  lpj = preset_lpj;
  if (!printed)
   ({ do { if (__builtin_constant_p("\001" "6" "Calibrating delay loop (skipped) " "preset value.. ") && __builtin_constant_p(((void *)0))) { static const struct pi_entry _entry __attribute__((__used__)) = { .fmt = __builtin_constant_p("\001" "6" "Calibrating delay loop (skipped) " "preset value.. ") ? ("\001" "6" "Calibrating delay loop (skipped) " "preset value.. ") : ((void *)0), .func = __func__, .file = "init/calibrate.c", .line = 290, .level = __builtin_constant_p(((void *)0)) ? (((void *)0)) : ((void *)0), .subsys_fmt_prefix = ((void *)0), }; static const struct pi_entry *_entry_ptr __attribute__((__used__)) __attribute__((__section__(".printk_index"))) = &_entry; } } while (0); _printk("\001" "6" "Calibrating delay loop (skipped) " "preset value.. "); });

 } else if ((!printed) && lpj_fine) {
  lpj = lpj_fine;
  ({ do { if (__builtin_constant_p("\001" "6" "Calibrating delay loop (skipped), " "value calculated using timer frequency.. ") && __builtin_constant_p(((void *)0))) { static const struct pi_entry _entry __attribute__((__used__)) = { .fmt = __builtin_constant_p("\001" "6" "Calibrating delay loop (skipped), " "value calculated using timer frequency.. ") ? ("\001" "6" "Calibrating delay loop (skipped), " "value calculated using timer frequency.. ") : ((void *)0), .func = __func__, .file = "init/calibrate.c", .line = 294, .level = __builtin_constant_p(((void *)0)) ? (((void *)0)) : ((void *)0), .subsys_fmt_prefix = ((void *)0), }; static const struct pi_entry *_entry_ptr __attribute__((__used__)) __attribute__((__section__(".printk_index"))) = &_entry; } } while (0); _printk("\001" "6" "Calibrating delay loop (skipped), " "value calculated using timer frequency.. "); });

 } else if ((lpj = calibrate_delay_is_known())) {
  ;
 } else if ((lpj = calibrate_delay_direct()) != 0) {
  if (!printed)
   ({ do { if (__builtin_constant_p("\001" "6" "Calibrating delay using timer " "specific routine.. ") && __builtin_constant_p(((void *)0))) { static const struct pi_entry _entry __attribute__((__used__)) = { .fmt = __builtin_constant_p("\001" "6" "Calibrating delay using timer " "specific routine.. ") ? ("\001" "6" "Calibrating delay using timer " "specific routine.. ") : ((void *)0), .func = __func__, .file = "init/calibrate.c", .line = 300, .level = __builtin_constant_p(((void *)0)) ? (((void *)0)) : ((void *)0), .subsys_fmt_prefix = ((void *)0), }; static const struct pi_entry *_entry_ptr __attribute__((__used__)) __attribute__((__section__(".printk_index"))) = &_entry; } } while (0); _printk("\001" "6" "Calibrating delay using timer " "specific routine.. "); });

 } else {
  if (!printed)
   ({ do { if (__builtin_constant_p("\001" "6" "Calibrating delay loop... ") && __builtin_constant_p(((void *)0))) { static const struct pi_entry _entry __attribute__((__used__)) = { .fmt = __builtin_constant_p("\001" "6" "Calibrating delay loop... ") ? ("\001" "6" "Calibrating delay loop... ") : ((void *)0), .func = __func__, .file = "init/calibrate.c", .line = 303, .level = __builtin_constant_p(((void *)0)) ? (((void *)0)) : ((void *)0), .subsys_fmt_prefix = ((void *)0), }; static const struct pi_entry *_entry_ptr __attribute__((__used__)) __attribute__((__section__(".printk_index"))) = &_entry; } } while (0); _printk("\001" "6" "Calibrating delay loop... "); });
  lpj = calibrate_delay_converge();
 }
 (*({ do { const void *__vpp_verify = (typeof((&(cpu_loops_per_jiffy)) + 0))((void *)0); (void)__vpp_verify; } while (0); ({ unsigned long __ptr; __ptr = (unsigned long) ((typeof(*((&(cpu_loops_per_jiffy)))) *)((&(cpu_loops_per_jiffy)))); (typeof((typeof(*((&(cpu_loops_per_jiffy)))) *)((&(cpu_loops_per_jiffy))))) (__ptr + (((__per_cpu_offset[(this_cpu)])))); }); })) = lpj;
 if (!printed)
  ({ do { if (__builtin_constant_p("\001" "c" "%lu.%02lu BogoMIPS (lpj=%lu)\n") && __builtin_constant_p(((void *)0))) { static const struct pi_entry _entry __attribute__((__used__)) = { .fmt = __builtin_constant_p("\001" "c" "%lu.%02lu BogoMIPS (lpj=%lu)\n") ? ("\001" "c" "%lu.%02lu BogoMIPS (lpj=%lu)\n") : ((void *)0), .func = __func__, .file = "init/calibrate.c", .line = 310, .level = __builtin_constant_p(((void *)0)) ? (((void *)0)) : ((void *)0), .subsys_fmt_prefix = ((void *)0), }; static const struct pi_entry *_entry_ptr __attribute__((__used__)) __attribute__((__section__(".printk_index"))) = &_entry; } } while (0); _printk("\001" "c" "%lu.%02lu BogoMIPS (lpj=%lu)\n", lpj/(500000/250), (lpj/(5000/250)) % 100, lpj); });



 loops_per_jiffy = lpj;
 printed = true;

 calibration_delay_done();
}
