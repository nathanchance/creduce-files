# 1 "/home/nathan/src/linux/arch/mips/kernel/reset.c"
# 1 "<built-in>" 1
# 1 "<built-in>" 3
# 341 "<built-in>" 3
# 1 "<command line>" 1
# 1 "<built-in>" 2
# 1 "/home/nathan/src/linux/include/linux/kconfig.h" 1






# 1 "./include/generated/autoconf.h" 1
# 8 "/home/nathan/src/linux/include/linux/kconfig.h" 2
# 2 "<built-in>" 2
# 1 "/home/nathan/src/linux/include/linux/compiler_types.h" 1
# 65 "/home/nathan/src/linux/include/linux/compiler_types.h"
# 1 "/home/nathan/src/linux/include/linux/compiler_attributes.h" 1
# 66 "/home/nathan/src/linux/include/linux/compiler_types.h" 2
# 80 "/home/nathan/src/linux/include/linux/compiler_types.h"
# 1 "/home/nathan/src/linux/include/linux/compiler-clang.h" 1
# 81 "/home/nathan/src/linux/include/linux/compiler_types.h" 2
# 99 "/home/nathan/src/linux/include/linux/compiler_types.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/compiler.h" 1
# 100 "/home/nathan/src/linux/include/linux/compiler_types.h" 2


struct ftrace_branch_data {
 const char *func;
 const char *file;
 unsigned line;
 union {
  struct {
   unsigned long correct;
   unsigned long incorrect;
  };
  struct {
   unsigned long miss;
   unsigned long hit;
  };
  unsigned long miss_hit[2];
 };
};

struct ftrace_likely_data {
 struct ftrace_branch_data data;
 unsigned long constant;
};
# 3 "<built-in>" 2
# 1 "/home/nathan/src/linux/arch/mips/kernel/reset.c" 2








# 1 "/home/nathan/src/linux/include/linux/kernel.h" 1




# 1 "/home/nathan/cbl/github/tc-build/build/llvm/stage1/lib/clang/12.0.0/include/stdarg.h" 1 3
# 14 "/home/nathan/cbl/github/tc-build/build/llvm/stage1/lib/clang/12.0.0/include/stdarg.h" 3
typedef __builtin_va_list va_list;
# 32 "/home/nathan/cbl/github/tc-build/build/llvm/stage1/lib/clang/12.0.0/include/stdarg.h" 3
typedef __builtin_va_list __gnuc_va_list;
# 6 "/home/nathan/src/linux/include/linux/kernel.h" 2
# 1 "/home/nathan/src/linux/include/linux/limits.h" 1




# 1 "/home/nathan/src/linux/include/uapi/linux/limits.h" 1
# 6 "/home/nathan/src/linux/include/linux/limits.h" 2
# 1 "/home/nathan/src/linux/include/linux/types.h" 1





# 1 "/home/nathan/src/linux/include/uapi/linux/types.h" 1




# 1 "/home/nathan/src/linux/arch/mips/include/asm/types.h" 1
# 14 "/home/nathan/src/linux/arch/mips/include/asm/types.h"
# 1 "/home/nathan/src/linux/include/asm-generic/int-ll64.h" 1
# 11 "/home/nathan/src/linux/include/asm-generic/int-ll64.h"
# 1 "/home/nathan/src/linux/include/uapi/asm-generic/int-ll64.h" 1
# 12 "/home/nathan/src/linux/include/uapi/asm-generic/int-ll64.h"
# 1 "/home/nathan/src/linux/arch/mips/include/uapi/asm/bitsperlong.h" 1






# 1 "/home/nathan/src/linux/include/asm-generic/bitsperlong.h" 1




# 1 "/home/nathan/src/linux/include/uapi/asm-generic/bitsperlong.h" 1
# 6 "/home/nathan/src/linux/include/asm-generic/bitsperlong.h" 2
# 8 "/home/nathan/src/linux/arch/mips/include/uapi/asm/bitsperlong.h" 2
# 13 "/home/nathan/src/linux/include/uapi/asm-generic/int-ll64.h" 2







typedef __signed__ char __s8;
typedef unsigned char __u8;

typedef __signed__ short __s16;
typedef unsigned short __u16;

typedef __signed__ int __s32;
typedef unsigned int __u32;


__extension__ typedef __signed__ long long __s64;
__extension__ typedef unsigned long long __u64;
# 12 "/home/nathan/src/linux/include/asm-generic/int-ll64.h" 2




typedef __s8 s8;
typedef __u8 u8;
typedef __s16 s16;
typedef __u16 u16;
typedef __s32 s32;
typedef __u32 u32;
typedef __s64 s64;
typedef __u64 u64;
# 15 "/home/nathan/src/linux/arch/mips/include/asm/types.h" 2
# 6 "/home/nathan/src/linux/include/uapi/linux/types.h" 2








# 1 "/home/nathan/src/linux/include/uapi/linux/posix_types.h" 1




# 1 "/home/nathan/src/linux/include/linux/stddef.h" 1




# 1 "/home/nathan/src/linux/include/uapi/linux/stddef.h" 1
# 6 "/home/nathan/src/linux/include/linux/stddef.h" 2




enum {
 false = 0,
 true = 1
};
# 6 "/home/nathan/src/linux/include/uapi/linux/posix_types.h" 2
# 25 "/home/nathan/src/linux/include/uapi/linux/posix_types.h"
typedef struct {
 unsigned long fds_bits[1024 / (8 * sizeof(long))];
} __kernel_fd_set;


typedef void (*__kernel_sighandler_t)(int);


typedef int __kernel_key_t;
typedef int __kernel_mqd_t;


# 1 "/home/nathan/src/linux/arch/mips/include/uapi/asm/posix_types.h" 1
# 13 "/home/nathan/src/linux/arch/mips/include/uapi/asm/posix_types.h"
# 1 "/home/nathan/src/linux/arch/mips/include/uapi/asm/sgidefs.h" 1
# 14 "/home/nathan/src/linux/arch/mips/include/uapi/asm/posix_types.h" 2







typedef long __kernel_daddr_t;



# 1 "/home/nathan/src/linux/include/uapi/asm-generic/posix_types.h" 1
# 15 "/home/nathan/src/linux/include/uapi/asm-generic/posix_types.h"
typedef long __kernel_long_t;
typedef unsigned long __kernel_ulong_t;



typedef __kernel_ulong_t __kernel_ino_t;



typedef unsigned int __kernel_mode_t;



typedef int __kernel_pid_t;



typedef int __kernel_ipc_pid_t;



typedef unsigned int __kernel_uid_t;
typedef unsigned int __kernel_gid_t;



typedef __kernel_long_t __kernel_suseconds_t;







typedef unsigned int __kernel_uid32_t;
typedef unsigned int __kernel_gid32_t;



typedef __kernel_uid_t __kernel_old_uid_t;
typedef __kernel_gid_t __kernel_old_gid_t;



typedef unsigned int __kernel_old_dev_t;
# 68 "/home/nathan/src/linux/include/uapi/asm-generic/posix_types.h"
typedef unsigned int __kernel_size_t;
typedef int __kernel_ssize_t;
typedef int __kernel_ptrdiff_t;
# 79 "/home/nathan/src/linux/include/uapi/asm-generic/posix_types.h"
typedef struct {
 int val[2];
} __kernel_fsid_t;





typedef __kernel_long_t __kernel_off_t;
typedef long long __kernel_loff_t;
typedef __kernel_long_t __kernel_old_time_t;



typedef long long __kernel_time64_t;
typedef __kernel_long_t __kernel_clock_t;
typedef int __kernel_timer_t;
typedef int __kernel_clockid_t;
typedef char * __kernel_caddr_t;
typedef unsigned short __kernel_uid16_t;
typedef unsigned short __kernel_gid16_t;
# 25 "/home/nathan/src/linux/arch/mips/include/uapi/asm/posix_types.h" 2
# 37 "/home/nathan/src/linux/include/uapi/linux/posix_types.h" 2
# 15 "/home/nathan/src/linux/include/uapi/linux/types.h" 2
# 29 "/home/nathan/src/linux/include/uapi/linux/types.h"
typedef __u16 __le16;
typedef __u16 __be16;
typedef __u32 __le32;
typedef __u32 __be32;
typedef __u64 __le64;
typedef __u64 __be64;

typedef __u16 __sum16;
typedef __u32 __wsum;
# 52 "/home/nathan/src/linux/include/uapi/linux/types.h"
typedef unsigned __poll_t;
# 7 "/home/nathan/src/linux/include/linux/types.h" 2






typedef u32 __kernel_dev_t;

typedef __kernel_fd_set fd_set;
typedef __kernel_dev_t dev_t;
typedef __kernel_ino_t ino_t;
typedef __kernel_mode_t mode_t;
typedef unsigned short umode_t;
typedef u32 nlink_t;
typedef __kernel_off_t off_t;
typedef __kernel_pid_t pid_t;
typedef __kernel_daddr_t daddr_t;
typedef __kernel_key_t key_t;
typedef __kernel_suseconds_t suseconds_t;
typedef __kernel_timer_t timer_t;
typedef __kernel_clockid_t clockid_t;
typedef __kernel_mqd_t mqd_t;

typedef _Bool bool;

typedef __kernel_uid32_t uid_t;
typedef __kernel_gid32_t gid_t;
typedef __kernel_uid16_t uid16_t;
typedef __kernel_gid16_t gid16_t;

typedef unsigned long uintptr_t;
# 46 "/home/nathan/src/linux/include/linux/types.h"
typedef __kernel_loff_t loff_t;
# 55 "/home/nathan/src/linux/include/linux/types.h"
typedef __kernel_size_t size_t;




typedef __kernel_ssize_t ssize_t;




typedef __kernel_ptrdiff_t ptrdiff_t;




typedef __kernel_clock_t clock_t;




typedef __kernel_caddr_t caddr_t;



typedef unsigned char u_char;
typedef unsigned short u_short;
typedef unsigned int u_int;
typedef unsigned long u_long;


typedef unsigned char unchar;
typedef unsigned short ushort;
typedef unsigned int uint;
typedef unsigned long ulong;




typedef u8 u_int8_t;
typedef s8 int8_t;
typedef u16 u_int16_t;
typedef s16 int16_t;
typedef u32 u_int32_t;
typedef s32 int32_t;



typedef u8 uint8_t;
typedef u16 uint16_t;
typedef u32 uint32_t;


typedef u64 uint64_t;
typedef u64 u_int64_t;
typedef s64 int64_t;
# 125 "/home/nathan/src/linux/include/linux/types.h"
typedef u64 sector_t;
typedef u64 blkcnt_t;
# 145 "/home/nathan/src/linux/include/linux/types.h"
typedef u32 dma_addr_t;


typedef unsigned int gfp_t;
typedef unsigned int slab_flags_t;
typedef unsigned int fmode_t;




typedef u32 phys_addr_t;


typedef phys_addr_t resource_size_t;





typedef unsigned long irq_hw_number_t;

typedef struct {
 int counter;
} atomic_t;
# 178 "/home/nathan/src/linux/include/linux/types.h"
struct list_head {
 struct list_head *next, *prev;
};

struct hlist_head {
 struct hlist_node *first;
};

struct hlist_node {
 struct hlist_node *next, **pprev;
};

struct ustat {
 __kernel_daddr_t f_tfree;
 __kernel_ino_t f_tinode;
 char f_fname[6];
 char f_fpack[6];
};
# 216 "/home/nathan/src/linux/include/linux/types.h"
struct callback_head {
 struct callback_head *next;
 void (*func)(struct callback_head *head);
} __attribute__((aligned(sizeof(void *))));


typedef void (*rcu_callback_t)(struct callback_head *head);
typedef void (*call_rcu_func_t)(struct callback_head *head, rcu_callback_t func);

typedef void (*swap_func_t)(void *a, void *b, int size);

typedef int (*cmp_r_func_t)(const void *a, const void *b, const void *priv);
typedef int (*cmp_func_t)(const void *a, const void *b);
# 7 "/home/nathan/src/linux/include/linux/limits.h" 2
# 1 "/home/nathan/src/linux/include/vdso/limits.h" 1
# 8 "/home/nathan/src/linux/include/linux/limits.h" 2
# 7 "/home/nathan/src/linux/include/linux/kernel.h" 2
# 1 "/home/nathan/src/linux/include/linux/linkage.h" 1





# 1 "/home/nathan/src/linux/include/linux/stringify.h" 1
# 7 "/home/nathan/src/linux/include/linux/linkage.h" 2
# 1 "/home/nathan/src/linux/include/linux/export.h" 1
# 72 "/home/nathan/src/linux/include/linux/export.h"
struct kernel_symbol {
 unsigned long value;
 const char *name;
 const char *namespace;
};
# 123 "/home/nathan/src/linux/include/linux/export.h"
# 1 "./include/generated/autoksyms.h" 1
# 124 "/home/nathan/src/linux/include/linux/export.h" 2
# 8 "/home/nathan/src/linux/include/linux/linkage.h" 2
# 1 "/home/nathan/src/linux/arch/mips/include/asm/linkage.h" 1
# 9 "/home/nathan/src/linux/include/linux/linkage.h" 2
# 8 "/home/nathan/src/linux/include/linux/kernel.h" 2


# 1 "/home/nathan/src/linux/include/linux/compiler.h" 1
# 230 "/home/nathan/src/linux/include/linux/compiler.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *offset_to_ptr(const int *off)
{
 return (void *)((unsigned long)off + *off);
}
# 246 "/home/nathan/src/linux/include/linux/compiler.h"
# 1 "./arch/mips/include/generated/asm/rwonce.h" 1
# 1 "/home/nathan/src/linux/include/asm-generic/rwonce.h" 1
# 26 "/home/nathan/src/linux/include/asm-generic/rwonce.h"
# 1 "/home/nathan/src/linux/include/linux/kasan-checks.h" 1
# 16 "/home/nathan/src/linux/include/linux/kasan-checks.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __kasan_check_read(const volatile void *p, unsigned int size)
{
 return true;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __kasan_check_write(const volatile void *p, unsigned int size)
{
 return true;
}
# 34 "/home/nathan/src/linux/include/linux/kasan-checks.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool kasan_check_read(const volatile void *p, unsigned int size)
{
 return true;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool kasan_check_write(const volatile void *p, unsigned int size)
{
 return true;
}
# 27 "/home/nathan/src/linux/include/asm-generic/rwonce.h" 2
# 1 "/home/nathan/src/linux/include/linux/kcsan-checks.h" 1
# 142 "/home/nathan/src/linux/include/linux/kcsan-checks.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __kcsan_check_access(const volatile void *ptr, size_t size,
     int type) { }

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_disable_current(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_enable_current(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_enable_current_nowarn(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_nestable_atomic_begin(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_nestable_atomic_end(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_flat_atomic_begin(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_flat_atomic_end(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_atomic_next(int n) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_set_access_mask(unsigned long mask) { }

struct kcsan_scoped_access { };

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct kcsan_scoped_access *
kcsan_begin_scoped_access(const volatile void *ptr, size_t size, int type,
     struct kcsan_scoped_access *sa) { return sa; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_end_scoped_access(struct kcsan_scoped_access *sa) { }
# 178 "/home/nathan/src/linux/include/linux/kcsan-checks.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void kcsan_check_access(const volatile void *ptr, size_t size,
          int type) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __kcsan_enable_current(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __kcsan_disable_current(void) { }
# 28 "/home/nathan/src/linux/include/asm-generic/rwonce.h" 2
# 64 "/home/nathan/src/linux/include/asm-generic/rwonce.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__))
unsigned long __read_once_word_nocheck(const void *addr)
{
 return (*(const volatile typeof( _Generic((*(unsigned long *)addr), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*(unsigned long *)addr))) *)&(*(unsigned long *)addr));
}
# 82 "/home/nathan/src/linux/include/asm-generic/rwonce.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__))
unsigned long read_word_at_a_time(const void *addr)
{
 kasan_check_read(addr, 1);
 return *(unsigned long *)addr;
}
# 2 "./arch/mips/include/generated/asm/rwonce.h" 2
# 247 "/home/nathan/src/linux/include/linux/compiler.h" 2
# 11 "/home/nathan/src/linux/include/linux/kernel.h" 2
# 1 "/home/nathan/src/linux/include/linux/bitops.h" 1





# 1 "/home/nathan/src/linux/include/linux/bits.h" 1




# 1 "/home/nathan/src/linux/include/linux/const.h" 1



# 1 "/home/nathan/src/linux/include/vdso/const.h" 1




# 1 "/home/nathan/src/linux/include/uapi/linux/const.h" 1
# 6 "/home/nathan/src/linux/include/vdso/const.h" 2
# 5 "/home/nathan/src/linux/include/linux/const.h" 2
# 6 "/home/nathan/src/linux/include/linux/bits.h" 2
# 1 "/home/nathan/src/linux/include/vdso/bits.h" 1
# 7 "/home/nathan/src/linux/include/linux/bits.h" 2
# 22 "/home/nathan/src/linux/include/linux/bits.h"
# 1 "/home/nathan/src/linux/include/linux/build_bug.h" 1
# 23 "/home/nathan/src/linux/include/linux/bits.h" 2
# 7 "/home/nathan/src/linux/include/linux/bitops.h" 2

# 1 "/home/nathan/src/linux/include/uapi/linux/kernel.h" 1




# 1 "/home/nathan/src/linux/include/uapi/linux/sysinfo.h" 1







struct sysinfo {
 __kernel_long_t uptime;
 __kernel_ulong_t loads[3];
 __kernel_ulong_t totalram;
 __kernel_ulong_t freeram;
 __kernel_ulong_t sharedram;
 __kernel_ulong_t bufferram;
 __kernel_ulong_t totalswap;
 __kernel_ulong_t freeswap;
 __u16 procs;
 __u16 pad;
 __kernel_ulong_t totalhigh;
 __kernel_ulong_t freehigh;
 __u32 mem_unit;
 char _f[20-2*sizeof(__kernel_ulong_t)-sizeof(__u32)];
};
# 6 "/home/nathan/src/linux/include/uapi/linux/kernel.h" 2
# 9 "/home/nathan/src/linux/include/linux/bitops.h" 2
# 23 "/home/nathan/src/linux/include/linux/bitops.h"
extern unsigned int __sw_hweight8(unsigned int w);
extern unsigned int __sw_hweight16(unsigned int w);
extern unsigned int __sw_hweight32(unsigned int w);
extern unsigned long __sw_hweight64(__u64 w);






# 1 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 1
# 19 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/barrier.h" 1
# 11 "/home/nathan/src/linux/arch/mips/include/asm/barrier.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/addrspace.h" 1
# 13 "/home/nathan/src/linux/arch/mips/include/asm/addrspace.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/mach-generic/spaces.h" 1
# 15 "/home/nathan/src/linux/arch/mips/include/asm/mach-generic/spaces.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h" 1
# 18 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/hazards.h" 1
# 418 "/home/nathan/src/linux/arch/mips/include/asm/hazards.h"
extern void mips_ihb(void);
# 19 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h" 2
# 1 "/home/nathan/src/linux/arch/mips/include/asm/isa-rev.h" 1
# 20 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h" 2
# 1 "/home/nathan/src/linux/arch/mips/include/asm/war.h" 1
# 21 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h" 2
# 1235 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int mm_insn_16bit(u16 insn)
{
 u16 opcode = (insn >> 10) & 0x7;

 return (opcode >= 1 && opcode <= 3) ? 1 : 0;
}
# 1296 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h"
__asm__(".macro	parse_r var r\n\t"
 "\\var	= -1\n\t"
 ".ifc	\\r, $" "0" "\n\t" "\\var	= " "0" "\n\t" ".endif\n\t" ".ifc	\\r, $" "1" "\n\t" "\\var	= " "1" "\n\t" ".endif\n\t" ".ifc	\\r, $" "2" "\n\t" "\\var	= " "2" "\n\t" ".endif\n\t" ".ifc	\\r, $" "3" "\n\t" "\\var	= " "3" "\n\t" ".endif\n\t"
 ".ifc	\\r, $" "4" "\n\t" "\\var	= " "4" "\n\t" ".endif\n\t" ".ifc	\\r, $" "5" "\n\t" "\\var	= " "5" "\n\t" ".endif\n\t" ".ifc	\\r, $" "6" "\n\t" "\\var	= " "6" "\n\t" ".endif\n\t" ".ifc	\\r, $" "7" "\n\t" "\\var	= " "7" "\n\t" ".endif\n\t"
 ".ifc	\\r, $" "8" "\n\t" "\\var	= " "8" "\n\t" ".endif\n\t" ".ifc	\\r, $" "9" "\n\t" "\\var	= " "9" "\n\t" ".endif\n\t" ".ifc	\\r, $" "10" "\n\t" "\\var	= " "10" "\n\t" ".endif\n\t" ".ifc	\\r, $" "11" "\n\t" "\\var	= " "11" "\n\t" ".endif\n\t"
 ".ifc	\\r, $" "12" "\n\t" "\\var	= " "12" "\n\t" ".endif\n\t" ".ifc	\\r, $" "13" "\n\t" "\\var	= " "13" "\n\t" ".endif\n\t" ".ifc	\\r, $" "14" "\n\t" "\\var	= " "14" "\n\t" ".endif\n\t" ".ifc	\\r, $" "15" "\n\t" "\\var	= " "15" "\n\t" ".endif\n\t"
 ".ifc	\\r, $" "16" "\n\t" "\\var	= " "16" "\n\t" ".endif\n\t" ".ifc	\\r, $" "17" "\n\t" "\\var	= " "17" "\n\t" ".endif\n\t" ".ifc	\\r, $" "18" "\n\t" "\\var	= " "18" "\n\t" ".endif\n\t" ".ifc	\\r, $" "19" "\n\t" "\\var	= " "19" "\n\t" ".endif\n\t"
 ".ifc	\\r, $" "20" "\n\t" "\\var	= " "20" "\n\t" ".endif\n\t" ".ifc	\\r, $" "21" "\n\t" "\\var	= " "21" "\n\t" ".endif\n\t" ".ifc	\\r, $" "22" "\n\t" "\\var	= " "22" "\n\t" ".endif\n\t" ".ifc	\\r, $" "23" "\n\t" "\\var	= " "23" "\n\t" ".endif\n\t"
 ".ifc	\\r, $" "24" "\n\t" "\\var	= " "24" "\n\t" ".endif\n\t" ".ifc	\\r, $" "25" "\n\t" "\\var	= " "25" "\n\t" ".endif\n\t" ".ifc	\\r, $" "26" "\n\t" "\\var	= " "26" "\n\t" ".endif\n\t" ".ifc	\\r, $" "27" "\n\t" "\\var	= " "27" "\n\t" ".endif\n\t"
 ".ifc	\\r, $" "28" "\n\t" "\\var	= " "28" "\n\t" ".endif\n\t" ".ifc	\\r, $" "29" "\n\t" "\\var	= " "29" "\n\t" ".endif\n\t" ".ifc	\\r, $" "30" "\n\t" "\\var	= " "30" "\n\t" ".endif\n\t" ".ifc	\\r, $" "31" "\n\t" "\\var	= " "31" "\n\t" ".endif\n\t"
 ".iflt	\\var\n\t"
 ".error	\"Unable to parse register name \\r\"\n\t"
 ".endif\n\t"
 ".endm");
# 1362 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tlbinvf(void)
{
 __asm__ __volatile__(
  ".set push\n\t"
  ".set noreorder\n\t"
  "# tlbinvf\n\t"
  ".insn\n\t" ".word (" "0x42000004" ")\n\t"

  ".set pop");
}
# 1617 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h"
__asm__(".macro	" "mfhc0" " " "rt" ", " "rs" ", " "sel" " = 0\n\t" "parse_r __" "rt" ", \\" "rt" "\n\t" "parse_r __" "rs" ", \\" "rs" "\n\t" ".insn\n\t" ".word (" "0x40400000 | __rt << 16 | __rs << 11 | \\sel" ")\n\t" ".endm");


__asm__(".macro	" "mthc0" " " "rt" ", " "rd" ", " "sel" " = 0\n\t" "parse_r __" "rt" ", \\" "rt" "\n\t" "parse_r __" "rd" ", \\" "rd" "\n\t" ".insn\n\t" ".word (" "0x40c00000 | __rt << 16 | __rd << 11 | \\sel" ")\n\t" ".endm");
# 2716 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tlb_probe(void)
{
 __asm__ __volatile__(
  ".set noreorder\n\t"
  "tlbp\n\t"
  ".set reorder");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tlb_read(void)
{
# 2743 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h"
 __asm__ __volatile__(
  ".set noreorder\n\t"
  "tlbr\n\t"
  ".set reorder");
# 2759 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h"
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tlb_write_indexed(void)
{
 __asm__ __volatile__(
  ".set noreorder\n\t"
  "tlbwi\n\t"
  ".set reorder");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tlb_write_random(void)
{
 __asm__ __volatile__(
  ".set noreorder\n\t"
  "tlbwr\n\t"
  ".set reorder");
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void guest_tlb_probe(void)
{
 __asm__ __volatile__(
  ".set push\n\t"
  ".set noreorder\n\t"
  ".set\tvirt\n\t"
  "tlbgp\n\t"
  ".set pop");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void guest_tlb_read(void)
{
 __asm__ __volatile__(
  ".set push\n\t"
  ".set noreorder\n\t"
  ".set\tvirt\n\t"
  "tlbgr\n\t"
  ".set pop");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void guest_tlb_write_indexed(void)
{
 __asm__ __volatile__(
  ".set push\n\t"
  ".set noreorder\n\t"
  ".set\tvirt\n\t"
  "tlbgwi\n\t"
  ".set pop");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void guest_tlb_write_random(void)
{
 __asm__ __volatile__(
  ".set push\n\t"
  ".set noreorder\n\t"
  ".set\tvirt\n\t"
  "tlbgwr\n\t"
  ".set pop");
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void guest_tlbinvf(void)
{
 __asm__ __volatile__(
  ".set push\n\t"
  ".set noreorder\n\t"
  ".set\tvirt\n\t"
  "tlbginvf\n\t"
  ".set pop");
}
# 2881 "/home/nathan/src/linux/arch/mips/include/asm/mipsregs.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_status(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_status(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_status(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_cause(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$13" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$13" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$13" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$13" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_cause(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$13" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$13" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$13" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$13" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_cause(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$13" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$13" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$13" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$13" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_config(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_config(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_config(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_config5(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_config5(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_config5(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_config6(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_config6(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_config6(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_config7(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (7 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "7" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (7 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "7" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_config7(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (7 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "7" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (7 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "7" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_config7(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (7 == 0) __asm__ __volatile__( "mfc0\t%0, " "$16" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$16" ", " "7" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (7 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$16" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$16" ", " "7" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_diag(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_diag(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_diag(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_intcontrol(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; __asm__ __volatile__( "cfc0\t%0, " "$20" "\n\t" : "=r" (__res)); __res; }); new = res | set; do { __asm__ __volatile__( "ctc0\t%z0, " "$20" "\n\t" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_intcontrol(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; __asm__ __volatile__( "cfc0\t%0, " "$20" "\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { __asm__ __volatile__( "ctc0\t%z0, " "$20" "\n\t" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_intcontrol(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; __asm__ __volatile__( "cfc0\t%0, " "$20" "\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { __asm__ __volatile__( "ctc0\t%z0, " "$20" "\n\t" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_intctl(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_intctl(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_intctl(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_srsmap(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (3 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "3" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (3 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "3" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_srsmap(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (3 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "3" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (3 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "3" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_srsmap(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (3 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "3" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (3 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "3" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_pagegrain(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$5" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$5" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$5" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$5" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_pagegrain(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$5" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$5" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$5" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$5" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_pagegrain(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$5" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$5" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$5" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$5" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_guestctl0(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_guestctl0(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_guestctl0(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$12" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$12" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$12" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$12" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_guestctl0ext(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$11" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$11" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$11" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$11" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_guestctl0ext(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$11" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$11" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$11" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$11" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_guestctl0ext(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$11" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$11" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$11" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$11" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_guestctl1(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_guestctl1(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_guestctl1(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_guestctl2(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_guestctl2(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_guestctl2(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_guestctl3(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_guestctl3(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_guestctl3(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (6 == 0) __asm__ __volatile__( "mfc0\t%0, " "$10" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$10" ", " "6" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (6 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$10" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$10" ", " "6" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_config_0(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_config_0(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_config_0(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_bus_pll(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_bus_pll(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_bus_pll(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (4 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "4" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (4 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "4" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_reset(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_reset(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_reset(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (5 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "5" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (5 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "5" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_cmt_intr(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_cmt_intr(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_cmt_intr(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_cmt_ctrl(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (2 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "2" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (2 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "2" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_cmt_ctrl(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (2 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "2" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (2 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "2" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_cmt_ctrl(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (2 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "2" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (2 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "2" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_config(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_config(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_config(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_c0_brcm_mode(unsigned int set) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res | set; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_c0_brcm_mode(unsigned int clear) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~clear; do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_c0_brcm_mode(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$22" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$22" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }); new = res & ~change; new |= (val & change); do { if (1 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$22" "\n\t" : : "Jr" ((unsigned int)(new))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$22" ", " "1" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new))); } while (0); return res; }






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_gc0_wired(unsigned int set) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$6" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res | set; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$6" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_gc0_wired(unsigned int clear) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$6" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res & ~clear; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$6" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_gc0_wired(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$6" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res & ~change; new |= (val & change); do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$6" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_gc0_status(unsigned int set) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$12" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res | set; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$12" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_gc0_status(unsigned int clear) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$12" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res & ~clear; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$12" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_gc0_status(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$12" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res & ~change; new |= (val & change); do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$12" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_gc0_cause(unsigned int set) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$13" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res | set; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$13" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_gc0_cause(unsigned int clear) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$13" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res & ~clear; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$13" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_gc0_cause(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$13" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (0)); __res; }); new = res & ~change; new |= (val & change); do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$13" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (0)); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_gc0_ebase(unsigned int set) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$15" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (1)); __res; }); new = res | set; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$15" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (1)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_gc0_ebase(unsigned int clear) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$15" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (1)); __res; }); new = res & ~clear; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$15" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (1)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_gc0_ebase(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$15" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (1)); __res; }); new = res & ~change; new |= (val & change); do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$15" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (1)); } while (0); return res; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int set_gc0_config1(unsigned int set) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$16" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (1)); __res; }); new = res | set; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$16" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (1)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int clear_gc0_config1(unsigned int clear) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$16" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (1)); __res; }); new = res & ~clear; do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$16" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (1)); } while (0); return res; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int change_gc0_config1(unsigned int change, unsigned int val) { unsigned int res, new; res = ({ int __res; __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mfgc0\t%0, " "$16" ", %1\n\t" ".set\tpop" : "=r" (__res) : "i" (1)); __res; }); new = res & ~change; new |= (val & change); do { __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32r2\n\t" ".set\tvirt\n\t" "mtgc0\t%z0, " "$16" ", %1\n\t" ".set\tpop" : : "Jr" ((unsigned int)(new)), "i" (1)); } while (0); return res; }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int get_ebase_cpunum(void)
{
 return ({ unsigned int __res; if (1 == 0) __asm__ __volatile__( "mfc0\t%0, " "$15" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$15" ", " "1" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; }) & ((unsigned long)(0x3ff) << 0);
}
# 16 "/home/nathan/src/linux/arch/mips/include/asm/mach-generic/spaces.h" 2
# 14 "/home/nathan/src/linux/arch/mips/include/asm/addrspace.h" 2
# 12 "/home/nathan/src/linux/arch/mips/include/asm/barrier.h" 2
# 1 "/home/nathan/src/linux/arch/mips/include/asm/sync.h" 1
# 13 "/home/nathan/src/linux/arch/mips/include/asm/barrier.h" 2

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __sync(void)
{
 asm volatile(".if (( 0x00 ) != -1) && ( (1 << 0) ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" ::: "memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rmb(void)
{
 asm volatile(".if (( 0x00 ) != -1) && ( (1 << 0) ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" ::: "memory");
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void wmb(void)
{
 asm volatile(".if (( 0x00 ) != -1) && ( (1 << 0) ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" ::: "memory");
}
# 135 "/home/nathan/src/linux/arch/mips/include/asm/barrier.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void sync_ginv(void)
{
 asm volatile(".if (( 0x14 ) != -1) && ( (1 << 0) ); .set push; .set mips64r6; .rept 1; sync 0x14; .endr; .set pop; .else; ; .endif");
}


# 1 "/home/nathan/src/linux/include/asm-generic/barrier.h" 1
# 17 "/home/nathan/src/linux/include/asm-generic/barrier.h"
# 1 "./arch/mips/include/generated/asm/rwonce.h" 1
# 18 "/home/nathan/src/linux/include/asm-generic/barrier.h" 2
# 141 "/home/nathan/src/linux/arch/mips/include/asm/barrier.h" 2
# 20 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2
# 1 "/home/nathan/src/linux/arch/mips/include/uapi/asm/byteorder.h" 1
# 13 "/home/nathan/src/linux/arch/mips/include/uapi/asm/byteorder.h"
# 1 "/home/nathan/src/linux/include/linux/byteorder/big_endian.h" 1




# 1 "/home/nathan/src/linux/include/uapi/linux/byteorder/big_endian.h" 1
# 13 "/home/nathan/src/linux/include/uapi/linux/byteorder/big_endian.h"
# 1 "/home/nathan/src/linux/include/linux/swab.h" 1




# 1 "/home/nathan/src/linux/include/uapi/linux/swab.h" 1







# 1 "/home/nathan/src/linux/arch/mips/include/uapi/asm/swab.h" 1
# 21 "/home/nathan/src/linux/arch/mips/include/uapi/asm/swab.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__)) __u16 __arch_swab16(__u16 x)
{
 __asm__(
 "	.set	push			\n"
 "	.set	arch=mips32r2		\n"
 "	wsbh	%0, %1			\n"
 "	.set	pop			\n"
 : "=r" (x)
 : "r" (x));

 return x;
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__)) __u32 __arch_swab32(__u32 x)
{
 __asm__(
 "	.set	push			\n"
 "	.set	arch=mips32r2		\n"
 "	wsbh	%0, %1			\n"
 "	rotr	%0, %0, 16		\n"
 "	.set	pop			\n"
 : "=r" (x)
 : "r" (x));

 return x;
}
# 9 "/home/nathan/src/linux/include/uapi/linux/swab.h" 2
# 48 "/home/nathan/src/linux/include/uapi/linux/swab.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__)) __u16 __fswab16(__u16 val)
{

 return __arch_swab16(val);



}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__)) __u32 __fswab32(__u32 val)
{

 return __arch_swab32(val);



}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__)) __u64 __fswab64(__u64 val)
{



 __u32 h = val >> 32;
 __u32 l = val & ((1ULL << 32) - 1);
 return (((__u64)__fswab32(l)) << 32) | ((__u64)(__fswab32(h)));



}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__)) __u32 __fswahw32(__u32 val)
{



 return ((__u32)( (((__u32)(val) & (__u32)0x0000ffffUL) << 16) | (((__u32)(val) & (__u32)0xffff0000UL) >> 16)));

}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__)) __u32 __fswahb32(__u32 val)
{



 return ((__u32)( (((__u32)(val) & (__u32)0x00ff00ffUL) << 8) | (((__u32)(val) & (__u32)0xff00ff00UL) >> 8)));

}
# 136 "/home/nathan/src/linux/include/uapi/linux/swab.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned long __swab(const unsigned long y)
{



 return (__builtin_constant_p((__u32)(y)) ? ((__u32)( (((__u32)(y) & (__u32)0x000000ffUL) << 24) | (((__u32)(y) & (__u32)0x0000ff00UL) << 8) | (((__u32)(y) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(y) & (__u32)0xff000000UL) >> 24))) : __fswab32(y));

}
# 171 "/home/nathan/src/linux/include/uapi/linux/swab.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u16 __swab16p(const __u16 *p)
{



 return (__builtin_constant_p((__u16)(*p)) ? ((__u16)( (((__u16)(*p) & (__u16)0x00ffU) << 8) | (((__u16)(*p) & (__u16)0xff00U) >> 8))) : __fswab16(*p));

}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u32 __swab32p(const __u32 *p)
{



 return (__builtin_constant_p((__u32)(*p)) ? ((__u32)( (((__u32)(*p) & (__u32)0x000000ffUL) << 24) | (((__u32)(*p) & (__u32)0x0000ff00UL) << 8) | (((__u32)(*p) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(*p) & (__u32)0xff000000UL) >> 24))) : __fswab32(*p));

}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u64 __swab64p(const __u64 *p)
{



 return (__builtin_constant_p((__u64)(*p)) ? ((__u64)( (((__u64)(*p) & (__u64)0x00000000000000ffULL) << 56) | (((__u64)(*p) & (__u64)0x000000000000ff00ULL) << 40) | (((__u64)(*p) & (__u64)0x0000000000ff0000ULL) << 24) | (((__u64)(*p) & (__u64)0x00000000ff000000ULL) << 8) | (((__u64)(*p) & (__u64)0x000000ff00000000ULL) >> 8) | (((__u64)(*p) & (__u64)0x0000ff0000000000ULL) >> 24) | (((__u64)(*p) & (__u64)0x00ff000000000000ULL) >> 40) | (((__u64)(*p) & (__u64)0xff00000000000000ULL) >> 56))) : __fswab64(*p));

}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u32 __swahw32p(const __u32 *p)
{



 return (__builtin_constant_p((__u32)(*p)) ? ((__u32)( (((__u32)(*p) & (__u32)0x0000ffffUL) << 16) | (((__u32)(*p) & (__u32)0xffff0000UL) >> 16))) : __fswahw32(*p));

}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u32 __swahb32p(const __u32 *p)
{



 return (__builtin_constant_p((__u32)(*p)) ? ((__u32)( (((__u32)(*p) & (__u32)0x00ff00ffUL) << 8) | (((__u32)(*p) & (__u32)0xff00ff00UL) >> 8))) : __fswahb32(*p));

}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __swab16s(__u16 *p)
{



 *p = __swab16p(p);

}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __swab32s(__u32 *p)
{



 *p = __swab32p(p);

}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __swab64s(__u64 *p)
{



 *p = __swab64p(p);

}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __swahw32s(__u32 *p)
{



 *p = __swahw32p(p);

}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __swahb32s(__u32 *p)
{



 *p = __swahb32p(p);

}
# 6 "/home/nathan/src/linux/include/linux/swab.h" 2
# 14 "/home/nathan/src/linux/include/uapi/linux/byteorder/big_endian.h" 2
# 44 "/home/nathan/src/linux/include/uapi/linux/byteorder/big_endian.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __le64 __cpu_to_le64p(const __u64 *p)
{
 return ( __le64)__swab64p(p);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u64 __le64_to_cpup(const __le64 *p)
{
 return __swab64p((__u64 *)p);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __le32 __cpu_to_le32p(const __u32 *p)
{
 return ( __le32)__swab32p(p);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u32 __le32_to_cpup(const __le32 *p)
{
 return __swab32p((__u32 *)p);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __le16 __cpu_to_le16p(const __u16 *p)
{
 return ( __le16)__swab16p(p);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u16 __le16_to_cpup(const __le16 *p)
{
 return __swab16p((__u16 *)p);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __be64 __cpu_to_be64p(const __u64 *p)
{
 return ( __be64)*p;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u64 __be64_to_cpup(const __be64 *p)
{
 return ( __u64)*p;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __be32 __cpu_to_be32p(const __u32 *p)
{
 return ( __be32)*p;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u32 __be32_to_cpup(const __be32 *p)
{
 return ( __u32)*p;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __be16 __cpu_to_be16p(const __u16 *p)
{
 return ( __be16)*p;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __u16 __be16_to_cpup(const __be16 *p)
{
 return ( __u16)*p;
}
# 6 "/home/nathan/src/linux/include/linux/byteorder/big_endian.h" 2





# 1 "/home/nathan/src/linux/include/linux/byteorder/generic.h" 1
# 144 "/home/nathan/src/linux/include/linux/byteorder/generic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void le16_add_cpu(__le16 *var, u16 val)
{
 *var = (( __le16)(__builtin_constant_p((__u16)(((__builtin_constant_p((__u16)(( __u16)(__le16)(*var))) ? ((__u16)( (((__u16)(( __u16)(__le16)(*var)) & (__u16)0x00ffU) << 8) | (((__u16)(( __u16)(__le16)(*var)) & (__u16)0xff00U) >> 8))) : __fswab16(( __u16)(__le16)(*var))) + val))) ? ((__u16)( (((__u16)(((__builtin_constant_p((__u16)(( __u16)(__le16)(*var))) ? ((__u16)( (((__u16)(( __u16)(__le16)(*var)) & (__u16)0x00ffU) << 8) | (((__u16)(( __u16)(__le16)(*var)) & (__u16)0xff00U) >> 8))) : __fswab16(( __u16)(__le16)(*var))) + val)) & (__u16)0x00ffU) << 8) | (((__u16)(((__builtin_constant_p((__u16)(( __u16)(__le16)(*var))) ? ((__u16)( (((__u16)(( __u16)(__le16)(*var)) & (__u16)0x00ffU) << 8) | (((__u16)(( __u16)(__le16)(*var)) & (__u16)0xff00U) >> 8))) : __fswab16(( __u16)(__le16)(*var))) + val)) & (__u16)0xff00U) >> 8))) : __fswab16(((__builtin_constant_p((__u16)(( __u16)(__le16)(*var))) ? ((__u16)( (((__u16)(( __u16)(__le16)(*var)) & (__u16)0x00ffU) << 8) | (((__u16)(( __u16)(__le16)(*var)) & (__u16)0xff00U) >> 8))) : __fswab16(( __u16)(__le16)(*var))) + val))));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void le32_add_cpu(__le32 *var, u32 val)
{
 *var = (( __le32)(__builtin_constant_p((__u32)(((__builtin_constant_p((__u32)(( __u32)(__le32)(*var))) ? ((__u32)( (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(*var))) + val))) ? ((__u32)( (((__u32)(((__builtin_constant_p((__u32)(( __u32)(__le32)(*var))) ? ((__u32)( (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(*var))) + val)) & (__u32)0x000000ffUL) << 24) | (((__u32)(((__builtin_constant_p((__u32)(( __u32)(__le32)(*var))) ? ((__u32)( (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(*var))) + val)) & (__u32)0x0000ff00UL) << 8) | (((__u32)(((__builtin_constant_p((__u32)(( __u32)(__le32)(*var))) ? ((__u32)( (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(*var))) + val)) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(((__builtin_constant_p((__u32)(( __u32)(__le32)(*var))) ? ((__u32)( (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(*var))) + val)) & (__u32)0xff000000UL) >> 24))) : __fswab32(((__builtin_constant_p((__u32)(( __u32)(__le32)(*var))) ? ((__u32)( (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(*var)) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(*var))) + val))));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void le64_add_cpu(__le64 *var, u64 val)
{
 *var = (( __le64)(__builtin_constant_p((__u64)(((__builtin_constant_p((__u64)(( __u64)(__le64)(*var))) ? ((__u64)( (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000000000ffULL) << 56) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000000000ff00ULL) << 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000000000ff0000ULL) << 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000ff000000ULL) << 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000ff00000000ULL) >> 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000ff0000000000ULL) >> 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00ff000000000000ULL) >> 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0xff00000000000000ULL) >> 56))) : __fswab64(( __u64)(__le64)(*var))) + val))) ? ((__u64)( (((__u64)(((__builtin_constant_p((__u64)(( __u64)(__le64)(*var))) ? ((__u64)( (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000000000ffULL) << 56) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000000000ff00ULL) << 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000000000ff0000ULL) << 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000ff000000ULL) << 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000ff00000000ULL) >> 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000ff0000000000ULL) >> 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00ff000000000000ULL) >> 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0xff00000000000000ULL) >> 56))) : __fswab64(( __u64)(__le64)(*var))) + val)) & (__u64)0x00000000000000ffULL) << 56) | (((__u64)(((__builtin_constant_p((__u64)(( __u64)(__le64)(*var))) ? ((__u64)( (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000000000ffULL) << 56) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000000000ff00ULL) << 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000000000ff0000ULL) << 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000ff000000ULL) << 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000ff00000000ULL) >> 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000ff0000000000ULL) >> 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00ff000000000000ULL) >> 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0xff00000000000000ULL) >> 56))) : __fswab64(( __u64)(__le64)(*var))) + val)) & (__u64)0x000000000000ff00ULL) << 40) | (((__u64)(((__builtin_constant_p((__u64)(( __u64)(__le64)(*var))) ? ((__u64)( (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000000000ffULL) << 56) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000000000ff00ULL) << 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000000000ff0000ULL) << 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000ff000000ULL) << 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000ff00000000ULL) >> 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000ff0000000000ULL) >> 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00ff000000000000ULL) >> 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0xff00000000000000ULL) >> 56))) : __fswab64(( __u64)(__le64)(*var))) + val)) & (__u64)0x0000000000ff0000ULL) << 24) | (((__u64)(((__builtin_constant_p((__u64)(( __u64)(__le64)(*var))) ? ((__u64)( (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000000000ffULL) << 56) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000000000ff00ULL) << 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000000000ff0000ULL) << 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000ff000000ULL) << 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000ff00000000ULL) >> 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000ff0000000000ULL) >> 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00ff000000000000ULL) >> 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0xff00000000000000ULL) >> 56))) : __fswab64(( __u64)(__le64)(*var))) + val)) & (__u64)0x00000000ff000000ULL) << 8) | (((__u64)(((__builtin_constant_p((__u64)(( __u64)(__le64)(*var))) ? ((__u64)( (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000000000ffULL) << 56) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000000000ff00ULL) << 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000000000ff0000ULL) << 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000ff000000ULL) << 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000ff00000000ULL) >> 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000ff0000000000ULL) >> 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00ff000000000000ULL) >> 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0xff00000000000000ULL) >> 56))) : __fswab64(( __u64)(__le64)(*var))) + val)) & (__u64)0x000000ff00000000ULL) >> 8) | (((__u64)(((__builtin_constant_p((__u64)(( __u64)(__le64)(*var))) ? ((__u64)( (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000000000ffULL) << 56) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000000000ff00ULL) << 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000000000ff0000ULL) << 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000ff000000ULL) << 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000ff00000000ULL) >> 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000ff0000000000ULL) >> 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00ff000000000000ULL) >> 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0xff00000000000000ULL) >> 56))) : __fswab64(( __u64)(__le64)(*var))) + val)) & (__u64)0x0000ff0000000000ULL) >> 24) | (((__u64)(((__builtin_constant_p((__u64)(( __u64)(__le64)(*var))) ? ((__u64)( (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000000000ffULL) << 56) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000000000ff00ULL) << 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000000000ff0000ULL) << 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000ff000000ULL) << 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000ff00000000ULL) >> 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000ff0000000000ULL) >> 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00ff000000000000ULL) >> 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0xff00000000000000ULL) >> 56))) : __fswab64(( __u64)(__le64)(*var))) + val)) & (__u64)0x00ff000000000000ULL) >> 40) | (((__u64)(((__builtin_constant_p((__u64)(( __u64)(__le64)(*var))) ? ((__u64)( (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000000000ffULL) << 56) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000000000ff00ULL) << 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000000000ff0000ULL) << 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000ff000000ULL) << 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000ff00000000ULL) >> 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000ff0000000000ULL) >> 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00ff000000000000ULL) >> 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0xff00000000000000ULL) >> 56))) : __fswab64(( __u64)(__le64)(*var))) + val)) & (__u64)0xff00000000000000ULL) >> 56))) : __fswab64(((__builtin_constant_p((__u64)(( __u64)(__le64)(*var))) ? ((__u64)( (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000000000ffULL) << 56) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000000000ff00ULL) << 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000000000ff0000ULL) << 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00000000ff000000ULL) << 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x000000ff00000000ULL) >> 8) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x0000ff0000000000ULL) >> 24) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0x00ff000000000000ULL) >> 40) | (((__u64)(( __u64)(__le64)(*var)) & (__u64)0xff00000000000000ULL) >> 56))) : __fswab64(( __u64)(__le64)(*var))) + val))));
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void le32_to_cpu_array(u32 *buf, unsigned int words)
{
 while (words--) {
  __swab32s((buf));
  buf++;
 }
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpu_to_le32_array(u32 *buf, unsigned int words)
{
 while (words--) {
  __swab32s((buf));
  buf++;
 }
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void be16_add_cpu(__be16 *var, u16 val)
{
 *var = (( __be16)(__u16)((( __u16)(__be16)(*var)) + val));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void be32_add_cpu(__be32 *var, u32 val)
{
 *var = (( __be32)(__u32)((( __u32)(__be32)(*var)) + val));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void be64_add_cpu(__be64 *var, u64 val)
{
 *var = (( __be64)(__u64)((( __u64)(__be64)(*var)) + val));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpu_to_be32_array(__be32 *dst, const u32 *src, size_t len)
{
 int i;

 for (i = 0; i < len; i++)
  dst[i] = (( __be32)(__u32)(src[i]));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void be32_to_cpu_array(u32 *dst, const __be32 *src, size_t len)
{
 int i;

 for (i = 0; i < len; i++)
  dst[i] = (( __u32)(__be32)(src[i]));
}
# 12 "/home/nathan/src/linux/include/linux/byteorder/big_endian.h" 2
# 14 "/home/nathan/src/linux/arch/mips/include/uapi/asm/byteorder.h" 2
# 21 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2

# 1 "/home/nathan/src/linux/arch/mips/include/asm/cpu-features.h" 1
# 12 "/home/nathan/src/linux/arch/mips/include/asm/cpu-features.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/cpu.h" 1
# 293 "/home/nathan/src/linux/arch/mips/include/asm/cpu.h"
enum cpu_type_enum {
 CPU_UNKNOWN,




 CPU_R2000, CPU_R3000, CPU_R3000A, CPU_R3041, CPU_R3051, CPU_R3052,
 CPU_R3081, CPU_R3081E,




 CPU_R4000PC, CPU_R4000SC, CPU_R4000MC, CPU_R4200,
 CPU_R4400PC, CPU_R4400SC, CPU_R4400MC, CPU_R4600, CPU_R4640, CPU_R4650,
 CPU_R4700, CPU_R5000, CPU_R5500, CPU_NEVADA, CPU_R10000,
 CPU_R12000, CPU_R14000, CPU_R16000, CPU_VR41XX, CPU_VR4111, CPU_VR4121,
 CPU_VR4122, CPU_VR4131, CPU_VR4133, CPU_VR4181, CPU_VR4181A, CPU_RM7000,
 CPU_SR71000, CPU_TX49XX,




 CPU_TX3912, CPU_TX3922, CPU_TX3927,




 CPU_4KC, CPU_4KEC, CPU_4KSC, CPU_24K, CPU_34K, CPU_1004K, CPU_74K,
 CPU_ALCHEMY, CPU_PR4450, CPU_BMIPS32, CPU_BMIPS3300, CPU_BMIPS4350,
 CPU_BMIPS4380, CPU_BMIPS5000, CPU_XBURST, CPU_LOONGSON32, CPU_M14KC,
 CPU_M14KEC, CPU_INTERAPTIV, CPU_P5600, CPU_PROAPTIV, CPU_1074K,
 CPU_M5150, CPU_I6400, CPU_P6600, CPU_M6250,




 CPU_5KC, CPU_5KE, CPU_20KC, CPU_25KF, CPU_SB1, CPU_SB1A, CPU_LOONGSON2EF,
 CPU_LOONGSON64, CPU_CAVIUM_OCTEON, CPU_CAVIUM_OCTEON_PLUS,
 CPU_CAVIUM_OCTEON2, CPU_CAVIUM_OCTEON3, CPU_XLR, CPU_XLP, CPU_I6500,

 CPU_QEMU_GENERIC,

 CPU_LAST
};
# 13 "/home/nathan/src/linux/arch/mips/include/asm/cpu-features.h" 2
# 1 "/home/nathan/src/linux/arch/mips/include/asm/cpu-info.h" 1
# 15 "/home/nathan/src/linux/arch/mips/include/asm/cpu-info.h"
# 1 "/home/nathan/src/linux/include/linux/cache.h" 1





# 1 "/home/nathan/src/linux/arch/mips/include/asm/cache.h" 1
# 12 "/home/nathan/src/linux/arch/mips/include/asm/cache.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/mach-generic/kmalloc.h" 1
# 13 "/home/nathan/src/linux/arch/mips/include/asm/cache.h" 2
# 7 "/home/nathan/src/linux/include/linux/cache.h" 2
# 16 "/home/nathan/src/linux/arch/mips/include/asm/cpu-info.h" 2







struct cache_desc {
 unsigned int waysize;
 unsigned short sets;
 unsigned char ways;
 unsigned char linesz;
 unsigned char waybit;
 unsigned char flags;
};

struct guest_info {
 unsigned long ases;
 unsigned long ases_dyn;
 unsigned long long options;
 unsigned long long options_dyn;
 int tlbsize;
 u8 conf;
 u8 kscratch_mask;
};
# 52 "/home/nathan/src/linux/arch/mips/include/asm/cpu-info.h"
struct cpuinfo_mips {
 u64 asid_cache;

 unsigned long asid_mask;





 unsigned long ases;
 unsigned long long options;
 unsigned int udelay_val;
 unsigned int processor_id;
 unsigned int fpu_id;
 unsigned int fpu_csr31;
 unsigned int fpu_msk31;
 unsigned int msa_id;
 unsigned int cputype;
 int isa_level;
 int tlbsize;
 int tlbsizevtlb;
 int tlbsizeftlbsets;
 int tlbsizeftlbways;
 struct cache_desc icache;
 struct cache_desc dcache;
 struct cache_desc vcache;
 struct cache_desc scache;
 struct cache_desc tcache;
 int srsets;
 int package;
 unsigned int globalnumber;



 void *data;
 unsigned int watch_reg_count;
 unsigned int watch_reg_use_cnt;

 u16 watch_reg_masks[4];
 unsigned int kscratch_mask;




 unsigned int writecombine;




 unsigned int htw_seq;


 struct guest_info guest;
 unsigned int gtoffset_mask;
 unsigned int guestid_mask;
 unsigned int guestid_cache;
# 117 "/home/nathan/src/linux/arch/mips/include/asm/cpu-info.h"
} __attribute__((aligned((1 << 7))));

extern struct cpuinfo_mips cpu_data[];




extern void cpu_probe(void);
extern void cpu_report(void);

extern const char *__cpu_name[];


struct seq_file;
struct notifier_block;

extern int register_proc_cpuinfo_notifier(struct notifier_block *nb);
extern int proc_cpuinfo_notifier_call_chain(unsigned long val, void *v);
# 146 "/home/nathan/src/linux/arch/mips/include/asm/cpu-info.h"
struct proc_cpuinfo_notifier_args {
 struct seq_file *m;
 unsigned long n;
};

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpu_cluster(struct cpuinfo_mips *cpuinfo)
{

 if (!0 && !1)
  return 0;

 return (cpuinfo->globalnumber & ((unsigned long)(0xf) << 16)) >>
  16;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpu_core(struct cpuinfo_mips *cpuinfo)
{
 return (cpuinfo->globalnumber & ((unsigned long)(0xff) << 8)) >>
  8;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpu_vpe_id(struct cpuinfo_mips *cpuinfo)
{

 if (!0 && !1)
  return 0;

 return (cpuinfo->globalnumber & ((unsigned long)(0xff) << 0)) >>
  0;
}

extern void cpu_set_cluster(struct cpuinfo_mips *cpuinfo, unsigned int cluster);
extern void cpu_set_core(struct cpuinfo_mips *cpuinfo, unsigned int core);
extern void cpu_set_vpe_id(struct cpuinfo_mips *cpuinfo, unsigned int vpe);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpus_are_siblings(int cpua, int cpub)
{
 struct cpuinfo_mips *infoa = &cpu_data[cpua];
 struct cpuinfo_mips *infob = &cpu_data[cpub];
 unsigned int gnuma, gnumb;

 if (infoa->package != infob->package)
  return false;

 gnuma = infoa->globalnumber & ~((unsigned long)(0xff) << 0);
 gnumb = infob->globalnumber & ~((unsigned long)(0xff) << 0);
 if (gnuma != gnumb)
  return false;

 return true;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long cpu_asid_inc(void)
{
 return 1 << 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long cpu_asid_mask(struct cpuinfo_mips *cpuinfo)
{

 return cpuinfo->asid_mask;

 return ((1 << 0) - 1) << 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpu_asid_mask(struct cpuinfo_mips *cpuinfo,
         unsigned long asid_mask)
{

 cpuinfo->asid_mask = asid_mask;

}
# 14 "/home/nathan/src/linux/arch/mips/include/asm/cpu-features.h" 2

# 1 "/home/nathan/src/linux/arch/mips/include/asm/mach-generic/cpu-feature-overrides.h" 1
# 16 "/home/nathan/src/linux/arch/mips/include/asm/cpu-features.h" 2
# 23 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2

# 1 "/home/nathan/src/linux/arch/mips/include/asm/llsc.h" 1
# 25 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2
# 69 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
void __mips_set_bit(unsigned long nr, volatile unsigned long *addr);
void __mips_clear_bit(unsigned long nr, volatile unsigned long *addr);
void __mips_change_bit(unsigned long nr, volatile unsigned long *addr);
int __mips_test_and_set_bit_lock(unsigned long nr,
     volatile unsigned long *addr);
int __mips_test_and_clear_bit(unsigned long nr,
         volatile unsigned long *addr);
int __mips_test_and_change_bit(unsigned long nr,
          volatile unsigned long *addr);
# 90 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_bit(unsigned long nr, volatile unsigned long *addr)
{
 volatile unsigned long *m = &addr[((nr) / 32)];
 int bit = nr % 32;

 if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) {
  __mips_set_bit(nr, addr);
  return;
 }

 if ((6 >= 2) && __builtin_constant_p(bit) && (bit >= 16)) {
  do { unsigned long temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r6" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0, %1			\n" "	" "ins	" "%0, %3, %2, 1" "			\n" "	" "sc	" "%0, %1			\n" "	" "beqzc	" "%0, 1b			\n" "	.set		pop			\n" : "=&r"(temp), "+" "ZC"(*m) : "i"(bit), "r"(~0) : "memory"); } while (0);
  return;
 }

 do { unsigned long temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r6" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0, %1			\n" "	" "or\t%0, %2" "			\n" "	" "sc	" "%0, %1			\n" "	" "beqzc	" "%0, 1b			\n" "	.set		pop			\n" : "=&r"(temp), "+" "ZC"(*m) : "ir"(((((1UL))) << (bit))) : "memory"); } while (0);
}
# 118 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_bit(unsigned long nr, volatile unsigned long *addr)
{
 volatile unsigned long *m = &addr[((nr) / 32)];
 int bit = nr % 32;

 if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) {
  __mips_clear_bit(nr, addr);
  return;
 }

 if ((6 >= 2) && __builtin_constant_p(bit)) {
  do { unsigned long temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r6" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0, %1			\n" "	" "ins	" "%0, $0, %2, 1" "			\n" "	" "sc	" "%0, %1			\n" "	" "beqzc	" "%0, 1b			\n" "	.set		pop			\n" : "=&r"(temp), "+" "ZC"(*m) : "i"(bit) : "memory"); } while (0);
  return;
 }

 do { unsigned long temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r6" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0, %1			\n" "	" "and\t%0, %2" "			\n" "	" "sc	" "%0, %1			\n" "	" "beqzc	" "%0, 1b			\n" "	.set		pop			\n" : "=&r"(temp), "+" "ZC"(*m) : "ir"(~((((1UL))) << (bit))) : "memory"); } while (0);
}
# 144 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_bit_unlock(unsigned long nr, volatile unsigned long *addr)
{
 do { } while (0);
 clear_bit(nr, addr);
}
# 159 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_bit(unsigned long nr, volatile unsigned long *addr)
{
 volatile unsigned long *m = &addr[((nr) / 32)];
 int bit = nr % 32;

 if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) {
  __mips_change_bit(nr, addr);
  return;
 }

 do { unsigned long temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r6" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0, %1			\n" "	" "xor\t%0, %2" "			\n" "	" "sc	" "%0, %1			\n" "	" "beqzc	" "%0, 1b			\n" "	.set		pop			\n" : "=&r"(temp), "+" "ZC"(*m) : "ir"(((((1UL))) << (bit))) : "memory"); } while (0);
}
# 180 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_set_bit_lock(unsigned long nr,
 volatile unsigned long *addr)
{
 volatile unsigned long *m = &addr[((nr) / 32)];
 int bit = nr % 32;
 unsigned long res, orig;

 if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) {
  res = __mips_test_and_set_bit_lock(nr, addr);
 } else {
  orig = ({ unsigned long orig, temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r6" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0" ", %2		\n" "	" "or\t%1, %0, %3" "			\n" "	" "sc	" "%1, %2			\n" "	" "beqzc	" "%1, 1b			\n" "	.set		pop			\n" : "=&r"(orig), "=&r"(temp), "+" "ZC"(*m) : "ir"(((((1UL))) << (bit))) : "memory"); orig; });


  res = (orig & ((((1UL))) << (bit))) != 0;
 }

 do { } while (0);

 return res;
}
# 209 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_set_bit(unsigned long nr,
 volatile unsigned long *addr)
{
 do { } while (0);
 return test_and_set_bit_lock(nr, addr);
}
# 224 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_clear_bit(unsigned long nr,
 volatile unsigned long *addr)
{
 volatile unsigned long *m = &addr[((nr) / 32)];
 int bit = nr % 32;
 unsigned long res, orig;

 do { } while (0);

 if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) {
  res = __mips_test_and_clear_bit(nr, addr);
 } else if ((6 >= 2) && __builtin_constant_p(nr)) {
  res = ({ unsigned long orig, temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r6" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%1" ", %2		\n" "	" "ext	" "%0, %1, %3, 1;" "ins	" "%1, $0, %3, 1" "			\n" "	" "sc	" "%1, %2			\n" "	" "beqzc	" "%1, 1b			\n" "	.set		pop			\n" : "=&r"(orig), "=&r"(temp), "+" "ZC"(*m) : "i"(bit) : "memory"); orig; });



 } else {
  orig = ({ unsigned long orig, temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r6" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0" ", %2		\n" "	" "or\t%1, %0, %3;" "xor\t%1, %1, %3" "			\n" "	" "sc	" "%1, %2			\n" "	" "beqzc	" "%1, 1b			\n" "	.set		pop			\n" : "=&r"(orig), "=&r"(temp), "+" "ZC"(*m) : "ir"(((((1UL))) << (bit))) : "memory"); orig; });



  res = (orig & ((((1UL))) << (bit))) != 0;
 }

 do { } while (0);

 return res;
}
# 261 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_change_bit(unsigned long nr,
 volatile unsigned long *addr)
{
 volatile unsigned long *m = &addr[((nr) / 32)];
 int bit = nr % 32;
 unsigned long res, orig;

 do { } while (0);

 if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) {
  res = __mips_test_and_change_bit(nr, addr);
 } else {
  orig = ({ unsigned long orig, temp; asm volatile( "	.set		push			\n" "	.set		" "mips64r6" "	\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll	" "%0" ", %2		\n" "	" "xor\t%1, %0, %3" "			\n" "	" "sc	" "%1, %2			\n" "	" "beqzc	" "%1, 1b			\n" "	.set		pop			\n" : "=&r"(orig), "=&r"(temp), "+" "ZC"(*m) : "ir"(((((1UL))) << (bit))) : "memory"); orig; });


  res = (orig & ((((1UL))) << (bit))) != 0;
 }

 do { } while (0);

 return res;
}





# 1 "/home/nathan/src/linux/include/asm-generic/bitops/non-atomic.h" 1
# 16 "/home/nathan/src/linux/include/asm-generic/bitops/non-atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __set_bit(int nr, volatile unsigned long *addr)
{
 unsigned long mask = ((((1UL))) << ((nr) % 32));
 unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);

 *p |= mask;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __clear_bit(int nr, volatile unsigned long *addr)
{
 unsigned long mask = ((((1UL))) << ((nr) % 32));
 unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);

 *p &= ~mask;
}
# 41 "/home/nathan/src/linux/include/asm-generic/bitops/non-atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __change_bit(int nr, volatile unsigned long *addr)
{
 unsigned long mask = ((((1UL))) << ((nr) % 32));
 unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);

 *p ^= mask;
}
# 58 "/home/nathan/src/linux/include/asm-generic/bitops/non-atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __test_and_set_bit(int nr, volatile unsigned long *addr)
{
 unsigned long mask = ((((1UL))) << ((nr) % 32));
 unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);
 unsigned long old = *p;

 *p = old | mask;
 return (old & mask) != 0;
}
# 77 "/home/nathan/src/linux/include/asm-generic/bitops/non-atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __test_and_clear_bit(int nr, volatile unsigned long *addr)
{
 unsigned long mask = ((((1UL))) << ((nr) % 32));
 unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);
 unsigned long old = *p;

 *p = old & ~mask;
 return (old & mask) != 0;
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __test_and_change_bit(int nr,
         volatile unsigned long *addr)
{
 unsigned long mask = ((((1UL))) << ((nr) % 32));
 unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);
 unsigned long old = *p;

 *p = old ^ mask;
 return (old & mask) != 0;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_bit(int nr, const volatile unsigned long *addr)
{
 return 1UL & (addr[((nr) / 32)] >> (nr & (32 -1)));
}
# 288 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2
# 298 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __clear_bit_unlock(unsigned long nr, volatile unsigned long *addr)
{
 do { } while (0);
 __clear_bit(nr, addr);
 __sync();
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned long __fls(unsigned long word)
{
 int num;

 if (32 == 32 && !__builtin_constant_p(word) &&
     __builtin_constant_p(((((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((6 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((6 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) && ((((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((6 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((6 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) {
  __asm__(
  "	.set	push					\n"
  "	.set	""mips64r6""			\n"
  "	clz	%0, %1					\n"
  "	.set	pop					\n"
  : "=r" (num)
  : "r" (word));

  return 31 - num;
 }

 if (32 == 64 && !__builtin_constant_p(word) &&
     __builtin_constant_p((((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((6 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) && (((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((6 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) {
  __asm__(
  "	.set	push					\n"
  "	.set	""mips64r6""			\n"
  "	dclz	%0, %1					\n"
  "	.set	pop					\n"
  : "=r" (num)
  : "r" (word));

  return 63 - num;
 }

 num = 32 - 1;







 if (!(word & (~0ul << (32 -16)))) {
  num -= 16;
  word <<= 16;
 }
 if (!(word & (~0ul << (32 -8)))) {
  num -= 8;
  word <<= 8;
 }
 if (!(word & (~0ul << (32 -4)))) {
  num -= 4;
  word <<= 4;
 }
 if (!(word & (~0ul << (32 -2)))) {
  num -= 2;
  word <<= 2;
 }
 if (!(word & (~0ul << (32 -1))))
  num -= 1;
 return num;
}
# 375 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned long __ffs(unsigned long word)
{
 return __fls(word & -word);
}
# 387 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int fls(unsigned int x)
{
 int r;

 if (!__builtin_constant_p(x) &&
     __builtin_constant_p(((((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((6 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((6 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) && ((((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((6 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((6 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) {
  __asm__(
  "	.set	push					\n"
  "	.set	""mips64r6""			\n"
  "	clz	%0, %1					\n"
  "	.set	pop					\n"
  : "=r" (x)
  : "r" (x));

  return 32 - x;
 }

 r = 32;
 if (!x)
  return 0;
 if (!(x & 0xffff0000u)) {
  x <<= 16;
  r -= 16;
 }
 if (!(x & 0xff000000u)) {
  x <<= 8;
  r -= 8;
 }
 if (!(x & 0xf0000000u)) {
  x <<= 4;
  r -= 4;
 }
 if (!(x & 0xc0000000u)) {
  x <<= 2;
  r -= 2;
 }
 if (!(x & 0x80000000u)) {
  x <<= 1;
  r -= 1;
 }
 return r;
}


# 1 "/home/nathan/src/linux/include/asm-generic/bitops/fls64.h" 1
# 19 "/home/nathan/src/linux/include/asm-generic/bitops/fls64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int fls64(__u64 x)
{
 __u32 h = x >> 32;
 if (h)
  return fls(h) + 32;
 return fls(x);
}
# 431 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2
# 440 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int ffs(int word)
{
 if (!word)
  return 0;

 return fls(word & -word);
}


# 1 "/home/nathan/src/linux/include/asm-generic/bitops/ffz.h" 1
# 449 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2
# 1 "/home/nathan/src/linux/include/asm-generic/bitops/find.h" 1
# 15 "/home/nathan/src/linux/include/asm-generic/bitops/find.h"
extern unsigned long find_next_bit(const unsigned long *addr, unsigned long
  size, unsigned long offset);
# 30 "/home/nathan/src/linux/include/asm-generic/bitops/find.h"
extern unsigned long find_next_and_bit(const unsigned long *addr1,
  const unsigned long *addr2, unsigned long size,
  unsigned long offset);
# 45 "/home/nathan/src/linux/include/asm-generic/bitops/find.h"
extern unsigned long find_next_zero_bit(const unsigned long *addr, unsigned
  long size, unsigned long offset);
# 93 "/home/nathan/src/linux/include/asm-generic/bitops/find.h"
extern unsigned long find_next_clump8(unsigned long *clump,
          const unsigned long *addr,
          unsigned long size, unsigned long offset);
# 450 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2



# 1 "/home/nathan/src/linux/include/asm-generic/bitops/sched.h" 1
# 13 "/home/nathan/src/linux/include/asm-generic/bitops/sched.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int sched_find_first_bit(const unsigned long *b)
{





 if (b[0])
  return __ffs(b[0]);
 if (b[1])
  return __ffs(b[1]) + 32;
 if (b[2])
  return __ffs(b[2]) + 64;
 return __ffs(b[3]) + 96;



}
# 454 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2

# 1 "/home/nathan/src/linux/arch/mips/include/asm/arch_hweight.h" 1
# 35 "/home/nathan/src/linux/arch/mips/include/asm/arch_hweight.h"
# 1 "/home/nathan/src/linux/include/asm-generic/bitops/arch_hweight.h" 1






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int __arch_hweight32(unsigned int w)
{
 return __sw_hweight32(w);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int __arch_hweight16(unsigned int w)
{
 return __sw_hweight16(w);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int __arch_hweight8(unsigned int w)
{
 return __sw_hweight8(w);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __arch_hweight64(__u64 w)
{
 return __sw_hweight64(w);
}
# 36 "/home/nathan/src/linux/arch/mips/include/asm/arch_hweight.h" 2
# 456 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2
# 1 "/home/nathan/src/linux/include/asm-generic/bitops/const_hweight.h" 1
# 457 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2

# 1 "/home/nathan/src/linux/include/asm-generic/bitops/le.h" 1
# 35 "/home/nathan/src/linux/include/asm-generic/bitops/le.h"
extern unsigned long find_next_zero_bit_le(const void *addr,
  unsigned long size, unsigned long offset);



extern unsigned long find_next_bit_le(const void *addr,
  unsigned long size, unsigned long offset);
# 53 "/home/nathan/src/linux/include/asm-generic/bitops/le.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_bit_le(int nr, const void *addr)
{
 return test_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_bit_le(int nr, void *addr)
{
 set_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_bit_le(int nr, void *addr)
{
 clear_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __set_bit_le(int nr, void *addr)
{
 __set_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __clear_bit_le(int nr, void *addr)
{
 __clear_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_set_bit_le(int nr, void *addr)
{
 return test_and_set_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_clear_bit_le(int nr, void *addr)
{
 return test_and_clear_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __test_and_set_bit_le(int nr, void *addr)
{
 return __test_and_set_bit(nr ^ ((32 -1) & ~0x7), addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __test_and_clear_bit_le(int nr, void *addr)
{
 return __test_and_clear_bit(nr ^ ((32 -1) & ~0x7), addr);
}
# 459 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2
# 1 "/home/nathan/src/linux/include/asm-generic/bitops/ext2-atomic.h" 1
# 460 "/home/nathan/src/linux/arch/mips/include/asm/bitops.h" 2
# 33 "/home/nathan/src/linux/include/linux/bitops.h" 2
# 68 "/home/nathan/src/linux/include/linux/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int get_bitmask_order(unsigned int count)
{
 int order;

 order = fls(count);
 return order;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned long hweight_long(unsigned long w)
{
 return sizeof(w) == 4 ? (__builtin_constant_p(w) ? ((((unsigned int) ((!!((w) & (1ULL << 0))) + (!!((w) & (1ULL << 1))) + (!!((w) & (1ULL << 2))) + (!!((w) & (1ULL << 3))) + (!!((w) & (1ULL << 4))) + (!!((w) & (1ULL << 5))) + (!!((w) & (1ULL << 6))) + (!!((w) & (1ULL << 7))))) + ((unsigned int) ((!!(((w) >> 8) & (1ULL << 0))) + (!!(((w) >> 8) & (1ULL << 1))) + (!!(((w) >> 8) & (1ULL << 2))) + (!!(((w) >> 8) & (1ULL << 3))) + (!!(((w) >> 8) & (1ULL << 4))) + (!!(((w) >> 8) & (1ULL << 5))) + (!!(((w) >> 8) & (1ULL << 6))) + (!!(((w) >> 8) & (1ULL << 7)))))) + (((unsigned int) ((!!(((w) >> 16) & (1ULL << 0))) + (!!(((w) >> 16) & (1ULL << 1))) + (!!(((w) >> 16) & (1ULL << 2))) + (!!(((w) >> 16) & (1ULL << 3))) + (!!(((w) >> 16) & (1ULL << 4))) + (!!(((w) >> 16) & (1ULL << 5))) + (!!(((w) >> 16) & (1ULL << 6))) + (!!(((w) >> 16) & (1ULL << 7))))) + ((unsigned int) ((!!((((w) >> 16) >> 8) & (1ULL << 0))) + (!!((((w) >> 16) >> 8) & (1ULL << 1))) + (!!((((w) >> 16) >> 8) & (1ULL << 2))) + (!!((((w) >> 16) >> 8) & (1ULL << 3))) + (!!((((w) >> 16) >> 8) & (1ULL << 4))) + (!!((((w) >> 16) >> 8) & (1ULL << 5))) + (!!((((w) >> 16) >> 8) & (1ULL << 6))) + (!!((((w) >> 16) >> 8) & (1ULL << 7))))))) : __arch_hweight32(w)) : (__builtin_constant_p((__u64)w) ? (((((unsigned int) ((!!(((__u64)w) & (1ULL << 0))) + (!!(((__u64)w) & (1ULL << 1))) + (!!(((__u64)w) & (1ULL << 2))) + (!!(((__u64)w) & (1ULL << 3))) + (!!(((__u64)w) & (1ULL << 4))) + (!!(((__u64)w) & (1ULL << 5))) + (!!(((__u64)w) & (1ULL << 6))) + (!!(((__u64)w) & (1ULL << 7))))) + ((unsigned int) ((!!((((__u64)w) >> 8) & (1ULL << 0))) + (!!((((__u64)w) >> 8) & (1ULL << 1))) + (!!((((__u64)w) >> 8) & (1ULL << 2))) + (!!((((__u64)w) >> 8) & (1ULL << 3))) + (!!((((__u64)w) >> 8) & (1ULL << 4))) + (!!((((__u64)w) >> 8) & (1ULL << 5))) + (!!((((__u64)w) >> 8) & (1ULL << 6))) + (!!((((__u64)w) >> 8) & (1ULL << 7)))))) + (((unsigned int) ((!!((((__u64)w) >> 16) & (1ULL << 0))) + (!!((((__u64)w) >> 16) & (1ULL << 1))) + (!!((((__u64)w) >> 16) & (1ULL << 2))) + (!!((((__u64)w) >> 16) & (1ULL << 3))) + (!!((((__u64)w) >> 16) & (1ULL << 4))) + (!!((((__u64)w) >> 16) & (1ULL << 5))) + (!!((((__u64)w) >> 16) & (1ULL << 6))) + (!!((((__u64)w) >> 16) & (1ULL << 7))))) + ((unsigned int) ((!!(((((__u64)w) >> 16) >> 8) & (1ULL << 0))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 1))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 2))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 3))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 4))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 5))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 6))) + (!!(((((__u64)w) >> 16) >> 8) & (1ULL << 7))))))) + ((((unsigned int) ((!!((((__u64)w) >> 32) & (1ULL << 0))) + (!!((((__u64)w) >> 32) & (1ULL << 1))) + (!!((((__u64)w) >> 32) & (1ULL << 2))) + (!!((((__u64)w) >> 32) & (1ULL << 3))) + (!!((((__u64)w) >> 32) & (1ULL << 4))) + (!!((((__u64)w) >> 32) & (1ULL << 5))) + (!!((((__u64)w) >> 32) & (1ULL << 6))) + (!!((((__u64)w) >> 32) & (1ULL << 7))))) + ((unsigned int) ((!!(((((__u64)w) >> 32) >> 8) & (1ULL << 0))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 1))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 2))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 3))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 4))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 5))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 6))) + (!!(((((__u64)w) >> 32) >> 8) & (1ULL << 7)))))) + (((unsigned int) ((!!(((((__u64)w) >> 32) >> 16) & (1ULL << 0))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 1))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 2))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 3))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 4))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 5))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 6))) + (!!(((((__u64)w) >> 32) >> 16) & (1ULL << 7))))) + ((unsigned int) ((!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 0))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 1))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 2))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 3))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 4))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 5))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 6))) + (!!((((((__u64)w) >> 32) >> 16) >> 8) & (1ULL << 7)))))))) : __arch_hweight64((__u64)w));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u64 rol64(__u64 word, unsigned int shift)
{
 return (word << (shift & 63)) | (word >> ((-shift) & 63));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u64 ror64(__u64 word, unsigned int shift)
{
 return (word >> (shift & 63)) | (word << ((-shift) & 63));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u32 rol32(__u32 word, unsigned int shift)
{
 return (word << (shift & 31)) | (word >> ((-shift) & 31));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u32 ror32(__u32 word, unsigned int shift)
{
 return (word >> (shift & 31)) | (word << ((-shift) & 31));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u16 rol16(__u16 word, unsigned int shift)
{
 return (word << (shift & 15)) | (word >> ((-shift) & 15));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u16 ror16(__u16 word, unsigned int shift)
{
 return (word >> (shift & 15)) | (word << ((-shift) & 15));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u8 rol8(__u8 word, unsigned int shift)
{
 return (word << (shift & 7)) | (word >> ((-shift) & 7));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __u8 ror8(__u8 word, unsigned int shift)
{
 return (word >> (shift & 7)) | (word << ((-shift) & 7));
}
# 168 "/home/nathan/src/linux/include/linux/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __s32 sign_extend32(__u32 value, int index)
{
 __u8 shift = 31 - index;
 return (__s32)(value << shift) >> shift;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __s64 sign_extend64(__u64 value, int index)
{
 __u8 shift = 63 - index;
 return (__s64)(value << shift) >> shift;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned fls_long(unsigned long l)
{
 if (sizeof(l) == 4)
  return fls(l);
 return fls64(l);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int get_count_order(unsigned int count)
{
 if (count == 0)
  return -1;

 return fls(--count);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int get_count_order_long(unsigned long l)
{
 if (l == 0UL)
  return -1;
 return (int)fls_long(--l);
}
# 221 "/home/nathan/src/linux/include/linux/bitops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __ffs64(u64 word)
{

 if (((u32)word) == 0UL)
  return __ffs((u32)(word >> 32)) + 32;



 return __ffs((unsigned long)word);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void assign_bit(long nr, volatile unsigned long *addr,
           bool value)
{
 if (value)
  set_bit(nr, addr);
 else
  clear_bit(nr, addr);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __assign_bit(long nr, volatile unsigned long *addr,
      bool value)
{
 if (value)
  __set_bit(nr, addr);
 else
  __clear_bit(nr, addr);
}
# 297 "/home/nathan/src/linux/include/linux/bitops.h"
extern unsigned long find_last_bit(const unsigned long *addr,
       unsigned long size);
# 12 "/home/nathan/src/linux/include/linux/kernel.h" 2
# 1 "/home/nathan/src/linux/include/linux/log2.h" 1
# 21 "/home/nathan/src/linux/include/linux/log2.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((const))
int __ilog2_u32(u32 n)
{
 return fls(n) - 1;
}



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((const))
int __ilog2_u64(u64 n)
{
 return fls64(n) - 1;
}
# 44 "/home/nathan/src/linux/include/linux/log2.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((const))
bool is_power_of_2(unsigned long n)
{
 return (n != 0 && ((n & (n - 1)) == 0));
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((const))
unsigned long __roundup_pow_of_two(unsigned long n)
{
 return 1UL << fls_long(n - 1);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((const))
unsigned long __rounddown_pow_of_two(unsigned long n)
{
 return 1UL << (fls_long(n) - 1);
}
# 198 "/home/nathan/src/linux/include/linux/log2.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__const__))
int __order_base_2(unsigned long n)
{
 return n > 1 ? ( __builtin_constant_p(n - 1) ? ((n - 1) < 2 ? 0 : 63 - __builtin_clzll(n - 1)) : (sizeof(n - 1) <= 4) ? __ilog2_u32(n - 1) : __ilog2_u64(n - 1) ) + 1 : 0;
}
# 225 "/home/nathan/src/linux/include/linux/log2.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((const))
int __bits_per(unsigned long n)
{
 if (n < 2)
  return 1;
 if (is_power_of_2(n))
  return ( __builtin_constant_p(n) ? ( ((n) == 0 || (n) == 1) ? 0 : ( __builtin_constant_p((n) - 1) ? (((n) - 1) < 2 ? 0 : 63 - __builtin_clzll((n) - 1)) : (sizeof((n) - 1) <= 4) ? __ilog2_u32((n) - 1) : __ilog2_u64((n) - 1) ) + 1) : __order_base_2(n) ) + 1;
 return ( __builtin_constant_p(n) ? ( ((n) == 0 || (n) == 1) ? 0 : ( __builtin_constant_p((n) - 1) ? (((n) - 1) < 2 ? 0 : 63 - __builtin_clzll((n) - 1)) : (sizeof((n) - 1) <= 4) ? __ilog2_u32((n) - 1) : __ilog2_u64((n) - 1) ) + 1) : __order_base_2(n) );
}
# 13 "/home/nathan/src/linux/include/linux/kernel.h" 2
# 1 "/home/nathan/src/linux/include/linux/math.h" 1




# 1 "/home/nathan/src/linux/arch/mips/include/asm/div64.h" 1
# 12 "/home/nathan/src/linux/arch/mips/include/asm/div64.h"
# 1 "/home/nathan/src/linux/include/asm-generic/div64.h" 1
# 175 "/home/nathan/src/linux/include/asm-generic/div64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t __arch_xprod_64(const uint64_t m, uint64_t n, bool bias)
{
 uint32_t m_lo = m;
 uint32_t m_hi = m >> 32;
 uint32_t n_lo = n;
 uint32_t n_hi = n >> 32;
 uint64_t res;
 uint32_t res_lo, res_hi, tmp;

 if (!bias) {
  res = ((uint64_t)m_lo * n_lo) >> 32;
 } else if (!(m & ((1ULL << 63) | (1ULL << 31)))) {

  res = (m + (uint64_t)m_lo * n_lo) >> 32;
 } else {
  res = m + (uint64_t)m_lo * n_lo;
  res_lo = res >> 32;
  res_hi = (res_lo < m_hi);
  res = res_lo | ((uint64_t)res_hi << 32);
 }

 if (!(m & ((1ULL << 63) | (1ULL << 31)))) {

  res += (uint64_t)m_lo * n_hi;
  res += (uint64_t)m_hi * n_lo;
  res >>= 32;
 } else {
  res += (uint64_t)m_lo * n_hi;
  tmp = res >> 32;
  res += (uint64_t)m_hi * n_lo;
  res_lo = res >> 32;
  res_hi = (res_lo < tmp);
  res = res_lo | ((uint64_t)res_hi << 32);
 }

 res += (uint64_t)m_hi * n_hi;

 return res;
}



extern uint32_t __div64_32(uint64_t *dividend, uint32_t divisor);
# 13 "/home/nathan/src/linux/arch/mips/include/asm/div64.h" 2
# 6 "/home/nathan/src/linux/include/linux/math.h" 2
# 160 "/home/nathan/src/linux/include/linux/math.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 reciprocal_scale(u32 val, u32 ep_ro)
{
 return (u32)(((u64) val * ep_ro) >> 32);
}

u64 int_pow(u64 base, unsigned int exp);
unsigned long int_sqrt(unsigned long);


u32 int_sqrt64(u64 x);
# 14 "/home/nathan/src/linux/include/linux/kernel.h" 2
# 1 "/home/nathan/src/linux/include/linux/minmax.h" 1
# 15 "/home/nathan/src/linux/include/linux/kernel.h" 2
# 1 "/home/nathan/src/linux/include/linux/typecheck.h" 1
# 16 "/home/nathan/src/linux/include/linux/kernel.h" 2
# 1 "/home/nathan/src/linux/include/linux/printk.h" 1





# 1 "/home/nathan/src/linux/include/linux/init.h" 1
# 116 "/home/nathan/src/linux/include/linux/init.h"
typedef int (*initcall_t)(void);
typedef void (*exitcall_t)(void);
# 127 "/home/nathan/src/linux/include/linux/init.h"
typedef initcall_t initcall_entry_t;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) initcall_t initcall_from_entry(initcall_entry_t *entry)
{
 return *entry;
}


extern initcall_entry_t __con_initcall_start[], __con_initcall_end[];


typedef void (*ctor_fn_t)(void);

struct file_system_type;


extern int do_one_initcall(initcall_t fn);
extern char __attribute__((__section__(".init.data"))) boot_command_line[];
extern char *saved_command_line;
extern unsigned int reset_devices;


void setup_arch(char **);
void prepare_namespace(void);
void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) init_rootfs(void);
extern struct file_system_type rootfs_fs_type;
# 161 "/home/nathan/src/linux/include/linux/init.h"
extern void (*late_time_init)(void);

extern bool initcall_debug;
# 241 "/home/nathan/src/linux/include/linux/init.h"
struct obs_kernel_param {
 const char *str;
 int (*setup_func)(char *);
 int early;
};
# 290 "/home/nathan/src/linux/include/linux/init.h"
void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) parse_early_param(void);
void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) parse_early_options(char *cmdline);
# 7 "/home/nathan/src/linux/include/linux/printk.h" 2
# 1 "/home/nathan/src/linux/include/linux/kern_levels.h" 1
# 8 "/home/nathan/src/linux/include/linux/printk.h" 2


# 1 "/home/nathan/src/linux/include/linux/ratelimit_types.h" 1





# 1 "/home/nathan/src/linux/include/uapi/linux/param.h" 1




# 1 "/home/nathan/src/linux/arch/mips/include/uapi/asm/param.h" 1
# 15 "/home/nathan/src/linux/arch/mips/include/uapi/asm/param.h"
# 1 "/home/nathan/src/linux/include/asm-generic/param.h" 1




# 1 "/home/nathan/src/linux/include/uapi/asm-generic/param.h" 1
# 6 "/home/nathan/src/linux/include/asm-generic/param.h" 2
# 16 "/home/nathan/src/linux/arch/mips/include/uapi/asm/param.h" 2
# 6 "/home/nathan/src/linux/include/uapi/linux/param.h" 2
# 7 "/home/nathan/src/linux/include/linux/ratelimit_types.h" 2
# 1 "/home/nathan/src/linux/include/linux/spinlock_types.h" 1
# 13 "/home/nathan/src/linux/include/linux/spinlock_types.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/spinlock_types.h" 1




# 1 "/home/nathan/src/linux/include/asm-generic/qspinlock_types.h" 1
# 14 "/home/nathan/src/linux/include/asm-generic/qspinlock_types.h"
typedef struct qspinlock {
 union {
  atomic_t val;
# 33 "/home/nathan/src/linux/include/asm-generic/qspinlock_types.h"
  struct {
   u16 tail;
   u16 locked_pending;
  };
  struct {
   u8 reserved[2];
   u8 pending;
   u8 locked;
  };

 };
} arch_spinlock_t;
# 6 "/home/nathan/src/linux/arch/mips/include/asm/spinlock_types.h" 2
# 1 "/home/nathan/src/linux/include/asm-generic/qrwlock_types.h" 1






# 1 "/home/nathan/src/linux/arch/mips/include/asm/spinlock_types.h" 1
# 8 "/home/nathan/src/linux/include/asm-generic/qrwlock_types.h" 2





typedef struct qrwlock {
 union {
  atomic_t cnts;
  struct {




   u8 __lstate[3];
   u8 wlocked;

  };
 };
 arch_spinlock_t wait_lock;
} arch_rwlock_t;
# 7 "/home/nathan/src/linux/arch/mips/include/asm/spinlock_types.h" 2
# 14 "/home/nathan/src/linux/include/linux/spinlock_types.h" 2




# 1 "/home/nathan/src/linux/include/linux/lockdep_types.h" 1
# 17 "/home/nathan/src/linux/include/linux/lockdep_types.h"
enum lockdep_wait_type {
 LD_WAIT_INV = 0,

 LD_WAIT_FREE,
 LD_WAIT_SPIN,




 LD_WAIT_CONFIG = LD_WAIT_SPIN,

 LD_WAIT_SLEEP,

 LD_WAIT_MAX,
};
# 187 "/home/nathan/src/linux/include/linux/lockdep_types.h"
struct lock_class_key { };




struct lockdep_map { };

struct pin_cookie { };
# 19 "/home/nathan/src/linux/include/linux/spinlock_types.h" 2

typedef struct raw_spinlock {
 arch_spinlock_t raw_lock;







} raw_spinlock_t;
# 71 "/home/nathan/src/linux/include/linux/spinlock_types.h"
typedef struct spinlock {
 union {
  struct raw_spinlock rlock;
# 82 "/home/nathan/src/linux/include/linux/spinlock_types.h"
 };
} spinlock_t;
# 99 "/home/nathan/src/linux/include/linux/spinlock_types.h"
# 1 "/home/nathan/src/linux/include/linux/rwlock_types.h" 1
# 11 "/home/nathan/src/linux/include/linux/rwlock_types.h"
typedef struct {
 arch_rwlock_t raw_lock;







} rwlock_t;
# 100 "/home/nathan/src/linux/include/linux/spinlock_types.h" 2
# 8 "/home/nathan/src/linux/include/linux/ratelimit_types.h" 2







struct ratelimit_state {
 raw_spinlock_t lock;

 int interval;
 int burst;
 int printed;
 int missed;
 unsigned long begin;
 unsigned long flags;
};
# 40 "/home/nathan/src/linux/include/linux/ratelimit_types.h"
extern int ___ratelimit(struct ratelimit_state *rs, const char *func);
# 11 "/home/nathan/src/linux/include/linux/printk.h" 2

extern const char linux_banner[];
extern const char linux_proc_banner[];

extern int oops_in_progress;



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int printk_get_level(const char *buffer)
{
 if (buffer[0] == '\001' && buffer[1]) {
  switch (buffer[1]) {
  case '0' ... '7':
  case 'c':
   return buffer[1];
  }
 }
 return 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) const char *printk_skip_level(const char *buffer)
{
 if (printk_get_level(buffer))
  return buffer + 2;

 return buffer;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) const char *printk_skip_headers(const char *buffer)
{
 while (printk_get_level(buffer))
  buffer = printk_skip_level(buffer);

 return buffer;
}
# 65 "/home/nathan/src/linux/include/linux/printk.h"
extern int console_printk[];






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void console_silent(void)
{
 (console_printk[0]) = 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void console_verbose(void)
{
 if ((console_printk[0]))
  (console_printk[0]) = 15;
}



extern char devkmsg_log_str[];
struct ctl_table;

extern int suppress_printk;

struct va_format {
 const char *fmt;
 va_list *va;
};
# 148 "/home/nathan/src/linux/include/linux/printk.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__format__(printf, 1, 2))) __attribute__((__cold__))
void early_printk(const char *s, ...) { }



extern void printk_nmi_enter(void);
extern void printk_nmi_exit(void);
extern void printk_nmi_direct_enter(void);
extern void printk_nmi_direct_exit(void);







struct dev_printk_info;


           __attribute__((__format__(printf, 4, 0)))
int vprintk_emit(int facility, int level,
   const struct dev_printk_info *dev_info,
   const char *fmt, va_list args);

           __attribute__((__format__(printf, 1, 0)))
int vprintk(const char *fmt, va_list args);

           __attribute__((__format__(printf, 1, 2))) __attribute__((__cold__))
int printk(const char *fmt, ...);




__attribute__((__format__(printf, 1, 2))) __attribute__((__cold__)) int printk_deferred(const char *fmt, ...);






extern int __printk_ratelimit(const char *func);

extern bool printk_timed_ratelimit(unsigned long *caller_jiffies,
       unsigned int interval_msec);

extern int printk_delay_msec;
extern int dmesg_restrict;

extern int
devkmsg_sysctl_set_loglvl(struct ctl_table *table, int write, void *buf,
     size_t *lenp, loff_t *ppos);

extern void wake_up_klogd(void);

char *log_buf_addr_get(void);
u32 log_buf_len_get(void);
void log_buf_vmcoreinfo_setup(void);
void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) setup_log_buf(int early);
__attribute__((__format__(printf, 1, 2))) void dump_stack_set_arch_desc(const char *fmt, ...);
void dump_stack_print_info(const char *log_lvl);
void show_regs_print_info(const char *log_lvl);
extern void dump_stack(void) __attribute__((__cold__));
extern void printk_safe_flush(void);
extern void printk_safe_flush_on_panic(void);
# 285 "/home/nathan/src/linux/include/linux/printk.h"
extern int kptr_restrict;
# 565 "/home/nathan/src/linux/include/linux/printk.h"
extern const struct file_operations kmsg_fops;

enum {
 DUMP_PREFIX_NONE,
 DUMP_PREFIX_ADDRESS,
 DUMP_PREFIX_OFFSET
};
extern int hex_dump_to_buffer(const void *buf, size_t len, int rowsize,
         int groupsize, char *linebuf, size_t linebuflen,
         bool ascii);

extern void print_hex_dump(const char *level, const char *prefix_str,
      int prefix_type, int rowsize, int groupsize,
      const void *buf, size_t len, bool ascii);
# 604 "/home/nathan/src/linux/include/linux/printk.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void print_hex_dump_debug(const char *prefix_str, int prefix_type,
     int rowsize, int groupsize,
     const void *buf, size_t len, bool ascii)
{
}
# 17 "/home/nathan/src/linux/include/linux/kernel.h" 2
# 79 "/home/nathan/src/linux/include/linux/kernel.h"
struct completion;
struct pt_regs;
struct user;
# 148 "/home/nathan/src/linux/include/linux/kernel.h"
  static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ___might_sleep(const char *file, int line,
       int preempt_offset) { }
  static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __might_sleep(const char *file, int line,
       int preempt_offset) { }
# 167 "/home/nathan/src/linux/include/linux/kernel.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void might_fault(void) { }


extern struct atomic_notifier_head panic_notifier_list;
extern long (*panic_blink)(int state);
__attribute__((__format__(printf, 1, 2)))
void panic(const char *fmt, ...) __attribute__((__noreturn__)) __attribute__((__cold__));
void nmi_panic(struct pt_regs *regs, const char *msg);
extern void oops_enter(void);
extern void oops_exit(void);
extern bool oops_may_print(void);
void do_exit(long error_code) __attribute__((__noreturn__));
void complete_and_exit(struct completion *, long) __attribute__((__noreturn__));


int __attribute__((__warn_unused_result__)) _kstrtoul(const char *s, unsigned int base, unsigned long *res);
int __attribute__((__warn_unused_result__)) _kstrtol(const char *s, unsigned int base, long *res);

int __attribute__((__warn_unused_result__)) kstrtoull(const char *s, unsigned int base, unsigned long long *res);
int __attribute__((__warn_unused_result__)) kstrtoll(const char *s, unsigned int base, long long *res);
# 203 "/home/nathan/src/linux/include/linux/kernel.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtoul(const char *s, unsigned int base, unsigned long *res)
{




 if (sizeof(unsigned long) == sizeof(unsigned long long) &&
     __alignof__(unsigned long) == __alignof__(unsigned long long))
  return kstrtoull(s, base, (unsigned long long *)res);
 else
  return _kstrtoul(s, base, res);
}
# 231 "/home/nathan/src/linux/include/linux/kernel.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtol(const char *s, unsigned int base, long *res)
{




 if (sizeof(long) == sizeof(long long) &&
     __alignof__(long) == __alignof__(long long))
  return kstrtoll(s, base, (long long *)res);
 else
  return _kstrtol(s, base, res);
}

int __attribute__((__warn_unused_result__)) kstrtouint(const char *s, unsigned int base, unsigned int *res);
int __attribute__((__warn_unused_result__)) kstrtoint(const char *s, unsigned int base, int *res);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtou64(const char *s, unsigned int base, u64 *res)
{
 return kstrtoull(s, base, res);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtos64(const char *s, unsigned int base, s64 *res)
{
 return kstrtoll(s, base, res);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtou32(const char *s, unsigned int base, u32 *res)
{
 return kstrtouint(s, base, res);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtos32(const char *s, unsigned int base, s32 *res)
{
 return kstrtoint(s, base, res);
}

int __attribute__((__warn_unused_result__)) kstrtou16(const char *s, unsigned int base, u16 *res);
int __attribute__((__warn_unused_result__)) kstrtos16(const char *s, unsigned int base, s16 *res);
int __attribute__((__warn_unused_result__)) kstrtou8(const char *s, unsigned int base, u8 *res);
int __attribute__((__warn_unused_result__)) kstrtos8(const char *s, unsigned int base, s8 *res);
int __attribute__((__warn_unused_result__)) kstrtobool(const char *s, bool *res);

int __attribute__((__warn_unused_result__)) kstrtoull_from_user(const char *s, size_t count, unsigned int base, unsigned long long *res);
int __attribute__((__warn_unused_result__)) kstrtoll_from_user(const char *s, size_t count, unsigned int base, long long *res);
int __attribute__((__warn_unused_result__)) kstrtoul_from_user(const char *s, size_t count, unsigned int base, unsigned long *res);
int __attribute__((__warn_unused_result__)) kstrtol_from_user(const char *s, size_t count, unsigned int base, long *res);
int __attribute__((__warn_unused_result__)) kstrtouint_from_user(const char *s, size_t count, unsigned int base, unsigned int *res);
int __attribute__((__warn_unused_result__)) kstrtoint_from_user(const char *s, size_t count, unsigned int base, int *res);
int __attribute__((__warn_unused_result__)) kstrtou16_from_user(const char *s, size_t count, unsigned int base, u16 *res);
int __attribute__((__warn_unused_result__)) kstrtos16_from_user(const char *s, size_t count, unsigned int base, s16 *res);
int __attribute__((__warn_unused_result__)) kstrtou8_from_user(const char *s, size_t count, unsigned int base, u8 *res);
int __attribute__((__warn_unused_result__)) kstrtos8_from_user(const char *s, size_t count, unsigned int base, s8 *res);
int __attribute__((__warn_unused_result__)) kstrtobool_from_user(const char *s, size_t count, bool *res);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtou64_from_user(const char *s, size_t count, unsigned int base, u64 *res)
{
 return kstrtoull_from_user(s, count, base, res);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtos64_from_user(const char *s, size_t count, unsigned int base, s64 *res)
{
 return kstrtoll_from_user(s, count, base, res);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtou32_from_user(const char *s, size_t count, unsigned int base, u32 *res)
{
 return kstrtouint_from_user(s, count, base, res);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) kstrtos32_from_user(const char *s, size_t count, unsigned int base, s32 *res)
{
 return kstrtoint_from_user(s, count, base, res);
}
# 318 "/home/nathan/src/linux/include/linux/kernel.h"
extern unsigned long simple_strtoul(const char *,char **,unsigned int);
extern long simple_strtol(const char *,char **,unsigned int);
extern unsigned long long simple_strtoull(const char *,char **,unsigned int);
extern long long simple_strtoll(const char *,char **,unsigned int);

extern int num_to_str(char *buf, int size,
        unsigned long long num, unsigned int width);



extern __attribute__((__format__(printf, 2, 3))) int sprintf(char *buf, const char * fmt, ...);
extern __attribute__((__format__(printf, 2, 0))) int vsprintf(char *buf, const char *, va_list);
extern __attribute__((__format__(printf, 3, 4)))
int snprintf(char *buf, size_t size, const char *fmt, ...);
extern __attribute__((__format__(printf, 3, 0)))
int vsnprintf(char *buf, size_t size, const char *fmt, va_list args);
extern __attribute__((__format__(printf, 3, 4)))
int scnprintf(char *buf, size_t size, const char *fmt, ...);
extern __attribute__((__format__(printf, 3, 0)))
int vscnprintf(char *buf, size_t size, const char *fmt, va_list args);
extern __attribute__((__format__(printf, 2, 3))) __attribute__((__malloc__))
char *kasprintf(gfp_t gfp, const char *fmt, ...);
extern __attribute__((__format__(printf, 2, 0))) __attribute__((__malloc__))
char *kvasprintf(gfp_t gfp, const char *fmt, va_list args);
extern __attribute__((__format__(printf, 2, 0)))
const char *kvasprintf_const(gfp_t gfp, const char *fmt, va_list args);

extern __attribute__((__format__(scanf, 2, 3)))
int sscanf(const char *, const char *, ...);
extern __attribute__((__format__(scanf, 2, 0)))
int vsscanf(const char *, const char *, va_list);

extern int get_option(char **str, int *pint);
extern char *get_options(const char *str, int nints, int *ints);
extern unsigned long long memparse(const char *ptr, char **retptr);
extern bool parse_option_str(const char *str, const char *option);
extern char *next_arg(char *args, char **param, char **val);

extern int core_kernel_text(unsigned long addr);
extern int init_kernel_text(unsigned long addr);
extern int core_kernel_data(unsigned long addr);
extern int __kernel_text_address(unsigned long addr);
extern int kernel_text_address(unsigned long addr);
extern int func_ptr_is_kernel_text(void *ptr);


extern unsigned int sysctl_oops_all_cpu_backtrace;




extern void bust_spinlocks(int yes);
extern int panic_timeout;
extern unsigned long panic_print;
extern int panic_on_oops;
extern int panic_on_unrecovered_nmi;
extern int panic_on_io_nmi;
extern int panic_on_warn;
extern unsigned long panic_on_taint;
extern bool panic_on_taint_nousertaint;
extern int sysctl_panic_on_rcu_stall;
extern int sysctl_max_rcu_stall_to_panic;
extern int sysctl_panic_on_stackoverflow;

extern bool crash_kexec_post_notifiers;






extern atomic_t panic_cpu;






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_arch_panic_timeout(int timeout, int arch_default_timeout)
{
 if (panic_timeout == arch_default_timeout)
  panic_timeout = timeout;
}
extern const char *print_tainted(void);
enum lockdep_ok {
 LOCKDEP_STILL_OK,
 LOCKDEP_NOW_UNRELIABLE
};
extern void add_taint(unsigned flag, enum lockdep_ok);
extern int test_taint(unsigned flag);
extern unsigned long get_taint(void);
extern int root_mountflags;

extern bool early_boot_irqs_disabled;





extern enum system_states {
 SYSTEM_BOOTING,
 SYSTEM_SCHEDULING,
 SYSTEM_RUNNING,
 SYSTEM_HALT,
 SYSTEM_POWER_OFF,
 SYSTEM_RESTART,
 SYSTEM_SUSPEND,
} system_state;
# 449 "/home/nathan/src/linux/include/linux/kernel.h"
struct taint_flag {
 char c_true;
 char c_false;
 bool module;
};

extern const struct taint_flag taint_flags[18];

extern const char hex_asc[];



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) char *hex_byte_pack(char *buf, u8 byte)
{
 *buf++ = hex_asc[((byte) & 0xf0) >> 4];
 *buf++ = hex_asc[((byte) & 0x0f)];
 return buf;
}

extern const char hex_asc_upper[];



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) char *hex_byte_pack_upper(char *buf, u8 byte)
{
 *buf++ = hex_asc_upper[((byte) & 0xf0) >> 4];
 *buf++ = hex_asc_upper[((byte) & 0x0f)];
 return buf;
}

extern int hex_to_bin(char ch);
extern int __attribute__((__warn_unused_result__)) hex2bin(u8 *dst, const char *src, size_t count);
extern char *bin2hex(char *dst, const void *src, size_t count);

bool mac_pton(const char *s, u8 *mac);
# 505 "/home/nathan/src/linux/include/linux/kernel.h"
enum ftrace_dump_mode {
 DUMP_NONE,
 DUMP_ALL,
 DUMP_ORIG,
};
# 655 "/home/nathan/src/linux/include/linux/kernel.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tracing_start(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tracing_stop(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void trace_dump_stack(int skip) { }

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tracing_on(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tracing_off(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int tracing_is_on(void) { return 0; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tracing_snapshot(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void tracing_snapshot_alloc(void) { }

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__format__(printf, 1, 2)))
int trace_printk(const char *fmt, ...)
{
 return 0;
}
static __attribute__((__format__(printf, 1, 0))) inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int
ftrace_vprintk(const char *fmt, va_list ap)
{
 return 0;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ftrace_dump(enum ftrace_dump_mode oops_dump_mode) { }
# 10 "/home/nathan/src/linux/arch/mips/kernel/reset.c" 2

# 1 "/home/nathan/src/linux/include/linux/pm.h" 1
# 11 "/home/nathan/src/linux/include/linux/pm.h"
# 1 "/home/nathan/src/linux/include/linux/list.h" 1






# 1 "/home/nathan/src/linux/include/linux/poison.h" 1
# 8 "/home/nathan/src/linux/include/linux/list.h" 2
# 33 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void INIT_LIST_HEAD(struct list_head *list)
{
 do { do { extern void __compiletime_assert_0(void) ; if (!((sizeof(list->next) == sizeof(char) || sizeof(list->next) == sizeof(short) || sizeof(list->next) == sizeof(int) || sizeof(list->next) == sizeof(long)) || sizeof(list->next) == sizeof(long long))) __compiletime_assert_0(); } while (0); do { *(volatile typeof(list->next) *)&(list->next) = (list); } while (0); } while (0);
 list->prev = list;
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __list_add_valid(struct list_head *new,
    struct list_head *prev,
    struct list_head *next)
{
 return true;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __list_del_entry_valid(struct list_head *entry)
{
 return true;
}
# 63 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __list_add(struct list_head *new,
         struct list_head *prev,
         struct list_head *next)
{
 if (!__list_add_valid(new, prev, next))
  return;

 next->prev = new;
 new->next = next;
 new->prev = prev;
 do { do { extern void __compiletime_assert_1(void) ; if (!((sizeof(prev->next) == sizeof(char) || sizeof(prev->next) == sizeof(short) || sizeof(prev->next) == sizeof(int) || sizeof(prev->next) == sizeof(long)) || sizeof(prev->next) == sizeof(long long))) __compiletime_assert_1(); } while (0); do { *(volatile typeof(prev->next) *)&(prev->next) = (new); } while (0); } while (0);
}
# 84 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_add(struct list_head *new, struct list_head *head)
{
 __list_add(new, head, head->next);
}
# 98 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_add_tail(struct list_head *new, struct list_head *head)
{
 __list_add(new, head->prev, head);
}
# 110 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __list_del(struct list_head * prev, struct list_head * next)
{
 next->prev = prev;
 do { do { extern void __compiletime_assert_2(void) ; if (!((sizeof(prev->next) == sizeof(char) || sizeof(prev->next) == sizeof(short) || sizeof(prev->next) == sizeof(int) || sizeof(prev->next) == sizeof(long)) || sizeof(prev->next) == sizeof(long long))) __compiletime_assert_2(); } while (0); do { *(volatile typeof(prev->next) *)&(prev->next) = (next); } while (0); } while (0);
}
# 124 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __list_del_clearprev(struct list_head *entry)
{
 __list_del(entry->prev, entry->next);
 entry->prev = ((void *)0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __list_del_entry(struct list_head *entry)
{
 if (!__list_del_entry_valid(entry))
  return;

 __list_del(entry->prev, entry->next);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_del(struct list_head *entry)
{
 __list_del_entry(entry);
 entry->next = ((void *) 0x100 + 0);
 entry->prev = ((void *) 0x122 + 0);
}
# 158 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_replace(struct list_head *old,
    struct list_head *new)
{
 new->next = old->next;
 new->next->prev = new;
 new->prev = old->prev;
 new->prev->next = new;
}
# 174 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_replace_init(struct list_head *old,
         struct list_head *new)
{
 list_replace(old, new);
 INIT_LIST_HEAD(old);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_swap(struct list_head *entry1,
        struct list_head *entry2)
{
 struct list_head *pos = entry2->prev;

 list_del(entry2);
 list_replace(entry1, entry2);
 if (pos == entry1)
  pos = entry2;
 list_add(entry1, pos);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_del_init(struct list_head *entry)
{
 __list_del_entry(entry);
 INIT_LIST_HEAD(entry);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_move(struct list_head *list, struct list_head *head)
{
 __list_del_entry(list);
 list_add(list, head);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_move_tail(struct list_head *list,
      struct list_head *head)
{
 __list_del_entry(list);
 list_add_tail(list, head);
}
# 240 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_bulk_move_tail(struct list_head *head,
           struct list_head *first,
           struct list_head *last)
{
 first->prev->next = last->next;
 last->next->prev = first->prev;

 head->prev->next = first;
 first->prev = head->prev;

 last->next = head;
 head->prev = last;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int list_is_first(const struct list_head *list,
     const struct list_head *head)
{
 return list->prev == head;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int list_is_last(const struct list_head *list,
    const struct list_head *head)
{
 return list->next == head;
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int list_empty(const struct list_head *head)
{
 return ({ do { extern void __compiletime_assert_3(void) ; if (!((sizeof(head->next) == sizeof(char) || sizeof(head->next) == sizeof(short) || sizeof(head->next) == sizeof(int) || sizeof(head->next) == sizeof(long)) || sizeof(head->next) == sizeof(long long))) __compiletime_assert_3(); } while (0); (*(const volatile typeof( _Generic((head->next), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (head->next))) *)&(head->next)); }) == head;
}
# 296 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_del_init_careful(struct list_head *entry)
{
 __list_del_entry(entry);
 entry->prev = entry;
 do { do { extern void __compiletime_assert_4(void) ; if (!((sizeof(*&entry->next) == sizeof(char) || sizeof(*&entry->next) == sizeof(short) || sizeof(*&entry->next) == sizeof(int) || sizeof(*&entry->next) == sizeof(long)))) __compiletime_assert_4(); } while (0); __sync(); do { do { extern void __compiletime_assert_5(void) ; if (!((sizeof(*&entry->next) == sizeof(char) || sizeof(*&entry->next) == sizeof(short) || sizeof(*&entry->next) == sizeof(int) || sizeof(*&entry->next) == sizeof(long)) || sizeof(*&entry->next) == sizeof(long long))) __compiletime_assert_5(); } while (0); do { *(volatile typeof(*&entry->next) *)&(*&entry->next) = (entry); } while (0); } while (0); } while (0);
}
# 316 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int list_empty_careful(const struct list_head *head)
{
 struct list_head *next = ({ typeof( _Generic((*&head->next), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*&head->next))) ___p1 = ({ do { extern void __compiletime_assert_6(void) ; if (!((sizeof(*&head->next) == sizeof(char) || sizeof(*&head->next) == sizeof(short) || sizeof(*&head->next) == sizeof(int) || sizeof(*&head->next) == sizeof(long)) || sizeof(*&head->next) == sizeof(long long))) __compiletime_assert_6(); } while (0); (*(const volatile typeof( _Generic((*&head->next), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*&head->next))) *)&(*&head->next)); }); do { extern void __compiletime_assert_7(void) ; if (!((sizeof(*&head->next) == sizeof(char) || sizeof(*&head->next) == sizeof(short) || sizeof(*&head->next) == sizeof(int) || sizeof(*&head->next) == sizeof(long)))) __compiletime_assert_7(); } while (0); __sync(); (typeof(*&head->next))___p1; });
 return (next == head) && (next == head->prev);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_rotate_left(struct list_head *head)
{
 struct list_head *first;

 if (!list_empty(head)) {
  first = head->next;
  list_move_tail(first, head);
 }
}
# 343 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_rotate_to_front(struct list_head *list,
     struct list_head *head)
{





 list_move_tail(head, list);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int list_is_singular(const struct list_head *head)
{
 return !list_empty(head) && (head->next == head->prev);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __list_cut_position(struct list_head *list,
  struct list_head *head, struct list_head *entry)
{
 struct list_head *new_first = entry->next;
 list->next = head->next;
 list->next->prev = list;
 list->prev = entry;
 entry->next = list;
 head->next = new_first;
 new_first->prev = head;
}
# 389 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_cut_position(struct list_head *list,
  struct list_head *head, struct list_head *entry)
{
 if (list_empty(head))
  return;
 if (list_is_singular(head) &&
  (head->next != entry && head != entry))
  return;
 if (entry == head)
  INIT_LIST_HEAD(list);
 else
  __list_cut_position(list, head, entry);
}
# 417 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_cut_before(struct list_head *list,
       struct list_head *head,
       struct list_head *entry)
{
 if (head->next == entry) {
  INIT_LIST_HEAD(list);
  return;
 }
 list->next = head->next;
 list->next->prev = list;
 list->prev = entry->prev;
 list->prev->next = list;
 head->next = entry;
 entry->prev = head;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __list_splice(const struct list_head *list,
     struct list_head *prev,
     struct list_head *next)
{
 struct list_head *first = list->next;
 struct list_head *last = list->prev;

 first->prev = prev;
 prev->next = first;

 last->next = next;
 next->prev = last;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_splice(const struct list_head *list,
    struct list_head *head)
{
 if (!list_empty(list))
  __list_splice(list, head, head->next);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_splice_tail(struct list_head *list,
    struct list_head *head)
{
 if (!list_empty(list))
  __list_splice(list, head->prev, head);
}
# 478 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_splice_init(struct list_head *list,
        struct list_head *head)
{
 if (!list_empty(list)) {
  __list_splice(list, head, head->next);
  INIT_LIST_HEAD(list);
 }
}
# 495 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void list_splice_tail_init(struct list_head *list,
      struct list_head *head)
{
 if (!list_empty(list)) {
  __list_splice(list, head->prev, head);
  INIT_LIST_HEAD(list);
 }
}
# 792 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void INIT_HLIST_NODE(struct hlist_node *h)
{
 h->next = ((void *)0);
 h->pprev = ((void *)0);
}
# 806 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int hlist_unhashed(const struct hlist_node *h)
{
 return !h->pprev;
}
# 819 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int hlist_unhashed_lockless(const struct hlist_node *h)
{
 return !({ do { extern void __compiletime_assert_8(void) ; if (!((sizeof(h->pprev) == sizeof(char) || sizeof(h->pprev) == sizeof(short) || sizeof(h->pprev) == sizeof(int) || sizeof(h->pprev) == sizeof(long)) || sizeof(h->pprev) == sizeof(long long))) __compiletime_assert_8(); } while (0); (*(const volatile typeof( _Generic((h->pprev), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (h->pprev))) *)&(h->pprev)); });
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int hlist_empty(const struct hlist_head *h)
{
 return !({ do { extern void __compiletime_assert_9(void) ; if (!((sizeof(h->first) == sizeof(char) || sizeof(h->first) == sizeof(short) || sizeof(h->first) == sizeof(int) || sizeof(h->first) == sizeof(long)) || sizeof(h->first) == sizeof(long long))) __compiletime_assert_9(); } while (0); (*(const volatile typeof( _Generic((h->first), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (h->first))) *)&(h->first)); });
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __hlist_del(struct hlist_node *n)
{
 struct hlist_node *next = n->next;
 struct hlist_node **pprev = n->pprev;

 do { do { extern void __compiletime_assert_10(void) ; if (!((sizeof(*pprev) == sizeof(char) || sizeof(*pprev) == sizeof(short) || sizeof(*pprev) == sizeof(int) || sizeof(*pprev) == sizeof(long)) || sizeof(*pprev) == sizeof(long long))) __compiletime_assert_10(); } while (0); do { *(volatile typeof(*pprev) *)&(*pprev) = (next); } while (0); } while (0);
 if (next)
  do { do { extern void __compiletime_assert_11(void) ; if (!((sizeof(next->pprev) == sizeof(char) || sizeof(next->pprev) == sizeof(short) || sizeof(next->pprev) == sizeof(int) || sizeof(next->pprev) == sizeof(long)) || sizeof(next->pprev) == sizeof(long long))) __compiletime_assert_11(); } while (0); do { *(volatile typeof(next->pprev) *)&(next->pprev) = (pprev); } while (0); } while (0);
}
# 850 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_del(struct hlist_node *n)
{
 __hlist_del(n);
 n->next = ((void *) 0x100 + 0);
 n->pprev = ((void *) 0x122 + 0);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_del_init(struct hlist_node *n)
{
 if (!hlist_unhashed(n)) {
  __hlist_del(n);
  INIT_HLIST_NODE(n);
 }
}
# 879 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_add_head(struct hlist_node *n, struct hlist_head *h)
{
 struct hlist_node *first = h->first;
 do { do { extern void __compiletime_assert_12(void) ; if (!((sizeof(n->next) == sizeof(char) || sizeof(n->next) == sizeof(short) || sizeof(n->next) == sizeof(int) || sizeof(n->next) == sizeof(long)) || sizeof(n->next) == sizeof(long long))) __compiletime_assert_12(); } while (0); do { *(volatile typeof(n->next) *)&(n->next) = (first); } while (0); } while (0);
 if (first)
  do { do { extern void __compiletime_assert_13(void) ; if (!((sizeof(first->pprev) == sizeof(char) || sizeof(first->pprev) == sizeof(short) || sizeof(first->pprev) == sizeof(int) || sizeof(first->pprev) == sizeof(long)) || sizeof(first->pprev) == sizeof(long long))) __compiletime_assert_13(); } while (0); do { *(volatile typeof(first->pprev) *)&(first->pprev) = (&n->next); } while (0); } while (0);
 do { do { extern void __compiletime_assert_14(void) ; if (!((sizeof(h->first) == sizeof(char) || sizeof(h->first) == sizeof(short) || sizeof(h->first) == sizeof(int) || sizeof(h->first) == sizeof(long)) || sizeof(h->first) == sizeof(long long))) __compiletime_assert_14(); } while (0); do { *(volatile typeof(h->first) *)&(h->first) = (n); } while (0); } while (0);
 do { do { extern void __compiletime_assert_15(void) ; if (!((sizeof(n->pprev) == sizeof(char) || sizeof(n->pprev) == sizeof(short) || sizeof(n->pprev) == sizeof(int) || sizeof(n->pprev) == sizeof(long)) || sizeof(n->pprev) == sizeof(long long))) __compiletime_assert_15(); } while (0); do { *(volatile typeof(n->pprev) *)&(n->pprev) = (&h->first); } while (0); } while (0);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_add_before(struct hlist_node *n,
        struct hlist_node *next)
{
 do { do { extern void __compiletime_assert_16(void) ; if (!((sizeof(n->pprev) == sizeof(char) || sizeof(n->pprev) == sizeof(short) || sizeof(n->pprev) == sizeof(int) || sizeof(n->pprev) == sizeof(long)) || sizeof(n->pprev) == sizeof(long long))) __compiletime_assert_16(); } while (0); do { *(volatile typeof(n->pprev) *)&(n->pprev) = (next->pprev); } while (0); } while (0);
 do { do { extern void __compiletime_assert_17(void) ; if (!((sizeof(n->next) == sizeof(char) || sizeof(n->next) == sizeof(short) || sizeof(n->next) == sizeof(int) || sizeof(n->next) == sizeof(long)) || sizeof(n->next) == sizeof(long long))) __compiletime_assert_17(); } while (0); do { *(volatile typeof(n->next) *)&(n->next) = (next); } while (0); } while (0);
 do { do { extern void __compiletime_assert_18(void) ; if (!((sizeof(next->pprev) == sizeof(char) || sizeof(next->pprev) == sizeof(short) || sizeof(next->pprev) == sizeof(int) || sizeof(next->pprev) == sizeof(long)) || sizeof(next->pprev) == sizeof(long long))) __compiletime_assert_18(); } while (0); do { *(volatile typeof(next->pprev) *)&(next->pprev) = (&n->next); } while (0); } while (0);
 do { do { extern void __compiletime_assert_19(void) ; if (!((sizeof(*(n->pprev)) == sizeof(char) || sizeof(*(n->pprev)) == sizeof(short) || sizeof(*(n->pprev)) == sizeof(int) || sizeof(*(n->pprev)) == sizeof(long)) || sizeof(*(n->pprev)) == sizeof(long long))) __compiletime_assert_19(); } while (0); do { *(volatile typeof(*(n->pprev)) *)&(*(n->pprev)) = (n); } while (0); } while (0);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_add_behind(struct hlist_node *n,
        struct hlist_node *prev)
{
 do { do { extern void __compiletime_assert_20(void) ; if (!((sizeof(n->next) == sizeof(char) || sizeof(n->next) == sizeof(short) || sizeof(n->next) == sizeof(int) || sizeof(n->next) == sizeof(long)) || sizeof(n->next) == sizeof(long long))) __compiletime_assert_20(); } while (0); do { *(volatile typeof(n->next) *)&(n->next) = (prev->next); } while (0); } while (0);
 do { do { extern void __compiletime_assert_21(void) ; if (!((sizeof(prev->next) == sizeof(char) || sizeof(prev->next) == sizeof(short) || sizeof(prev->next) == sizeof(int) || sizeof(prev->next) == sizeof(long)) || sizeof(prev->next) == sizeof(long long))) __compiletime_assert_21(); } while (0); do { *(volatile typeof(prev->next) *)&(prev->next) = (n); } while (0); } while (0);
 do { do { extern void __compiletime_assert_22(void) ; if (!((sizeof(n->pprev) == sizeof(char) || sizeof(n->pprev) == sizeof(short) || sizeof(n->pprev) == sizeof(int) || sizeof(n->pprev) == sizeof(long)) || sizeof(n->pprev) == sizeof(long long))) __compiletime_assert_22(); } while (0); do { *(volatile typeof(n->pprev) *)&(n->pprev) = (&prev->next); } while (0); } while (0);

 if (n->next)
  do { do { extern void __compiletime_assert_23(void) ; if (!((sizeof(n->next->pprev) == sizeof(char) || sizeof(n->next->pprev) == sizeof(short) || sizeof(n->next->pprev) == sizeof(int) || sizeof(n->next->pprev) == sizeof(long)) || sizeof(n->next->pprev) == sizeof(long long))) __compiletime_assert_23(); } while (0); do { *(volatile typeof(n->next->pprev) *)&(n->next->pprev) = (&n->next); } while (0); } while (0);
}
# 927 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_add_fake(struct hlist_node *n)
{
 n->pprev = &n->next;
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool hlist_fake(struct hlist_node *h)
{
 return h->pprev == &h->next;
}
# 949 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool
hlist_is_singular_node(struct hlist_node *n, struct hlist_head *h)
{
 return !n->next && n->pprev == &h->first;
}
# 963 "/home/nathan/src/linux/include/linux/list.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hlist_move_list(struct hlist_head *old,
       struct hlist_head *new)
{
 new->first = old->first;
 if (new->first)
  new->first->pprev = &new->first;
 old->first = ((void *)0);
}
# 12 "/home/nathan/src/linux/include/linux/pm.h" 2
# 1 "/home/nathan/src/linux/include/linux/workqueue.h" 1








# 1 "/home/nathan/src/linux/include/linux/timer.h" 1





# 1 "/home/nathan/src/linux/include/linux/ktime.h" 1
# 24 "/home/nathan/src/linux/include/linux/ktime.h"
# 1 "/home/nathan/src/linux/include/linux/time.h" 1





# 1 "/home/nathan/src/linux/include/linux/math64.h" 1





# 1 "/home/nathan/src/linux/include/vdso/math64.h" 1




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) u32
__iter_div_u64_rem(u64 dividend, u32 divisor, u64 *remainder)
{
 u32 ret = 0;

 while (dividend >= divisor) {


  asm("" : "+rm"(dividend));

  dividend -= divisor;
  ret++;
 }

 *remainder = dividend;

 return ret;
}
# 7 "/home/nathan/src/linux/include/linux/math64.h" 2
# 89 "/home/nathan/src/linux/include/linux/math64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)
{
 *remainder = ({ uint32_t __base = (divisor); uint32_t __rem; (void)(((typeof((dividend)) *)0) == ((uint64_t *)0)); if (__builtin_constant_p(__base) && is_power_of_2(__base)) { __rem = (dividend) & (__base - 1); (dividend) >>= ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); } else if ((4 >= 4) && __builtin_constant_p(__base) && __base != 0) { uint32_t __res_lo, __n_lo = (dividend); (dividend) = ({ uint64_t ___res, ___x, ___t, ___m, ___n = (dividend); uint32_t ___p, ___bias; ___p = 1 << ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); ___m = (~0ULL / __base) * ___p; ___m += (((~0ULL % __base + 1) * ___p) + __base - 1) / __base; ___x = ~0ULL / __base * __base - 1; ___res = ((___m & 0xffffffff) * (___x & 0xffffffff)) >> 32; ___t = ___res += (___m & 0xffffffff) * (___x >> 32); ___res += (___x & 0xffffffff) * (___m >> 32); ___t = (___res < ___t) ? (1ULL << 32) : 0; ___res = (___res >> 32) + ___t; ___res += (___m >> 32) * (___x >> 32); ___res /= ___p; if (~0ULL % (__base / (__base & -__base)) == 0) { ___n /= (__base & -__base); ___m = ~0ULL / (__base / (__base & -__base)); ___p = 1; ___bias = 1; } else if (___res != ___x / __base) { ___bias = 1; ___m = (~0ULL / __base) * ___p; ___m += ((~0ULL % __base + 1) * ___p) / __base; } else { uint32_t ___bits = -(___m & -___m); ___bits |= ___m >> 32; ___bits = (~___bits) << 1; if (!___bits) { ___p /= (___m & -___m); ___m /= (___m & -___m); } else { ___p >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); ___m >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); } ___bias = 0; } ___res = __arch_xprod_64(___m, ___n, ___bias); ___res /= ___p; }); __res_lo = (dividend); __rem = __n_lo - __res_lo * __base; } else if (__builtin_expect(!!(((dividend) >> 32) == 0), 1)) { __rem = (uint32_t)(dividend) % __base; (dividend) = (uint32_t)(dividend) / __base; } else __rem = __div64_32(&(dividend), __base); __rem; });
 return dividend;
}



extern s64 div_s64_rem(s64 dividend, s32 divisor, s32 *remainder);



extern u64 div64_u64_rem(u64 dividend, u64 divisor, u64 *remainder);



extern u64 div64_u64(u64 dividend, u64 divisor);



extern s64 div64_s64(s64 dividend, s64 divisor);
# 124 "/home/nathan/src/linux/include/linux/math64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 div_u64(u64 dividend, u32 divisor)
{
 u32 remainder;
 return div_u64_rem(dividend, divisor, &remainder);
}
# 137 "/home/nathan/src/linux/include/linux/math64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 div_s64(s64 dividend, s32 divisor)
{
 s32 remainder;
 return div_s64_rem(dividend, divisor, &remainder);
}


u32 iter_div_u64_rem(u64 dividend, u32 divisor, u64 *remainder);





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 mul_u32_u32(u32 a, u32 b)
{
 return (u64)a * b;
}
# 175 "/home/nathan/src/linux/include/linux/math64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 mul_u64_u32_shr(u64 a, u32 mul, unsigned int shift)
{
 u32 ah, al;
 u64 ret;

 al = a;
 ah = a >> 32;

 ret = mul_u32_u32(al, mul) >> shift;
 if (ah)
  ret += mul_u32_u32(ah, mul) << (32 - shift);

 return ret;
}



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 mul_u64_u64_shr(u64 a, u64 b, unsigned int shift)
{
 union {
  u64 ll;
  struct {

   u32 high, low;



  } l;
 } rl, rm, rn, rh, a0, b0;
 u64 c;

 a0.ll = a;
 b0.ll = b;

 rl.ll = mul_u32_u32(a0.l.low, b0.l.low);
 rm.ll = mul_u32_u32(a0.l.low, b0.l.high);
 rn.ll = mul_u32_u32(a0.l.high, b0.l.low);
 rh.ll = mul_u32_u32(a0.l.high, b0.l.high);






 rl.l.high = c = (u64)rl.l.high + rm.l.low + rn.l.low;
 rh.l.low = c = (c >> 32) + rm.l.high + rn.l.high + rh.l.low;
 rh.l.high = (c >> 32) + rh.l.high;





 if (shift == 0)
  return rl.ll;
 if (shift < 64)
  return (rl.ll >> shift) | (rh.ll << (64 - shift));
 return rh.ll >> (shift & 63);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 mul_u64_u32_div(u64 a, u32 mul, u32 divisor)
{
 union {
  u64 ll;
  struct {

   u32 high, low;



  } l;
 } u, rl, rh;

 u.ll = a;
 rl.ll = mul_u32_u32(u.l.low, mul);
 rh.ll = mul_u32_u32(u.l.high, mul) + rl.l.high;


 rl.l.high = ({ uint32_t __base = (divisor); uint32_t __rem; (void)(((typeof((rh.ll)) *)0) == ((uint64_t *)0)); if (__builtin_constant_p(__base) && is_power_of_2(__base)) { __rem = (rh.ll) & (__base - 1); (rh.ll) >>= ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); } else if ((4 >= 4) && __builtin_constant_p(__base) && __base != 0) { uint32_t __res_lo, __n_lo = (rh.ll); (rh.ll) = ({ uint64_t ___res, ___x, ___t, ___m, ___n = (rh.ll); uint32_t ___p, ___bias; ___p = 1 << ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); ___m = (~0ULL / __base) * ___p; ___m += (((~0ULL % __base + 1) * ___p) + __base - 1) / __base; ___x = ~0ULL / __base * __base - 1; ___res = ((___m & 0xffffffff) * (___x & 0xffffffff)) >> 32; ___t = ___res += (___m & 0xffffffff) * (___x >> 32); ___res += (___x & 0xffffffff) * (___m >> 32); ___t = (___res < ___t) ? (1ULL << 32) : 0; ___res = (___res >> 32) + ___t; ___res += (___m >> 32) * (___x >> 32); ___res /= ___p; if (~0ULL % (__base / (__base & -__base)) == 0) { ___n /= (__base & -__base); ___m = ~0ULL / (__base / (__base & -__base)); ___p = 1; ___bias = 1; } else if (___res != ___x / __base) { ___bias = 1; ___m = (~0ULL / __base) * ___p; ___m += ((~0ULL % __base + 1) * ___p) / __base; } else { uint32_t ___bits = -(___m & -___m); ___bits |= ___m >> 32; ___bits = (~___bits) << 1; if (!___bits) { ___p /= (___m & -___m); ___m /= (___m & -___m); } else { ___p >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); ___m >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); } ___bias = 0; } ___res = __arch_xprod_64(___m, ___n, ___bias); ___res /= ___p; }); __res_lo = (rh.ll); __rem = __n_lo - __res_lo * __base; } else if (__builtin_expect(!!(((rh.ll) >> 32) == 0), 1)) { __rem = (uint32_t)(rh.ll) % __base; (rh.ll) = (uint32_t)(rh.ll) / __base; } else __rem = __div64_32(&(rh.ll), __base); __rem; });


 ({ uint32_t __base = (divisor); uint32_t __rem; (void)(((typeof((rl.ll)) *)0) == ((uint64_t *)0)); if (__builtin_constant_p(__base) && is_power_of_2(__base)) { __rem = (rl.ll) & (__base - 1); (rl.ll) >>= ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); } else if ((4 >= 4) && __builtin_constant_p(__base) && __base != 0) { uint32_t __res_lo, __n_lo = (rl.ll); (rl.ll) = ({ uint64_t ___res, ___x, ___t, ___m, ___n = (rl.ll); uint32_t ___p, ___bias; ___p = 1 << ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); ___m = (~0ULL / __base) * ___p; ___m += (((~0ULL % __base + 1) * ___p) + __base - 1) / __base; ___x = ~0ULL / __base * __base - 1; ___res = ((___m & 0xffffffff) * (___x & 0xffffffff)) >> 32; ___t = ___res += (___m & 0xffffffff) * (___x >> 32); ___res += (___x & 0xffffffff) * (___m >> 32); ___t = (___res < ___t) ? (1ULL << 32) : 0; ___res = (___res >> 32) + ___t; ___res += (___m >> 32) * (___x >> 32); ___res /= ___p; if (~0ULL % (__base / (__base & -__base)) == 0) { ___n /= (__base & -__base); ___m = ~0ULL / (__base / (__base & -__base)); ___p = 1; ___bias = 1; } else if (___res != ___x / __base) { ___bias = 1; ___m = (~0ULL / __base) * ___p; ___m += ((~0ULL % __base + 1) * ___p) / __base; } else { uint32_t ___bits = -(___m & -___m); ___bits |= ___m >> 32; ___bits = (~___bits) << 1; if (!___bits) { ___p /= (___m & -___m); ___m /= (___m & -___m); } else { ___p >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); ___m >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); } ___bias = 0; } ___res = __arch_xprod_64(___m, ___n, ___bias); ___res /= ___p; }); __res_lo = (rl.ll); __rem = __n_lo - __res_lo * __base; } else if (__builtin_expect(!!(((rl.ll) >> 32) == 0), 1)) { __rem = (uint32_t)(rl.ll) % __base; (rl.ll) = (uint32_t)(rl.ll) / __base; } else __rem = __div64_32(&(rl.ll), __base); __rem; });

 rl.l.high = rh.l.low;
 return rl.ll;
}


u64 mul_u64_u64_div_u64(u64 a, u64 mul, u64 div);
# 7 "/home/nathan/src/linux/include/linux/time.h" 2
# 1 "/home/nathan/src/linux/include/linux/time64.h" 1





# 1 "/home/nathan/src/linux/include/vdso/time64.h" 1
# 7 "/home/nathan/src/linux/include/linux/time64.h" 2

typedef __s64 time64_t;
typedef __u64 timeu64_t;


# 1 "/home/nathan/src/linux/include/uapi/linux/time.h" 1





# 1 "/home/nathan/src/linux/include/uapi/linux/time_types.h" 1






struct __kernel_timespec {
 __kernel_time64_t tv_sec;
 long long tv_nsec;
};

struct __kernel_itimerspec {
 struct __kernel_timespec it_interval;
 struct __kernel_timespec it_value;
};
# 25 "/home/nathan/src/linux/include/uapi/linux/time_types.h"
struct __kernel_old_timeval {
 __kernel_long_t tv_sec;
 __kernel_long_t tv_usec;
};


struct __kernel_old_timespec {
 __kernel_old_time_t tv_sec;
 long tv_nsec;
};

struct __kernel_old_itimerval {
 struct __kernel_old_timeval it_interval;
 struct __kernel_old_timeval it_value;
};

struct __kernel_sock_timeval {
 __s64 tv_sec;
 __s64 tv_usec;
};
# 7 "/home/nathan/src/linux/include/uapi/linux/time.h" 2
# 33 "/home/nathan/src/linux/include/uapi/linux/time.h"
struct timezone {
 int tz_minuteswest;
 int tz_dsttime;
};
# 12 "/home/nathan/src/linux/include/linux/time64.h" 2

struct timespec64 {
 time64_t tv_sec;
 long tv_nsec;
};

struct itimerspec64 {
 struct timespec64 it_interval;
 struct timespec64 it_value;
};
# 41 "/home/nathan/src/linux/include/linux/time64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int timespec64_equal(const struct timespec64 *a,
       const struct timespec64 *b)
{
 return (a->tv_sec == b->tv_sec) && (a->tv_nsec == b->tv_nsec);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int timespec64_compare(const struct timespec64 *lhs, const struct timespec64 *rhs)
{
 if (lhs->tv_sec < rhs->tv_sec)
  return -1;
 if (lhs->tv_sec > rhs->tv_sec)
  return 1;
 return lhs->tv_nsec - rhs->tv_nsec;
}

extern void set_normalized_timespec64(struct timespec64 *ts, time64_t sec, s64 nsec);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct timespec64 timespec64_add(struct timespec64 lhs,
      struct timespec64 rhs)
{
 struct timespec64 ts_delta;
 set_normalized_timespec64(&ts_delta, lhs.tv_sec + rhs.tv_sec,
    lhs.tv_nsec + rhs.tv_nsec);
 return ts_delta;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct timespec64 timespec64_sub(struct timespec64 lhs,
      struct timespec64 rhs)
{
 struct timespec64 ts_delta;
 set_normalized_timespec64(&ts_delta, lhs.tv_sec - rhs.tv_sec,
    lhs.tv_nsec - rhs.tv_nsec);
 return ts_delta;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool timespec64_valid(const struct timespec64 *ts)
{

 if (ts->tv_sec < 0)
  return false;

 if ((unsigned long)ts->tv_nsec >= 1000000000L)
  return false;
 return true;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool timespec64_valid_strict(const struct timespec64 *ts)
{
 if (!timespec64_valid(ts))
  return false;

 if ((unsigned long long)ts->tv_sec >= (((s64)~((u64)1 << 63)) / 1000000000L))
  return false;
 return true;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool timespec64_valid_settod(const struct timespec64 *ts)
{
 if (!timespec64_valid(ts))
  return false;

 if ((unsigned long long)ts->tv_sec >= ((((s64)~((u64)1 << 63)) / 1000000000L) - (30LL * 365 * 24 *3600)))
  return false;
 return true;
}
# 125 "/home/nathan/src/linux/include/linux/time64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 timespec64_to_ns(const struct timespec64 *ts)
{

 if ((unsigned long long)ts->tv_sec >= (((s64)~((u64)1 << 63)) / 1000000000L))
  return ((s64)~((u64)1 << 63));

 return ((s64) ts->tv_sec * 1000000000L) + ts->tv_nsec;
}







extern struct timespec64 ns_to_timespec64(const s64 nsec);
# 150 "/home/nathan/src/linux/include/linux/time64.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void timespec64_add_ns(struct timespec64 *a, u64 ns)
{
 a->tv_sec += __iter_div_u64_rem(a->tv_nsec + ns, 1000000000L, &ns);
 a->tv_nsec = ns;
}





extern struct timespec64 timespec64_add_safe(const struct timespec64 lhs,
      const struct timespec64 rhs);
# 8 "/home/nathan/src/linux/include/linux/time.h" 2

extern struct timezone sys_tz;

int get_timespec64(struct timespec64 *ts,
  const struct __kernel_timespec *uts);
int put_timespec64(const struct timespec64 *ts,
  struct __kernel_timespec *uts);
int get_itimerspec64(struct itimerspec64 *it,
   const struct __kernel_itimerspec *uit);
int put_itimerspec64(const struct itimerspec64 *it,
   struct __kernel_itimerspec *uit);

extern time64_t mktime64(const unsigned int year, const unsigned int mon,
   const unsigned int day, const unsigned int hour,
   const unsigned int min, const unsigned int sec);


extern void clear_itimer(void);




extern long do_utimes(int dfd, const char *filename, struct timespec64 *times, int flags);





struct tm {




 int tm_sec;

 int tm_min;

 int tm_hour;

 int tm_mday;

 int tm_mon;

 long tm_year;

 int tm_wday;

 int tm_yday;
};

void time64_to_tm(time64_t totalsecs, int offset, struct tm *result);


# 1 "/home/nathan/src/linux/include/linux/time32.h" 1
# 13 "/home/nathan/src/linux/include/linux/time32.h"
# 1 "/home/nathan/src/linux/include/linux/timex.h" 1
# 56 "/home/nathan/src/linux/include/linux/timex.h"
# 1 "/home/nathan/src/linux/include/uapi/linux/timex.h" 1
# 56 "/home/nathan/src/linux/include/uapi/linux/timex.h"
# 1 "/home/nathan/src/linux/include/linux/time.h" 1
# 57 "/home/nathan/src/linux/include/uapi/linux/timex.h" 2
# 97 "/home/nathan/src/linux/include/uapi/linux/timex.h"
struct __kernel_timex_timeval {
 __kernel_time64_t tv_sec;
 long long tv_usec;
};

struct __kernel_timex {
 unsigned int modes;
 int :32;
 long long offset;
 long long freq;
 long long maxerror;
 long long esterror;
 int status;
 int :32;
 long long constant;
 long long precision;
 long long tolerance;


 struct __kernel_timex_timeval time;
 long long tick;

 long long ppsfreq;
 long long jitter;
 int shift;
 int :32;
 long long stabil;
 long long jitcnt;
 long long calcnt;
 long long errcnt;
 long long stbcnt;

 int tai;

 int :32; int :32; int :32; int :32;
 int :32; int :32; int :32; int :32;
 int :32; int :32; int :32;
};
# 57 "/home/nathan/src/linux/include/linux/timex.h" 2








# 1 "/home/nathan/src/linux/arch/mips/include/asm/timex.h" 1
# 19 "/home/nathan/src/linux/arch/mips/include/asm/timex.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/cpu-type.h" 1
# 12 "/home/nathan/src/linux/arch/mips/include/asm/cpu-type.h"
# 1 "/home/nathan/src/linux/include/linux/smp.h" 1
# 10 "/home/nathan/src/linux/include/linux/smp.h"
# 1 "/home/nathan/src/linux/include/linux/errno.h" 1




# 1 "/home/nathan/src/linux/include/uapi/linux/errno.h" 1
# 1 "/home/nathan/src/linux/arch/mips/include/asm/errno.h" 1
# 11 "/home/nathan/src/linux/arch/mips/include/asm/errno.h"
# 1 "/home/nathan/src/linux/arch/mips/include/uapi/asm/errno.h" 1
# 16 "/home/nathan/src/linux/arch/mips/include/uapi/asm/errno.h"
# 1 "/home/nathan/src/linux/include/uapi/asm-generic/errno-base.h" 1
# 17 "/home/nathan/src/linux/arch/mips/include/uapi/asm/errno.h" 2
# 12 "/home/nathan/src/linux/arch/mips/include/asm/errno.h" 2
# 2 "/home/nathan/src/linux/include/uapi/linux/errno.h" 2
# 6 "/home/nathan/src/linux/include/linux/errno.h" 2
# 11 "/home/nathan/src/linux/include/linux/smp.h" 2


# 1 "/home/nathan/src/linux/include/linux/cpumask.h" 1
# 11 "/home/nathan/src/linux/include/linux/cpumask.h"
# 1 "/home/nathan/src/linux/include/linux/threads.h" 1
# 12 "/home/nathan/src/linux/include/linux/cpumask.h" 2
# 1 "/home/nathan/src/linux/include/linux/bitmap.h" 1








# 1 "/home/nathan/src/linux/include/linux/string.h" 1
# 11 "/home/nathan/src/linux/include/linux/string.h"
# 1 "/home/nathan/src/linux/include/uapi/linux/string.h" 1
# 12 "/home/nathan/src/linux/include/linux/string.h" 2

extern char *strndup_user(const char *, long);
extern void *memdup_user(const void *, size_t);
extern void *vmemdup_user(const void *, size_t);
extern void *memdup_user_nul(const void *, size_t);





# 1 "/home/nathan/src/linux/arch/mips/include/asm/string.h" 1
# 14 "/home/nathan/src/linux/arch/mips/include/asm/string.h"
extern void *memset(void *__s, int __c, size_t __count);


extern void *memcpy(void *__to, __const__ void *__from, size_t __n);


extern void *memmove(void *__dest, __const__ void *__src, size_t __n);
# 22 "/home/nathan/src/linux/include/linux/string.h" 2


extern char * strcpy(char *,const char *);


extern char * strncpy(char *,const char *, __kernel_size_t);


size_t strlcpy(char *, const char *, size_t);


ssize_t strscpy(char *, const char *, size_t);



ssize_t strscpy_pad(char *dest, const char *src, size_t count);


extern char * strcat(char *, const char *);


extern char * strncat(char *, const char *, __kernel_size_t);


extern size_t strlcat(char *, const char *, __kernel_size_t);


extern int strcmp(const char *,const char *);


extern int strncmp(const char *,const char *,__kernel_size_t);


extern int strcasecmp(const char *s1, const char *s2);


extern int strncasecmp(const char *s1, const char *s2, size_t n);


extern char * strchr(const char *,int);


extern char * strchrnul(const char *,int);

extern char * strnchrnul(const char *, size_t, int);

extern char * strnchr(const char *, size_t, int);


extern char * strrchr(const char *,int);

extern char * __attribute__((__warn_unused_result__)) skip_spaces(const char *);

extern char *strim(char *);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__warn_unused_result__)) char *strstrip(char *str)
{
 return strim(str);
}


extern char * strstr(const char *, const char *);


extern char * strnstr(const char *, const char *, size_t);


extern __kernel_size_t strlen(const char *);


extern __kernel_size_t strnlen(const char *,__kernel_size_t);


extern char * strpbrk(const char *,const char *);


extern char * strsep(char **,const char *);


extern __kernel_size_t strspn(const char *,const char *);


extern __kernel_size_t strcspn(const char *,const char *);







extern void *memset16(uint16_t *, uint16_t, __kernel_size_t);



extern void *memset32(uint32_t *, uint32_t, __kernel_size_t);



extern void *memset64(uint64_t *, uint64_t, __kernel_size_t);


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *memset_l(unsigned long *p, unsigned long v,
  __kernel_size_t n)
{
 if (32 == 32)
  return memset32((uint32_t *)p, v, n);
 else
  return memset64((uint64_t *)p, v, n);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *memset_p(void **p, void *v, __kernel_size_t n)
{
 if (32 == 32)
  return memset32((uint32_t *)p, (uintptr_t)v, n);
 else
  return memset64((uint64_t *)p, (uintptr_t)v, n);
}

extern void **__memcat_p(void **a, void **b);
# 154 "/home/nathan/src/linux/include/linux/string.h"
extern void * memscan(void *,int,__kernel_size_t);


extern int memcmp(const void *,const void *,__kernel_size_t);


extern int bcmp(const void *,const void *,__kernel_size_t);


extern void * memchr(const void *,int,__kernel_size_t);


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void memcpy_flushcache(void *dst, const void *src, size_t cnt)
{
 memcpy(dst, src, cnt);
}


void *memchr_inv(const void *s, int c, size_t n);
char *strreplace(char *s, char old, char new);

extern void kfree_const(const void *x);

extern char *kstrdup(const char *s, gfp_t gfp) __attribute__((__malloc__));
extern const char *kstrdup_const(const char *s, gfp_t gfp);
extern char *kstrndup(const char *s, size_t len, gfp_t gfp);
extern void *kmemdup(const void *src, size_t len, gfp_t gfp);
extern char *kmemdup_nul(const char *s, size_t len, gfp_t gfp);

extern char **argv_split(gfp_t gfp, const char *str, int *argcp);
extern void argv_free(char **argv);

extern bool sysfs_streq(const char *s1, const char *s2);
extern int kstrtobool(const char *s, bool *res);
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int strtobool(const char *s, bool *res)
{
 return kstrtobool(s, res);
}

int match_string(const char * const *array, size_t n, const char *string);
int __sysfs_match_string(const char * const *array, size_t n, const char *s);
# 211 "/home/nathan/src/linux/include/linux/string.h"
extern ssize_t memory_read_from_buffer(void *to, size_t count, loff_t *ppos,
           const void *from, size_t available);

int ptr_to_hashval(const void *ptr, unsigned long *hashval_out);






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool strstarts(const char *str, const char *prefix)
{
 return strncmp(str, prefix, strlen(prefix)) == 0;
}

size_t memweight(const void *ptr, size_t bytes);
# 242 "/home/nathan/src/linux/include/linux/string.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void memzero_explicit(void *s, size_t count)
{
 memset(s, 0, count);
 __asm__ __volatile__("": :"r"(s) :"memory");
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) const char *kbasename(const char *path)
{
 const char *tail = strrchr(path, '/');
 return tail ? tail + 1 : path;
}




void fortify_panic(const char *name) __attribute__((__noreturn__)) __attribute__((__cold__));
void __read_overflow(void) ;
void __read_overflow2(void) ;
void __read_overflow3(void) ;
void __write_overflow(void) ;
# 560 "/home/nathan/src/linux/include/linux/string.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void memcpy_and_pad(void *dest, size_t dest_len,
      const void *src, size_t count, int pad)
{
 if (dest_len > count) {
  memcpy(dest, src, count);
  memset(dest + count, pad, dest_len - count);
 } else
  memcpy(dest, src, dest_len);
}
# 585 "/home/nathan/src/linux/include/linux/string.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) size_t str_has_prefix(const char *str, const char *prefix)
{
 size_t len = strlen(prefix);
 return strncmp(str, prefix, len) == 0 ? len : 0;
}
# 10 "/home/nathan/src/linux/include/linux/bitmap.h" 2
# 121 "/home/nathan/src/linux/include/linux/bitmap.h"
extern unsigned long *bitmap_alloc(unsigned int nbits, gfp_t flags);
extern unsigned long *bitmap_zalloc(unsigned int nbits, gfp_t flags);
extern void bitmap_free(const unsigned long *bitmap);





extern int __bitmap_equal(const unsigned long *bitmap1,
     const unsigned long *bitmap2, unsigned int nbits);
extern bool __attribute__((__pure__)) __bitmap_or_equal(const unsigned long *src1,
         const unsigned long *src2,
         const unsigned long *src3,
         unsigned int nbits);
extern void __bitmap_complement(unsigned long *dst, const unsigned long *src,
   unsigned int nbits);
extern void __bitmap_shift_right(unsigned long *dst, const unsigned long *src,
    unsigned int shift, unsigned int nbits);
extern void __bitmap_shift_left(unsigned long *dst, const unsigned long *src,
    unsigned int shift, unsigned int nbits);
extern void bitmap_cut(unsigned long *dst, const unsigned long *src,
         unsigned int first, unsigned int cut,
         unsigned int nbits);
extern int __bitmap_and(unsigned long *dst, const unsigned long *bitmap1,
   const unsigned long *bitmap2, unsigned int nbits);
extern void __bitmap_or(unsigned long *dst, const unsigned long *bitmap1,
   const unsigned long *bitmap2, unsigned int nbits);
extern void __bitmap_xor(unsigned long *dst, const unsigned long *bitmap1,
   const unsigned long *bitmap2, unsigned int nbits);
extern int __bitmap_andnot(unsigned long *dst, const unsigned long *bitmap1,
   const unsigned long *bitmap2, unsigned int nbits);
extern void __bitmap_replace(unsigned long *dst,
   const unsigned long *old, const unsigned long *new,
   const unsigned long *mask, unsigned int nbits);
extern int __bitmap_intersects(const unsigned long *bitmap1,
   const unsigned long *bitmap2, unsigned int nbits);
extern int __bitmap_subset(const unsigned long *bitmap1,
   const unsigned long *bitmap2, unsigned int nbits);
extern int __bitmap_weight(const unsigned long *bitmap, unsigned int nbits);
extern void __bitmap_set(unsigned long *map, unsigned int start, int len);
extern void __bitmap_clear(unsigned long *map, unsigned int start, int len);

extern unsigned long bitmap_find_next_zero_area_off(unsigned long *map,
          unsigned long size,
          unsigned long start,
          unsigned int nr,
          unsigned long align_mask,
          unsigned long align_offset);
# 182 "/home/nathan/src/linux/include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long
bitmap_find_next_zero_area(unsigned long *map,
      unsigned long size,
      unsigned long start,
      unsigned int nr,
      unsigned long align_mask)
{
 return bitmap_find_next_zero_area_off(map, size, start, nr,
           align_mask, 0);
}

extern int bitmap_parse(const char *buf, unsigned int buflen,
   unsigned long *dst, int nbits);
extern int bitmap_parse_user(const char *ubuf, unsigned int ulen,
   unsigned long *dst, int nbits);
extern int bitmap_parselist(const char *buf, unsigned long *maskp,
   int nmaskbits);
extern int bitmap_parselist_user(const char *ubuf, unsigned int ulen,
   unsigned long *dst, int nbits);
extern void bitmap_remap(unsigned long *dst, const unsigned long *src,
  const unsigned long *old, const unsigned long *new, unsigned int nbits);
extern int bitmap_bitremap(int oldbit,
  const unsigned long *old, const unsigned long *new, int bits);
extern void bitmap_onto(unsigned long *dst, const unsigned long *orig,
  const unsigned long *relmap, unsigned int bits);
extern void bitmap_fold(unsigned long *dst, const unsigned long *orig,
  unsigned int sz, unsigned int nbits);
extern int bitmap_find_free_region(unsigned long *bitmap, unsigned int bits, int order);
extern void bitmap_release_region(unsigned long *bitmap, unsigned int pos, int order);
extern int bitmap_allocate_region(unsigned long *bitmap, unsigned int pos, int order);


extern void bitmap_copy_le(unsigned long *dst, const unsigned long *src, unsigned int nbits);



extern unsigned int bitmap_ord_to_pos(const unsigned long *bitmap, unsigned int ord, unsigned int nbits);
extern int bitmap_print_to_pagebuf(bool list, char *buf,
       const unsigned long *maskp, int nmaskbits);
# 233 "/home/nathan/src/linux/include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_zero(unsigned long *dst, unsigned int nbits)
{
 unsigned int len = (((nbits) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8))) * sizeof(unsigned long);
 memset(dst, 0, len);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_fill(unsigned long *dst, unsigned int nbits)
{
 unsigned int len = (((nbits) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8))) * sizeof(unsigned long);
 memset(dst, 0xff, len);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_copy(unsigned long *dst, const unsigned long *src,
   unsigned int nbits)
{
 unsigned int len = (((nbits) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8))) * sizeof(unsigned long);
 memcpy(dst, src, len);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_copy_clear_tail(unsigned long *dst,
  const unsigned long *src, unsigned int nbits)
{
 bitmap_copy(dst, src, nbits);
 if (nbits % 32)
  dst[nbits / 32] &= (~0UL >> (-(nbits) & (32 - 1)));
}
# 281 "/home/nathan/src/linux/include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int bitmap_and(unsigned long *dst, const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return (*dst = *src1 & *src2 & (~0UL >> (-(nbits) & (32 - 1)))) != 0;
 return __bitmap_and(dst, src1, src2, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_or(unsigned long *dst, const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  *dst = *src1 | *src2;
 else
  __bitmap_or(dst, src1, src2, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_xor(unsigned long *dst, const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  *dst = *src1 ^ *src2;
 else
  __bitmap_xor(dst, src1, src2, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int bitmap_andnot(unsigned long *dst, const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return (*dst = *src1 & ~(*src2) & (~0UL >> (-(nbits) & (32 - 1)))) != 0;
 return __bitmap_andnot(dst, src1, src2, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_complement(unsigned long *dst, const unsigned long *src,
   unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  *dst = ~(*src);
 else
  __bitmap_complement(dst, src, nbits);
}
# 331 "/home/nathan/src/linux/include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int bitmap_equal(const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return !((*src1 ^ *src2) & (~0UL >> (-(nbits) & (32 - 1))));
 if (__builtin_constant_p(nbits & ((8 * sizeof(unsigned long)) - 1)) &&
     (((nbits) & ((typeof(nbits))((8 * sizeof(unsigned long))) - 1)) == 0))
  return !memcmp(src1, src2, nbits / 8);
 return __bitmap_equal(src1, src2, nbits);
}
# 351 "/home/nathan/src/linux/include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool bitmap_or_equal(const unsigned long *src1,
       const unsigned long *src2,
       const unsigned long *src3,
       unsigned int nbits)
{
 if (!(__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return __bitmap_or_equal(src1, src2, src3, nbits);

 return !(((*src1 | *src2) ^ *src3) & (~0UL >> (-(nbits) & (32 - 1))));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int bitmap_intersects(const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return ((*src1 & *src2) & (~0UL >> (-(nbits) & (32 - 1)))) != 0;
 else
  return __bitmap_intersects(src1, src2, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int bitmap_subset(const unsigned long *src1,
   const unsigned long *src2, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return ! ((*src1 & ~(*src2)) & (~0UL >> (-(nbits) & (32 - 1))));
 else
  return __bitmap_subset(src1, src2, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool bitmap_empty(const unsigned long *src, unsigned nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return ! (*src & (~0UL >> (-(nbits) & (32 - 1))));

 return find_next_bit((src), (nbits), 0) == nbits;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool bitmap_full(const unsigned long *src, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return ! (~(*src) & (~0UL >> (-(nbits) & (32 - 1))));

 return find_next_zero_bit((src), (nbits), 0) == nbits;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int bitmap_weight(const unsigned long *src, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  return hweight_long(*src & (~0UL >> (-(nbits) & (32 - 1))));
 return __bitmap_weight(src, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void bitmap_set(unsigned long *map, unsigned int start,
  unsigned int nbits)
{
 if (__builtin_constant_p(nbits) && nbits == 1)
  __set_bit(start, map);
 else if (__builtin_constant_p(start & ((8 * sizeof(unsigned long)) - 1)) &&
   (((start) & ((typeof(start))((8 * sizeof(unsigned long))) - 1)) == 0) &&
   __builtin_constant_p(nbits & ((8 * sizeof(unsigned long)) - 1)) &&
   (((nbits) & ((typeof(nbits))((8 * sizeof(unsigned long))) - 1)) == 0))
  memset((char *)map + start / 8, 0xff, nbits / 8);
 else
  __bitmap_set(map, start, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void bitmap_clear(unsigned long *map, unsigned int start,
  unsigned int nbits)
{
 if (__builtin_constant_p(nbits) && nbits == 1)
  __clear_bit(start, map);
 else if (__builtin_constant_p(start & ((8 * sizeof(unsigned long)) - 1)) &&
   (((start) & ((typeof(start))((8 * sizeof(unsigned long))) - 1)) == 0) &&
   __builtin_constant_p(nbits & ((8 * sizeof(unsigned long)) - 1)) &&
   (((nbits) & ((typeof(nbits))((8 * sizeof(unsigned long))) - 1)) == 0))
  memset((char *)map + start / 8, 0, nbits / 8);
 else
  __bitmap_clear(map, start, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_shift_right(unsigned long *dst, const unsigned long *src,
    unsigned int shift, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  *dst = (*src & (~0UL >> (-(nbits) & (32 - 1)))) >> shift;
 else
  __bitmap_shift_right(dst, src, shift, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_shift_left(unsigned long *dst, const unsigned long *src,
    unsigned int shift, unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  *dst = (*src << shift) & (~0UL >> (-(nbits) & (32 - 1)));
 else
  __bitmap_shift_left(dst, src, shift, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_replace(unsigned long *dst,
      const unsigned long *old,
      const unsigned long *new,
      const unsigned long *mask,
      unsigned int nbits)
{
 if ((__builtin_constant_p(nbits) && (nbits) <= 32 && (nbits) > 0))
  *dst = (*old & ~(*mask)) | (*new & *mask);
 else
  __bitmap_replace(dst, old, new, mask, nbits);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_next_clear_region(unsigned long *bitmap,
         unsigned int *rs, unsigned int *re,
         unsigned int end)
{
 *rs = find_next_zero_bit(bitmap, end, *rs);
 *re = find_next_bit(bitmap, end, *rs + 1);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_next_set_region(unsigned long *bitmap,
       unsigned int *rs, unsigned int *re,
       unsigned int end)
{
 *rs = find_next_bit(bitmap, end, *rs);
 *re = find_next_zero_bit(bitmap, end, *rs + 1);
}
# 539 "/home/nathan/src/linux/include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_from_u64(unsigned long *dst, u64 mask)
{
 dst[0] = mask & (~0UL);

 if (sizeof(mask) > sizeof(unsigned long))
  dst[1] = mask >> 32;
}
# 555 "/home/nathan/src/linux/include/linux/bitmap.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long bitmap_get_value8(const unsigned long *map,
           unsigned long start)
{
 const size_t index = ((start) / 32);
 const unsigned long offset = start % 32;

 return (map[index] >> offset) & 0xFF;
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void bitmap_set_value8(unsigned long *map, unsigned long value,
         unsigned long start)
{
 const size_t index = ((start) / 32);
 const unsigned long offset = start % 32;

 map[index] &= ~(0xFFUL << offset);
 map[index] |= value << offset;
}
# 13 "/home/nathan/src/linux/include/linux/cpumask.h" 2
# 1 "/home/nathan/src/linux/include/linux/atomic.h" 1






# 1 "/home/nathan/src/linux/arch/mips/include/asm/atomic.h" 1
# 17 "/home/nathan/src/linux/arch/mips/include/asm/atomic.h"
# 1 "/home/nathan/src/linux/include/linux/irqflags.h" 1
# 16 "/home/nathan/src/linux/include/linux/irqflags.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/irqflags.h" 1
# 23 "/home/nathan/src/linux/arch/mips/include/asm/irqflags.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_local_irq_disable(void)
{
 __asm__ __volatile__(
 "	.set	push						\n"
 "	.set	noat						\n"
 "	di							\n"
 "	" "sll $0, $0, 3" "			\n"
 "	.set	pop						\n"
 :
 :
 : "memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long arch_local_irq_save(void)
{
 unsigned long flags;

 asm __volatile__(
 "	.set	push						\n"
 "	.set	reorder						\n"
 "	.set	noat						\n"




 "	di	%[flags]					\n"

 "	andi	%[flags], 1					\n"
 "	" "sll $0, $0, 3" "			\n"
 "	.set	pop						\n"
 : [flags] "=r" (flags)
 :
 : "memory");

 return flags;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_local_irq_restore(unsigned long flags)
{
 unsigned long __tmp1;

 __asm__ __volatile__(
 "	.set	push						\n"
 "	.set	noreorder					\n"
 "	.set	noat						\n"





 "	beqz	%[flags], 1f					\n"
 "	di							\n"
 "	ei							\n"
 "1:								\n"
# 85 "/home/nathan/src/linux/arch/mips/include/asm/irqflags.h"
 "	" "sll $0, $0, 3" "			\n"
 "	.set	pop						\n"
 : [flags] "=r" (__tmp1)
 : "0" (flags)
 : "memory");
}
# 99 "/home/nathan/src/linux/arch/mips/include/asm/irqflags.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_local_irq_enable(void)
{
 __asm__ __volatile__(
 "	.set	push						\n"
 "	.set	reorder						\n"
 "	.set	noat						\n"

 "	ei							\n"






 "	" "sll $0, $0, 3" "			\n"
 "	.set	pop						\n"
 :
 :
 : "memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long arch_local_save_flags(void)
{
 unsigned long flags;

 asm __volatile__(
 "	.set	push						\n"
 "	.set	reorder						\n"
 "	mfc0	%[flags], $12					\n"
 "	.set	pop						\n"
 : [flags] "=r" (flags));

 return flags;
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_irqs_disabled_flags(unsigned long flags)
{
 return !(flags & 1);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_irqs_disabled(void)
{
 return arch_irqs_disabled_flags(arch_local_save_flags());
}
# 17 "/home/nathan/src/linux/include/linux/irqflags.h" 2
# 1 "./arch/mips/include/generated/asm/percpu.h" 1
# 1 "/home/nathan/src/linux/include/asm-generic/percpu.h" 1






# 1 "/home/nathan/src/linux/include/linux/percpu-defs.h" 1
# 308 "/home/nathan/src/linux/include/linux/percpu-defs.h"
extern void __bad_size_call_parameter(void);




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __this_cpu_preempt_check(const char *op) { }
# 8 "/home/nathan/src/linux/include/asm-generic/percpu.h" 2
# 19 "/home/nathan/src/linux/include/asm-generic/percpu.h"
extern unsigned long __per_cpu_offset[16];
# 2 "./arch/mips/include/generated/asm/percpu.h" 2
# 18 "/home/nathan/src/linux/include/linux/irqflags.h" 2
# 27 "/home/nathan/src/linux/include/linux/irqflags.h"
  static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_softirqs_on(unsigned long ip) { }
  static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_softirqs_off(unsigned long ip) { }
  static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_hardirqs_on_prepare(unsigned long ip) { }
  static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_hardirqs_on(unsigned long ip) { }
  static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_hardirqs_off(unsigned long ip) { }
# 18 "/home/nathan/src/linux/arch/mips/include/asm/atomic.h" 2




# 1 "/home/nathan/src/linux/arch/mips/include/asm/cmpxchg.h" 1
# 11 "/home/nathan/src/linux/arch/mips/include/asm/cmpxchg.h"
# 1 "/home/nathan/src/linux/include/linux/bug.h" 1




# 1 "/home/nathan/src/linux/arch/mips/include/asm/bug.h" 1
# 10 "/home/nathan/src/linux/arch/mips/include/asm/bug.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/break.h" 1
# 15 "/home/nathan/src/linux/arch/mips/include/asm/break.h"
# 1 "/home/nathan/src/linux/arch/mips/include/uapi/asm/break.h" 1
# 16 "/home/nathan/src/linux/arch/mips/include/asm/break.h" 2
# 11 "/home/nathan/src/linux/arch/mips/include/asm/bug.h" 2

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __attribute__((__noreturn__)) BUG(void)
{
 __asm__ __volatile__("break %0" : : "i" (12));
 do { ; __builtin_unreachable(); } while (0);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __BUG_ON(unsigned long condition)
{
 if (__builtin_constant_p(condition)) {
  if (condition)
   BUG();
  else
   return;
 }
 __asm__ __volatile__("tne $0, %0, %1"
        : : "r" (condition), "i" (12));
}
# 42 "/home/nathan/src/linux/arch/mips/include/asm/bug.h"
# 1 "/home/nathan/src/linux/include/asm-generic/bug.h" 1





# 1 "/home/nathan/src/linux/include/linux/instrumentation.h" 1
# 7 "/home/nathan/src/linux/include/asm-generic/bug.h" 2
# 83 "/home/nathan/src/linux/include/asm-generic/bug.h"
extern __attribute__((__format__(printf, 4, 5)))
void warn_slowpath_fmt(const char *file, const int line, unsigned taint,
         const char *fmt, ...);
# 111 "/home/nathan/src/linux/include/asm-generic/bug.h"
struct warn_args;
struct pt_regs;

void __warn(const char *file, int line, void *caller, unsigned taint,
     struct pt_regs *regs, struct warn_args *args);
# 43 "/home/nathan/src/linux/arch/mips/include/asm/bug.h" 2
# 6 "/home/nathan/src/linux/include/linux/bug.h" 2



enum bug_trap_type {
 BUG_TRAP_TYPE_NONE = 0,
 BUG_TRAP_TYPE_WARN = 1,
 BUG_TRAP_TYPE_BUG = 2,
};

struct pt_regs;
# 50 "/home/nathan/src/linux/include/linux/bug.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *find_bug(unsigned long bugaddr)
{
 return ((void *)0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) enum bug_trap_type report_bug(unsigned long bug_addr,
         struct pt_regs *regs)
{
 return BUG_TRAP_TYPE_BUG;
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void generic_bug_clear_once(void) {}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__warn_unused_result__)) bool check_data_corruption(bool v) { return v; }
# 12 "/home/nathan/src/linux/arch/mips/include/asm/cmpxchg.h" 2
# 28 "/home/nathan/src/linux/arch/mips/include/asm/cmpxchg.h"
extern unsigned long __cmpxchg_called_with_bad_pointer(void)
                                                     ;
extern unsigned long __cmpxchg64_unsupported(void)
                                                                            ;
extern unsigned long __xchg_called_with_bad_pointer(void)
                                                  ;
# 68 "/home/nathan/src/linux/arch/mips/include/asm/cmpxchg.h"
extern unsigned long __xchg_small(volatile void *ptr, unsigned long val,
      unsigned int size);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__))
unsigned long __xchg(volatile void *ptr, unsigned long x, int size)
{
 switch (size) {
 case 1:
 case 2:
  return __xchg_small(ptr, x, size);

 case 4:
  return ({ __typeof(*((volatile u32 *)ptr)) __ret; if (((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { __asm__ __volatile__( "	.set	push				\n" "	.set	noat				\n" "	.set	push				\n" "	.set	" "mips64r6" "		\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll" "	%0, %2		# __xchg_asm	\n" "	.set	pop				\n" "	move	$1, %z3				\n" "	.set	" "mips64r6" "		\n" "	" "sc" "	$1, %1				\n" "\t" "beqzc	" "$1, 1b				\n" "	.set	pop				\n" : "=&r" (__ret), "=" "ZC" (*(volatile u32 *)ptr) : "ZC" (*(volatile u32 *)ptr), "Jr" (x) : "memory"); } else { unsigned long __flags; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); __ret = *(volatile u32 *)ptr; *(volatile u32 *)ptr = x; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } __ret; });

 case 8:
  if (!0)
   return __xchg_called_with_bad_pointer();

  return ({ __typeof(*((volatile u64 *)ptr)) __ret; if (((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { __asm__ __volatile__( "	.set	push				\n" "	.set	noat				\n" "	.set	push				\n" "	.set	" "mips64r6" "		\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "lld" "	%0, %2		# __xchg_asm	\n" "	.set	pop				\n" "	move	$1, %z3				\n" "	.set	" "mips64r6" "		\n" "	" "scd" "	$1, %1				\n" "\t" "beqzc	" "$1, 1b				\n" "	.set	pop				\n" : "=&r" (__ret), "=" "ZC" (*(volatile u64 *)ptr) : "ZC" (*(volatile u64 *)ptr), "Jr" (x) : "memory"); } else { unsigned long __flags; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); __ret = *(volatile u64 *)ptr; *(volatile u64 *)ptr = x; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } __ret; });

 default:
  return __xchg_called_with_bad_pointer();
 }
}
# 149 "/home/nathan/src/linux/arch/mips/include/asm/cmpxchg.h"
extern unsigned long __cmpxchg_small(volatile void *ptr, unsigned long old,
         unsigned long new, unsigned int size);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__))
unsigned long __cmpxchg(volatile void *ptr, unsigned long old,
   unsigned long new, unsigned int size)
{
 switch (size) {
 case 1:
 case 2:
  return __cmpxchg_small(ptr, old, new, size);

 case 4:
  return ({ __typeof(*((volatile u32 *)ptr)) __ret; if (((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { __asm__ __volatile__( "	.set	push				\n" "	.set	noat				\n" "	.set	push				\n" "	.set	""mips64r6""		\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "ll" "	%0, %2		# __cmpxchg_asm \n" "	bne	%0, %z3, 2f			\n" "	.set	pop				\n" "	move	$1, %z4				\n" "	.set	""mips64r6""		\n" "	" "sc" "	$1, %1				\n" "\t" "beqzc	" "$1, 1b				\n" "	.set	pop				\n" "2:	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" : "=&r" (__ret), "=" "ZC" (*(volatile u32 *)ptr) : "ZC" (*(volatile u32 *)ptr), "Jr" ((u32)old), "Jr" (new) : "memory"); } else { unsigned long __flags; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); __ret = *(volatile u32 *)ptr; if (__ret == (u32)old) *(volatile u32 *)ptr = new; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } __ret; });


 case 8:

  if (!0)
   return __cmpxchg_called_with_bad_pointer();

  return ({ __typeof(*((volatile u64 *)ptr)) __ret; if (((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { __asm__ __volatile__( "	.set	push				\n" "	.set	noat				\n" "	.set	push				\n" "	.set	""mips64r6""		\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" "1:	" "lld" "	%0, %2		# __cmpxchg_asm \n" "	bne	%0, %z3, 2f			\n" "	.set	pop				\n" "	move	$1, %z4				\n" "	.set	""mips64r6""		\n" "	" "scd" "	$1, %1				\n" "\t" "beqzc	" "$1, 1b				\n" "	.set	pop				\n" "2:	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n" : "=&r" (__ret), "=" "ZC" (*(volatile u64 *)ptr) : "ZC" (*(volatile u64 *)ptr), "Jr" ((u64)old), "Jr" (new) : "memory"); } else { unsigned long __flags; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); __ret = *(volatile u64 *)ptr; if (__ret == (u64)old) *(volatile u64 *)ptr = new; do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } __ret; });


 default:
  return __cmpxchg_called_with_bad_pointer();
 }
}
# 224 "/home/nathan/src/linux/arch/mips/include/asm/cmpxchg.h"
# 1 "/home/nathan/src/linux/include/asm-generic/cmpxchg-local.h" 1







extern unsigned long wrong_size_cmpxchg(volatile void *ptr)
 __attribute__((__noreturn__));





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __cmpxchg_local_generic(volatile void *ptr,
  unsigned long old, unsigned long new, int size)
{
 unsigned long flags, prev;




 if (size == 8 && sizeof(unsigned long) != 8)
  wrong_size_cmpxchg(ptr);

 do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0);
 switch (size) {
 case 1: prev = *(u8 *)ptr;
  if (prev == old)
   *(u8 *)ptr = (u8)new;
  break;
 case 2: prev = *(u16 *)ptr;
  if (prev == old)
   *(u16 *)ptr = (u16)new;
  break;
 case 4: prev = *(u32 *)ptr;
  if (prev == old)
   *(u32 *)ptr = (u32)new;
  break;
 case 8: prev = *(u64 *)ptr;
  if (prev == old)
   *(u64 *)ptr = (u64)new;
  break;
 default:
  wrong_size_cmpxchg(ptr);
 }
 do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0);
 return prev;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 __cmpxchg64_local_generic(volatile void *ptr,
  u64 old, u64 new)
{
 u64 prev;
 unsigned long flags;

 do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0);
 prev = *(u64 *)ptr;
 if (prev == old)
  *(u64 *)ptr = new;
 do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0);
 return prev;
}
# 225 "/home/nathan/src/linux/arch/mips/include/asm/cmpxchg.h" 2




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __cmpxchg64(volatile void *ptr,
     unsigned long long old,
     unsigned long long new)
{
 unsigned long long tmp, ret;
 unsigned long flags;
# 244 "/home/nathan/src/linux/arch/mips/include/asm/cmpxchg.h"
 do { do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); } while (0);

 asm volatile(
 "	.set	push				\n"
 "	.set	" "mips64r6" "		\n"

 "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n"
 "1:	lld	%L0, %3		# __cmpxchg64	\n"




 "	dsra	%M0, %L0, 32			\n"
 "	sll	%L0, %L0, 0			\n"




 "	bne	%M0, %M4, 2f			\n"
 "	bne	%L0, %L4, 2f			\n"





 "	move	%L1, %L5			\n"
 "	dins	%L1, %M5, 32, 32		\n"
# 280 "/home/nathan/src/linux/arch/mips/include/asm/cmpxchg.h"
 "	scd	%L1, %2				\n"

 "\t" "beqzc	" "%L1, 1b				\n"
 "	.set	pop				\n"
 "2:	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "		\n"
 : "=&r"(ret),
   "=&r"(tmp),
   "=" "ZC" (*(unsigned long long *)ptr)
 : "ZC" (*(unsigned long long *)ptr),
   "r" (old),
   "r" (new)
 : "memory");

 do { do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); } while (0);
 return ret;
}
# 23 "/home/nathan/src/linux/arch/mips/include/asm/atomic.h" 2
# 48 "/home/nathan/src/linux/arch/mips/include/asm/atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int atomic_read(const atomic_t *v) { return ({ do { extern void __compiletime_assert_24(void) ; if (!((sizeof(v->counter) == sizeof(char) || sizeof(v->counter) == sizeof(short) || sizeof(v->counter) == sizeof(int) || sizeof(v->counter) == sizeof(long)) || sizeof(v->counter) == sizeof(long long))) __compiletime_assert_24(); } while (0); (*(const volatile typeof( _Generic((v->counter), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (v->counter))) *)&(v->counter)); }); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void atomic_set(atomic_t *v, int i) { do { do { extern void __compiletime_assert_25(void) ; if (!((sizeof(v->counter) == sizeof(char) || sizeof(v->counter) == sizeof(short) || sizeof(v->counter) == sizeof(int) || sizeof(v->counter) == sizeof(long)) || sizeof(v->counter) == sizeof(long long))) __compiletime_assert_25(); } while (0); do { *(volatile typeof(v->counter) *)&(v->counter) = (i); } while (0); } while (0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int atomic_cmpxchg(atomic_t *v, int o, int n) { return ({ __typeof__(*(&v->counter)) __res; if (!0) do { } while (0); __res = ((__typeof__(*((&v->counter)))) __cmpxchg(((&v->counter)), (unsigned long)(__typeof__(*((&v->counter))))((o)), (unsigned long)(__typeof__(*((&v->counter))))((n)), sizeof(*((&v->counter))))); if (!0) do { } while (0); __res; }); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int atomic_xchg(atomic_t *v, int n) { return ({ __typeof__(*(&v->counter)) __res; if (!0) do { } while (0); __res = (__typeof__(*(&v->counter))) __xchg((&v->counter), (unsigned long)(n), sizeof(*(&v->counter))); do { } while (0); __res; }); }
# 153 "/home/nathan/src/linux/arch/mips/include/asm/atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void atomic_add(int i, atomic_t * v) { int temp; if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); v->counter += i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); return; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%0, %1		# " "atomic" "_" "add" "	\n" "	" "addu" " %0, %2				\n" "	" "sc" "	%0, %1					\n" "\t" "beqzc	" "%0, 1b					\n" "	.set	pop					\n" : "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int atomic_add_return_relaxed(int i, atomic_t * v) { int temp, result; if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; result += i; v->counter = result; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_" "add" "_return\n" "	" "addu" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqzc	" "%0, 1b					\n" "	" "addu" " %0, %1, %3				\n" "	.set	pop					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int atomic_fetch_add_relaxed(int i, atomic_t * v) { int temp, result; if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; v->counter += i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_fetch_" "add" "\n" "	" "addu" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqzc	" "%0, 1b					\n" "	.set	pop					\n" "	move	%0, %1					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void atomic_sub(int i, atomic_t * v) { int temp; if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); v->counter -= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); return; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%0, %1		# " "atomic" "_" "sub" "	\n" "	" "subu" " %0, %2				\n" "	" "sc" "	%0, %1					\n" "\t" "beqzc	" "%0, 1b					\n" "	.set	pop					\n" : "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int atomic_sub_return_relaxed(int i, atomic_t * v) { int temp, result; if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; result -= i; v->counter = result; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_" "sub" "_return\n" "	" "subu" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqzc	" "%0, 1b					\n" "	" "subu" " %0, %1, %3				\n" "	.set	pop					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int atomic_fetch_sub_relaxed(int i, atomic_t * v) { int temp, result; if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; v->counter -= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_fetch_" "sub" "\n" "	" "subu" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqzc	" "%0, 1b					\n" "	.set	pop					\n" "	move	%0, %1					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; }
# 175 "/home/nathan/src/linux/arch/mips/include/asm/atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void atomic_and(int i, atomic_t * v) { int temp; if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); v->counter &= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); return; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%0, %1		# " "atomic" "_" "and" "	\n" "	" "and" " %0, %2				\n" "	" "sc" "	%0, %1					\n" "\t" "beqzc	" "%0, 1b					\n" "	.set	pop					\n" : "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int atomic_fetch_and_relaxed(int i, atomic_t * v) { int temp, result; if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; v->counter &= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_fetch_" "and" "\n" "	" "and" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqzc	" "%0, 1b					\n" "	.set	pop					\n" "	move	%0, %1					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void atomic_or(int i, atomic_t * v) { int temp; if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); v->counter |= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); return; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%0, %1		# " "atomic" "_" "or" "	\n" "	" "or" " %0, %2				\n" "	" "sc" "	%0, %1					\n" "\t" "beqzc	" "%0, 1b					\n" "	.set	pop					\n" : "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int atomic_fetch_or_relaxed(int i, atomic_t * v) { int temp, result; if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; v->counter |= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_fetch_" "or" "\n" "	" "or" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqzc	" "%0, 1b					\n" "	.set	pop					\n" "	move	%0, %1					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void atomic_xor(int i, atomic_t * v) { int temp; if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); v->counter ^= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); return; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%0, %1		# " "atomic" "_" "xor" "	\n" "	" "xor" " %0, %2				\n" "	" "sc" "	%0, %1					\n" "\t" "beqzc	" "%0, 1b					\n" "	.set	pop					\n" : "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int atomic_fetch_xor_relaxed(int i, atomic_t * v) { int temp, result; if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; v->counter ^= i; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# " "atomic" "_fetch_" "xor" "\n" "	" "xor" " %0, %1, %3				\n" "	" "sc" "	%0, %2					\n" "\t" "beqzc	" "%0, 1b					\n" "	.set	pop					\n" "	move	%0, %1					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); return result; }
# 257 "/home/nathan/src/linux/arch/mips/include/asm/atomic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int atomic_sub_if_positive(int i, atomic_t * v) { int temp, result; do { } while (0); if (!((6 >= (1)) || (cpu_data[0].options & (((((1ULL))) << (16)))))) { unsigned long flags; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); result = v->counter; result -= i; if (result >= 0) v->counter = result; do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); do { } while (0); return result; } __asm__ __volatile__( "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "1:	" "ll" "	%1, %2		# atomic_sub_if_positive\n" "	.set	pop					\n" "	" "subu" "	%0, %1, %3				\n" "	move	%1, %0					\n" "	bltz	%0, 2f					\n" "	.set	push					\n" "	.set	" "mips64r6" "			\n" "	" "sc" "	%1, %2					\n" "	" "beqzc	" "%1, 1b				\n" "2:	" ".if (( 0x00 ) != -1) && ( 0 ); .set push; .set mips64r6; .rept 1; sync 0x00; .endr; .set pop; .else; ; .endif" "			\n" "	.set	pop					\n" : "=&r" (result), "=&r" (temp), "+" "ZC" (v->counter) : "Ir" (i) : "memory"); if (!0) do { } while (0); return result; }
# 8 "/home/nathan/src/linux/include/linux/atomic.h" 2
# 84 "/home/nathan/src/linux/include/linux/atomic.h"
# 1 "/home/nathan/src/linux/include/linux/atomic-fallback.h" 1
# 154 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_read_acquire(const atomic_t *v)
{
 return ({ typeof( _Generic((*&(v)->counter), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*&(v)->counter))) ___p1 = ({ do { extern void __compiletime_assert_26(void) ; if (!((sizeof(*&(v)->counter) == sizeof(char) || sizeof(*&(v)->counter) == sizeof(short) || sizeof(*&(v)->counter) == sizeof(int) || sizeof(*&(v)->counter) == sizeof(long)) || sizeof(*&(v)->counter) == sizeof(long long))) __compiletime_assert_26(); } while (0); (*(const volatile typeof( _Generic((*&(v)->counter), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*&(v)->counter))) *)&(*&(v)->counter)); }); do { extern void __compiletime_assert_27(void) ; if (!((sizeof(*&(v)->counter) == sizeof(char) || sizeof(*&(v)->counter) == sizeof(short) || sizeof(*&(v)->counter) == sizeof(int) || sizeof(*&(v)->counter) == sizeof(long)))) __compiletime_assert_27(); } while (0); __sync(); (typeof(*&(v)->counter))___p1; });
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_set_release(atomic_t *v, int i)
{
 do { do { extern void __compiletime_assert_28(void) ; if (!((sizeof(*&(v)->counter) == sizeof(char) || sizeof(*&(v)->counter) == sizeof(short) || sizeof(*&(v)->counter) == sizeof(int) || sizeof(*&(v)->counter) == sizeof(long)))) __compiletime_assert_28(); } while (0); __sync(); do { do { extern void __compiletime_assert_29(void) ; if (!((sizeof(*&(v)->counter) == sizeof(char) || sizeof(*&(v)->counter) == sizeof(short) || sizeof(*&(v)->counter) == sizeof(int) || sizeof(*&(v)->counter) == sizeof(long)) || sizeof(*&(v)->counter) == sizeof(long long))) __compiletime_assert_29(); } while (0); do { *(volatile typeof(*&(v)->counter) *)&(*&(v)->counter) = (i); } while (0); } while (0); } while (0);
}
# 188 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_add_return_acquire(int i, atomic_t *v)
{
 int ret = atomic_add_return_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_add_return_release(int i, atomic_t *v)
{
 do { } while (0);
 return atomic_add_return_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_add_return(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = atomic_add_return_relaxed(i, v);
 do { } while (0);
 return ret;
}
# 235 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_add_acquire(int i, atomic_t *v)
{
 int ret = atomic_fetch_add_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_add_release(int i, atomic_t *v)
{
 do { } while (0);
 return atomic_fetch_add_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_add(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = atomic_fetch_add_relaxed(i, v);
 do { } while (0);
 return ret;
}
# 284 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_sub_return_acquire(int i, atomic_t *v)
{
 int ret = atomic_sub_return_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_sub_return_release(int i, atomic_t *v)
{
 do { } while (0);
 return atomic_sub_return_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_sub_return(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = atomic_sub_return_relaxed(i, v);
 do { } while (0);
 return ret;
}
# 331 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_sub_acquire(int i, atomic_t *v)
{
 int ret = atomic_fetch_sub_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_sub_release(int i, atomic_t *v)
{
 do { } while (0);
 return atomic_fetch_sub_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_sub(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = atomic_fetch_sub_relaxed(i, v);
 do { } while (0);
 return ret;
}
# 369 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_inc(atomic_t *v)
{
 atomic_add(1, v);
}
# 390 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_inc_return(atomic_t *v)
{
 return atomic_add_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_inc_return_acquire(atomic_t *v)
{
 return atomic_add_return_acquire(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_inc_return_release(atomic_t *v)
{
 return atomic_add_return_release(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_inc_return_relaxed(atomic_t *v)
{
 return atomic_add_return_relaxed(1, v);
}
# 476 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_inc(atomic_t *v)
{
 return atomic_fetch_add(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_inc_acquire(atomic_t *v)
{
 return atomic_fetch_add_acquire(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_inc_release(atomic_t *v)
{
 return atomic_fetch_add_release(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_inc_relaxed(atomic_t *v)
{
 return atomic_fetch_add_relaxed(1, v);
}
# 552 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_dec(atomic_t *v)
{
 atomic_sub(1, v);
}
# 573 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_dec_return(atomic_t *v)
{
 return atomic_sub_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_dec_return_acquire(atomic_t *v)
{
 return atomic_sub_return_acquire(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_dec_return_release(atomic_t *v)
{
 return atomic_sub_return_release(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_dec_return_relaxed(atomic_t *v)
{
 return atomic_sub_return_relaxed(1, v);
}
# 659 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_dec(atomic_t *v)
{
 return atomic_fetch_sub(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_dec_acquire(atomic_t *v)
{
 return atomic_fetch_sub_acquire(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_dec_release(atomic_t *v)
{
 return atomic_fetch_sub_release(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_dec_relaxed(atomic_t *v)
{
 return atomic_fetch_sub_relaxed(1, v);
}
# 746 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_and_acquire(int i, atomic_t *v)
{
 int ret = atomic_fetch_and_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_and_release(int i, atomic_t *v)
{
 do { } while (0);
 return atomic_fetch_and_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_and(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = atomic_fetch_and_relaxed(i, v);
 do { } while (0);
 return ret;
}
# 784 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_andnot(int i, atomic_t *v)
{
 atomic_and(~i, v);
}
# 805 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_andnot(int i, atomic_t *v)
{
 return atomic_fetch_and(~i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_andnot_acquire(int i, atomic_t *v)
{
 return atomic_fetch_and_acquire(~i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_andnot_release(int i, atomic_t *v)
{
 return atomic_fetch_and_release(~i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_andnot_relaxed(int i, atomic_t *v)
{
 return atomic_fetch_and_relaxed(~i, v);
}
# 892 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_or_acquire(int i, atomic_t *v)
{
 int ret = atomic_fetch_or_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_or_release(int i, atomic_t *v)
{
 do { } while (0);
 return atomic_fetch_or_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_or(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = atomic_fetch_or_relaxed(i, v);
 do { } while (0);
 return ret;
}
# 941 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_xor_acquire(int i, atomic_t *v)
{
 int ret = atomic_fetch_xor_relaxed(i, v);
 do { } while (0);
 return ret;
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_xor_release(int i, atomic_t *v)
{
 do { } while (0);
 return atomic_fetch_xor_relaxed(i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_xor(int i, atomic_t *v)
{
 int ret;
 do { } while (0);
 ret = atomic_fetch_xor_relaxed(i, v);
 do { } while (0);
 return ret;
}
# 1083 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_try_cmpxchg(atomic_t *v, int *old, int new)
{
 int r, o = *old;
 r = atomic_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)
{
 int r, o = *old;
 r = atomic_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_try_cmpxchg_release(atomic_t *v, int *old, int new)
{
 int r, o = *old;
 r = atomic_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_try_cmpxchg_relaxed(atomic_t *v, int *old, int new)
{
 int r, o = *old;
 r = atomic_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}
# 1184 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_sub_and_test(int i, atomic_t *v)
{
 return atomic_sub_return(i, v) == 0;
}
# 1203 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_dec_and_test(atomic_t *v)
{
 return atomic_dec_return(v) == 0;
}
# 1222 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_inc_and_test(atomic_t *v)
{
 return atomic_inc_return(v) == 0;
}
# 1242 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_add_negative(int i, atomic_t *v)
{
 return atomic_add_return(i, v) < 0;
}
# 1262 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int
atomic_fetch_add_unless(atomic_t *v, int a, int u)
{
 int c = atomic_read(v);

 do {
  if (__builtin_expect(!!(c == u), 0))
   break;
 } while (!atomic_try_cmpxchg(v, &c, c + a));

 return c;
}
# 1289 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_add_unless(atomic_t *v, int a, int u)
{
 return atomic_fetch_add_unless(v, a, u) != u;
}
# 1307 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_inc_not_zero(atomic_t *v)
{
 return atomic_add_unless(v, 1, 0);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_inc_unless_negative(atomic_t *v)
{
 int c = atomic_read(v);

 do {
  if (__builtin_expect(!!(c < 0), 0))
   return false;
 } while (!atomic_try_cmpxchg(v, &c, c + 1));

 return true;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_dec_unless_positive(atomic_t *v)
{
 int c = atomic_read(v);

 do {
  if (__builtin_expect(!!(c > 0), 0))
   return false;
 } while (!atomic_try_cmpxchg(v, &c, c - 1));

 return true;
}
# 1371 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
# 1 "/home/nathan/src/linux/include/asm-generic/atomic64.h" 1
# 12 "/home/nathan/src/linux/include/asm-generic/atomic64.h"
typedef struct {
 s64 counter;
} atomic64_t;



extern s64 atomic64_read(const atomic64_t *v);
extern void atomic64_set(atomic64_t *v, s64 i);
# 34 "/home/nathan/src/linux/include/asm-generic/atomic64.h"
extern void atomic64_add(s64 a, atomic64_t *v); extern s64 atomic64_add_return(s64 a, atomic64_t *v); extern s64 atomic64_fetch_add(s64 a, atomic64_t *v);
extern void atomic64_sub(s64 a, atomic64_t *v); extern s64 atomic64_sub_return(s64 a, atomic64_t *v); extern s64 atomic64_fetch_sub(s64 a, atomic64_t *v);




extern void atomic64_and(s64 a, atomic64_t *v); extern s64 atomic64_fetch_and(s64 a, atomic64_t *v);
extern void atomic64_or(s64 a, atomic64_t *v); extern s64 atomic64_fetch_or(s64 a, atomic64_t *v);
extern void atomic64_xor(s64 a, atomic64_t *v); extern s64 atomic64_fetch_xor(s64 a, atomic64_t *v);






extern s64 atomic64_dec_if_positive(atomic64_t *v);

extern s64 atomic64_cmpxchg(atomic64_t *v, s64 o, s64 n);
extern s64 atomic64_xchg(atomic64_t *v, s64 new);
extern s64 atomic64_fetch_add_unless(atomic64_t *v, s64 a, s64 u);
# 1372 "/home/nathan/src/linux/include/linux/atomic-fallback.h" 2






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_read_acquire(const atomic64_t *v)
{
 return ({ typeof( _Generic((*&(v)->counter), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*&(v)->counter))) ___p1 = ({ do { extern void __compiletime_assert_30(void) ; if (!((sizeof(*&(v)->counter) == sizeof(char) || sizeof(*&(v)->counter) == sizeof(short) || sizeof(*&(v)->counter) == sizeof(int) || sizeof(*&(v)->counter) == sizeof(long)) || sizeof(*&(v)->counter) == sizeof(long long))) __compiletime_assert_30(); } while (0); (*(const volatile typeof( _Generic((*&(v)->counter), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (*&(v)->counter))) *)&(*&(v)->counter)); }); do { extern void __compiletime_assert_31(void) ; if (!((sizeof(*&(v)->counter) == sizeof(char) || sizeof(*&(v)->counter) == sizeof(short) || sizeof(*&(v)->counter) == sizeof(int) || sizeof(*&(v)->counter) == sizeof(long)))) __compiletime_assert_31(); } while (0); __sync(); (typeof(*&(v)->counter))___p1; });
}
# 1593 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_inc(atomic64_t *v)
{
 atomic64_add(1, v);
}
# 1614 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_inc_return(atomic64_t *v)
{
 return atomic64_add_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_inc_return_acquire(atomic64_t *v)
{
 return atomic64_add_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_inc_return_release(atomic64_t *v)
{
 return atomic64_add_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_inc_return_relaxed(atomic64_t *v)
{
 return atomic64_add_return(1, v);
}
# 1700 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_inc(atomic64_t *v)
{
 return atomic64_fetch_add(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_inc_acquire(atomic64_t *v)
{
 return atomic64_fetch_add(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_inc_release(atomic64_t *v)
{
 return atomic64_fetch_add(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_inc_relaxed(atomic64_t *v)
{
 return atomic64_fetch_add(1, v);
}
# 1776 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_dec(atomic64_t *v)
{
 atomic64_sub(1, v);
}
# 1797 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_dec_return(atomic64_t *v)
{
 return atomic64_sub_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_dec_return_acquire(atomic64_t *v)
{
 return atomic64_sub_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_dec_return_release(atomic64_t *v)
{
 return atomic64_sub_return(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_dec_return_relaxed(atomic64_t *v)
{
 return atomic64_sub_return(1, v);
}
# 1883 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_dec(atomic64_t *v)
{
 return atomic64_fetch_sub(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_dec_acquire(atomic64_t *v)
{
 return atomic64_fetch_sub(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_dec_release(atomic64_t *v)
{
 return atomic64_fetch_sub(1, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_dec_relaxed(atomic64_t *v)
{
 return atomic64_fetch_sub(1, v);
}
# 2008 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic64_andnot(s64 i, atomic64_t *v)
{
 atomic64_and(~i, v);
}
# 2029 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_andnot(s64 i, atomic64_t *v)
{
 return atomic64_fetch_and(~i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_andnot_acquire(s64 i, atomic64_t *v)
{
 return atomic64_fetch_and(~i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_andnot_release(s64 i, atomic64_t *v)
{
 return atomic64_fetch_and(~i, v);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) s64
atomic64_fetch_andnot_relaxed(s64 i, atomic64_t *v)
{
 return atomic64_fetch_and(~i, v);
}
# 2307 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_try_cmpxchg(atomic64_t *v, s64 *old, s64 new)
{
 s64 r, o = *old;
 r = atomic64_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_try_cmpxchg_acquire(atomic64_t *v, s64 *old, s64 new)
{
 s64 r, o = *old;
 r = atomic64_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_try_cmpxchg_release(atomic64_t *v, s64 *old, s64 new)
{
 s64 r, o = *old;
 r = atomic64_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_try_cmpxchg_relaxed(atomic64_t *v, s64 *old, s64 new)
{
 s64 r, o = *old;
 r = atomic64_cmpxchg(v, o, new);
 if (__builtin_expect(!!(r != o), 0))
  *old = r;
 return __builtin_expect(!!(r == o), 1);
}
# 2408 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_sub_and_test(s64 i, atomic64_t *v)
{
 return atomic64_sub_return(i, v) == 0;
}
# 2427 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_dec_and_test(atomic64_t *v)
{
 return atomic64_dec_return(v) == 0;
}
# 2446 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_inc_and_test(atomic64_t *v)
{
 return atomic64_inc_return(v) == 0;
}
# 2466 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_add_negative(s64 i, atomic64_t *v)
{
 return atomic64_add_return(i, v) < 0;
}
# 2513 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_add_unless(atomic64_t *v, s64 a, s64 u)
{
 return atomic64_fetch_add_unless(v, a, u) != u;
}
# 2531 "/home/nathan/src/linux/include/linux/atomic-fallback.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_inc_not_zero(atomic64_t *v)
{
 return atomic64_add_unless(v, 1, 0);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_inc_unless_negative(atomic64_t *v)
{
 s64 c = atomic64_read(v);

 do {
  if (__builtin_expect(!!(c < 0), 0))
   return false;
 } while (!atomic64_try_cmpxchg(v, &c, c + 1));

 return true;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic64_dec_unless_positive(atomic64_t *v)
{
 s64 c = atomic64_read(v);

 do {
  if (__builtin_expect(!!(c > 0), 0))
   return false;
 } while (!atomic64_try_cmpxchg(v, &c, c - 1));

 return true;
}
# 85 "/home/nathan/src/linux/include/linux/atomic.h" 2


# 1 "/home/nathan/src/linux/include/asm-generic/atomic-long.h" 1
# 18 "/home/nathan/src/linux/include/asm-generic/atomic-long.h"
typedef atomic_t atomic_long_t;
# 520 "/home/nathan/src/linux/include/asm-generic/atomic-long.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_read(const atomic_long_t *v)
{
 return atomic_read(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_read_acquire(const atomic_long_t *v)
{
 return atomic_read_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_set(atomic_long_t *v, long i)
{
 atomic_set(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_set_release(atomic_long_t *v, long i)
{
 atomic_set_release(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_add(long i, atomic_long_t *v)
{
 atomic_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_add_return(long i, atomic_long_t *v)
{
 return atomic_add_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_add_return_acquire(long i, atomic_long_t *v)
{
 return atomic_add_return_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_add_return_release(long i, atomic_long_t *v)
{
 return atomic_add_return_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_add_return_relaxed(long i, atomic_long_t *v)
{
 return atomic_add_return_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_add(long i, atomic_long_t *v)
{
 return atomic_fetch_add(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_add_acquire(long i, atomic_long_t *v)
{
 return atomic_fetch_add_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_add_release(long i, atomic_long_t *v)
{
 return atomic_fetch_add_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_add_relaxed(long i, atomic_long_t *v)
{
 return atomic_fetch_add_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_sub(long i, atomic_long_t *v)
{
 atomic_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_sub_return(long i, atomic_long_t *v)
{
 return atomic_sub_return(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_sub_return_acquire(long i, atomic_long_t *v)
{
 return atomic_sub_return_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_sub_return_release(long i, atomic_long_t *v)
{
 return atomic_sub_return_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_sub_return_relaxed(long i, atomic_long_t *v)
{
 return atomic_sub_return_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_sub(long i, atomic_long_t *v)
{
 return atomic_fetch_sub(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_sub_acquire(long i, atomic_long_t *v)
{
 return atomic_fetch_sub_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_sub_release(long i, atomic_long_t *v)
{
 return atomic_fetch_sub_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_sub_relaxed(long i, atomic_long_t *v)
{
 return atomic_fetch_sub_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_inc(atomic_long_t *v)
{
 atomic_inc(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_inc_return(atomic_long_t *v)
{
 return atomic_inc_return(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_inc_return_acquire(atomic_long_t *v)
{
 return atomic_inc_return_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_inc_return_release(atomic_long_t *v)
{
 return atomic_inc_return_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_inc_return_relaxed(atomic_long_t *v)
{
 return atomic_inc_return_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_inc(atomic_long_t *v)
{
 return atomic_fetch_inc(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_inc_acquire(atomic_long_t *v)
{
 return atomic_fetch_inc_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_inc_release(atomic_long_t *v)
{
 return atomic_fetch_inc_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_inc_relaxed(atomic_long_t *v)
{
 return atomic_fetch_inc_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_dec(atomic_long_t *v)
{
 atomic_dec(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_dec_return(atomic_long_t *v)
{
 return atomic_dec_return(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_dec_return_acquire(atomic_long_t *v)
{
 return atomic_dec_return_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_dec_return_release(atomic_long_t *v)
{
 return atomic_dec_return_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_dec_return_relaxed(atomic_long_t *v)
{
 return atomic_dec_return_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_dec(atomic_long_t *v)
{
 return atomic_fetch_dec(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_dec_acquire(atomic_long_t *v)
{
 return atomic_fetch_dec_acquire(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_dec_release(atomic_long_t *v)
{
 return atomic_fetch_dec_release(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_dec_relaxed(atomic_long_t *v)
{
 return atomic_fetch_dec_relaxed(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_and(long i, atomic_long_t *v)
{
 atomic_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_and(long i, atomic_long_t *v)
{
 return atomic_fetch_and(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_and_acquire(long i, atomic_long_t *v)
{
 return atomic_fetch_and_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_and_release(long i, atomic_long_t *v)
{
 return atomic_fetch_and_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_and_relaxed(long i, atomic_long_t *v)
{
 return atomic_fetch_and_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_andnot(long i, atomic_long_t *v)
{
 atomic_andnot(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_andnot(long i, atomic_long_t *v)
{
 return atomic_fetch_andnot(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_andnot_acquire(long i, atomic_long_t *v)
{
 return atomic_fetch_andnot_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_andnot_release(long i, atomic_long_t *v)
{
 return atomic_fetch_andnot_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_andnot_relaxed(long i, atomic_long_t *v)
{
 return atomic_fetch_andnot_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_or(long i, atomic_long_t *v)
{
 atomic_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_or(long i, atomic_long_t *v)
{
 return atomic_fetch_or(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_or_acquire(long i, atomic_long_t *v)
{
 return atomic_fetch_or_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_or_release(long i, atomic_long_t *v)
{
 return atomic_fetch_or_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_or_relaxed(long i, atomic_long_t *v)
{
 return atomic_fetch_or_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void
atomic_long_xor(long i, atomic_long_t *v)
{
 atomic_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_xor(long i, atomic_long_t *v)
{
 return atomic_fetch_xor(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_xor_acquire(long i, atomic_long_t *v)
{
 return atomic_fetch_xor_acquire(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_xor_release(long i, atomic_long_t *v)
{
 return atomic_fetch_xor_release(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_xor_relaxed(long i, atomic_long_t *v)
{
 return atomic_fetch_xor_relaxed(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_xchg(atomic_long_t *v, long i)
{
 return atomic_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_xchg_acquire(atomic_long_t *v, long i)
{
 return atomic_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_xchg_release(atomic_long_t *v, long i)
{
 return atomic_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_xchg_relaxed(atomic_long_t *v, long i)
{
 return atomic_xchg(v, i);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_cmpxchg(atomic_long_t *v, long old, long new)
{
 return atomic_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_cmpxchg_acquire(atomic_long_t *v, long old, long new)
{
 return atomic_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_cmpxchg_release(atomic_long_t *v, long old, long new)
{
 return atomic_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_cmpxchg_relaxed(atomic_long_t *v, long old, long new)
{
 return atomic_cmpxchg(v, old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_try_cmpxchg(atomic_long_t *v, long *old, long new)
{
 return atomic_try_cmpxchg(v, (int *)old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_try_cmpxchg_acquire(atomic_long_t *v, long *old, long new)
{
 return atomic_try_cmpxchg_acquire(v, (int *)old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_try_cmpxchg_release(atomic_long_t *v, long *old, long new)
{
 return atomic_try_cmpxchg_release(v, (int *)old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_try_cmpxchg_relaxed(atomic_long_t *v, long *old, long new)
{
 return atomic_try_cmpxchg_relaxed(v, (int *)old, new);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_sub_and_test(long i, atomic_long_t *v)
{
 return atomic_sub_and_test(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_dec_and_test(atomic_long_t *v)
{
 return atomic_dec_and_test(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_inc_and_test(atomic_long_t *v)
{
 return atomic_inc_and_test(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_add_negative(long i, atomic_long_t *v)
{
 return atomic_add_negative(i, v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_fetch_add_unless(atomic_long_t *v, long a, long u)
{
 return atomic_fetch_add_unless(v, a, u);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_add_unless(atomic_long_t *v, long a, long u)
{
 return atomic_add_unless(v, a, u);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_inc_not_zero(atomic_long_t *v)
{
 return atomic_inc_not_zero(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_inc_unless_negative(atomic_long_t *v)
{
 return atomic_inc_unless_negative(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool
atomic_long_dec_unless_positive(atomic_long_t *v)
{
 return atomic_dec_unless_positive(v);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) long
atomic_long_dec_if_positive(atomic_long_t *v)
{
 return atomic_sub_if_positive(1, v);
}
# 88 "/home/nathan/src/linux/include/linux/atomic.h" 2
# 14 "/home/nathan/src/linux/include/linux/cpumask.h" 2



typedef struct cpumask { unsigned long bits[(((16) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8)))]; } cpumask_t;
# 39 "/home/nathan/src/linux/include/linux/cpumask.h"
extern unsigned int nr_cpu_ids;
# 90 "/home/nathan/src/linux/include/linux/cpumask.h"
extern struct cpumask __cpu_possible_mask;
extern struct cpumask __cpu_online_mask;
extern struct cpumask __cpu_present_mask;
extern struct cpumask __cpu_active_mask;





extern atomic_t __num_online_cpus;
# 110 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int num_online_cpus(void)
{
 return atomic_read(&__num_online_cpus);
}
# 132 "/home/nathan/src/linux/include/linux/cpumask.h"
extern cpumask_t cpus_booted_once_mask;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpu_max_bits_warn(unsigned int cpu, unsigned int bits)
{



}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpumask_check(unsigned int cpu)
{
 cpu_max_bits_warn(cpu, ((unsigned int)16));
 return cpu;
}
# 222 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpumask_first(const struct cpumask *srcp)
{
 return find_next_bit((((srcp)->bits)), (((unsigned int)16)), 0);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpumask_last(const struct cpumask *srcp)
{
 return find_last_bit(((srcp)->bits), ((unsigned int)16));
}

unsigned int cpumask_next(int n, const struct cpumask *srcp);
# 247 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpumask_next_zero(int n, const struct cpumask *srcp)
{

 if (n != -1)
  cpumask_check(n);
 return find_next_zero_bit(((srcp)->bits), ((unsigned int)16), n+1);
}

int cpumask_next_and(int n, const struct cpumask *, const struct cpumask *);
int cpumask_any_but(const struct cpumask *mask, unsigned int cpu);
unsigned int cpumask_local_spread(unsigned int i, int node);
int cpumask_any_and_distribute(const struct cpumask *src1p,
          const struct cpumask *src2p);
int cpumask_any_distribute(const struct cpumask *srcp);
# 286 "/home/nathan/src/linux/include/linux/cpumask.h"
extern int cpumask_next_wrap(int n, const struct cpumask *mask, int start, bool wrap);
# 338 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_set_cpu(unsigned int cpu, struct cpumask *dstp)
{
 set_bit(cpumask_check(cpu), ((dstp)->bits));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __cpumask_set_cpu(unsigned int cpu, struct cpumask *dstp)
{
 __set_bit(cpumask_check(cpu), ((dstp)->bits));
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_clear_cpu(int cpu, struct cpumask *dstp)
{
 clear_bit(cpumask_check(cpu), ((dstp)->bits));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __cpumask_clear_cpu(int cpu, struct cpumask *dstp)
{
 __clear_bit(cpumask_check(cpu), ((dstp)->bits));
}
# 371 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_test_cpu(int cpu, const struct cpumask *cpumask)
{
 return test_bit(cpumask_check(cpu), (((cpumask))->bits));
}
# 385 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_test_and_set_cpu(int cpu, struct cpumask *cpumask)
{
 return test_and_set_bit(cpumask_check(cpu), ((cpumask)->bits));
}
# 399 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_test_and_clear_cpu(int cpu, struct cpumask *cpumask)
{
 return test_and_clear_bit(cpumask_check(cpu), ((cpumask)->bits));
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_setall(struct cpumask *dstp)
{
 bitmap_fill(((dstp)->bits), ((unsigned int)16));
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_clear(struct cpumask *dstp)
{
 bitmap_zero(((dstp)->bits), ((unsigned int)16));
}
# 430 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_and(struct cpumask *dstp,
          const struct cpumask *src1p,
          const struct cpumask *src2p)
{
 return bitmap_and(((dstp)->bits), ((src1p)->bits),
           ((src2p)->bits), ((unsigned int)16));
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_or(struct cpumask *dstp, const struct cpumask *src1p,
         const struct cpumask *src2p)
{
 bitmap_or(((dstp)->bits), ((src1p)->bits),
          ((src2p)->bits), ((unsigned int)16));
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_xor(struct cpumask *dstp,
          const struct cpumask *src1p,
          const struct cpumask *src2p)
{
 bitmap_xor(((dstp)->bits), ((src1p)->bits),
           ((src2p)->bits), ((unsigned int)16));
}
# 473 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_andnot(struct cpumask *dstp,
      const struct cpumask *src1p,
      const struct cpumask *src2p)
{
 return bitmap_andnot(((dstp)->bits), ((src1p)->bits),
       ((src2p)->bits), ((unsigned int)16));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_complement(struct cpumask *dstp,
          const struct cpumask *srcp)
{
 bitmap_complement(((dstp)->bits), ((srcp)->bits),
           ((unsigned int)16));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpumask_equal(const struct cpumask *src1p,
    const struct cpumask *src2p)
{
 return bitmap_equal(((src1p)->bits), ((src2p)->bits),
       ((unsigned int)16));
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpumask_or_equal(const struct cpumask *src1p,
        const struct cpumask *src2p,
        const struct cpumask *src3p)
{
 return bitmap_or_equal(((src1p)->bits), ((src2p)->bits),
          ((src3p)->bits), ((unsigned int)16));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpumask_intersects(const struct cpumask *src1p,
         const struct cpumask *src2p)
{
 return bitmap_intersects(((src1p)->bits), ((src2p)->bits),
            ((unsigned int)16));
}
# 538 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_subset(const struct cpumask *src1p,
     const struct cpumask *src2p)
{
 return bitmap_subset(((src1p)->bits), ((src2p)->bits),
        ((unsigned int)16));
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpumask_empty(const struct cpumask *srcp)
{
 return bitmap_empty(((srcp)->bits), ((unsigned int)16));
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpumask_full(const struct cpumask *srcp)
{
 return bitmap_full(((srcp)->bits), ((unsigned int)16));
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpumask_weight(const struct cpumask *srcp)
{
 return bitmap_weight(((srcp)->bits), ((unsigned int)16));
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_shift_right(struct cpumask *dstp,
           const struct cpumask *srcp, int n)
{
 bitmap_shift_right(((dstp)->bits), ((srcp)->bits), n,
            ((unsigned int)16));
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_shift_left(struct cpumask *dstp,
          const struct cpumask *srcp, int n)
{
 bitmap_shift_left(((dstp)->bits), ((srcp)->bits), n,
           ((unsigned int)16));
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpumask_copy(struct cpumask *dstp,
    const struct cpumask *srcp)
{
 bitmap_copy(((dstp)->bits), ((srcp)->bits), ((unsigned int)16));
}
# 649 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_parse_user(const char *buf, int len,
         struct cpumask *dstp)
{
 return bitmap_parse_user(buf, len, ((dstp)->bits), ((unsigned int)16));
}
# 663 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_parselist_user(const char *buf, int len,
         struct cpumask *dstp)
{
 return bitmap_parselist_user(buf, len, ((dstp)->bits),
         ((unsigned int)16));
}
# 677 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpumask_parse(const char *buf, struct cpumask *dstp)
{
 return bitmap_parse(buf, (~0U), ((dstp)->bits), ((unsigned int)16));
}
# 689 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpulist_parse(const char *buf, struct cpumask *dstp)
{
 return bitmap_parselist(buf, ((dstp)->bits), ((unsigned int)16));
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int cpumask_size(void)
{
 return (((((unsigned int)16)) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8))) * sizeof(long);
}
# 762 "/home/nathan/src/linux/include/linux/cpumask.h"
typedef struct cpumask cpumask_var_t[1];




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool alloc_cpumask_var(cpumask_var_t *mask, gfp_t flags)
{
 return true;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool alloc_cpumask_var_node(cpumask_var_t *mask, gfp_t flags,
       int node)
{
 return true;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool zalloc_cpumask_var(cpumask_var_t *mask, gfp_t flags)
{
 cpumask_clear(*mask);
 return true;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool zalloc_cpumask_var_node(cpumask_var_t *mask, gfp_t flags,
       int node)
{
 cpumask_clear(*mask);
 return true;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void alloc_bootmem_cpumask_var(cpumask_var_t *mask)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void free_cpumask_var(cpumask_var_t mask)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void free_bootmem_cpumask_var(cpumask_var_t mask)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpumask_available(cpumask_var_t mask)
{
 return true;
}




extern const unsigned long cpu_all_bits[(((16) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8)))];
# 822 "/home/nathan/src/linux/include/linux/cpumask.h"
void init_cpu_present(const struct cpumask *src);
void init_cpu_possible(const struct cpumask *src);
void init_cpu_online(const struct cpumask *src);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void reset_cpu_possible_mask(void)
{
 bitmap_zero(((&__cpu_possible_mask)->bits), 16);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
set_cpu_possible(unsigned int cpu, bool possible)
{
 if (possible)
  cpumask_set_cpu(cpu, &__cpu_possible_mask);
 else
  cpumask_clear_cpu(cpu, &__cpu_possible_mask);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
set_cpu_present(unsigned int cpu, bool present)
{
 if (present)
  cpumask_set_cpu(cpu, &__cpu_present_mask);
 else
  cpumask_clear_cpu(cpu, &__cpu_present_mask);
}

void set_cpu_online(unsigned int cpu, bool online);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
set_cpu_active(unsigned int cpu, bool active)
{
 if (active)
  cpumask_set_cpu(cpu, &__cpu_active_mask);
 else
  cpumask_clear_cpu(cpu, &__cpu_active_mask);
}
# 875 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __check_is_bitmap(const unsigned long *bitmap)
{
 return 1;
}
# 887 "/home/nathan/src/linux/include/linux/cpumask.h"
extern const unsigned long
 cpu_bit_bitmap[32 +1][(((16) + ((sizeof(long) * 8)) - 1) / ((sizeof(long) * 8)))];

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) const struct cpumask *get_cpu_mask(unsigned int cpu)
{
 const unsigned long *p = cpu_bit_bitmap[1 + cpu % 32];
 p -= cpu / 32;
 return ((struct cpumask *)(1 ? (p) : (void *)sizeof(__check_is_bitmap(p))));
}
# 924 "/home/nathan/src/linux/include/linux/cpumask.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ssize_t
cpumap_print_to_pagebuf(bool list, char *buf, const struct cpumask *mask)
{
 return bitmap_print_to_pagebuf(list, buf, ((mask)->bits),
          nr_cpu_ids);
}
# 14 "/home/nathan/src/linux/include/linux/smp.h" 2

# 1 "/home/nathan/src/linux/include/linux/smp_types.h" 1




# 1 "/home/nathan/src/linux/include/linux/llist.h" 1
# 54 "/home/nathan/src/linux/include/linux/llist.h"
struct llist_head {
 struct llist_node *first;
};

struct llist_node {
 struct llist_node *next;
};
# 69 "/home/nathan/src/linux/include/linux/llist.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void init_llist_head(struct llist_head *list)
{
 list->first = ((void *)0);
}
# 187 "/home/nathan/src/linux/include/linux/llist.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool llist_empty(const struct llist_head *head)
{
 return ({ do { extern void __compiletime_assert_32(void) ; if (!((sizeof(head->first) == sizeof(char) || sizeof(head->first) == sizeof(short) || sizeof(head->first) == sizeof(int) || sizeof(head->first) == sizeof(long)) || sizeof(head->first) == sizeof(long long))) __compiletime_assert_32(); } while (0); (*(const volatile typeof( _Generic((head->first), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (head->first))) *)&(head->first)); }) == ((void *)0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct llist_node *llist_next(struct llist_node *node)
{
 return node->next;
}

extern bool llist_add_batch(struct llist_node *new_first,
       struct llist_node *new_last,
       struct llist_head *head);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __llist_add_batch(struct llist_node *new_first,
         struct llist_node *new_last,
         struct llist_head *head)
{
 new_last->next = head->first;
 head->first = new_first;
 return new_last->next == ((void *)0);
}
# 217 "/home/nathan/src/linux/include/linux/llist.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool llist_add(struct llist_node *new, struct llist_head *head)
{
 return llist_add_batch(new, new, head);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __llist_add(struct llist_node *new, struct llist_head *head)
{
 return __llist_add_batch(new, new, head);
}
# 235 "/home/nathan/src/linux/include/linux/llist.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct llist_node *llist_del_all(struct llist_head *head)
{
 return ({ __typeof__(*(&head->first)) __res; if (!0) do { } while (0); __res = (__typeof__(*(&head->first))) __xchg((&head->first), (unsigned long)(((void *)0)), sizeof(*(&head->first))); do { } while (0); __res; });
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct llist_node *__llist_del_all(struct llist_head *head)
{
 struct llist_node *first = head->first;

 head->first = ((void *)0);
 return first;
}

extern struct llist_node *llist_del_first(struct llist_head *head);

struct llist_node *llist_reverse_order(struct llist_node *head);
# 6 "/home/nathan/src/linux/include/linux/smp_types.h" 2

enum {
 CSD_FLAG_LOCK = 0x01,

 IRQ_WORK_PENDING = 0x01,
 IRQ_WORK_BUSY = 0x02,
 IRQ_WORK_LAZY = 0x04,
 IRQ_WORK_HARD_IRQ = 0x08,

 IRQ_WORK_CLAIMED = (IRQ_WORK_PENDING | IRQ_WORK_BUSY),

 CSD_TYPE_ASYNC = 0x00,
 CSD_TYPE_SYNC = 0x10,
 CSD_TYPE_IRQ_WORK = 0x20,
 CSD_TYPE_TTWU = 0x30,

 CSD_FLAG_TYPE_MASK = 0xF0,
};
# 58 "/home/nathan/src/linux/include/linux/smp_types.h"
struct __call_single_node {
 struct llist_node llist;
 union {
  unsigned int u_flags;
  atomic_t a_flags;
 };



};
# 16 "/home/nathan/src/linux/include/linux/smp.h" 2

typedef void (*smp_call_func_t)(void *info);
typedef bool (*smp_cond_func_t)(int cpu, void *info);




struct __call_single_data {
 struct __call_single_node node;
 smp_call_func_t func;
 void *info;
};





typedef struct __call_single_data call_single_data_t
 __attribute__((__aligned__(sizeof(struct __call_single_data))));
# 45 "/home/nathan/src/linux/include/linux/smp.h"
extern void __smp_call_single_queue(int cpu, struct llist_node *node);


extern unsigned int total_cpus;

int smp_call_function_single(int cpuid, smp_call_func_t func, void *info,
        int wait);




void on_each_cpu(smp_call_func_t func, void *info, int wait);





void on_each_cpu_mask(const struct cpumask *mask, smp_call_func_t func,
  void *info, bool wait);






void on_each_cpu_cond(smp_cond_func_t cond_func, smp_call_func_t func,
        void *info, bool wait);

void on_each_cpu_cond_mask(smp_cond_func_t cond_func, smp_call_func_t func,
      void *info, bool wait, const struct cpumask *mask);

int smp_call_function_single_async(int cpu, call_single_data_t *csd);




# 1 "/home/nathan/src/linux/include/linux/preempt.h" 1
# 78 "/home/nathan/src/linux/include/linux/preempt.h"
# 1 "./arch/mips/include/generated/asm/preempt.h" 1
# 1 "/home/nathan/src/linux/include/asm-generic/preempt.h" 1




# 1 "/home/nathan/src/linux/include/linux/thread_info.h" 1
# 13 "/home/nathan/src/linux/include/linux/thread_info.h"
# 1 "/home/nathan/src/linux/include/linux/restart_block.h" 1
# 12 "/home/nathan/src/linux/include/linux/restart_block.h"
struct timespec;
struct old_timespec32;
struct pollfd;

enum timespec_type {
 TT_NONE = 0,
 TT_NATIVE = 1,
 TT_COMPAT = 2,
};




struct restart_block {
 long (*fn)(struct restart_block *);
 union {

  struct {
   u32 *uaddr;
   u32 val;
   u32 flags;
   u32 bitset;
   u64 time;
   u32 *uaddr2;
  } futex;

  struct {
   clockid_t clockid;
   enum timespec_type type;
   union {
    struct __kernel_timespec *rmtp;
    struct old_timespec32 *compat_rmtp;
   };
   u64 expires;
  } nanosleep;

  struct {
   struct pollfd *ufds;
   int nfds;
   int has_timeout;
   unsigned long tv_sec;
   unsigned long tv_nsec;
  } poll;
 };
};

extern long do_no_restart_syscall(struct restart_block *parm);
# 14 "/home/nathan/src/linux/include/linux/thread_info.h" 2
# 31 "/home/nathan/src/linux/include/linux/thread_info.h"
enum {
 BAD_STACK = -1,
 NOT_STACK = 0,
 GOOD_FRAME,
 GOOD_STACK,
};
# 56 "/home/nathan/src/linux/include/linux/thread_info.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/thread_info.h" 1
# 16 "/home/nathan/src/linux/arch/mips/include/asm/thread_info.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/processor.h" 1
# 16 "/home/nathan/src/linux/arch/mips/include/asm/processor.h"
# 1 "/home/nathan/src/linux/include/linux/sizes.h" 1
# 17 "/home/nathan/src/linux/arch/mips/include/asm/processor.h" 2


# 1 "/home/nathan/src/linux/arch/mips/include/uapi/asm/cachectl.h" 1
# 20 "/home/nathan/src/linux/arch/mips/include/asm/processor.h" 2


# 1 "/home/nathan/src/linux/arch/mips/include/asm/dsemul.h" 1
# 11 "/home/nathan/src/linux/arch/mips/include/asm/dsemul.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/inst.h" 1
# 14 "/home/nathan/src/linux/arch/mips/include/asm/inst.h"
# 1 "/home/nathan/src/linux/arch/mips/include/uapi/asm/inst.h" 1
# 17 "/home/nathan/src/linux/arch/mips/include/uapi/asm/inst.h"
# 1 "/home/nathan/src/linux/arch/mips/include/uapi/asm/bitfield.h" 1
# 18 "/home/nathan/src/linux/arch/mips/include/uapi/asm/inst.h" 2




enum major_op {
 spec_op, bcond_op, j_op, jal_op,
 beq_op, bne_op, blez_op, bgtz_op,
 addi_op, pop10_op = addi_op, addiu_op, slti_op, sltiu_op,
 andi_op, ori_op, xori_op, lui_op,
 cop0_op, cop1_op, cop2_op, cop1x_op,
 beql_op, bnel_op, blezl_op, bgtzl_op,
 daddi_op, pop30_op = daddi_op, daddiu_op, ldl_op, ldr_op,
 spec2_op, jalx_op, mdmx_op, msa_op = mdmx_op, spec3_op,
 lb_op, lh_op, lwl_op, lw_op,
 lbu_op, lhu_op, lwr_op, lwu_op,
 sb_op, sh_op, swl_op, sw_op,
 sdl_op, sdr_op, swr_op, cache_op,
 ll_op, lwc1_op, lwc2_op, bc6_op = lwc2_op, pref_op,
 lld_op, ldc1_op, ldc2_op, pop66_op = ldc2_op, ld_op,
 sc_op, swc1_op, swc2_op, balc6_op = swc2_op, major_3b_op,
 scd_op, sdc1_op, sdc2_op, pop76_op = sdc2_op, sd_op
};




enum spec_op {
 sll_op, movc_op, srl_op, sra_op,
 sllv_op, pmon_op, srlv_op, srav_op,
 jr_op, jalr_op, movz_op, movn_op,
 syscall_op, break_op, spim_op, sync_op,
 mfhi_op, mthi_op, mflo_op, mtlo_op,
 dsllv_op, spec2_unused_op, dsrlv_op, dsrav_op,
 mult_op, multu_op, div_op, divu_op,
 dmult_op, dmultu_op, ddiv_op, ddivu_op,
 add_op, addu_op, sub_op, subu_op,
 and_op, or_op, xor_op, nor_op,
 spec3_unused_op, spec4_unused_op, slt_op, sltu_op,
 dadd_op, daddu_op, dsub_op, dsubu_op,
 tge_op, tgeu_op, tlt_op, tltu_op,
 teq_op, seleqz_op, tne_op, selnez_op,
 dsll_op, spec5_unused_op, dsrl_op, dsra_op,
 dsll32_op, spec6_unused_op, dsrl32_op, dsra32_op
};




enum spec2_op {
 madd_op, maddu_op, mul_op, spec2_3_unused_op,
 msub_op, msubu_op,
 clz_op = 0x20, clo_op,
 dclz_op = 0x24, dclo_op,
 sdbpp_op = 0x3f
};




enum spec3_op {
 ext_op, dextm_op, dextu_op, dext_op,
 ins_op, dinsm_op, dinsu_op, dins_op,
 yield_op = 0x09, lx_op = 0x0a,
 lwle_op = 0x19, lwre_op = 0x1a,
 cachee_op = 0x1b, sbe_op = 0x1c,
 she_op = 0x1d, sce_op = 0x1e,
 swe_op = 0x1f, bshfl_op = 0x20,
 swle_op = 0x21, swre_op = 0x22,
 prefe_op = 0x23, dbshfl_op = 0x24,
 cache6_op = 0x25, sc6_op = 0x26,
 scd6_op = 0x27, lbue_op = 0x28,
 lhue_op = 0x29, lbe_op = 0x2c,
 lhe_op = 0x2d, lle_op = 0x2e,
 lwe_op = 0x2f, pref6_op = 0x35,
 ll6_op = 0x36, lld6_op = 0x37,
 rdhwr_op = 0x3b
};




enum mult_op {
 mult_mult_op = 0x0,
 mult_mul_op = 0x2,
 mult_muh_op = 0x3,
};
enum multu_op {
 multu_multu_op = 0x0,
 multu_mulu_op = 0x2,
 multu_muhu_op = 0x3,
};
enum div_op {
 div_div_op = 0x0,
 div_div6_op = 0x2,
 div_mod_op = 0x3,
};
enum divu_op {
 divu_divu_op = 0x0,
 divu_divu6_op = 0x2,
 divu_modu_op = 0x3,
};
enum dmult_op {
 dmult_dmult_op = 0x0,
 dmult_dmul_op = 0x2,
 dmult_dmuh_op = 0x3,
};
enum dmultu_op {
 dmultu_dmultu_op = 0x0,
 dmultu_dmulu_op = 0x2,
 dmultu_dmuhu_op = 0x3,
};
enum ddiv_op {
 ddiv_ddiv_op = 0x0,
 ddiv_ddiv6_op = 0x2,
 ddiv_dmod_op = 0x3,
};
enum ddivu_op {
 ddivu_ddivu_op = 0x0,
 ddivu_ddivu6_op = 0x2,
 ddivu_dmodu_op = 0x3,
};




enum rt_op {
 bltz_op, bgez_op, bltzl_op, bgezl_op,
 spimi_op, unused_rt_op_0x05, unused_rt_op_0x06, unused_rt_op_0x07,
 tgei_op, tgeiu_op, tlti_op, tltiu_op,
 teqi_op, unused_0x0d_rt_op, tnei_op, unused_0x0f_rt_op,
 bltzal_op, bgezal_op, bltzall_op, bgezall_op,
 rt_op_0x14, rt_op_0x15, rt_op_0x16, rt_op_0x17,
 rt_op_0x18, rt_op_0x19, rt_op_0x1a, rt_op_0x1b,
 bposge32_op, rt_op_0x1d, rt_op_0x1e, synci_op
};




enum cop_op {
 mfc_op = 0x00, dmfc_op = 0x01,
 cfc_op = 0x02, mfhc0_op = 0x02,
 mfhc_op = 0x03, mtc_op = 0x04,
 dmtc_op = 0x05, ctc_op = 0x06,
 mthc0_op = 0x06, mthc_op = 0x07,
 bc_op = 0x08, bc1eqz_op = 0x09,
 mfmc0_op = 0x0b, bc1nez_op = 0x0d,
 wrpgpr_op = 0x0e, cop_op = 0x10,
 copm_op = 0x18
};




enum bcop_op {
 bcf_op, bct_op, bcfl_op, bctl_op
};




enum cop0_coi_func {
 tlbr_op = 0x01, tlbwi_op = 0x02,
 tlbwr_op = 0x06, tlbp_op = 0x08,
 rfe_op = 0x10, eret_op = 0x18,
 wait_op = 0x20, hypcall_op = 0x28
};




enum cop0_com_func {
 tlbr1_op = 0x01, tlbw_op = 0x02,
 tlbp1_op = 0x08, dctr_op = 0x09,
 dctw_op = 0x0a
};




enum cop1_fmt {
 s_fmt, d_fmt, e_fmt, q_fmt,
 w_fmt, l_fmt
};




enum cop1_sdw_func {
 fadd_op = 0x00, fsub_op = 0x01,
 fmul_op = 0x02, fdiv_op = 0x03,
 fsqrt_op = 0x04, fabs_op = 0x05,
 fmov_op = 0x06, fneg_op = 0x07,
 froundl_op = 0x08, ftruncl_op = 0x09,
 fceill_op = 0x0a, ffloorl_op = 0x0b,
 fround_op = 0x0c, ftrunc_op = 0x0d,
 fceil_op = 0x0e, ffloor_op = 0x0f,
 fsel_op = 0x10,
 fmovc_op = 0x11, fmovz_op = 0x12,
 fmovn_op = 0x13, fseleqz_op = 0x14,
 frecip_op = 0x15, frsqrt_op = 0x16,
 fselnez_op = 0x17, fmaddf_op = 0x18,
 fmsubf_op = 0x19, frint_op = 0x1a,
 fclass_op = 0x1b, fmin_op = 0x1c,
 fmina_op = 0x1d, fmax_op = 0x1e,
 fmaxa_op = 0x1f, fcvts_op = 0x20,
 fcvtd_op = 0x21, fcvte_op = 0x22,
 fcvtw_op = 0x24, fcvtl_op = 0x25,
 fcmp_op = 0x30
};




enum cop1x_func {
 lwxc1_op = 0x00, ldxc1_op = 0x01,
 swxc1_op = 0x08, sdxc1_op = 0x09,
 pfetch_op = 0x0f, madd_s_op = 0x20,
 madd_d_op = 0x21, madd_e_op = 0x22,
 msub_s_op = 0x28, msub_d_op = 0x29,
 msub_e_op = 0x2a, nmadd_s_op = 0x30,
 nmadd_d_op = 0x31, nmadd_e_op = 0x32,
 nmsub_s_op = 0x38, nmsub_d_op = 0x39,
 nmsub_e_op = 0x3a
};




enum mad_func {
 madd_fp_op = 0x08, msub_fp_op = 0x0a,
 nmadd_fp_op = 0x0c, nmsub_fp_op = 0x0e
};




enum ptw_func {
 lwdir_op = 0x00,
 lwpte_op = 0x01,
 lddir_op = 0x02,
 ldpte_op = 0x03,
};




enum lx_func {
 lwx_op = 0x00,
 lhx_op = 0x04,
 lbux_op = 0x06,
 ldx_op = 0x08,
 lwux_op = 0x10,
 lhux_op = 0x14,
 lbx_op = 0x16,
};




enum bshfl_func {
 wsbh_op = 0x2,
 seb_op = 0x10,
 seh_op = 0x18,
};




enum dbshfl_func {
 dsbh_op = 0x2,
 dshd_op = 0x5,
};




enum msa_func {
 msa_elm_op = 0x19,
};




enum msa_elm {
 msa_ctc_op = 0x3e,
 msa_cfc_op = 0x7e,
};




enum msa_mi10_func {
 msa_ld_op = 8,
 msa_st_op = 9,
};




enum msa_2b_fmt {
 msa_fmt_b = 0,
 msa_fmt_h = 1,
 msa_fmt_w = 2,
 msa_fmt_d = 3,
};




enum mm_major_op {
 mm_pool32a_op, mm_pool16a_op, mm_lbu16_op, mm_move16_op,
 mm_addi32_op, mm_lbu32_op, mm_sb32_op, mm_lb32_op,
 mm_pool32b_op, mm_pool16b_op, mm_lhu16_op, mm_andi16_op,
 mm_addiu32_op, mm_lhu32_op, mm_sh32_op, mm_lh32_op,
 mm_pool32i_op, mm_pool16c_op, mm_lwsp16_op, mm_pool16d_op,
 mm_ori32_op, mm_pool32f_op, mm_pool32s_op, mm_reserved2_op,
 mm_pool32c_op, mm_lwgp16_op, mm_lw16_op, mm_pool16e_op,
 mm_xori32_op, mm_jals32_op, mm_addiupc_op, mm_reserved3_op,
 mm_reserved4_op, mm_pool16f_op, mm_sb16_op, mm_beqz16_op,
 mm_slti32_op, mm_beq32_op, mm_swc132_op, mm_lwc132_op,
 mm_reserved5_op, mm_reserved6_op, mm_sh16_op, mm_bnez16_op,
 mm_sltiu32_op, mm_bne32_op, mm_sdc132_op, mm_ldc132_op,
 mm_reserved7_op, mm_reserved8_op, mm_swsp16_op, mm_b16_op,
 mm_andi32_op, mm_j32_op, mm_sd32_op, mm_ld32_op,
 mm_reserved11_op, mm_reserved12_op, mm_sw16_op, mm_li16_op,
 mm_jalx32_op, mm_jal32_op, mm_sw32_op, mm_lw32_op,
};




enum mm_32i_minor_op {
 mm_bltz_op, mm_bltzal_op, mm_bgez_op, mm_bgezal_op,
 mm_blez_op, mm_bnezc_op, mm_bgtz_op, mm_beqzc_op,
 mm_tlti_op, mm_tgei_op, mm_tltiu_op, mm_tgeiu_op,
 mm_tnei_op, mm_lui_op, mm_teqi_op, mm_reserved13_op,
 mm_synci_op, mm_bltzals_op, mm_reserved14_op, mm_bgezals_op,
 mm_bc2f_op, mm_bc2t_op, mm_reserved15_op, mm_reserved16_op,
 mm_reserved17_op, mm_reserved18_op, mm_bposge64_op, mm_bposge32_op,
 mm_bc1f_op, mm_bc1t_op, mm_reserved19_op, mm_reserved20_op,
 mm_bc1any2f_op, mm_bc1any2t_op, mm_bc1any4f_op, mm_bc1any4t_op,
};




enum mm_32a_minor_op {
 mm_sll32_op = 0x000,
 mm_ins_op = 0x00c,
 mm_sllv32_op = 0x010,
 mm_ext_op = 0x02c,
 mm_pool32axf_op = 0x03c,
 mm_srl32_op = 0x040,
 mm_srlv32_op = 0x050,
 mm_sra_op = 0x080,
 mm_srav_op = 0x090,
 mm_rotr_op = 0x0c0,
 mm_lwxs_op = 0x118,
 mm_addu32_op = 0x150,
 mm_subu32_op = 0x1d0,
 mm_wsbh_op = 0x1ec,
 mm_mul_op = 0x210,
 mm_and_op = 0x250,
 mm_or32_op = 0x290,
 mm_xor32_op = 0x310,
 mm_slt_op = 0x350,
 mm_sltu_op = 0x390,
};




enum mm_32b_func {
 mm_lwc2_func = 0x0,
 mm_lwp_func = 0x1,
 mm_ldc2_func = 0x2,
 mm_ldp_func = 0x4,
 mm_lwm32_func = 0x5,
 mm_cache_func = 0x6,
 mm_ldm_func = 0x7,
 mm_swc2_func = 0x8,
 mm_swp_func = 0x9,
 mm_sdc2_func = 0xa,
 mm_sdp_func = 0xc,
 mm_swm32_func = 0xd,
 mm_sdm_func = 0xf,
};




enum mm_32c_func {
 mm_pref_func = 0x2,
 mm_ll_func = 0x3,
 mm_swr_func = 0x9,
 mm_sc_func = 0xb,
 mm_lwu_func = 0xe,
};




enum mm_32axf_minor_op {
 mm_mfc0_op = 0x003,
 mm_mtc0_op = 0x00b,
 mm_tlbp_op = 0x00d,
 mm_mfhi32_op = 0x035,
 mm_jalr_op = 0x03c,
 mm_tlbr_op = 0x04d,
 mm_mflo32_op = 0x075,
 mm_jalrhb_op = 0x07c,
 mm_tlbwi_op = 0x08d,
 mm_mthi32_op = 0x0b5,
 mm_tlbwr_op = 0x0cd,
 mm_mtlo32_op = 0x0f5,
 mm_di_op = 0x11d,
 mm_jalrs_op = 0x13c,
 mm_jalrshb_op = 0x17c,
 mm_sync_op = 0x1ad,
 mm_syscall_op = 0x22d,
 mm_wait_op = 0x24d,
 mm_eret_op = 0x3cd,
 mm_divu_op = 0x5dc,
};




enum mm_32f_minor_op {
 mm_32f_00_op = 0x00,
 mm_32f_01_op = 0x01,
 mm_32f_02_op = 0x02,
 mm_32f_10_op = 0x08,
 mm_32f_11_op = 0x09,
 mm_32f_12_op = 0x0a,
 mm_32f_20_op = 0x10,
 mm_32f_30_op = 0x18,
 mm_32f_40_op = 0x20,
 mm_32f_41_op = 0x21,
 mm_32f_42_op = 0x22,
 mm_32f_50_op = 0x28,
 mm_32f_51_op = 0x29,
 mm_32f_52_op = 0x2a,
 mm_32f_60_op = 0x30,
 mm_32f_70_op = 0x38,
 mm_32f_73_op = 0x3b,
 mm_32f_74_op = 0x3c,
};




enum mm_32f_10_minor_op {
 mm_lwxc1_op = 0x1,
 mm_swxc1_op,
 mm_ldxc1_op,
 mm_sdxc1_op,
 mm_luxc1_op,
 mm_suxc1_op,
};

enum mm_32f_func {
 mm_lwxc1_func = 0x048,
 mm_swxc1_func = 0x088,
 mm_ldxc1_func = 0x0c8,
 mm_sdxc1_func = 0x108,
};




enum mm_32f_40_minor_op {
 mm_fmovf_op,
 mm_fmovt_op,
};




enum mm_32f_60_minor_op {
 mm_fadd_op,
 mm_fsub_op,
 mm_fmul_op,
 mm_fdiv_op,
};




enum mm_32f_70_minor_op {
 mm_fmovn_op,
 mm_fmovz_op,
};




enum mm_32f_73_minor_op {
 mm_fmov0_op = 0x01,
 mm_fcvtl_op = 0x04,
 mm_movf0_op = 0x05,
 mm_frsqrt_op = 0x08,
 mm_ffloorl_op = 0x0c,
 mm_fabs0_op = 0x0d,
 mm_fcvtw_op = 0x24,
 mm_movt0_op = 0x25,
 mm_fsqrt_op = 0x28,
 mm_ffloorw_op = 0x2c,
 mm_fneg0_op = 0x2d,
 mm_cfc1_op = 0x40,
 mm_frecip_op = 0x48,
 mm_fceill_op = 0x4c,
 mm_fcvtd0_op = 0x4d,
 mm_ctc1_op = 0x60,
 mm_fceilw_op = 0x6c,
 mm_fcvts0_op = 0x6d,
 mm_mfc1_op = 0x80,
 mm_fmov1_op = 0x81,
 mm_movf1_op = 0x85,
 mm_ftruncl_op = 0x8c,
 mm_fabs1_op = 0x8d,
 mm_mtc1_op = 0xa0,
 mm_movt1_op = 0xa5,
 mm_ftruncw_op = 0xac,
 mm_fneg1_op = 0xad,
 mm_mfhc1_op = 0xc0,
 mm_froundl_op = 0xcc,
 mm_fcvtd1_op = 0xcd,
 mm_mthc1_op = 0xe0,
 mm_froundw_op = 0xec,
 mm_fcvts1_op = 0xed,
};




enum mm_32s_minor_op {
 mm_32s_elm_op = 0x16,
};




enum mm_16c_minor_op {
 mm_lwm16_op = 0x04,
 mm_swm16_op = 0x05,
 mm_jr16_op = 0x0c,
 mm_jrc_op = 0x0d,
 mm_jalr16_op = 0x0e,
 mm_jalrs16_op = 0x0f,
 mm_jraddiusp_op = 0x18,
};




enum mm_16d_minor_op {
 mm_addius5_func,
 mm_addiusp_func,
};




enum MIPS16e_ops {
 MIPS16e_jal_op = 003,
 MIPS16e_ld_op = 007,
 MIPS16e_i8_op = 014,
 MIPS16e_sd_op = 017,
 MIPS16e_lb_op = 020,
 MIPS16e_lh_op = 021,
 MIPS16e_lwsp_op = 022,
 MIPS16e_lw_op = 023,
 MIPS16e_lbu_op = 024,
 MIPS16e_lhu_op = 025,
 MIPS16e_lwpc_op = 026,
 MIPS16e_lwu_op = 027,
 MIPS16e_sb_op = 030,
 MIPS16e_sh_op = 031,
 MIPS16e_swsp_op = 032,
 MIPS16e_sw_op = 033,
 MIPS16e_rr_op = 035,
 MIPS16e_extend_op = 036,
 MIPS16e_i64_op = 037,
};

enum MIPS16e_i64_func {
 MIPS16e_ldsp_func,
 MIPS16e_sdsp_func,
 MIPS16e_sdrasp_func,
 MIPS16e_dadjsp_func,
 MIPS16e_ldpc_func,
};

enum MIPS16e_rr_func {
 MIPS16e_jr_func,
};

enum MIPS6e_i8_func {
 MIPS16e_swrasp_func = 02,
};






struct j_format {
 unsigned int opcode : 6; unsigned int target : 26; ;


};

struct i_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int rt : 5; signed int simmediate : 16; ;




};

struct u_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int rt : 5; unsigned int uimmediate : 16; ;




};

struct c_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int c_op : 3; unsigned int cache : 2; unsigned int simmediate : 16; ;





};

struct r_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int rt : 5; unsigned int rd : 5; unsigned int re : 5; unsigned int func : 6; ;






};

struct c0r_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int rt : 5; unsigned int rd : 5; unsigned int z: 8; unsigned int sel : 3; ;






};

struct mfmc0_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int rt : 5; unsigned int rd : 5; unsigned int re : 5; unsigned int sc : 1; unsigned int : 2; unsigned int sel : 3; ;
# 687 "/home/nathan/src/linux/arch/mips/include/uapi/asm/inst.h"
};

struct co_format {
 unsigned int opcode : 6; unsigned int co : 1; unsigned int code : 19; unsigned int func : 6; ;




};

struct p_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int rt : 5; unsigned int rd : 5; unsigned int re : 5; unsigned int func : 6; ;






};

struct f_format {
 unsigned int opcode : 6; unsigned int : 1; unsigned int fmt : 4; unsigned int rt : 5; unsigned int rd : 5; unsigned int re : 5; unsigned int func : 6; ;







};

struct ma_format {
 unsigned int opcode : 6; unsigned int fr : 5; unsigned int ft : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int func : 4; unsigned int fmt : 2; ;







};

struct b_format {
 unsigned int opcode : 6; unsigned int code : 20; unsigned int func : 6; ;



};

struct ps_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int ft : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int func : 6; ;






};

struct v_format {
 unsigned int opcode : 6; unsigned int sel : 4; unsigned int fmt : 1; unsigned int vt : 5; unsigned int vs : 5; unsigned int vd : 5; unsigned int func : 6; ;







};

struct msa_mi10_format {
 unsigned int opcode : 6; signed int s10 : 10; unsigned int rs : 5; unsigned int wd : 5; unsigned int func : 4; unsigned int df : 2; ;






};

struct dsp_format {
 unsigned int opcode : 6; unsigned int base : 5; unsigned int index : 5; unsigned int rd : 5; unsigned int op : 5; unsigned int func : 6; ;






};

struct spec3_format {
 unsigned int opcode:6; unsigned int rs:5; unsigned int rt:5; signed int simmediate:9; unsigned int func:7; ;





};
# 793 "/home/nathan/src/linux/arch/mips/include/uapi/asm/inst.h"
struct fb_format {
 unsigned int opcode : 6; unsigned int bc : 5; unsigned int cc : 3; unsigned int flag : 2; signed int simmediate : 16; ;





};

struct fp0_format {
 unsigned int opcode : 6; unsigned int fmt : 5; unsigned int ft : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int func : 6; ;






};

struct mm_fp0_format {
 unsigned int opcode : 6; unsigned int ft : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int fmt : 3; unsigned int op : 2; unsigned int func : 6; ;







};

struct fp1_format {
 unsigned int opcode : 6; unsigned int op : 5; unsigned int rt : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int func : 6; ;






};

struct mm_fp1_format {
 unsigned int opcode : 6; unsigned int rt : 5; unsigned int fs : 5; unsigned int fmt : 2; unsigned int op : 8; unsigned int func : 6; ;






};

struct mm_fp2_format {
 unsigned int opcode : 6; unsigned int fd : 5; unsigned int fs : 5; unsigned int cc : 3; unsigned int zero : 2; unsigned int fmt : 2; unsigned int op : 3; unsigned int func : 6; ;
# 853 "/home/nathan/src/linux/arch/mips/include/uapi/asm/inst.h"
};

struct mm_fp3_format {
 unsigned int opcode : 6; unsigned int rt : 5; unsigned int fs : 5; unsigned int fmt : 3; unsigned int op : 7; unsigned int func : 6; ;






};

struct mm_fp4_format {
 unsigned int opcode : 6; unsigned int rt : 5; unsigned int fs : 5; unsigned int cc : 3; unsigned int fmt : 3; unsigned int cond : 4; unsigned int func : 6; ;







};

struct mm_fp5_format {
 unsigned int opcode : 6; unsigned int index : 5; unsigned int base : 5; unsigned int fd : 5; unsigned int op : 5; unsigned int func : 6; ;






};

struct fp6_format {
 unsigned int opcode : 6; unsigned int fr : 5; unsigned int ft : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int func : 6; ;






};

struct mm_fp6_format {
 unsigned int opcode : 6; unsigned int ft : 5; unsigned int fs : 5; unsigned int fd : 5; unsigned int fr : 5; unsigned int func : 6; ;






};

struct mm_i_format {
 unsigned int opcode : 6; unsigned int rt : 5; unsigned int rs : 5; signed int simmediate : 16; ;




};

struct mm_m_format {
 unsigned int opcode : 6; unsigned int rd : 5; unsigned int base : 5; unsigned int func : 4; signed int simmediate : 12; ;





};

struct mm_x_format {
 unsigned int opcode : 6; unsigned int index : 5; unsigned int base : 5; unsigned int rd : 5; unsigned int func : 11; ;





};

struct mm_a_format {
 unsigned int opcode : 6; unsigned int rs : 3; signed int simmediate : 23; ;



};




struct mm_b0_format {
 unsigned int opcode : 6; signed int simmediate : 10; unsigned int : 16; ;



};

struct mm_b1_format {
 unsigned int opcode : 6; unsigned int rs : 3; signed int simmediate : 7; unsigned int : 16; ;




};

struct mm16_m_format {
 unsigned int opcode : 6; unsigned int func : 4; unsigned int rlist : 2; unsigned int imm : 4; unsigned int : 16; ;





};

struct mm16_rb_format {
 unsigned int opcode : 6; unsigned int rt : 3; unsigned int base : 3; signed int simmediate : 4; unsigned int : 16; ;





};

struct mm16_r3_format {
 unsigned int opcode : 6; unsigned int rt : 3; signed int simmediate : 7; unsigned int : 16; ;




};

struct mm16_r5_format {
 unsigned int opcode : 6; unsigned int rt : 5; unsigned int imm : 5; unsigned int : 16; ;




};




struct loongson3_lswc2_format {
 unsigned int opcode : 6; unsigned int base : 5; unsigned int rt : 5; unsigned int fr : 1; unsigned int offset : 9; unsigned int ls : 1; unsigned int rq : 5; ;







};

struct loongson3_lsdc2_format {
 unsigned int opcode : 6; unsigned int base : 5; unsigned int rt : 5; unsigned int index : 5; unsigned int offset : 8; unsigned int opcode1 : 3; ;






};

struct loongson3_lscsr_format {
 unsigned int opcode : 6; unsigned int rs : 5; unsigned int fr : 5; unsigned int rd : 5; unsigned int fd : 5; unsigned int func : 6; ;






};




struct m16e_rr {
 unsigned int opcode : 5; unsigned int rx : 3; unsigned int nd : 1; unsigned int l : 1; unsigned int ra : 1; unsigned int func : 5; ;






};

struct m16e_jal {
 unsigned int opcode : 5; unsigned int x : 1; unsigned int imm20_16 : 5; signed int imm25_21 : 5; ;




};

struct m16e_i64 {
 unsigned int opcode : 5; unsigned int func : 3; unsigned int imm : 8; ;



};

struct m16e_ri64 {
 unsigned int opcode : 5; unsigned int func : 3; unsigned int ry : 3; unsigned int imm : 5; ;




};

struct m16e_ri {
 unsigned int opcode : 5; unsigned int rx : 3; unsigned int imm : 8; ;



};

struct m16e_rri {
 unsigned int opcode : 5; unsigned int rx : 3; unsigned int ry : 3; unsigned int imm : 5; ;




};

struct m16e_i8 {
 unsigned int opcode : 5; unsigned int func : 3; unsigned int imm : 8; ;



};

union mips_instruction {
 unsigned int word;
 unsigned short halfword[2];
 unsigned char byte[4];
 struct j_format j_format;
 struct i_format i_format;
 struct u_format u_format;
 struct c_format c_format;
 struct r_format r_format;
 struct c0r_format c0r_format;
 struct mfmc0_format mfmc0_format;
 struct co_format co_format;
 struct p_format p_format;
 struct f_format f_format;
 struct ma_format ma_format;
 struct msa_mi10_format msa_mi10_format;
 struct b_format b_format;
 struct ps_format ps_format;
 struct v_format v_format;
 struct dsp_format dsp_format;
 struct spec3_format spec3_format;
 struct fb_format fb_format;
 struct fp0_format fp0_format;
 struct mm_fp0_format mm_fp0_format;
 struct fp1_format fp1_format;
 struct mm_fp1_format mm_fp1_format;
 struct mm_fp2_format mm_fp2_format;
 struct mm_fp3_format mm_fp3_format;
 struct mm_fp4_format mm_fp4_format;
 struct mm_fp5_format mm_fp5_format;
 struct fp6_format fp6_format;
 struct mm_fp6_format mm_fp6_format;
 struct mm_i_format mm_i_format;
 struct mm_m_format mm_m_format;
 struct mm_x_format mm_x_format;
 struct mm_a_format mm_a_format;
 struct mm_b0_format mm_b0_format;
 struct mm_b1_format mm_b1_format;
 struct mm16_m_format mm16_m_format ;
 struct mm16_rb_format mm16_rb_format;
 struct mm16_r3_format mm16_r3_format;
 struct mm16_r5_format mm16_r5_format;
 struct loongson3_lswc2_format loongson3_lswc2_format;
 struct loongson3_lsdc2_format loongson3_lsdc2_format;
 struct loongson3_lscsr_format loongson3_lscsr_format;
};

union mips16e_instruction {
 unsigned int full : 16;
 struct m16e_rr rr;
 struct m16e_jal jal;
 struct m16e_i64 i64;
 struct m16e_ri64 ri64;
 struct m16e_ri ri;
 struct m16e_rri rri;
 struct m16e_i8 i8;
};
# 15 "/home/nathan/src/linux/arch/mips/include/asm/inst.h" 2
# 74 "/home/nathan/src/linux/arch/mips/include/asm/inst.h"
typedef unsigned int mips_instruction;


struct mm_decoded_insn {
 mips_instruction insn;
 mips_instruction next_insn;
 int pc_inc;
 int next_pc_inc;
 int micro_mips_mode;
};


extern const int reg16to32[];
# 12 "/home/nathan/src/linux/arch/mips/include/asm/dsemul.h" 2







struct mm_struct;
struct pt_regs;
struct task_struct;
# 37 "/home/nathan/src/linux/arch/mips/include/asm/dsemul.h"
extern int mips_dsemul(struct pt_regs *regs, mips_instruction ir,
         unsigned long branch_pc, unsigned long cont_pc);
# 52 "/home/nathan/src/linux/arch/mips/include/asm/dsemul.h"
extern bool do_dsemulret(struct pt_regs *xcp);
# 70 "/home/nathan/src/linux/arch/mips/include/asm/dsemul.h"
extern bool dsemul_thread_cleanup(struct task_struct *tsk);
# 90 "/home/nathan/src/linux/arch/mips/include/asm/dsemul.h"
extern bool dsemul_thread_rollback(struct pt_regs *regs);
# 107 "/home/nathan/src/linux/arch/mips/include/asm/dsemul.h"
extern void dsemul_mm_cleanup(struct mm_struct *mm);
# 23 "/home/nathan/src/linux/arch/mips/include/asm/processor.h" 2

# 1 "/home/nathan/src/linux/arch/mips/include/asm/prefetch.h" 1
# 25 "/home/nathan/src/linux/arch/mips/include/asm/processor.h" 2
# 1 "/home/nathan/src/linux/arch/mips/include/asm/vdso/processor.h" 1
# 26 "/home/nathan/src/linux/arch/mips/include/asm/processor.h" 2





extern unsigned int vced_count, vcei_count;
extern int arch_dup_task_struct(struct task_struct *dst, struct task_struct *src);
# 78 "/home/nathan/src/linux/arch/mips/include/asm/processor.h"
extern unsigned long mips_stack_top(void);
# 96 "/home/nathan/src/linux/arch/mips/include/asm/processor.h"
union fpureg {
 __u32 val32[64 / 32];
 __u64 val64[64 / 64];
};
# 119 "/home/nathan/src/linux/arch/mips/include/asm/processor.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 get_fpr32(union fpureg *fpr, unsigned idx) { return fpr->val32[((idx) ^ ((64 / (32)) - 1))]; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_fpr32(union fpureg *fpr, unsigned idx, u32 val) { fpr->val32[((idx) ^ ((64 / (32)) - 1))] = val; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 get_fpr64(union fpureg *fpr, unsigned idx) { return fpr->val64[((idx) ^ ((64 / (64)) - 1))]; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_fpr64(union fpureg *fpr, unsigned idx, u64 val) { fpr->val64[((idx) ^ ((64 / (64)) - 1))] = val; }







struct mips_fpu_struct {
 union fpureg fpr[32];
 unsigned int fcr31;
 unsigned int msacsr;
};



typedef unsigned long dspreg_t;

struct mips_dsp_state {
 dspreg_t dspr[6];
 unsigned int dspcontrol;
};





struct mips3264_watch_reg_state {



 unsigned long watchlo[4];

 u16 watchhi[4];
};

union mips_watch_reg_state {
 struct mips3264_watch_reg_state mips3264;
};
# 229 "/home/nathan/src/linux/arch/mips/include/asm/processor.h"
typedef struct {
 unsigned long seg;
} mm_segment_t;
# 241 "/home/nathan/src/linux/arch/mips/include/asm/processor.h"
struct mips_abi;




struct thread_struct {

 unsigned long reg16;
 unsigned long reg17, reg18, reg19, reg20, reg21, reg22, reg23;
 unsigned long reg29, reg30, reg31;


 unsigned long cp0_status;



 struct mips_fpu_struct fpu ;

 atomic_t bd_emu_frame;

 unsigned long bd_emu_branch_pc;

 unsigned long bd_emu_cont_pc;
# 273 "/home/nathan/src/linux/arch/mips/include/asm/processor.h"
 struct mips_dsp_state dsp;


 union mips_watch_reg_state watch;


 unsigned long cp0_badvaddr;
 unsigned long cp0_baduaddr;
 unsigned long error_code;
 unsigned long trap_nr;







 struct mips_abi *abi;
};
# 367 "/home/nathan/src/linux/arch/mips/include/asm/processor.h"
struct task_struct;







extern void start_thread(struct pt_regs * regs, unsigned long pc, unsigned long sp);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void flush_thread(void)
{
}

unsigned long get_wchan(struct task_struct *p);
# 418 "/home/nathan/src/linux/arch/mips/include/asm/processor.h"
extern int mips_get_process_fp_mode(struct task_struct *task);
extern int mips_set_process_fp_mode(struct task_struct *task,
        unsigned int value);
# 17 "/home/nathan/src/linux/arch/mips/include/asm/thread_info.h" 2








struct thread_info {
 struct task_struct *task;
 unsigned long flags;
 unsigned long tp_value;
 __u32 cpu;
 int preempt_count;
 mm_segment_t addr_limit;




 struct pt_regs *regs;
 long syscall;
};
# 70 "/home/nathan/src/linux/arch/mips/include/asm/thread_info.h"
register struct thread_info *__current_thread_info __asm__("$28");


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct thread_info *current_thread_info(void)
{
 return __current_thread_info;
}
# 57 "/home/nathan/src/linux/include/linux/thread_info.h" 2
# 71 "/home/nathan/src/linux/include/linux/thread_info.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_ti_thread_flag(struct thread_info *ti, int flag)
{
 set_bit(flag, (unsigned long *)&ti->flags);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_ti_thread_flag(struct thread_info *ti, int flag)
{
 clear_bit(flag, (unsigned long *)&ti->flags);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void update_ti_thread_flag(struct thread_info *ti, int flag,
      bool value)
{
 if (value)
  set_ti_thread_flag(ti, flag);
 else
  clear_ti_thread_flag(ti, flag);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_set_ti_thread_flag(struct thread_info *ti, int flag)
{
 return test_and_set_bit(flag, (unsigned long *)&ti->flags);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_and_clear_ti_thread_flag(struct thread_info *ti, int flag)
{
 return test_and_clear_bit(flag, (unsigned long *)&ti->flags);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int test_ti_thread_flag(struct thread_info *ti, int flag)
{
 return test_bit(flag, (unsigned long *)&ti->flags);
}
# 153 "/home/nathan/src/linux/include/linux/thread_info.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_within_stack_frames(const void * const stack,
        const void * const stackend,
        const void *obj, unsigned long len)
{
 return 0;
}
# 172 "/home/nathan/src/linux/include/linux/thread_info.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void check_object_size(const void *ptr, unsigned long n,
         bool to_user)
{ }


extern void
__bad_copy_from(void);
extern void
__bad_copy_to(void);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void copy_overflow(int size, unsigned long count)
{
 ({ int __ret_warn_on = !!(1); if (__builtin_expect(!!(__ret_warn_on), 0)) do { do { } while(0); warn_slowpath_fmt("include/linux/thread_info.h", 184, 9, "Buffer overflow detected (%d < %lu)!\n", size, count); do { } while(0); } while (0); __builtin_expect(!!(__ret_warn_on), 0); });
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __attribute__((__warn_unused_result__)) bool
check_copy_size(const void *addr, size_t bytes, bool is_source)
{
 int sz = -1;
 if (__builtin_expect(!!(sz >= 0 && sz < bytes), 0)) {
  if (!__builtin_constant_p(bytes))
   copy_overflow(sz, bytes);
  else if (is_source)
   __bad_copy_from();
  else
   __bad_copy_to();
  return false;
 }
 if (({ static bool __attribute__((__section__(".data.once"))) __warned; int __ret_warn_once = !!(bytes > ((int)(~0U >> 1))); if (__builtin_expect(!!(__ret_warn_once && !__warned), 0)) { __warned = true; ({ int __ret_warn_on = !!(1); if (__builtin_expect(!!(__ret_warn_on), 0)) do { do { } while(0); warn_slowpath_fmt("include/linux/thread_info.h", 200, 9, ((void *)0)); do { } while(0); } while (0); __builtin_expect(!!(__ret_warn_on), 0); }); } __builtin_expect(!!(__ret_warn_once), 0); }))
  return false;
 check_object_size(addr, bytes, is_source);
 return true;
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_setup_new_exec(void) { }
# 6 "/home/nathan/src/linux/include/asm-generic/preempt.h" 2



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int preempt_count(void)
{
 return ({ do { extern void __compiletime_assert_33(void) ; if (!((sizeof(current_thread_info()->preempt_count) == sizeof(char) || sizeof(current_thread_info()->preempt_count) == sizeof(short) || sizeof(current_thread_info()->preempt_count) == sizeof(int) || sizeof(current_thread_info()->preempt_count) == sizeof(long)) || sizeof(current_thread_info()->preempt_count) == sizeof(long long))) __compiletime_assert_33(); } while (0); (*(const volatile typeof( _Generic((current_thread_info()->preempt_count), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (current_thread_info()->preempt_count))) *)&(current_thread_info()->preempt_count)); });
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) volatile int *preempt_count_ptr(void)
{
 return &current_thread_info()->preempt_count;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void preempt_count_set(int pc)
{
 *preempt_count_ptr() = pc;
}
# 35 "/home/nathan/src/linux/include/asm-generic/preempt.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void set_preempt_need_resched(void)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void clear_preempt_need_resched(void)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool test_preempt_need_resched(void)
{
 return false;
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __preempt_count_add(int val)
{
 *preempt_count_ptr() += val;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __preempt_count_sub(int val)
{
 *preempt_count_ptr() -= val;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool __preempt_count_dec_and_test(void)
{





 return !--*preempt_count_ptr() && test_ti_thread_flag(current_thread_info(), 2);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool should_resched(int preempt_offset)
{
 return __builtin_expect(!!(preempt_count() == preempt_offset && test_ti_thread_flag(current_thread_info(), 2)), 0);

}
# 2 "./arch/mips/include/generated/asm/preempt.h" 2
# 79 "/home/nathan/src/linux/include/linux/preempt.h" 2
# 384 "/home/nathan/src/linux/include/linux/preempt.h"
extern void migrate_disable(void);
extern void migrate_enable(void);
# 81 "/home/nathan/src/linux/include/linux/smp.h" 2



# 1 "/home/nathan/src/linux/arch/mips/include/asm/smp.h" 1
# 16 "/home/nathan/src/linux/arch/mips/include/asm/smp.h"
# 1 "/home/nathan/src/linux/include/linux/smp.h" 1
# 17 "/home/nathan/src/linux/arch/mips/include/asm/smp.h" 2




# 1 "/home/nathan/src/linux/arch/mips/include/asm/smp-ops.h" 1
# 16 "/home/nathan/src/linux/arch/mips/include/asm/smp-ops.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/mips-cps.h" 1
# 10 "/home/nathan/src/linux/arch/mips/include/asm/mips-cps.h"
# 1 "/home/nathan/src/linux/include/linux/io.h" 1
# 12 "/home/nathan/src/linux/include/linux/io.h"
# 1 "/home/nathan/src/linux/include/linux/err.h" 1
# 24 "/home/nathan/src/linux/include/linux/err.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void * __attribute__((__warn_unused_result__)) ERR_PTR(long error)
{
 return (void *) error;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) long __attribute__((__warn_unused_result__)) PTR_ERR( const void *ptr)
{
 return (long) ptr;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __attribute__((__warn_unused_result__)) IS_ERR( const void *ptr)
{
 return __builtin_expect(!!((unsigned long)(void *)((unsigned long)ptr) >= (unsigned long)-4095), 0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __attribute__((__warn_unused_result__)) IS_ERR_OR_NULL( const void *ptr)
{
 return __builtin_expect(!!(!ptr), 0) || __builtin_expect(!!((unsigned long)(void *)((unsigned long)ptr) >= (unsigned long)-4095), 0);
}
# 51 "/home/nathan/src/linux/include/linux/err.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void * __attribute__((__warn_unused_result__)) ERR_CAST( const void *ptr)
{

 return (void *) ptr;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) PTR_ERR_OR_ZERO( const void *ptr)
{
 if (IS_ERR(ptr))
  return PTR_ERR(ptr);
 else
  return 0;
}
# 13 "/home/nathan/src/linux/include/linux/io.h" 2
# 1 "/home/nathan/src/linux/arch/mips/include/asm/io.h" 1
# 28 "/home/nathan/src/linux/arch/mips/include/asm/io.h"
# 1 "/home/nathan/src/linux/include/asm-generic/iomap.h" 1
# 29 "/home/nathan/src/linux/include/asm-generic/iomap.h"
extern unsigned int ioread8(const void *);
extern unsigned int ioread16(const void *);
extern unsigned int ioread16be(const void *);
extern unsigned int ioread32(const void *);
extern unsigned int ioread32be(const void *);
# 50 "/home/nathan/src/linux/include/asm-generic/iomap.h"
extern void iowrite8(u8, void *);
extern void iowrite16(u16, void *);
extern void iowrite16be(u16, void *);
extern void iowrite32(u32, void *);
extern void iowrite32be(u32, void *);
# 82 "/home/nathan/src/linux/include/asm-generic/iomap.h"
extern void ioread8_rep(const void *port, void *buf, unsigned long count);
extern void ioread16_rep(const void *port, void *buf, unsigned long count);
extern void ioread32_rep(const void *port, void *buf, unsigned long count);

extern void iowrite8_rep(void *port, const void *buf, unsigned long count);
extern void iowrite16_rep(void *port, const void *buf, unsigned long count);
extern void iowrite32_rep(void *port, const void *buf, unsigned long count);



extern void *ioport_map(unsigned long port, unsigned int nr);
extern void ioport_unmap(void *);
# 106 "/home/nathan/src/linux/include/asm-generic/iomap.h"
struct pci_dev;
extern void pci_iounmap(struct pci_dev *dev, void *);







# 1 "/home/nathan/src/linux/include/asm-generic/pci_iomap.h" 1
# 10 "/home/nathan/src/linux/include/asm-generic/pci_iomap.h"
struct pci_dev;


extern void *pci_iomap(struct pci_dev *dev, int bar, unsigned long max);
extern void *pci_iomap_wc(struct pci_dev *dev, int bar, unsigned long max);
extern void *pci_iomap_range(struct pci_dev *dev, int bar,
         unsigned long offset,
         unsigned long maxlen);
extern void *pci_iomap_wc_range(struct pci_dev *dev, int bar,
     unsigned long offset,
     unsigned long maxlen);
# 115 "/home/nathan/src/linux/include/asm-generic/iomap.h" 2
# 29 "/home/nathan/src/linux/arch/mips/include/asm/io.h" 2
# 1 "/home/nathan/src/linux/arch/mips/include/asm/page.h" 1
# 42 "/home/nathan/src/linux/arch/mips/include/asm/page.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int page_size_ftlb(unsigned int mmuextdef)
{
 switch (mmuextdef) {
 case ((unsigned long)(2) << 14):
  if (((1UL) << 12) == (1 << 30))
   return 5;
  if (((1UL) << 12) == (1llu << 32))
   return 6;
  if (((1UL) << 12) > (256 << 10))
   return 7;
  __attribute__((__fallthrough__));
 case ((unsigned long)(3) << 14):
  return (12 - 10) / 2;
 default:
  panic("Invalid FTLB configuration with Conf4_mmuextdef=%d value\n",
        mmuextdef >> 14);
 }
}
# 73 "/home/nathan/src/linux/arch/mips/include/asm/page.h"
# 1 "/home/nathan/src/linux/include/linux/pfn.h" 1
# 13 "/home/nathan/src/linux/include/linux/pfn.h"
typedef struct {
 u64 val;
} pfn_t;
# 74 "/home/nathan/src/linux/arch/mips/include/asm/page.h" 2

extern void build_clear_page(void);
extern void build_copy_page(void);







extern unsigned long ARCH_PFN_OFFSET;





extern void clear_page(void * page);
extern void copy_page(void * to, void * from);

extern unsigned long shm_align_mask;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long pages_do_alias(unsigned long addr1,
 unsigned long addr2)
{
 return (addr1 ^ addr2) & shm_align_mask;
}

struct page;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_user_page(void *addr, unsigned long vaddr,
 struct page *page)
{
 extern void (*flush_data_cache_page)(unsigned long addr);

 clear_page(addr);
 if (pages_do_alias((unsigned long) addr, vaddr & (~((1 << 12) - 1))))
  flush_data_cache_page((unsigned long)addr);
}

struct vm_area_struct;
extern void copy_user_highpage(struct page *to, struct page *from,
 unsigned long vaddr, struct vm_area_struct *vma);
# 133 "/home/nathan/src/linux/arch/mips/include/asm/page.h"
typedef struct { unsigned long pte; } pte_t;



typedef struct page *pgtable_t;
# 147 "/home/nathan/src/linux/arch/mips/include/asm/page.h"
typedef struct { unsigned long pgd; } pgd_t;






typedef struct { unsigned long pgprot; } pgprot_t;
# 171 "/home/nathan/src/linux/arch/mips/include/asm/page.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long ___pa(unsigned long x)
{
 if (0) {





  return x < 0x80000000 ? (((__s64)(x)) & 0x0000ffffffffffffLL) : (((int)(int)(x)) & 0x1fffffff);
 }

 if (!0) {






  return (((int)(int)(x)) & 0x1fffffff);
 }





 return x - ((0x80000000UL) + ((unsigned long)((phys_addr_t)(ARCH_PFN_OFFSET) << 12))) + ((unsigned long)((phys_addr_t)(ARCH_PFN_OFFSET) << 12));
}



# 1 "/home/nathan/src/linux/arch/mips/include/asm/io.h" 1
# 201 "/home/nathan/src/linux/arch/mips/include/asm/page.h" 2
# 223 "/home/nathan/src/linux/arch/mips/include/asm/page.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int pfn_valid(unsigned long pfn)
{

 extern unsigned long max_mapnr;
 unsigned long pfn_offset = ARCH_PFN_OFFSET;

 return pfn >= pfn_offset && pfn < max_mapnr;
}
# 252 "/home/nathan/src/linux/arch/mips/include/asm/page.h"
extern bool __virt_addr_valid(const volatile void *kaddr);






# 1 "/home/nathan/src/linux/include/asm-generic/memory_model.h" 1
# 259 "/home/nathan/src/linux/arch/mips/include/asm/page.h" 2
# 1 "/home/nathan/src/linux/include/asm-generic/getorder.h" 1
# 29 "/home/nathan/src/linux/include/asm-generic/getorder.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) __attribute__((__const__)) int get_order(unsigned long size)
{
 if (__builtin_constant_p(size)) {
  if (!size)
   return 32 - 12;

  if (size < (1UL << 12))
   return 0;

  return ( __builtin_constant_p((size) - 1) ? (((size) - 1) < 2 ? 0 : 63 - __builtin_clzll((size) - 1)) : (sizeof((size) - 1) <= 4) ? __ilog2_u32((size) - 1) : __ilog2_u64((size) - 1) ) - 12 + 1;
 }

 size--;
 size >>= 12;

 return fls(size);



}
# 260 "/home/nathan/src/linux/arch/mips/include/asm/page.h" 2
# 30 "/home/nathan/src/linux/arch/mips/include/asm/io.h" 2
# 1 "/home/nathan/src/linux/arch/mips/include/asm/pgtable-bits.h" 1
# 122 "/home/nathan/src/linux/arch/mips/include/asm/pgtable-bits.h"
enum pgtable_bits {

 _PAGE_PRESENT_SHIFT,



 _PAGE_WRITE_SHIFT,
 _PAGE_ACCESSED_SHIFT,
 _PAGE_MODIFIED_SHIFT,
# 142 "/home/nathan/src/linux/arch/mips/include/asm/pgtable-bits.h"
 _PAGE_NO_EXEC_SHIFT,
 _PAGE_NO_READ_SHIFT,

 _PAGE_GLOBAL_SHIFT,
 _PAGE_VALID_SHIFT,
 _PAGE_DIRTY_SHIFT,
 _CACHE_SHIFT,
};
# 214 "/home/nathan/src/linux/arch/mips/include/asm/pgtable-bits.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t pte_to_entrylo(unsigned long pte_val)
{

 if (((6 >= (6)) || (cpu_data[0].options & (((((1ULL))) << (23)))))) {
  int sa;

  sa = 31 - _PAGE_NO_READ_SHIFT;
# 229 "/home/nathan/src/linux/arch/mips/include/asm/pgtable-bits.h"
  return (pte_val >> _PAGE_GLOBAL_SHIFT) |
   ((pte_val & ((((6 >= (6)) || (cpu_data[0].options & (((((1ULL))) << (23))))) ? (1 << _PAGE_NO_EXEC_SHIFT) : 0) | (1 << _PAGE_NO_READ_SHIFT))) << sa);
 }


 return pte_val >> _PAGE_GLOBAL_SHIFT;
}
# 31 "/home/nathan/src/linux/arch/mips/include/asm/io.h" 2


# 1 "/home/nathan/src/linux/arch/mips/include/asm/mach-generic/mangle-port.h" 1
# 34 "/home/nathan/src/linux/arch/mips/include/asm/io.h" 2
# 62 "/home/nathan/src/linux/arch/mips/include/asm/io.h"
extern unsigned long mips_io_port_base;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_io_port_base(unsigned long base)
{
 mips_io_port_base = base;
}
# 103 "/home/nathan/src/linux/arch/mips/include/asm/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long virt_to_phys(volatile const void *address)
{
 return ___pa((unsigned long)(address));
}
# 120 "/home/nathan/src/linux/arch/mips/include/asm/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void * phys_to_virt(unsigned long address)
{
 return (void *)(address + ((0x80000000UL) + ((unsigned long)((phys_addr_t)(ARCH_PFN_OFFSET) << 12))) - ((unsigned long)((phys_addr_t)(ARCH_PFN_OFFSET) << 12)));
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long isa_virt_to_bus(volatile void *address)
{
 return virt_to_phys(address);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *isa_bus_to_virt(unsigned long address)
{
 return phys_to_virt(address);
}
# 152 "/home/nathan/src/linux/arch/mips/include/asm/io.h"
void *ioremap_prot(phys_addr_t offset, unsigned long size,
  unsigned long prot_val);
void iounmap(const volatile void *addr);
# 350 "/home/nathan/src/linux/arch/mips/include/asm/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_writeb(u8 val, volatile void *mem) { volatile u8 *__mem; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u8 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 __raw_readb(const volatile void *mem) { volatile u8 *__mem; u8 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __relaxed_writeb(u8 val, volatile void *mem) { volatile u8 *__mem; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u8 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 __relaxed_readb(const volatile void *mem) { volatile u8 *__mem; u8 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!1) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_writeb(u8 val, volatile void *mem) { volatile u8 *__mem; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u8 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 __mem_readb(const volatile void *mem) { volatile u8 *__mem; u8 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void writeb(u8 val, volatile void *mem) { volatile u8 *__mem; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u8 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 readb(const volatile void *mem) { volatile u8 *__mem; u8 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u8) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_writew(u16 val, volatile void *mem) { volatile u16 *__mem; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u16 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 __raw_readw(const volatile void *mem) { volatile u16 *__mem; u16 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __relaxed_writew(u16 val, volatile void *mem) { volatile u16 *__mem; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (__builtin_constant_p((__u16)(( __u16)(__le16)(( __le16)(val)))) ? ((__u16)( (((__u16)(( __u16)(__le16)(( __le16)(val))) & (__u16)0x00ffU) << 8) | (((__u16)(( __u16)(__le16)(( __le16)(val))) & (__u16)0xff00U) >> 8))) : __fswab16(( __u16)(__le16)(( __le16)(val)))); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u16 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 __relaxed_readw(const volatile void *mem) { volatile u16 *__mem; u16 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!1) rmb(); return (__builtin_constant_p((__u16)(( __u16)(__le16)(( __le16)(__val)))) ? ((__u16)( (((__u16)(( __u16)(__le16)(( __le16)(__val))) & (__u16)0x00ffU) << 8) | (((__u16)(( __u16)(__le16)(( __le16)(__val))) & (__u16)0xff00U) >> 8))) : __fswab16(( __u16)(__le16)(( __le16)(__val)))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_writew(u16 val, volatile void *mem) { volatile u16 *__mem; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u16 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 __mem_readw(const volatile void *mem) { volatile u16 *__mem; u16 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void writew(u16 val, volatile void *mem) { volatile u16 *__mem; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (__builtin_constant_p((__u16)(( __u16)(__le16)(( __le16)(val)))) ? ((__u16)( (((__u16)(( __u16)(__le16)(( __le16)(val))) & (__u16)0x00ffU) << 8) | (((__u16)(( __u16)(__le16)(( __le16)(val))) & (__u16)0xff00U) >> 8))) : __fswab16(( __u16)(__le16)(( __le16)(val)))); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u16 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 readw(const volatile void *mem) { volatile u16 *__mem; u16 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u16) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__builtin_constant_p((__u16)(( __u16)(__le16)(( __le16)(__val)))) ? ((__u16)( (((__u16)(( __u16)(__le16)(( __le16)(__val))) & (__u16)0x00ffU) << 8) | (((__u16)(( __u16)(__le16)(( __le16)(__val))) & (__u16)0xff00U) >> 8))) : __fswab16(( __u16)(__le16)(( __le16)(__val)))); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_writel(u32 val, volatile void *mem) { volatile u32 *__mem; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u32 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 __raw_readl(const volatile void *mem) { volatile u32 *__mem; u32 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __relaxed_writel(u32 val, volatile void *mem) { volatile u32 *__mem; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (__builtin_constant_p((__u32)(( __u32)(__le32)(( __le32)(val)))) ? ((__u32)( (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(( __le32)(val)))); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u32 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 __relaxed_readl(const volatile void *mem) { volatile u32 *__mem; u32 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!1) rmb(); return (__builtin_constant_p((__u32)(( __u32)(__le32)(( __le32)(__val)))) ? ((__u32)( (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(( __le32)(__val)))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_writel(u32 val, volatile void *mem) { volatile u32 *__mem; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u32 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 __mem_readl(const volatile void *mem) { volatile u32 *__mem; u32 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void writel(u32 val, volatile void *mem) { volatile u32 *__mem; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (__builtin_constant_p((__u32)(( __u32)(__le32)(( __le32)(val)))) ? ((__u32)( (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(( __le32)(val)))); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u32 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 readl(const volatile void *mem) { volatile u32 *__mem; u32 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u32) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__builtin_constant_p((__u32)(( __u32)(__le32)(( __le32)(__val)))) ? ((__u32)( (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(( __le32)(__val)))); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_writeq(u64 val, volatile void *mem) { volatile u64 *__mem; u64 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u64) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u64 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 __raw_readq(const volatile void *mem) { volatile u64 *__mem; u64 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u64) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_writeq(u64 val, volatile void *mem) { volatile u64 *__mem; u64 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u64) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u64 __tmp; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 __mem_readq(const volatile void *mem) { volatile u64 *__mem; u64 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u64) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (1) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); }
# 368 "/home/nathan/src/linux/arch/mips/include/asm/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outb(u8 val, unsigned long port) { volatile u8 *__addr; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { extern void __compiletime_assert_34(void) ; if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_34(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 inb(unsigned long port) { volatile u8 *__addr; u8 __val; __addr = (void *)(mips_io_port_base + port); do { extern void __compiletime_assert_35(void) ; if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_35(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outb_p(u8 val, unsigned long port) { volatile u8 *__addr; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { extern void __compiletime_assert_36(void) ; if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_36(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 inb_p(unsigned long port) { volatile u8 *__addr; u8 __val; __addr = (void *)(mips_io_port_base + port); do { extern void __compiletime_assert_37(void) ; if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_37(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_outb(u8 val, unsigned long port) { volatile u8 *__addr; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { extern void __compiletime_assert_38(void) ; if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_38(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 __mem_inb(unsigned long port) { volatile u8 *__addr; u8 __val; __addr = (void *)(mips_io_port_base + port); do { extern void __compiletime_assert_39(void) ; if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_39(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_outb_p(u8 val, unsigned long port) { volatile u8 *__addr; u8 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { extern void __compiletime_assert_40(void) ; if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_40(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u8 __mem_inb_p(unsigned long port) { volatile u8 *__addr; u8 __val; __addr = (void *)(mips_io_port_base + port); do { extern void __compiletime_assert_41(void) ; if (!(!(sizeof(u8) > sizeof(unsigned long)))) __compiletime_assert_41(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outw(u16 val, unsigned long port) { volatile u16 *__addr; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (__builtin_constant_p((__u16)(( __u16)(__le16)(( __le16)(val)))) ? ((__u16)( (((__u16)(( __u16)(__le16)(( __le16)(val))) & (__u16)0x00ffU) << 8) | (((__u16)(( __u16)(__le16)(( __le16)(val))) & (__u16)0xff00U) >> 8))) : __fswab16(( __u16)(__le16)(( __le16)(val)))); do { extern void __compiletime_assert_42(void) ; if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_42(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 inw(unsigned long port) { volatile u16 *__addr; u16 __val; __addr = (void *)(mips_io_port_base + port); do { extern void __compiletime_assert_43(void) ; if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_43(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__builtin_constant_p((__u16)(( __u16)(__le16)(( __le16)(__val)))) ? ((__u16)( (((__u16)(( __u16)(__le16)(( __le16)(__val))) & (__u16)0x00ffU) << 8) | (((__u16)(( __u16)(__le16)(( __le16)(__val))) & (__u16)0xff00U) >> 8))) : __fswab16(( __u16)(__le16)(( __le16)(__val)))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outw_p(u16 val, unsigned long port) { volatile u16 *__addr; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (__builtin_constant_p((__u16)(( __u16)(__le16)(( __le16)(val)))) ? ((__u16)( (((__u16)(( __u16)(__le16)(( __le16)(val))) & (__u16)0x00ffU) << 8) | (((__u16)(( __u16)(__le16)(( __le16)(val))) & (__u16)0xff00U) >> 8))) : __fswab16(( __u16)(__le16)(( __le16)(val)))); do { extern void __compiletime_assert_44(void) ; if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_44(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 inw_p(unsigned long port) { volatile u16 *__addr; u16 __val; __addr = (void *)(mips_io_port_base + port); do { extern void __compiletime_assert_45(void) ; if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_45(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__builtin_constant_p((__u16)(( __u16)(__le16)(( __le16)(__val)))) ? ((__u16)( (((__u16)(( __u16)(__le16)(( __le16)(__val))) & (__u16)0x00ffU) << 8) | (((__u16)(( __u16)(__le16)(( __le16)(__val))) & (__u16)0xff00U) >> 8))) : __fswab16(( __u16)(__le16)(( __le16)(__val)))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_outw(u16 val, unsigned long port) { volatile u16 *__addr; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { extern void __compiletime_assert_46(void) ; if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_46(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 __mem_inw(unsigned long port) { volatile u16 *__addr; u16 __val; __addr = (void *)(mips_io_port_base + port); do { extern void __compiletime_assert_47(void) ; if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_47(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_outw_p(u16 val, unsigned long port) { volatile u16 *__addr; u16 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { extern void __compiletime_assert_48(void) ; if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_48(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u16 __mem_inw_p(unsigned long port) { volatile u16 *__addr; u16 __val; __addr = (void *)(mips_io_port_base + port); do { extern void __compiletime_assert_49(void) ; if (!(!(sizeof(u16) > sizeof(unsigned long)))) __compiletime_assert_49(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outl(u32 val, unsigned long port) { volatile u32 *__addr; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (__builtin_constant_p((__u32)(( __u32)(__le32)(( __le32)(val)))) ? ((__u32)( (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(( __le32)(val)))); do { extern void __compiletime_assert_50(void) ; if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_50(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 inl(unsigned long port) { volatile u32 *__addr; u32 __val; __addr = (void *)(mips_io_port_base + port); do { extern void __compiletime_assert_51(void) ; if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_51(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__builtin_constant_p((__u32)(( __u32)(__le32)(( __le32)(__val)))) ? ((__u32)( (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(( __le32)(__val)))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outl_p(u32 val, unsigned long port) { volatile u32 *__addr; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (__builtin_constant_p((__u32)(( __u32)(__le32)(( __le32)(val)))) ? ((__u32)( (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(( __le32)(val))) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(( __le32)(val)))); do { extern void __compiletime_assert_52(void) ; if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_52(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 inl_p(unsigned long port) { volatile u32 *__addr; u32 __val; __addr = (void *)(mips_io_port_base + port); do { extern void __compiletime_assert_53(void) ; if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_53(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__builtin_constant_p((__u32)(( __u32)(__le32)(( __le32)(__val)))) ? ((__u32)( (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0x000000ffUL) << 24) | (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0x0000ff00UL) << 8) | (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0x00ff0000UL) >> 8) | (((__u32)(( __u32)(__le32)(( __le32)(__val))) & (__u32)0xff000000UL) >> 24))) : __fswab32(( __u32)(__le32)(( __le32)(__val)))); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_outl(u32 val, unsigned long port) { volatile u32 *__addr; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { extern void __compiletime_assert_54(void) ; if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_54(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 __mem_inl(unsigned long port) { volatile u32 *__addr; u32 __val; __addr = (void *)(mips_io_port_base + port); do { extern void __compiletime_assert_55(void) ; if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_55(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __mem_outl_p(u32 val, unsigned long port) { volatile u32 *__addr; u32 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __addr = (void *)(mips_io_port_base + port); __val = (val); do { extern void __compiletime_assert_56(void) ; if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_56(); } while (0); *__addr = __val; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u32 __mem_inl_p(unsigned long port) { volatile u32 *__addr; u32 __val; __addr = (void *)(mips_io_port_base + port); do { extern void __compiletime_assert_57(void) ; if (!(!(sizeof(u32) > sizeof(unsigned long)))) __compiletime_assert_57(); } while (0); if (1) __sync(); __val = *__addr; if (!0) rmb(); return (__val); }
# 379 "/home/nathan/src/linux/arch/mips/include/asm/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ____raw_writeq(u64 val, volatile void *mem) { volatile u64 *__mem; u64 __val; if (1) __sync(); else __asm__ __volatile__("": : :"memory"); __mem = (void *)((unsigned long)(mem)); __val = (val); if (sizeof(u64) != sizeof(u64) || sizeof(u64) == sizeof(long)) *__mem = __val; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; u64 __tmp; if (0) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __writeq""\n\t" ".set	arch=r4000" "\n\t" "dsll32 %L0, %L0, 0" "\n\t" "dsrl32 %L0, %L0, 0" "\n\t" "dsll32 %M0, %M0, 0" "\n\t" "or	%L0, %L0, %M0" "\n\t" "sd	%L0, %2" "\n\t" ".set	pop" "\n" : "=r" (__tmp) : "0" (__val), "m" (*__mem)); if (0) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else BUG(); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 ____raw_readq(const volatile void *mem) { volatile u64 *__mem; u64 __val; __mem = (void *)((unsigned long)(mem)); if (1) __sync(); if (sizeof(u64) != sizeof(u64) || sizeof(u64) == sizeof(long)) __val = *__mem; else if ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800))) { unsigned long __flags; if (0) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); __flags = arch_local_irq_save(); } while (0); } while (0); __asm__ __volatile__( ".set	push" "\t\t# __readq" "\n\t" ".set	arch=r4000" "\n\t" "ld	%L0, %1" "\n\t" "dsra32 %M0, %L0, 0" "\n\t" "sll	%L0, %L0, 0" "\n\t" ".set	pop" "\n" : "=r" (__val) : "m" (*__mem)); if (0) do { do { ({ unsigned long __dummy; typeof(__flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(__flags); } while (0); } while (0); } else { __val = 0; BUG(); } if (!0) rmb(); return (__val); }
# 474 "/home/nathan/src/linux/arch/mips/include/asm/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void writesb(volatile void *mem, const void *addr, unsigned int count) { const volatile u8 *__addr = addr; while (count--) { __mem_writeb(*__addr, mem); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void readsb(volatile void *mem, void *addr, unsigned int count) { volatile u8 *__addr = addr; while (count--) { *__addr = __mem_readb(mem); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outsb(unsigned long port, const void *addr, unsigned int count) { const volatile u8 *__addr = addr; while (count--) { __mem_outb(*__addr, port); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void insb(unsigned long port, void *addr, unsigned int count) { volatile u8 *__addr = addr; while (count--) { *__addr = __mem_inb(port); __addr++; } }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void writesw(volatile void *mem, const void *addr, unsigned int count) { const volatile u16 *__addr = addr; while (count--) { __mem_writew(*__addr, mem); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void readsw(volatile void *mem, void *addr, unsigned int count) { volatile u16 *__addr = addr; while (count--) { *__addr = __mem_readw(mem); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outsw(unsigned long port, const void *addr, unsigned int count) { const volatile u16 *__addr = addr; while (count--) { __mem_outw(*__addr, port); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void insw(unsigned long port, void *addr, unsigned int count) { volatile u16 *__addr = addr; while (count--) { *__addr = __mem_inw(port); __addr++; } }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void writesl(volatile void *mem, const void *addr, unsigned int count) { const volatile u32 *__addr = addr; while (count--) { __mem_writel(*__addr, mem); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void readsl(volatile void *mem, void *addr, unsigned int count) { volatile u32 *__addr = addr; while (count--) { *__addr = __mem_readl(mem); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void outsl(unsigned long port, const void *addr, unsigned int count) { const volatile u32 *__addr = addr; while (count--) { __mem_outl(*__addr, port); __addr++; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void insl(unsigned long port, void *addr, unsigned int count) { volatile u32 *__addr = addr; while (count--) { *__addr = __mem_inl(port); __addr++; } }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void memset_io(volatile void *addr, unsigned char val, int count)
{
 memset((void *) addr, val, count);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void memcpy_fromio(void *dst, const volatile void *src, int count)
{
 memcpy(dst, (void *) src, count);
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void memcpy_toio(volatile void *dst, const void *src, int count)
{
 memcpy((void *) dst, src, count);
}
# 516 "/home/nathan/src/linux/arch/mips/include/asm/io.h"
extern void (*_dma_cache_wback_inv)(unsigned long start, unsigned long size);
extern void (*_dma_cache_wback)(unsigned long start, unsigned long size);
extern void (*_dma_cache_inv)(unsigned long start, unsigned long size);
# 560 "/home/nathan/src/linux/arch/mips/include/asm/io.h"
void __ioread64_copy(void *to, const void *from, size_t count);
# 14 "/home/nathan/src/linux/include/linux/io.h" 2


struct device;
struct resource;

          void __iowrite32_copy(void *to, const void *from, size_t count);
void __ioread32_copy(void *to, const void *from, size_t count);
void __iowrite64_copy(void *to, const void *from, size_t count);


int ioremap_page_range(unsigned long addr, unsigned long end,
         phys_addr_t phys_addr, pgprot_t prot);
# 40 "/home/nathan/src/linux/include/linux/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ioremap_huge_init(void) { }






void * devm_ioport_map(struct device *dev, unsigned long port,
          unsigned int nr);
void devm_ioport_unmap(struct device *dev, void *addr);
# 65 "/home/nathan/src/linux/include/linux/io.h"
void *devm_ioremap(struct device *dev, resource_size_t offset,
      resource_size_t size);
void *devm_ioremap_uc(struct device *dev, resource_size_t offset,
       resource_size_t size);
void *devm_ioremap_wc(struct device *dev, resource_size_t offset,
       resource_size_t size);
void devm_iounmap(struct device *dev, void *addr);
int check_signature(const volatile void *io_addr,
   const unsigned char *signature, int length);
void devm_ioremap_release(struct device *dev, void *res);

void *devm_memremap(struct device *dev, resource_size_t offset,
  size_t size, unsigned long flags);
void devm_memunmap(struct device *dev, void *addr);
# 93 "/home/nathan/src/linux/include/linux/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *pci_remap_cfgspace(phys_addr_t offset,
            size_t size)
{
 return ioremap_prot((offset), (size), (2<<_CACHE_SHIFT));
}
# 122 "/home/nathan/src/linux/include/linux/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) arch_phys_wc_add(unsigned long base,
      unsigned long size)
{
 return 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_phys_wc_del(int handle)
{
}



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_phys_wc_index(int handle)
{
 return -1;
}




enum {

 MEMREMAP_WB = 1 << 0,
 MEMREMAP_WT = 1 << 1,
 MEMREMAP_WC = 1 << 2,
 MEMREMAP_ENC = 1 << 3,
 MEMREMAP_DEC = 1 << 4,
};

void *memremap(resource_size_t offset, size_t size, unsigned long flags);
void memunmap(void *addr);
# 164 "/home/nathan/src/linux/include/linux/io.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int arch_io_reserve_memtype_wc(resource_size_t base,
          resource_size_t size)
{
 return 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_io_free_memtype_wc(resource_size_t base,
        resource_size_t size)
{
}
# 11 "/home/nathan/src/linux/arch/mips/include/asm/mips-cps.h" 2


extern unsigned long __cps_access_bad_size(void)
                                                 ;
# 104 "/home/nathan/src/linux/arch/mips/include/asm/mips-cps.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h" 1
# 18 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
extern void *mips_gcr_base;


extern void *mips_cm_l2sync_base;
# 33 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
extern phys_addr_t __mips_cm_phys_base(void);
# 47 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
extern int mips_cm_is64;





extern void mips_cm_error_report(void);
# 65 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
extern int mips_cm_probe(void);
# 78 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool mips_cm_present(void)
{

 return mips_gcr_base != ((void *)0);



}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool mips_cm_has_l2sync(void)
{

 return mips_cm_l2sync_base != ((void *)0);



}
# 130 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_config(void) { return mips_gcr_base + (0x0000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_config(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_config()); val64 = __raw_readl(addr_gcr_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_config(void) { return mips_gcr_base + (0x4000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_config(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_config()); val64 = __raw_readl(addr_gcr_redir_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_config()); return val64; default: return __cps_access_bad_size(); } }







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_base(void) { return mips_gcr_base + (0x0000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_base()); val64 = __raw_readl(addr_gcr_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_base() + 4); __raw_writel(val, addr_gcr_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_base(); reg_val &= ~mask; reg_val |= val; write_gcr_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_base(uint64_t val) { change_gcr_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_base(uint64_t val) { change_gcr_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_base(void) { return mips_gcr_base + (0x4000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_base()); val64 = __raw_readl(addr_gcr_redir_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_base() + 4); __raw_writel(val, addr_gcr_redir_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_base(uint64_t val) { change_gcr_redir_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_base(uint64_t val) { change_gcr_redir_base(val, 0); }
# 147 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_access(void) { return mips_gcr_base + (0x0000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_access(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_access()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_access()); val64 = __raw_readl(addr_gcr_access() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_access()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_access(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_access()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_access()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_access() + 4); __raw_writel(val, addr_gcr_access()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_access(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_access(); reg_val &= ~mask; reg_val |= val; write_gcr_access(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_access(uint32_t val) { change_gcr_access(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_access(uint32_t val) { change_gcr_access(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_access(void) { return mips_gcr_base + (0x4000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_access(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_access()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_access()); val64 = __raw_readl(addr_gcr_redir_access() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_access()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_access(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_redir_access()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_access()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_access() + 4); __raw_writel(val, addr_gcr_redir_access()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_access(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_redir_access(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_access(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_access(uint32_t val) { change_gcr_redir_access(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_access(uint32_t val) { change_gcr_redir_access(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_rev(void) { return mips_gcr_base + (0x0000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_rev(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_rev()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_rev()); val64 = __raw_readl(addr_gcr_rev() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_rev()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_rev(void) { return mips_gcr_base + (0x4000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_rev(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_rev()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_rev()); val64 = __raw_readl(addr_gcr_redir_rev() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_rev()); return val64; default: return __cps_access_bad_size(); } }
# 165 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_err_control(void) { return mips_gcr_base + (0x0000 + 0x038); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_err_control(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_err_control()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_err_control()); val64 = __raw_readl(addr_gcr_err_control() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_err_control()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_err_control(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_err_control()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_err_control()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_err_control() + 4); __raw_writel(val, addr_gcr_err_control()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_err_control(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_err_control(); reg_val &= ~mask; reg_val |= val; write_gcr_err_control(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_err_control(uint32_t val) { change_gcr_err_control(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_err_control(uint32_t val) { change_gcr_err_control(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_err_control(void) { return mips_gcr_base + (0x4000 + 0x038); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_err_control(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_err_control()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_err_control()); val64 = __raw_readl(addr_gcr_redir_err_control() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_err_control()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_err_control(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_redir_err_control()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_err_control()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_err_control() + 4); __raw_writel(val, addr_gcr_redir_err_control()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_err_control(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_redir_err_control(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_err_control(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_err_control(uint32_t val) { change_gcr_redir_err_control(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_err_control(uint32_t val) { change_gcr_redir_err_control(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_error_mask(void) { return mips_gcr_base + (0x0000 + 0x040); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_error_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_error_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_error_mask()); val64 = __raw_readl(addr_gcr_error_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_error_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_error_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_error_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_error_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_error_mask() + 4); __raw_writel(val, addr_gcr_error_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_error_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_error_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_error_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_error_mask(uint64_t val) { change_gcr_error_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_error_mask(uint64_t val) { change_gcr_error_mask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_error_mask(void) { return mips_gcr_base + (0x4000 + 0x040); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_error_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_error_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_error_mask()); val64 = __raw_readl(addr_gcr_redir_error_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_error_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_error_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_error_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_error_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_error_mask() + 4); __raw_writel(val, addr_gcr_redir_error_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_error_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_error_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_error_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_error_mask(uint64_t val) { change_gcr_redir_error_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_error_mask(uint64_t val) { change_gcr_redir_error_mask(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_error_cause(void) { return mips_gcr_base + (0x0000 + 0x048); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_error_cause(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_error_cause()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_error_cause()); val64 = __raw_readl(addr_gcr_error_cause() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_error_cause()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_error_cause(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_error_cause()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_error_cause()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_error_cause() + 4); __raw_writel(val, addr_gcr_error_cause()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_error_cause(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_error_cause(); reg_val &= ~mask; reg_val |= val; write_gcr_error_cause(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_error_cause(uint64_t val) { change_gcr_error_cause(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_error_cause(uint64_t val) { change_gcr_error_cause(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_error_cause(void) { return mips_gcr_base + (0x4000 + 0x048); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_error_cause(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_error_cause()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_error_cause()); val64 = __raw_readl(addr_gcr_redir_error_cause() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_error_cause()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_error_cause(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_error_cause()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_error_cause()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_error_cause() + 4); __raw_writel(val, addr_gcr_redir_error_cause()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_error_cause(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_error_cause(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_error_cause(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_error_cause(uint64_t val) { change_gcr_redir_error_cause(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_error_cause(uint64_t val) { change_gcr_redir_error_cause(val, 0); }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_error_addr(void) { return mips_gcr_base + (0x0000 + 0x050); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_error_addr(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_error_addr()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_error_addr()); val64 = __raw_readl(addr_gcr_error_addr() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_error_addr()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_error_addr(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_error_addr()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_error_addr()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_error_addr() + 4); __raw_writel(val, addr_gcr_error_addr()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_error_addr(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_error_addr(); reg_val &= ~mask; reg_val |= val; write_gcr_error_addr(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_error_addr(uint64_t val) { change_gcr_error_addr(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_error_addr(uint64_t val) { change_gcr_error_addr(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_error_addr(void) { return mips_gcr_base + (0x4000 + 0x050); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_error_addr(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_error_addr()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_error_addr()); val64 = __raw_readl(addr_gcr_redir_error_addr() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_error_addr()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_error_addr(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_error_addr()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_error_addr()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_error_addr() + 4); __raw_writel(val, addr_gcr_redir_error_addr()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_error_addr(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_error_addr(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_error_addr(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_error_addr(uint64_t val) { change_gcr_redir_error_addr(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_error_addr(uint64_t val) { change_gcr_redir_error_addr(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_error_mult(void) { return mips_gcr_base + (0x0000 + 0x058); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_error_mult(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_error_mult()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_error_mult()); val64 = __raw_readl(addr_gcr_error_mult() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_error_mult()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_error_mult(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_error_mult()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_error_mult()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_error_mult() + 4); __raw_writel(val, addr_gcr_error_mult()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_error_mult(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_error_mult(); reg_val &= ~mask; reg_val |= val; write_gcr_error_mult(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_error_mult(uint64_t val) { change_gcr_error_mult(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_error_mult(uint64_t val) { change_gcr_error_mult(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_error_mult(void) { return mips_gcr_base + (0x4000 + 0x058); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_error_mult(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_error_mult()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_error_mult()); val64 = __raw_readl(addr_gcr_redir_error_mult() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_error_mult()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_error_mult(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_error_mult()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_error_mult()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_error_mult() + 4); __raw_writel(val, addr_gcr_redir_error_mult()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_error_mult(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_error_mult(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_error_mult(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_error_mult(uint64_t val) { change_gcr_redir_error_mult(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_error_mult(uint64_t val) { change_gcr_redir_error_mult(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_l2_only_sync_base(void) { return mips_gcr_base + (0x0000 + 0x070); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_l2_only_sync_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_l2_only_sync_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_l2_only_sync_base()); val64 = __raw_readl(addr_gcr_l2_only_sync_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_l2_only_sync_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_l2_only_sync_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_l2_only_sync_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_l2_only_sync_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_l2_only_sync_base() + 4); __raw_writel(val, addr_gcr_l2_only_sync_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_l2_only_sync_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_l2_only_sync_base(); reg_val &= ~mask; reg_val |= val; write_gcr_l2_only_sync_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_l2_only_sync_base(uint64_t val) { change_gcr_l2_only_sync_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_l2_only_sync_base(uint64_t val) { change_gcr_l2_only_sync_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_l2_only_sync_base(void) { return mips_gcr_base + (0x4000 + 0x070); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_l2_only_sync_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_l2_only_sync_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_l2_only_sync_base()); val64 = __raw_readl(addr_gcr_redir_l2_only_sync_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_l2_only_sync_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_l2_only_sync_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_l2_only_sync_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_l2_only_sync_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_l2_only_sync_base() + 4); __raw_writel(val, addr_gcr_redir_l2_only_sync_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_l2_only_sync_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_l2_only_sync_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_l2_only_sync_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_l2_only_sync_base(uint64_t val) { change_gcr_redir_l2_only_sync_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_l2_only_sync_base(uint64_t val) { change_gcr_redir_l2_only_sync_base(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_gic_base(void) { return mips_gcr_base + (0x0000 + 0x080); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_gic_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_gic_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_gic_base()); val64 = __raw_readl(addr_gcr_gic_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_gic_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_gic_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_gic_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_gic_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_gic_base() + 4); __raw_writel(val, addr_gcr_gic_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_gic_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_gic_base(); reg_val &= ~mask; reg_val |= val; write_gcr_gic_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_gic_base(uint64_t val) { change_gcr_gic_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_gic_base(uint64_t val) { change_gcr_gic_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_gic_base(void) { return mips_gcr_base + (0x4000 + 0x080); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_gic_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_gic_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_gic_base()); val64 = __raw_readl(addr_gcr_redir_gic_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_gic_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_gic_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_gic_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_gic_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_gic_base() + 4); __raw_writel(val, addr_gcr_redir_gic_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_gic_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_gic_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_gic_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_gic_base(uint64_t val) { change_gcr_redir_gic_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_gic_base(uint64_t val) { change_gcr_redir_gic_base(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cpc_base(void) { return mips_gcr_base + (0x0000 + 0x088); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_cpc_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_cpc_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cpc_base()); val64 = __raw_readl(addr_gcr_cpc_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cpc_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_cpc_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_cpc_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_cpc_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_cpc_base() + 4); __raw_writel(val, addr_gcr_cpc_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_cpc_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_cpc_base(); reg_val &= ~mask; reg_val |= val; write_gcr_cpc_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_cpc_base(uint64_t val) { change_gcr_cpc_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_cpc_base(uint64_t val) { change_gcr_cpc_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_cpc_base(void) { return mips_gcr_base + (0x4000 + 0x088); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_cpc_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_cpc_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_cpc_base()); val64 = __raw_readl(addr_gcr_redir_cpc_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_cpc_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_cpc_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_cpc_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_cpc_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_cpc_base() + 4); __raw_writel(val, addr_gcr_redir_cpc_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_cpc_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_cpc_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_cpc_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_cpc_base(uint64_t val) { change_gcr_redir_cpc_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_cpc_base(uint64_t val) { change_gcr_redir_cpc_base(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg0_base(void) { return mips_gcr_base + (0x0000 + 0x090); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg0_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg0_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg0_base()); val64 = __raw_readl(addr_gcr_reg0_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg0_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg0_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg0_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg0_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg0_base() + 4); __raw_writel(val, addr_gcr_reg0_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg0_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg0_base(); reg_val &= ~mask; reg_val |= val; write_gcr_reg0_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg0_base(uint64_t val) { change_gcr_reg0_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg0_base(uint64_t val) { change_gcr_reg0_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg0_base(void) { return mips_gcr_base + (0x4000 + 0x090); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg0_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg0_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg0_base()); val64 = __raw_readl(addr_gcr_redir_reg0_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg0_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg0_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg0_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg0_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg0_base() + 4); __raw_writel(val, addr_gcr_redir_reg0_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg0_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg0_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg0_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg0_base(uint64_t val) { change_gcr_redir_reg0_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg0_base(uint64_t val) { change_gcr_redir_reg0_base(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg1_base(void) { return mips_gcr_base + (0x0000 + 0x0a0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg1_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg1_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg1_base()); val64 = __raw_readl(addr_gcr_reg1_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg1_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg1_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg1_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg1_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg1_base() + 4); __raw_writel(val, addr_gcr_reg1_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg1_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg1_base(); reg_val &= ~mask; reg_val |= val; write_gcr_reg1_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg1_base(uint64_t val) { change_gcr_reg1_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg1_base(uint64_t val) { change_gcr_reg1_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg1_base(void) { return mips_gcr_base + (0x4000 + 0x0a0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg1_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg1_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg1_base()); val64 = __raw_readl(addr_gcr_redir_reg1_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg1_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg1_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg1_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg1_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg1_base() + 4); __raw_writel(val, addr_gcr_redir_reg1_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg1_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg1_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg1_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg1_base(uint64_t val) { change_gcr_redir_reg1_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg1_base(uint64_t val) { change_gcr_redir_reg1_base(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg2_base(void) { return mips_gcr_base + (0x0000 + 0x0b0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg2_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg2_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg2_base()); val64 = __raw_readl(addr_gcr_reg2_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg2_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg2_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg2_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg2_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg2_base() + 4); __raw_writel(val, addr_gcr_reg2_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg2_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg2_base(); reg_val &= ~mask; reg_val |= val; write_gcr_reg2_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg2_base(uint64_t val) { change_gcr_reg2_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg2_base(uint64_t val) { change_gcr_reg2_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg2_base(void) { return mips_gcr_base + (0x4000 + 0x0b0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg2_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg2_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg2_base()); val64 = __raw_readl(addr_gcr_redir_reg2_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg2_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg2_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg2_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg2_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg2_base() + 4); __raw_writel(val, addr_gcr_redir_reg2_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg2_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg2_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg2_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg2_base(uint64_t val) { change_gcr_redir_reg2_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg2_base(uint64_t val) { change_gcr_redir_reg2_base(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg3_base(void) { return mips_gcr_base + (0x0000 + 0x0c0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg3_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg3_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg3_base()); val64 = __raw_readl(addr_gcr_reg3_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg3_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg3_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg3_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg3_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg3_base() + 4); __raw_writel(val, addr_gcr_reg3_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg3_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg3_base(); reg_val &= ~mask; reg_val |= val; write_gcr_reg3_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg3_base(uint64_t val) { change_gcr_reg3_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg3_base(uint64_t val) { change_gcr_reg3_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg3_base(void) { return mips_gcr_base + (0x4000 + 0x0c0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg3_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg3_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg3_base()); val64 = __raw_readl(addr_gcr_redir_reg3_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg3_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg3_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg3_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg3_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg3_base() + 4); __raw_writel(val, addr_gcr_redir_reg3_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg3_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg3_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg3_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg3_base(uint64_t val) { change_gcr_redir_reg3_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg3_base(uint64_t val) { change_gcr_redir_reg3_base(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg0_mask(void) { return mips_gcr_base + (0x0000 + 0x098); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg0_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg0_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg0_mask()); val64 = __raw_readl(addr_gcr_reg0_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg0_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg0_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg0_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg0_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg0_mask() + 4); __raw_writel(val, addr_gcr_reg0_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg0_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg0_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_reg0_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg0_mask(uint64_t val) { change_gcr_reg0_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg0_mask(uint64_t val) { change_gcr_reg0_mask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg0_mask(void) { return mips_gcr_base + (0x4000 + 0x098); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg0_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg0_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg0_mask()); val64 = __raw_readl(addr_gcr_redir_reg0_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg0_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg0_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg0_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg0_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg0_mask() + 4); __raw_writel(val, addr_gcr_redir_reg0_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg0_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg0_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg0_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg0_mask(uint64_t val) { change_gcr_redir_reg0_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg0_mask(uint64_t val) { change_gcr_redir_reg0_mask(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg1_mask(void) { return mips_gcr_base + (0x0000 + 0x0a8); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg1_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg1_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg1_mask()); val64 = __raw_readl(addr_gcr_reg1_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg1_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg1_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg1_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg1_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg1_mask() + 4); __raw_writel(val, addr_gcr_reg1_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg1_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg1_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_reg1_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg1_mask(uint64_t val) { change_gcr_reg1_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg1_mask(uint64_t val) { change_gcr_reg1_mask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg1_mask(void) { return mips_gcr_base + (0x4000 + 0x0a8); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg1_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg1_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg1_mask()); val64 = __raw_readl(addr_gcr_redir_reg1_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg1_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg1_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg1_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg1_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg1_mask() + 4); __raw_writel(val, addr_gcr_redir_reg1_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg1_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg1_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg1_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg1_mask(uint64_t val) { change_gcr_redir_reg1_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg1_mask(uint64_t val) { change_gcr_redir_reg1_mask(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg2_mask(void) { return mips_gcr_base + (0x0000 + 0x0b8); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg2_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg2_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg2_mask()); val64 = __raw_readl(addr_gcr_reg2_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg2_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg2_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg2_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg2_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg2_mask() + 4); __raw_writel(val, addr_gcr_reg2_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg2_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg2_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_reg2_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg2_mask(uint64_t val) { change_gcr_reg2_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg2_mask(uint64_t val) { change_gcr_reg2_mask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg2_mask(void) { return mips_gcr_base + (0x4000 + 0x0b8); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg2_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg2_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg2_mask()); val64 = __raw_readl(addr_gcr_redir_reg2_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg2_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg2_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg2_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg2_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg2_mask() + 4); __raw_writel(val, addr_gcr_redir_reg2_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg2_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg2_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg2_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg2_mask(uint64_t val) { change_gcr_redir_reg2_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg2_mask(uint64_t val) { change_gcr_redir_reg2_mask(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_reg3_mask(void) { return mips_gcr_base + (0x0000 + 0x0c8); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_reg3_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_reg3_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_reg3_mask()); val64 = __raw_readl(addr_gcr_reg3_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_reg3_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_reg3_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_reg3_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_reg3_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_reg3_mask() + 4); __raw_writel(val, addr_gcr_reg3_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_reg3_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_reg3_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_reg3_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_reg3_mask(uint64_t val) { change_gcr_reg3_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_reg3_mask(uint64_t val) { change_gcr_reg3_mask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_reg3_mask(void) { return mips_gcr_base + (0x4000 + 0x0c8); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_reg3_mask(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_reg3_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_reg3_mask()); val64 = __raw_readl(addr_gcr_redir_reg3_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_reg3_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_reg3_mask(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_reg3_mask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_reg3_mask()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_reg3_mask() + 4); __raw_writel(val, addr_gcr_redir_reg3_mask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_reg3_mask(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_reg3_mask(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_reg3_mask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_reg3_mask(uint64_t val) { change_gcr_redir_reg3_mask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_reg3_mask(uint64_t val) { change_gcr_redir_reg3_mask(val, 0); }
# 223 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_gic_status(void) { return mips_gcr_base + (0x0000 + 0x0d0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_gic_status(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_gic_status()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_gic_status()); val64 = __raw_readl(addr_gcr_gic_status() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_gic_status()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_gic_status(void) { return mips_gcr_base + (0x4000 + 0x0d0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_gic_status(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_gic_status()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_gic_status()); val64 = __raw_readl(addr_gcr_redir_gic_status() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_gic_status()); return val64; default: return __cps_access_bad_size(); } }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cpc_status(void) { return mips_gcr_base + (0x0000 + 0x0f0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cpc_status(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cpc_status()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cpc_status()); val64 = __raw_readl(addr_gcr_cpc_status() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cpc_status()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_cpc_status(void) { return mips_gcr_base + (0x4000 + 0x0f0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_cpc_status(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_cpc_status()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_cpc_status()); val64 = __raw_readl(addr_gcr_redir_cpc_status() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_cpc_status()); return val64; default: return __cps_access_bad_size(); } }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_l2_config(void) { return mips_gcr_base + (0x0000 + 0x130); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_l2_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_l2_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_l2_config()); val64 = __raw_readl(addr_gcr_l2_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_l2_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_l2_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_l2_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_l2_config()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_l2_config() + 4); __raw_writel(val, addr_gcr_l2_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_l2_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_l2_config(); reg_val &= ~mask; reg_val |= val; write_gcr_l2_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_l2_config(uint32_t val) { change_gcr_l2_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_l2_config(uint32_t val) { change_gcr_l2_config(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_l2_config(void) { return mips_gcr_base + (0x4000 + 0x130); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_l2_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_l2_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_l2_config()); val64 = __raw_readl(addr_gcr_redir_l2_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_l2_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_l2_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_redir_l2_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_l2_config()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_l2_config() + 4); __raw_writel(val, addr_gcr_redir_l2_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_l2_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_redir_l2_config(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_l2_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_l2_config(uint32_t val) { change_gcr_redir_l2_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_l2_config(uint32_t val) { change_gcr_redir_l2_config(val, 0); }






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_sys_config2(void) { return mips_gcr_base + (0x0000 + 0x150); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_sys_config2(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_sys_config2()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_sys_config2()); val64 = __raw_readl(addr_gcr_sys_config2() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_sys_config2()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_sys_config2(void) { return mips_gcr_base + (0x4000 + 0x150); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_sys_config2(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_sys_config2()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_sys_config2()); val64 = __raw_readl(addr_gcr_redir_sys_config2() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_sys_config2()); return val64; default: return __cps_access_bad_size(); } }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_l2_pft_control(void) { return mips_gcr_base + (0x0000 + 0x300); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_l2_pft_control(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_l2_pft_control()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_l2_pft_control()); val64 = __raw_readl(addr_gcr_l2_pft_control() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_l2_pft_control()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_l2_pft_control(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_l2_pft_control()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_l2_pft_control()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_l2_pft_control() + 4); __raw_writel(val, addr_gcr_l2_pft_control()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_l2_pft_control(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_l2_pft_control(); reg_val &= ~mask; reg_val |= val; write_gcr_l2_pft_control(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_l2_pft_control(uint32_t val) { change_gcr_l2_pft_control(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_l2_pft_control(uint32_t val) { change_gcr_l2_pft_control(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_l2_pft_control(void) { return mips_gcr_base + (0x4000 + 0x300); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_l2_pft_control(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_l2_pft_control()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_l2_pft_control()); val64 = __raw_readl(addr_gcr_redir_l2_pft_control() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_l2_pft_control()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_l2_pft_control(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_redir_l2_pft_control()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_l2_pft_control()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_l2_pft_control() + 4); __raw_writel(val, addr_gcr_redir_l2_pft_control()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_l2_pft_control(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_redir_l2_pft_control(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_l2_pft_control(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_l2_pft_control(uint32_t val) { change_gcr_redir_l2_pft_control(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_l2_pft_control(uint32_t val) { change_gcr_redir_l2_pft_control(val, 0); }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_l2_pft_control_b(void) { return mips_gcr_base + (0x0000 + 0x308); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_l2_pft_control_b(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_l2_pft_control_b()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_l2_pft_control_b()); val64 = __raw_readl(addr_gcr_l2_pft_control_b() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_l2_pft_control_b()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_l2_pft_control_b(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_l2_pft_control_b()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_l2_pft_control_b()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_l2_pft_control_b() + 4); __raw_writel(val, addr_gcr_l2_pft_control_b()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_l2_pft_control_b(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_l2_pft_control_b(); reg_val &= ~mask; reg_val |= val; write_gcr_l2_pft_control_b(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_l2_pft_control_b(uint32_t val) { change_gcr_l2_pft_control_b(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_l2_pft_control_b(uint32_t val) { change_gcr_l2_pft_control_b(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_l2_pft_control_b(void) { return mips_gcr_base + (0x4000 + 0x308); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_l2_pft_control_b(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_l2_pft_control_b()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_l2_pft_control_b()); val64 = __raw_readl(addr_gcr_redir_l2_pft_control_b() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_l2_pft_control_b()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_l2_pft_control_b(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_redir_l2_pft_control_b()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_l2_pft_control_b()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_l2_pft_control_b() + 4); __raw_writel(val, addr_gcr_redir_l2_pft_control_b()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_l2_pft_control_b(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_redir_l2_pft_control_b(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_l2_pft_control_b(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_l2_pft_control_b(uint32_t val) { change_gcr_redir_l2_pft_control_b(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_l2_pft_control_b(uint32_t val) { change_gcr_redir_l2_pft_control_b(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_l2sm_cop(void) { return mips_gcr_base + (0x0000 + 0x620); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_l2sm_cop(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_l2sm_cop()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_l2sm_cop()); val64 = __raw_readl(addr_gcr_l2sm_cop() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_l2sm_cop()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_l2sm_cop(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_l2sm_cop()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_l2sm_cop()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_l2sm_cop() + 4); __raw_writel(val, addr_gcr_l2sm_cop()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_l2sm_cop(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_l2sm_cop(); reg_val &= ~mask; reg_val |= val; write_gcr_l2sm_cop(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_l2sm_cop(uint32_t val) { change_gcr_l2sm_cop(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_l2sm_cop(uint32_t val) { change_gcr_l2sm_cop(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_l2sm_cop(void) { return mips_gcr_base + (0x4000 + 0x620); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_redir_l2sm_cop(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_redir_l2sm_cop()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_l2sm_cop()); val64 = __raw_readl(addr_gcr_redir_l2sm_cop() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_l2sm_cop()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_l2sm_cop(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_redir_l2sm_cop()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_l2sm_cop()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_l2sm_cop() + 4); __raw_writel(val, addr_gcr_redir_l2sm_cop()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_l2sm_cop(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_redir_l2sm_cop(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_l2sm_cop(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_l2sm_cop(uint32_t val) { change_gcr_redir_l2sm_cop(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_l2sm_cop(uint32_t val) { change_gcr_redir_l2sm_cop(val, 0); }
# 275 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_l2sm_tag_addr_cop(void) { return mips_gcr_base + (0x0000 + 0x628); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_l2sm_tag_addr_cop(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_l2sm_tag_addr_cop()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_l2sm_tag_addr_cop()); val64 = __raw_readl(addr_gcr_l2sm_tag_addr_cop() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_l2sm_tag_addr_cop()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_l2sm_tag_addr_cop(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_l2sm_tag_addr_cop()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_l2sm_tag_addr_cop()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_l2sm_tag_addr_cop() + 4); __raw_writel(val, addr_gcr_l2sm_tag_addr_cop()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_l2sm_tag_addr_cop(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_l2sm_tag_addr_cop(); reg_val &= ~mask; reg_val |= val; write_gcr_l2sm_tag_addr_cop(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_l2sm_tag_addr_cop(uint64_t val) { change_gcr_l2sm_tag_addr_cop(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_l2sm_tag_addr_cop(uint64_t val) { change_gcr_l2sm_tag_addr_cop(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_l2sm_tag_addr_cop(void) { return mips_gcr_base + (0x4000 + 0x628); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_l2sm_tag_addr_cop(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_l2sm_tag_addr_cop()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_l2sm_tag_addr_cop()); val64 = __raw_readl(addr_gcr_redir_l2sm_tag_addr_cop() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_l2sm_tag_addr_cop()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_l2sm_tag_addr_cop(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_l2sm_tag_addr_cop()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_l2sm_tag_addr_cop()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_l2sm_tag_addr_cop() + 4); __raw_writel(val, addr_gcr_redir_l2sm_tag_addr_cop()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_l2sm_tag_addr_cop(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_l2sm_tag_addr_cop(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_l2sm_tag_addr_cop(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_l2sm_tag_addr_cop(uint64_t val) { change_gcr_redir_l2sm_tag_addr_cop(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_l2sm_tag_addr_cop(uint64_t val) { change_gcr_redir_l2sm_tag_addr_cop(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_bev_base(void) { return mips_gcr_base + (0x0000 + 0x680); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_bev_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_bev_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_bev_base()); val64 = __raw_readl(addr_gcr_bev_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_bev_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_bev_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_bev_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_bev_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_bev_base() + 4); __raw_writel(val, addr_gcr_bev_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_bev_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_bev_base(); reg_val &= ~mask; reg_val |= val; write_gcr_bev_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_bev_base(uint64_t val) { change_gcr_bev_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_bev_base(uint64_t val) { change_gcr_bev_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_redir_bev_base(void) { return mips_gcr_base + (0x4000 + 0x680); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gcr_redir_bev_base(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gcr_redir_bev_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_redir_bev_base()); val64 = __raw_readl(addr_gcr_redir_bev_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_redir_bev_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_redir_bev_base(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gcr_redir_bev_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_redir_bev_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_redir_bev_base() + 4); __raw_writel(val, addr_gcr_redir_bev_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_redir_bev_base(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gcr_redir_bev_base(); reg_val &= ~mask; reg_val |= val; write_gcr_redir_bev_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_redir_bev_base(uint64_t val) { change_gcr_redir_bev_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_redir_bev_base(uint64_t val) { change_gcr_redir_bev_base(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_reset_release(void) { return mips_gcr_base + (0x2000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_reset_release(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_reset_release()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_reset_release()); val64 = __raw_readl(addr_gcr_cl_reset_release() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_reset_release()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_cl_reset_release(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_cl_reset_release()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_cl_reset_release()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_cl_reset_release() + 4); __raw_writel(val, addr_gcr_cl_reset_release()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_cl_reset_release(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_cl_reset_release(); reg_val &= ~mask; reg_val |= val; write_gcr_cl_reset_release(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_cl_reset_release(uint32_t val) { change_gcr_cl_reset_release(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_cl_reset_release(uint32_t val) { change_gcr_cl_reset_release(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_reset_release(void) { return mips_gcr_base + (0x4000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_reset_release(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_reset_release()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_reset_release()); val64 = __raw_readl(addr_gcr_co_reset_release() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_reset_release()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_co_reset_release(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_co_reset_release()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_co_reset_release()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_co_reset_release() + 4); __raw_writel(val, addr_gcr_co_reset_release()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_co_reset_release(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_co_reset_release(); reg_val &= ~mask; reg_val |= val; write_gcr_co_reset_release(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_co_reset_release(uint32_t val) { change_gcr_co_reset_release(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_co_reset_release(uint32_t val) { change_gcr_co_reset_release(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_coherence(void) { return mips_gcr_base + (0x2000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_coherence(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_coherence()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_coherence()); val64 = __raw_readl(addr_gcr_cl_coherence() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_coherence()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_cl_coherence(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_cl_coherence()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_cl_coherence()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_cl_coherence() + 4); __raw_writel(val, addr_gcr_cl_coherence()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_cl_coherence(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_cl_coherence(); reg_val &= ~mask; reg_val |= val; write_gcr_cl_coherence(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_cl_coherence(uint32_t val) { change_gcr_cl_coherence(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_cl_coherence(uint32_t val) { change_gcr_cl_coherence(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_coherence(void) { return mips_gcr_base + (0x4000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_coherence(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_coherence()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_coherence()); val64 = __raw_readl(addr_gcr_co_coherence() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_coherence()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_co_coherence(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_co_coherence()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_co_coherence()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_co_coherence() + 4); __raw_writel(val, addr_gcr_co_coherence()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_co_coherence(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_co_coherence(); reg_val &= ~mask; reg_val |= val; write_gcr_co_coherence(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_co_coherence(uint32_t val) { change_gcr_co_coherence(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_co_coherence(uint32_t val) { change_gcr_co_coherence(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_config(void) { return mips_gcr_base + (0x2000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_config()); val64 = __raw_readl(addr_gcr_cl_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_config(void) { return mips_gcr_base + (0x4000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_config()); val64 = __raw_readl(addr_gcr_co_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_config()); return val64; default: return __cps_access_bad_size(); } }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_other(void) { return mips_gcr_base + (0x2000 + 0x018); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_other(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_other()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_other()); val64 = __raw_readl(addr_gcr_cl_other() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_other()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_cl_other(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_cl_other()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_cl_other()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_cl_other() + 4); __raw_writel(val, addr_gcr_cl_other()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_cl_other(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_cl_other(); reg_val &= ~mask; reg_val |= val; write_gcr_cl_other(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_cl_other(uint32_t val) { change_gcr_cl_other(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_cl_other(uint32_t val) { change_gcr_cl_other(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_other(void) { return mips_gcr_base + (0x4000 + 0x018); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_other(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_other()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_other()); val64 = __raw_readl(addr_gcr_co_other() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_other()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_co_other(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_co_other()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_co_other()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_co_other() + 4); __raw_writel(val, addr_gcr_co_other()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_co_other(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_co_other(); reg_val &= ~mask; reg_val |= val; write_gcr_co_other(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_co_other(uint32_t val) { change_gcr_co_other(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_co_other(uint32_t val) { change_gcr_co_other(val, 0); }
# 311 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_reset_base(void) { return mips_gcr_base + (0x2000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_reset_base(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_reset_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_reset_base()); val64 = __raw_readl(addr_gcr_cl_reset_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_reset_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_cl_reset_base(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_cl_reset_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_cl_reset_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_cl_reset_base() + 4); __raw_writel(val, addr_gcr_cl_reset_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_cl_reset_base(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_cl_reset_base(); reg_val &= ~mask; reg_val |= val; write_gcr_cl_reset_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_cl_reset_base(uint32_t val) { change_gcr_cl_reset_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_cl_reset_base(uint32_t val) { change_gcr_cl_reset_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_reset_base(void) { return mips_gcr_base + (0x4000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_reset_base(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_reset_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_reset_base()); val64 = __raw_readl(addr_gcr_co_reset_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_reset_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_co_reset_base(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_co_reset_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_co_reset_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_co_reset_base() + 4); __raw_writel(val, addr_gcr_co_reset_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_co_reset_base(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_co_reset_base(); reg_val &= ~mask; reg_val |= val; write_gcr_co_reset_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_co_reset_base(uint32_t val) { change_gcr_co_reset_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_co_reset_base(uint32_t val) { change_gcr_co_reset_base(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_id(void) { return mips_gcr_base + (0x2000 + 0x028); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_id(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_id()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_id()); val64 = __raw_readl(addr_gcr_cl_id() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_id()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_id(void) { return mips_gcr_base + (0x4000 + 0x028); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_id(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_id()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_id()); val64 = __raw_readl(addr_gcr_co_id() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_id()); return val64; default: return __cps_access_bad_size(); } }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_cl_reset_ext_base(void) { return mips_gcr_base + (0x2000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_cl_reset_ext_base(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_cl_reset_ext_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_cl_reset_ext_base()); val64 = __raw_readl(addr_gcr_cl_reset_ext_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_cl_reset_ext_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_cl_reset_ext_base(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_cl_reset_ext_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_cl_reset_ext_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_cl_reset_ext_base() + 4); __raw_writel(val, addr_gcr_cl_reset_ext_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_cl_reset_ext_base(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_cl_reset_ext_base(); reg_val &= ~mask; reg_val |= val; write_gcr_cl_reset_ext_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_cl_reset_ext_base(uint32_t val) { change_gcr_cl_reset_ext_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_cl_reset_ext_base(uint32_t val) { change_gcr_cl_reset_ext_base(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gcr_co_reset_ext_base(void) { return mips_gcr_base + (0x4000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gcr_co_reset_ext_base(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gcr_co_reset_ext_base()); case 64: if (mips_cm_is64) return __raw_readq(addr_gcr_co_reset_ext_base()); val64 = __raw_readl(addr_gcr_co_reset_ext_base() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gcr_co_reset_ext_base()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gcr_co_reset_ext_base(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gcr_co_reset_ext_base()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gcr_co_reset_ext_base()); break; } __raw_writel((uint64_t)val >> 32, addr_gcr_co_reset_ext_base() + 4); __raw_writel(val, addr_gcr_co_reset_ext_base()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gcr_co_reset_ext_base(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gcr_co_reset_ext_base(); reg_val &= ~mask; reg_val |= val; write_gcr_co_reset_ext_base(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gcr_co_reset_ext_base(uint32_t val) { change_gcr_co_reset_ext_base(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gcr_co_reset_ext_base(uint32_t val) { change_gcr_co_reset_ext_base(val, 0); }
# 333 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int mips_cm_l2sync(void)
{
 if (!mips_cm_has_l2sync())
  return -19;

 writel(0, mips_cm_l2sync_base);
 return 0;
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int mips_cm_revision(void)
{
 if (!mips_cm_present())
  return 0;

 return read_gcr_rev();
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int mips_cm_max_vp_width(void)
{
 extern int smp_num_siblings;
 uint32_t cfg;

 if (mips_cm_revision() >= (((8) << __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((8) > (15)), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15))))))) | ((0) << __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((0) > (7)), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))))))
  return read_gcr_sys_config2() & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((0) > (3)), (0) > (3), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (3)))));

 if (mips_cm_present()) {





  cfg = read_gcr_cl_config() & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((0) > (9)), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))));
  return (cfg >> __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((0) > (9)), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9))))))) + 1;
 }

 if (1)
  return smp_num_siblings;

 return 1;
}
# 396 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int mips_cm_vp_id(unsigned int cpu)
{
 unsigned int core = cpu_core(&cpu_data[cpu]);
 unsigned int vp = cpu_vpe_id(&cpu_data[cpu]);

 return (core * mips_cm_max_vp_width()) + vp;
}
# 424 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
extern void mips_cm_lock_other(unsigned int cluster, unsigned int core,
          unsigned int vp, unsigned int block);







extern void mips_cm_unlock_other(void);
# 452 "/home/nathan/src/linux/arch/mips/include/asm/mips-cm.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void mips_cm_lock_other_cpu(unsigned int cpu, unsigned int block)
{
 struct cpuinfo_mips *d = &cpu_data[cpu];

 mips_cm_lock_other(cpu_cluster(d), cpu_core(d), cpu_vpe_id(d), block);
}
# 105 "/home/nathan/src/linux/arch/mips/include/asm/mips-cps.h" 2
# 1 "/home/nathan/src/linux/arch/mips/include/asm/mips-cpc.h" 1
# 18 "/home/nathan/src/linux/arch/mips/include/asm/mips-cpc.h"
extern void *mips_cpc_base;
# 28 "/home/nathan/src/linux/arch/mips/include/asm/mips-cpc.h"
extern phys_addr_t mips_cpc_default_phys_base(void);
# 37 "/home/nathan/src/linux/arch/mips/include/asm/mips-cpc.h"
extern int mips_cpc_probe(void);
# 50 "/home/nathan/src/linux/arch/mips/include/asm/mips-cpc.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool mips_cpc_present(void)
{

 return mips_cpc_base != ((void *)0);



}
# 81 "/home/nathan/src/linux/arch/mips/include/asm/mips-cpc.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_access(void) { return mips_cpc_base + (0x0000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_access(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_access()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_access()); val64 = __raw_readl(addr_cpc_access() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_access()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_access(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_access()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_access()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_access() + 4); __raw_writel(val, addr_cpc_access()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_access(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_access(); reg_val &= ~mask; reg_val |= val; write_cpc_access(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_access(uint32_t val) { change_cpc_access(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_access(uint32_t val) { change_cpc_access(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_access(void) { return mips_cpc_base + (0x4000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_access(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_access()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_access()); val64 = __raw_readl(addr_cpc_redir_access() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_access()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_access(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_redir_access()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_access()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_access() + 4); __raw_writel(val, addr_cpc_redir_access()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_access(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_redir_access(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_access(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_access(uint32_t val) { change_cpc_redir_access(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_access(uint32_t val) { change_cpc_redir_access(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_seqdel(void) { return mips_cpc_base + (0x0000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_seqdel(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_seqdel()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_seqdel()); val64 = __raw_readl(addr_cpc_seqdel() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_seqdel()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_seqdel(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_seqdel()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_seqdel()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_seqdel() + 4); __raw_writel(val, addr_cpc_seqdel()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_seqdel(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_seqdel(); reg_val &= ~mask; reg_val |= val; write_cpc_seqdel(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_seqdel(uint32_t val) { change_cpc_seqdel(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_seqdel(uint32_t val) { change_cpc_seqdel(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_seqdel(void) { return mips_cpc_base + (0x4000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_seqdel(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_seqdel()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_seqdel()); val64 = __raw_readl(addr_cpc_redir_seqdel() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_seqdel()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_seqdel(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_redir_seqdel()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_seqdel()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_seqdel() + 4); __raw_writel(val, addr_cpc_redir_seqdel()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_seqdel(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_redir_seqdel(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_seqdel(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_seqdel(uint32_t val) { change_cpc_redir_seqdel(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_seqdel(uint32_t val) { change_cpc_redir_seqdel(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_rail(void) { return mips_cpc_base + (0x0000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_rail(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_rail()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_rail()); val64 = __raw_readl(addr_cpc_rail() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_rail()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_rail(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_rail()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_rail()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_rail() + 4); __raw_writel(val, addr_cpc_rail()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_rail(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_rail(); reg_val &= ~mask; reg_val |= val; write_cpc_rail(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_rail(uint32_t val) { change_cpc_rail(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_rail(uint32_t val) { change_cpc_rail(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_rail(void) { return mips_cpc_base + (0x4000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_rail(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_rail()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_rail()); val64 = __raw_readl(addr_cpc_redir_rail() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_rail()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_rail(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_redir_rail()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_rail()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_rail() + 4); __raw_writel(val, addr_cpc_redir_rail()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_rail(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_redir_rail(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_rail(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_rail(uint32_t val) { change_cpc_redir_rail(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_rail(uint32_t val) { change_cpc_redir_rail(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_resetlen(void) { return mips_cpc_base + (0x0000 + 0x018); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_resetlen(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_resetlen()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_resetlen()); val64 = __raw_readl(addr_cpc_resetlen() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_resetlen()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_resetlen(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_resetlen()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_resetlen()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_resetlen() + 4); __raw_writel(val, addr_cpc_resetlen()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_resetlen(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_resetlen(); reg_val &= ~mask; reg_val |= val; write_cpc_resetlen(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_resetlen(uint32_t val) { change_cpc_resetlen(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_resetlen(uint32_t val) { change_cpc_resetlen(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_resetlen(void) { return mips_cpc_base + (0x4000 + 0x018); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_resetlen(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_resetlen()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_resetlen()); val64 = __raw_readl(addr_cpc_redir_resetlen() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_resetlen()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_resetlen(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_redir_resetlen()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_resetlen()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_resetlen() + 4); __raw_writel(val, addr_cpc_redir_resetlen()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_resetlen(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_redir_resetlen(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_resetlen(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_resetlen(uint32_t val) { change_cpc_redir_resetlen(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_resetlen(uint32_t val) { change_cpc_redir_resetlen(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_revision(void) { return mips_cpc_base + (0x0000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_revision(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_revision()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_revision()); val64 = __raw_readl(addr_cpc_revision() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_revision()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_revision(void) { return mips_cpc_base + (0x4000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_revision(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_revision()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_revision()); val64 = __raw_readl(addr_cpc_redir_revision() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_revision()); return val64; default: return __cps_access_bad_size(); } }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_pwrup_ctl(void) { return mips_cpc_base + (0x0000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_pwrup_ctl(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_pwrup_ctl()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_pwrup_ctl()); val64 = __raw_readl(addr_cpc_pwrup_ctl() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_pwrup_ctl()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_pwrup_ctl(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_pwrup_ctl()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_pwrup_ctl()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_pwrup_ctl() + 4); __raw_writel(val, addr_cpc_pwrup_ctl()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_pwrup_ctl(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_pwrup_ctl(); reg_val &= ~mask; reg_val |= val; write_cpc_pwrup_ctl(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_pwrup_ctl(uint32_t val) { change_cpc_pwrup_ctl(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_pwrup_ctl(uint32_t val) { change_cpc_pwrup_ctl(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_pwrup_ctl(void) { return mips_cpc_base + (0x4000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_pwrup_ctl(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_pwrup_ctl()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_pwrup_ctl()); val64 = __raw_readl(addr_cpc_redir_pwrup_ctl() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_pwrup_ctl()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_pwrup_ctl(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_redir_pwrup_ctl()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_pwrup_ctl()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_pwrup_ctl() + 4); __raw_writel(val, addr_cpc_redir_pwrup_ctl()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_pwrup_ctl(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_redir_pwrup_ctl(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_pwrup_ctl(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_pwrup_ctl(uint32_t val) { change_cpc_redir_pwrup_ctl(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_pwrup_ctl(uint32_t val) { change_cpc_redir_pwrup_ctl(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_config(void) { return mips_cpc_base + (0x0000 + 0x138); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_cpc_config(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_cpc_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_config()); val64 = __raw_readl(addr_cpc_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_config(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_cpc_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_config()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_config() + 4); __raw_writel(val, addr_cpc_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_config(uint64_t mask, uint64_t val) { uint64_t reg_val = read_cpc_config(); reg_val &= ~mask; reg_val |= val; write_cpc_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_config(uint64_t val) { change_cpc_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_config(uint64_t val) { change_cpc_config(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_config(void) { return mips_cpc_base + (0x4000 + 0x138); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_cpc_redir_config(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_cpc_redir_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_config()); val64 = __raw_readl(addr_cpc_redir_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_config(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_cpc_redir_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_config()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_config() + 4); __raw_writel(val, addr_cpc_redir_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_config(uint64_t mask, uint64_t val) { uint64_t reg_val = read_cpc_redir_config(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_config(uint64_t val) { change_cpc_redir_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_config(uint64_t val) { change_cpc_redir_config(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_sys_config(void) { return mips_cpc_base + (0x0000 + 0x140); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_sys_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_sys_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_sys_config()); val64 = __raw_readl(addr_cpc_sys_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_sys_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_sys_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_sys_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_sys_config()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_sys_config() + 4); __raw_writel(val, addr_cpc_sys_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_sys_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_sys_config(); reg_val &= ~mask; reg_val |= val; write_cpc_sys_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_sys_config(uint32_t val) { change_cpc_sys_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_sys_config(uint32_t val) { change_cpc_sys_config(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_redir_sys_config(void) { return mips_cpc_base + (0x4000 + 0x140); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_redir_sys_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_redir_sys_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_redir_sys_config()); val64 = __raw_readl(addr_cpc_redir_sys_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_redir_sys_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_redir_sys_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_redir_sys_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_redir_sys_config()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_redir_sys_config() + 4); __raw_writel(val, addr_cpc_redir_sys_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_redir_sys_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_redir_sys_config(); reg_val &= ~mask; reg_val |= val; write_cpc_redir_sys_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_redir_sys_config(uint32_t val) { change_cpc_redir_sys_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_redir_sys_config(uint32_t val) { change_cpc_redir_sys_config(val, 0); }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_cmd(void) { return mips_cpc_base + (0x2000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_cmd(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_cmd()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_cmd()); val64 = __raw_readl(addr_cpc_cl_cmd() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_cmd()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_cmd(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_cmd()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_cmd()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_cmd() + 4); __raw_writel(val, addr_cpc_cl_cmd()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_cmd(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_cmd(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_cmd(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_cmd(uint32_t val) { change_cpc_cl_cmd(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_cmd(uint32_t val) { change_cpc_cl_cmd(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_cmd(void) { return mips_cpc_base + (0x4000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_cmd(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_cmd()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_cmd()); val64 = __raw_readl(addr_cpc_co_cmd() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_cmd()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_cmd(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_cmd()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_cmd()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_cmd() + 4); __raw_writel(val, addr_cpc_co_cmd()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_cmd(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_cmd(); reg_val &= ~mask; reg_val |= val; write_cpc_co_cmd(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_cmd(uint32_t val) { change_cpc_co_cmd(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_cmd(uint32_t val) { change_cpc_co_cmd(val, 0); }







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_stat_conf(void) { return mips_cpc_base + (0x2000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_stat_conf(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_stat_conf()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_stat_conf()); val64 = __raw_readl(addr_cpc_cl_stat_conf() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_stat_conf()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_stat_conf(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_stat_conf()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_stat_conf()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_stat_conf() + 4); __raw_writel(val, addr_cpc_cl_stat_conf()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_stat_conf(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_stat_conf(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_stat_conf(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_stat_conf(uint32_t val) { change_cpc_cl_stat_conf(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_stat_conf(uint32_t val) { change_cpc_cl_stat_conf(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_stat_conf(void) { return mips_cpc_base + (0x4000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_stat_conf(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_stat_conf()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_stat_conf()); val64 = __raw_readl(addr_cpc_co_stat_conf() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_stat_conf()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_stat_conf(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_stat_conf()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_stat_conf()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_stat_conf() + 4); __raw_writel(val, addr_cpc_co_stat_conf()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_stat_conf(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_stat_conf(); reg_val &= ~mask; reg_val |= val; write_cpc_co_stat_conf(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_stat_conf(uint32_t val) { change_cpc_co_stat_conf(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_stat_conf(uint32_t val) { change_cpc_co_stat_conf(val, 0); }
# 136 "/home/nathan/src/linux/arch/mips/include/asm/mips-cpc.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_other(void) { return mips_cpc_base + (0x2000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_other(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_other()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_other()); val64 = __raw_readl(addr_cpc_cl_other() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_other()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_other(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_other()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_other()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_other() + 4); __raw_writel(val, addr_cpc_cl_other()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_other(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_other(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_other(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_other(uint32_t val) { change_cpc_cl_other(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_other(uint32_t val) { change_cpc_cl_other(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_other(void) { return mips_cpc_base + (0x4000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_other(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_other()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_other()); val64 = __raw_readl(addr_cpc_co_other() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_other()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_other(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_other()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_other()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_other() + 4); __raw_writel(val, addr_cpc_co_other()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_other(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_other(); reg_val &= ~mask; reg_val |= val; write_cpc_co_other(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_other(uint32_t val) { change_cpc_co_other(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_other(uint32_t val) { change_cpc_co_other(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_vp_stop(void) { return mips_cpc_base + (0x2000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_vp_stop(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_vp_stop()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_vp_stop()); val64 = __raw_readl(addr_cpc_cl_vp_stop() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_vp_stop()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_vp_stop(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_vp_stop()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_vp_stop()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_vp_stop() + 4); __raw_writel(val, addr_cpc_cl_vp_stop()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_vp_stop(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_vp_stop(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_vp_stop(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_vp_stop(uint32_t val) { change_cpc_cl_vp_stop(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_vp_stop(uint32_t val) { change_cpc_cl_vp_stop(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_vp_stop(void) { return mips_cpc_base + (0x4000 + 0x020); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_vp_stop(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_vp_stop()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_vp_stop()); val64 = __raw_readl(addr_cpc_co_vp_stop() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_vp_stop()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_vp_stop(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_vp_stop()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_vp_stop()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_vp_stop() + 4); __raw_writel(val, addr_cpc_co_vp_stop()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_vp_stop(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_vp_stop(); reg_val &= ~mask; reg_val |= val; write_cpc_co_vp_stop(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_vp_stop(uint32_t val) { change_cpc_co_vp_stop(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_vp_stop(uint32_t val) { change_cpc_co_vp_stop(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_vp_run(void) { return mips_cpc_base + (0x2000 + 0x028); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_vp_run(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_vp_run()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_vp_run()); val64 = __raw_readl(addr_cpc_cl_vp_run() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_vp_run()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_vp_run(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_vp_run()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_vp_run()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_vp_run() + 4); __raw_writel(val, addr_cpc_cl_vp_run()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_vp_run(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_vp_run(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_vp_run(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_vp_run(uint32_t val) { change_cpc_cl_vp_run(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_vp_run(uint32_t val) { change_cpc_cl_vp_run(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_vp_run(void) { return mips_cpc_base + (0x4000 + 0x028); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_vp_run(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_vp_run()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_vp_run()); val64 = __raw_readl(addr_cpc_co_vp_run() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_vp_run()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_vp_run(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_vp_run()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_vp_run()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_vp_run() + 4); __raw_writel(val, addr_cpc_co_vp_run()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_vp_run(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_vp_run(); reg_val &= ~mask; reg_val |= val; write_cpc_co_vp_run(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_vp_run(uint32_t val) { change_cpc_co_vp_run(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_vp_run(uint32_t val) { change_cpc_co_vp_run(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_vp_running(void) { return mips_cpc_base + (0x2000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_vp_running(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_vp_running()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_vp_running()); val64 = __raw_readl(addr_cpc_cl_vp_running() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_vp_running()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_vp_running(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_vp_running()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_vp_running()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_vp_running() + 4); __raw_writel(val, addr_cpc_cl_vp_running()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_vp_running(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_vp_running(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_vp_running(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_vp_running(uint32_t val) { change_cpc_cl_vp_running(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_vp_running(uint32_t val) { change_cpc_cl_vp_running(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_vp_running(void) { return mips_cpc_base + (0x4000 + 0x030); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_vp_running(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_vp_running()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_vp_running()); val64 = __raw_readl(addr_cpc_co_vp_running() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_vp_running()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_vp_running(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_vp_running()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_vp_running()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_vp_running() + 4); __raw_writel(val, addr_cpc_co_vp_running()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_vp_running(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_vp_running(); reg_val &= ~mask; reg_val |= val; write_cpc_co_vp_running(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_vp_running(uint32_t val) { change_cpc_co_vp_running(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_vp_running(uint32_t val) { change_cpc_co_vp_running(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_cl_config(void) { return mips_cpc_base + (0x2000 + 0x090); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_cl_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_cl_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_cl_config()); val64 = __raw_readl(addr_cpc_cl_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_cl_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_cl_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_cl_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_cl_config()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_cl_config() + 4); __raw_writel(val, addr_cpc_cl_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_cl_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_cl_config(); reg_val &= ~mask; reg_val |= val; write_cpc_cl_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_cl_config(uint32_t val) { change_cpc_cl_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_cl_config(uint32_t val) { change_cpc_cl_config(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_cpc_co_config(void) { return mips_cpc_base + (0x4000 + 0x090); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_cpc_co_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_cpc_co_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_cpc_co_config()); val64 = __raw_readl(addr_cpc_co_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_cpc_co_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_cpc_co_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_cpc_co_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_cpc_co_config()); break; } __raw_writel((uint64_t)val >> 32, addr_cpc_co_config() + 4); __raw_writel(val, addr_cpc_co_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_cpc_co_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_cpc_co_config(); reg_val &= ~mask; reg_val |= val; write_cpc_co_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_cpc_co_config(uint32_t val) { change_cpc_co_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_cpc_co_config(uint32_t val) { change_cpc_co_config(val, 0); }
# 162 "/home/nathan/src/linux/arch/mips/include/asm/mips-cpc.h"
extern void mips_cpc_lock_other(unsigned int core);







extern void mips_cpc_unlock_other(void);
# 106 "/home/nathan/src/linux/arch/mips/include/asm/mips-cps.h" 2
# 1 "/home/nathan/src/linux/arch/mips/include/asm/mips-gic.h" 1
# 17 "/home/nathan/src/linux/arch/mips/include/asm/mips-gic.h"
extern void *mips_gic_base;
# 164 "/home/nathan/src/linux/arch/mips/include/asm/mips-gic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_config(void) { return mips_gic_base + (0x00000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_config(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_config()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_config()); val64 = __raw_readl(addr_gic_config() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_config()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_config(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_config()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_config()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_config() + 4); __raw_writel(val, addr_gic_config()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_config(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_config(); reg_val &= ~mask; reg_val |= val; write_gic_config(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_config(uint32_t val) { change_gic_config(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_config(uint32_t val) { change_gic_config(val, 0); }






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_counter(void) { return mips_gic_base + (0x00000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gic_counter(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gic_counter()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_counter()); val64 = __raw_readl(addr_gic_counter() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_counter()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_counter(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gic_counter()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_counter()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_counter() + 4); __raw_writel(val, addr_gic_counter()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_counter(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gic_counter(); reg_val &= ~mask; reg_val |= val; write_gic_counter(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_counter(uint64_t val) { change_gic_counter(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_counter(uint64_t val) { change_gic_counter(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_counter_32l(void) { return mips_gic_base + (0x00000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_counter_32l(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_counter_32l()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_counter_32l()); val64 = __raw_readl(addr_gic_counter_32l() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_counter_32l()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_counter_32l(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_counter_32l()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_counter_32l()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_counter_32l() + 4); __raw_writel(val, addr_gic_counter_32l()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_counter_32l(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_counter_32l(); reg_val &= ~mask; reg_val |= val; write_gic_counter_32l(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_counter_32l(uint32_t val) { change_gic_counter_32l(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_counter_32l(uint32_t val) { change_gic_counter_32l(val, 0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_counter_32h(void) { return mips_gic_base + (0x00000 + 0x014); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_counter_32h(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_counter_32h()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_counter_32h()); val64 = __raw_readl(addr_gic_counter_32h() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_counter_32h()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_counter_32h(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_counter_32h()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_counter_32h()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_counter_32h() + 4); __raw_writel(val, addr_gic_counter_32h()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_counter_32h(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_counter_32h(); reg_val &= ~mask; reg_val |= val; write_gic_counter_32h(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_counter_32h(uint32_t val) { change_gic_counter_32h(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_counter_32h(uint32_t val) { change_gic_counter_32h(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_pol(void) { return mips_gic_base + (0x100); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_pol(unsigned int intr) { void *addr = addr_gic_pol(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_pol(unsigned int intr) { void *addr = addr_gic_pol(); if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); __raw_writeq(((((1UL))) << (intr % 64)), addr); } else { addr += (intr / 32) * sizeof(uint32_t); __raw_writel(((((1UL))) << (intr % 32)), addr); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_pol(unsigned int intr, unsigned int val) { void *addr = addr_gic_pol(); if (mips_cm_is64) { uint64_t _val; addr += (intr / 64) * sizeof(uint64_t); _val = __raw_readq(addr); _val &= ~((((1ULL))) << (intr % 64)); _val |= (uint64_t)val << (intr % 64); __raw_writeq(_val, addr); } else { uint32_t _val; addr += (intr / 32) * sizeof(uint32_t); _val = __raw_readl(addr); _val &= ~((((1UL))) << (intr % 32)); _val |= val << (intr % 32); __raw_writel(_val, addr); } }






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_trig(void) { return mips_gic_base + (0x180); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_trig(unsigned int intr) { void *addr = addr_gic_trig(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_trig(unsigned int intr) { void *addr = addr_gic_trig(); if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); __raw_writeq(((((1UL))) << (intr % 64)), addr); } else { addr += (intr / 32) * sizeof(uint32_t); __raw_writel(((((1UL))) << (intr % 32)), addr); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_trig(unsigned int intr, unsigned int val) { void *addr = addr_gic_trig(); if (mips_cm_is64) { uint64_t _val; addr += (intr / 64) * sizeof(uint64_t); _val = __raw_readq(addr); _val &= ~((((1ULL))) << (intr % 64)); _val |= (uint64_t)val << (intr % 64); __raw_writeq(_val, addr); } else { uint32_t _val; addr += (intr / 32) * sizeof(uint32_t); _val = __raw_readl(addr); _val &= ~((((1UL))) << (intr % 32)); _val |= val << (intr % 32); __raw_writel(_val, addr); } }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_dual(void) { return mips_gic_base + (0x200); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_dual(unsigned int intr) { void *addr = addr_gic_dual(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_dual(unsigned int intr) { void *addr = addr_gic_dual(); if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); __raw_writeq(((((1UL))) << (intr % 64)), addr); } else { addr += (intr / 32) * sizeof(uint32_t); __raw_writel(((((1UL))) << (intr % 32)), addr); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_dual(unsigned int intr, unsigned int val) { void *addr = addr_gic_dual(); if (mips_cm_is64) { uint64_t _val; addr += (intr / 64) * sizeof(uint64_t); _val = __raw_readq(addr); _val &= ~((((1ULL))) << (intr % 64)); _val |= (uint64_t)val << (intr % 64); __raw_writeq(_val, addr); } else { uint32_t _val; addr += (intr / 32) * sizeof(uint32_t); _val = __raw_readl(addr); _val &= ~((((1UL))) << (intr % 32)); _val |= val << (intr % 32); __raw_writel(_val, addr); } }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_wedge(void) { return mips_gic_base + (0x00000 + 0x280); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_wedge(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_wedge()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_wedge()); val64 = __raw_readl(addr_gic_wedge() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_wedge()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_wedge(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_wedge()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_wedge()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_wedge() + 4); __raw_writel(val, addr_gic_wedge()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_wedge(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_wedge(); reg_val &= ~mask; reg_val |= val; write_gic_wedge(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_wedge(uint32_t val) { change_gic_wedge(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_wedge(uint32_t val) { change_gic_wedge(val, 0); }




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_rmask(void) { return mips_gic_base + (0x300); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_rmask(unsigned int intr) { void *addr = addr_gic_rmask(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_rmask(unsigned int intr) { void *addr = addr_gic_rmask(); if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); __raw_writeq(((((1UL))) << (intr % 64)), addr); } else { addr += (intr / 32) * sizeof(uint32_t); __raw_writel(((((1UL))) << (intr % 32)), addr); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_rmask(unsigned int intr, unsigned int val) { void *addr = addr_gic_rmask(); if (mips_cm_is64) { uint64_t _val; addr += (intr / 64) * sizeof(uint64_t); _val = __raw_readq(addr); _val &= ~((((1ULL))) << (intr % 64)); _val |= (uint64_t)val << (intr % 64); __raw_writeq(_val, addr); } else { uint32_t _val; addr += (intr / 32) * sizeof(uint32_t); _val = __raw_readl(addr); _val &= ~((((1UL))) << (intr % 32)); _val |= val << (intr % 32); __raw_writel(_val, addr); } }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_smask(void) { return mips_gic_base + (0x380); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_smask(unsigned int intr) { void *addr = addr_gic_smask(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_smask(unsigned int intr) { void *addr = addr_gic_smask(); if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); __raw_writeq(((((1UL))) << (intr % 64)), addr); } else { addr += (intr / 32) * sizeof(uint32_t); __raw_writel(((((1UL))) << (intr % 32)), addr); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_smask(unsigned int intr, unsigned int val) { void *addr = addr_gic_smask(); if (mips_cm_is64) { uint64_t _val; addr += (intr / 64) * sizeof(uint64_t); _val = __raw_readq(addr); _val &= ~((((1ULL))) << (intr % 64)); _val |= (uint64_t)val << (intr % 64); __raw_writeq(_val, addr); } else { uint32_t _val; addr += (intr / 32) * sizeof(uint32_t); _val = __raw_readl(addr); _val &= ~((((1UL))) << (intr % 32)); _val |= val << (intr % 32); __raw_writel(_val, addr); } }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_mask(void) { return mips_gic_base + (0x400); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_mask(unsigned int intr) { void *addr = addr_gic_mask(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_pend(void) { return mips_gic_base + (0x480); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_pend(unsigned int intr) { void *addr = addr_gic_pend(); unsigned int val; if (mips_cm_is64) { addr += (intr / 64) * sizeof(uint64_t); val = __raw_readq(addr) >> intr % 64; } else { addr += (intr / 32) * sizeof(uint32_t); val = __raw_readl(addr) >> intr % 32; } return val & 0x1; }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_map_pin(unsigned int intr) { return mips_gic_base + (0x500) + (intr * (0x4)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_map_pin(unsigned int intr) { do { extern void __compiletime_assert_58(void) ; if (!(!(32 != 32))) __compiletime_assert_58(); } while (0); return __raw_readl(addr_gic_map_pin(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_map_pin(unsigned int intr, unsigned int val) { do { extern void __compiletime_assert_59(void) ; if (!(!(32 != 32))) __compiletime_assert_59(); } while (0); __raw_writel(val, addr_gic_map_pin(intr)); }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_map_vp(unsigned int intr) { return mips_gic_base + (0x2000) + (intr * (0x20)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_map_vp(unsigned int intr) { do { extern void __compiletime_assert_60(void) ; if (!(!(32 != 32))) __compiletime_assert_60(); } while (0); return __raw_readl(addr_gic_map_vp(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_map_vp(unsigned int intr, unsigned int val) { do { extern void __compiletime_assert_61(void) ; if (!(!(32 != 32))) __compiletime_assert_61(); } while (0); __raw_writel(val, addr_gic_map_vp(intr)); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_ctl(void) { return mips_gic_base + (0x08000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_ctl(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_ctl()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_ctl()); val64 = __raw_readl(addr_gic_vl_ctl() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_ctl()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_ctl(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_ctl()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_ctl()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_ctl() + 4); __raw_writel(val, addr_gic_vl_ctl()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_ctl(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_ctl(); reg_val &= ~mask; reg_val |= val; write_gic_vl_ctl(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_ctl(uint32_t val) { change_gic_vl_ctl(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_ctl(uint32_t val) { change_gic_vl_ctl(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_ctl(void) { return mips_gic_base + (0x0c000 + 0x000); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_ctl(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_ctl()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_ctl()); val64 = __raw_readl(addr_gic_vo_ctl() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_ctl()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_ctl(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_ctl()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_ctl()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_ctl() + 4); __raw_writel(val, addr_gic_vo_ctl()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_ctl(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_ctl(); reg_val &= ~mask; reg_val |= val; write_gic_vo_ctl(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_ctl(uint32_t val) { change_gic_vo_ctl(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_ctl(uint32_t val) { change_gic_vo_ctl(val, 0); }







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_pend(void) { return mips_gic_base + (0x08000 + 0x004); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_pend(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_pend()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_pend()); val64 = __raw_readl(addr_gic_vl_pend() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_pend()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_pend(void) { return mips_gic_base + (0x0c000 + 0x004); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_pend(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_pend()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_pend()); val64 = __raw_readl(addr_gic_vo_pend() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_pend()); return val64; default: return __cps_access_bad_size(); } }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_mask(void) { return mips_gic_base + (0x08000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_mask(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_mask()); val64 = __raw_readl(addr_gic_vl_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_mask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_mask(void) { return mips_gic_base + (0x0c000 + 0x008); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_mask(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_mask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_mask()); val64 = __raw_readl(addr_gic_vo_mask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_mask()); return val64; default: return __cps_access_bad_size(); } }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_rmask(void) { return mips_gic_base + (0x08000 + 0x00c); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_rmask(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_rmask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_rmask()); val64 = __raw_readl(addr_gic_vl_rmask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_rmask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_rmask(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_rmask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_rmask()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_rmask() + 4); __raw_writel(val, addr_gic_vl_rmask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_rmask(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_rmask(); reg_val &= ~mask; reg_val |= val; write_gic_vl_rmask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_rmask(uint32_t val) { change_gic_vl_rmask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_rmask(uint32_t val) { change_gic_vl_rmask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_rmask(void) { return mips_gic_base + (0x0c000 + 0x00c); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_rmask(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_rmask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_rmask()); val64 = __raw_readl(addr_gic_vo_rmask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_rmask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_rmask(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_rmask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_rmask()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_rmask() + 4); __raw_writel(val, addr_gic_vo_rmask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_rmask(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_rmask(); reg_val &= ~mask; reg_val |= val; write_gic_vo_rmask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_rmask(uint32_t val) { change_gic_vo_rmask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_rmask(uint32_t val) { change_gic_vo_rmask(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_smask(void) { return mips_gic_base + (0x08000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_smask(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_smask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_smask()); val64 = __raw_readl(addr_gic_vl_smask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_smask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_smask(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_smask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_smask()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_smask() + 4); __raw_writel(val, addr_gic_vl_smask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_smask(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_smask(); reg_val &= ~mask; reg_val |= val; write_gic_vl_smask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_smask(uint32_t val) { change_gic_vl_smask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_smask(uint32_t val) { change_gic_vl_smask(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_smask(void) { return mips_gic_base + (0x0c000 + 0x010); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_smask(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_smask()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_smask()); val64 = __raw_readl(addr_gic_vo_smask() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_smask()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_smask(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_smask()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_smask()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_smask() + 4); __raw_writel(val, addr_gic_vo_smask()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_smask(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_smask(); reg_val &= ~mask; reg_val |= val; write_gic_vo_smask(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_smask(uint32_t val) { change_gic_vo_smask(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_smask(uint32_t val) { change_gic_vo_smask(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_map(unsigned int intr) { return mips_gic_base + (0x08000 + 0x040) + (intr * (0x4)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_vl_map(unsigned int intr) { do { extern void __compiletime_assert_62(void) ; if (!(!(32 != 32))) __compiletime_assert_62(); } while (0); return __raw_readl(addr_gic_vl_map(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_map(unsigned int intr, unsigned int val) { do { extern void __compiletime_assert_63(void) ; if (!(!(32 != 32))) __compiletime_assert_63(); } while (0); __raw_writel(val, addr_gic_vl_map(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_map(unsigned int intr) { return mips_gic_base + (0x0c000 + 0x040) + (intr * (0x4)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_vo_map(unsigned int intr) { do { extern void __compiletime_assert_64(void) ; if (!(!(32 != 32))) __compiletime_assert_64(); } while (0); return __raw_readl(addr_gic_vo_map(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_map(unsigned int intr, unsigned int val) { do { extern void __compiletime_assert_65(void) ; if (!(!(32 != 32))) __compiletime_assert_65(); } while (0); __raw_writel(val, addr_gic_vo_map(intr)); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_wd_map(void) { return mips_gic_base + (0x08000 + 0x040); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_wd_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_wd_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_wd_map()); val64 = __raw_readl(addr_gic_vl_wd_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_wd_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_wd_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_wd_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_wd_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_wd_map() + 4); __raw_writel(val, addr_gic_vl_wd_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_wd_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_wd_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_wd_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_wd_map(uint32_t val) { change_gic_vl_wd_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_wd_map(uint32_t val) { change_gic_vl_wd_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_wd_map(void) { return mips_gic_base + (0x0c000 + 0x040); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_wd_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_wd_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_wd_map()); val64 = __raw_readl(addr_gic_vo_wd_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_wd_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_wd_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_wd_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_wd_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_wd_map() + 4); __raw_writel(val, addr_gic_vo_wd_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_wd_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_wd_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_wd_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_wd_map(uint32_t val) { change_gic_vo_wd_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_wd_map(uint32_t val) { change_gic_vo_wd_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_compare_map(void) { return mips_gic_base + (0x08000 + 0x044); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_compare_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_compare_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_compare_map()); val64 = __raw_readl(addr_gic_vl_compare_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_compare_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_compare_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_compare_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_compare_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_compare_map() + 4); __raw_writel(val, addr_gic_vl_compare_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_compare_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_compare_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_compare_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_compare_map(uint32_t val) { change_gic_vl_compare_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_compare_map(uint32_t val) { change_gic_vl_compare_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_compare_map(void) { return mips_gic_base + (0x0c000 + 0x044); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_compare_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_compare_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_compare_map()); val64 = __raw_readl(addr_gic_vo_compare_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_compare_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_compare_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_compare_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_compare_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_compare_map() + 4); __raw_writel(val, addr_gic_vo_compare_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_compare_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_compare_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_compare_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_compare_map(uint32_t val) { change_gic_vo_compare_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_compare_map(uint32_t val) { change_gic_vo_compare_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_timer_map(void) { return mips_gic_base + (0x08000 + 0x048); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_timer_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_timer_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_timer_map()); val64 = __raw_readl(addr_gic_vl_timer_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_timer_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_timer_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_timer_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_timer_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_timer_map() + 4); __raw_writel(val, addr_gic_vl_timer_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_timer_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_timer_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_timer_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_timer_map(uint32_t val) { change_gic_vl_timer_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_timer_map(uint32_t val) { change_gic_vl_timer_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_timer_map(void) { return mips_gic_base + (0x0c000 + 0x048); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_timer_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_timer_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_timer_map()); val64 = __raw_readl(addr_gic_vo_timer_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_timer_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_timer_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_timer_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_timer_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_timer_map() + 4); __raw_writel(val, addr_gic_vo_timer_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_timer_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_timer_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_timer_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_timer_map(uint32_t val) { change_gic_vo_timer_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_timer_map(uint32_t val) { change_gic_vo_timer_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_fdc_map(void) { return mips_gic_base + (0x08000 + 0x04c); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_fdc_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_fdc_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_fdc_map()); val64 = __raw_readl(addr_gic_vl_fdc_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_fdc_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_fdc_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_fdc_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_fdc_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_fdc_map() + 4); __raw_writel(val, addr_gic_vl_fdc_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_fdc_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_fdc_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_fdc_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_fdc_map(uint32_t val) { change_gic_vl_fdc_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_fdc_map(uint32_t val) { change_gic_vl_fdc_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_fdc_map(void) { return mips_gic_base + (0x0c000 + 0x04c); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_fdc_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_fdc_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_fdc_map()); val64 = __raw_readl(addr_gic_vo_fdc_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_fdc_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_fdc_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_fdc_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_fdc_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_fdc_map() + 4); __raw_writel(val, addr_gic_vo_fdc_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_fdc_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_fdc_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_fdc_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_fdc_map(uint32_t val) { change_gic_vo_fdc_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_fdc_map(uint32_t val) { change_gic_vo_fdc_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_perfctr_map(void) { return mips_gic_base + (0x08000 + 0x050); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_perfctr_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_perfctr_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_perfctr_map()); val64 = __raw_readl(addr_gic_vl_perfctr_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_perfctr_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_perfctr_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_perfctr_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_perfctr_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_perfctr_map() + 4); __raw_writel(val, addr_gic_vl_perfctr_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_perfctr_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_perfctr_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_perfctr_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_perfctr_map(uint32_t val) { change_gic_vl_perfctr_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_perfctr_map(uint32_t val) { change_gic_vl_perfctr_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_perfctr_map(void) { return mips_gic_base + (0x0c000 + 0x050); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_perfctr_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_perfctr_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_perfctr_map()); val64 = __raw_readl(addr_gic_vo_perfctr_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_perfctr_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_perfctr_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_perfctr_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_perfctr_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_perfctr_map() + 4); __raw_writel(val, addr_gic_vo_perfctr_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_perfctr_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_perfctr_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_perfctr_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_perfctr_map(uint32_t val) { change_gic_vo_perfctr_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_perfctr_map(uint32_t val) { change_gic_vo_perfctr_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_swint0_map(void) { return mips_gic_base + (0x08000 + 0x054); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_swint0_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_swint0_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_swint0_map()); val64 = __raw_readl(addr_gic_vl_swint0_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_swint0_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_swint0_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_swint0_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_swint0_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_swint0_map() + 4); __raw_writel(val, addr_gic_vl_swint0_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_swint0_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_swint0_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_swint0_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_swint0_map(uint32_t val) { change_gic_vl_swint0_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_swint0_map(uint32_t val) { change_gic_vl_swint0_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_swint0_map(void) { return mips_gic_base + (0x0c000 + 0x054); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_swint0_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_swint0_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_swint0_map()); val64 = __raw_readl(addr_gic_vo_swint0_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_swint0_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_swint0_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_swint0_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_swint0_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_swint0_map() + 4); __raw_writel(val, addr_gic_vo_swint0_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_swint0_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_swint0_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_swint0_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_swint0_map(uint32_t val) { change_gic_vo_swint0_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_swint0_map(uint32_t val) { change_gic_vo_swint0_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_swint1_map(void) { return mips_gic_base + (0x08000 + 0x058); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_swint1_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_swint1_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_swint1_map()); val64 = __raw_readl(addr_gic_vl_swint1_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_swint1_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_swint1_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_swint1_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_swint1_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_swint1_map() + 4); __raw_writel(val, addr_gic_vl_swint1_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_swint1_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_swint1_map(); reg_val &= ~mask; reg_val |= val; write_gic_vl_swint1_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_swint1_map(uint32_t val) { change_gic_vl_swint1_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_swint1_map(uint32_t val) { change_gic_vl_swint1_map(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_swint1_map(void) { return mips_gic_base + (0x0c000 + 0x058); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_swint1_map(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_swint1_map()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_swint1_map()); val64 = __raw_readl(addr_gic_vo_swint1_map() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_swint1_map()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_swint1_map(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_swint1_map()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_swint1_map()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_swint1_map() + 4); __raw_writel(val, addr_gic_vo_swint1_map()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_swint1_map(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_swint1_map(); reg_val &= ~mask; reg_val |= val; write_gic_vo_swint1_map(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_swint1_map(uint32_t val) { change_gic_vo_swint1_map(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_swint1_map(uint32_t val) { change_gic_vo_swint1_map(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_other(void) { return mips_gic_base + (0x08000 + 0x080); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_other(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_other()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_other()); val64 = __raw_readl(addr_gic_vl_other() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_other()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_other(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vl_other()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_other()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_other() + 4); __raw_writel(val, addr_gic_vl_other()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_other(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vl_other(); reg_val &= ~mask; reg_val |= val; write_gic_vl_other(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_other(uint32_t val) { change_gic_vl_other(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_other(uint32_t val) { change_gic_vl_other(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_other(void) { return mips_gic_base + (0x0c000 + 0x080); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_other(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_other()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_other()); val64 = __raw_readl(addr_gic_vo_other() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_other()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_other(uint32_t val) { switch (32) { case 32: __raw_writel(val, addr_gic_vo_other()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_other()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_other() + 4); __raw_writel(val, addr_gic_vo_other()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_other(uint32_t mask, uint32_t val) { uint32_t reg_val = read_gic_vo_other(); reg_val &= ~mask; reg_val |= val; write_gic_vo_other(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_other(uint32_t val) { change_gic_vo_other(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_other(uint32_t val) { change_gic_vo_other(val, 0); }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_ident(void) { return mips_gic_base + (0x08000 + 0x088); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vl_ident(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vl_ident()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_ident()); val64 = __raw_readl(addr_gic_vl_ident() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_ident()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_ident(void) { return mips_gic_base + (0x0c000 + 0x088); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint32_t read_gic_vo_ident(void) { uint64_t val64; switch (32) { case 32: return __raw_readl(addr_gic_vo_ident()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_ident()); val64 = __raw_readl(addr_gic_vo_ident() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_ident()); return val64; default: return __cps_access_bad_size(); } }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_compare(void) { return mips_gic_base + (0x08000 + 0x0a0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gic_vl_compare(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gic_vl_compare()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vl_compare()); val64 = __raw_readl(addr_gic_vl_compare() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vl_compare()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_compare(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gic_vl_compare()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vl_compare()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vl_compare() + 4); __raw_writel(val, addr_gic_vl_compare()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vl_compare(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gic_vl_compare(); reg_val &= ~mask; reg_val |= val; write_gic_vl_compare(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vl_compare(uint64_t val) { change_gic_vl_compare(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vl_compare(uint64_t val) { change_gic_vl_compare(val, 0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_compare(void) { return mips_gic_base + (0x0c000 + 0x0a0); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t read_gic_vo_compare(void) { uint64_t val64; switch (64) { case 32: return __raw_readl(addr_gic_vo_compare()); case 64: if (mips_cm_is64) return __raw_readq(addr_gic_vo_compare()); val64 = __raw_readl(addr_gic_vo_compare() + 4); val64 <<= 32; val64 |= __raw_readl(addr_gic_vo_compare()); return val64; default: return __cps_access_bad_size(); } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_compare(uint64_t val) { switch (64) { case 32: __raw_writel(val, addr_gic_vo_compare()); break; case 64: if (mips_cm_is64) { __raw_writeq(val, addr_gic_vo_compare()); break; } __raw_writel((uint64_t)val >> 32, addr_gic_vo_compare() + 4); __raw_writel(val, addr_gic_vo_compare()); break; default: __cps_access_bad_size(); break; } } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void change_gic_vo_compare(uint64_t mask, uint64_t val) { uint64_t reg_val = read_gic_vo_compare(); reg_val &= ~mask; reg_val |= val; write_gic_vo_compare(reg_val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void set_gic_vo_compare(uint64_t val) { change_gic_vo_compare(val, val); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clear_gic_vo_compare(uint64_t val) { change_gic_vo_compare(val, 0); }


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vl_eic_shadow_set(unsigned int intr) { return mips_gic_base + (0x08000 + 0x100) + (intr * (0x4)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_vl_eic_shadow_set(unsigned int intr) { do { extern void __compiletime_assert_66(void) ; if (!(!(32 != 32))) __compiletime_assert_66(); } while (0); return __raw_readl(addr_gic_vl_eic_shadow_set(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vl_eic_shadow_set(unsigned int intr, unsigned int val) { do { extern void __compiletime_assert_67(void) ; if (!(!(32 != 32))) __compiletime_assert_67(); } while (0); __raw_writel(val, addr_gic_vl_eic_shadow_set(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void *addr_gic_vo_eic_shadow_set(unsigned int intr) { return mips_gic_base + (0x0c000 + 0x100) + (intr * (0x4)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int read_gic_vo_eic_shadow_set(unsigned int intr) { do { extern void __compiletime_assert_68(void) ; if (!(!(32 != 32))) __compiletime_assert_68(); } while (0); return __raw_readl(addr_gic_vo_eic_shadow_set(intr)); } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_gic_vo_eic_shadow_set(unsigned int intr, unsigned int val) { do { extern void __compiletime_assert_69(void) ; if (!(!(32 != 32))) __compiletime_assert_69(); } while (0); __raw_writel(val, addr_gic_vo_eic_shadow_set(intr)); }
# 289 "/home/nathan/src/linux/arch/mips/include/asm/mips-gic.h"
enum mips_gic_local_interrupt {
 GIC_LOCAL_INT_WD,
 GIC_LOCAL_INT_COMPARE,
 GIC_LOCAL_INT_TIMER,
 GIC_LOCAL_INT_PERFCTR,
 GIC_LOCAL_INT_SWINT0,
 GIC_LOCAL_INT_SWINT1,
 GIC_LOCAL_INT_FDC,
 GIC_NUM_LOCAL_INTRS
};
# 308 "/home/nathan/src/linux/arch/mips/include/asm/mips-gic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool mips_gic_present(void)
{
 return 1 && mips_gic_base;
}
# 328 "/home/nathan/src/linux/arch/mips/include/asm/mips-gic.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int
mips_gic_vx_map_reg(enum mips_gic_local_interrupt intr)
{

 if (intr <= GIC_LOCAL_INT_TIMER)
  return intr;


 if (intr == GIC_LOCAL_INT_FDC)
  return GIC_LOCAL_INT_TIMER + 1;


 return intr + 1;
}
# 351 "/home/nathan/src/linux/arch/mips/include/asm/mips-gic.h"
extern int gic_get_c0_compare_int(void);
# 361 "/home/nathan/src/linux/arch/mips/include/asm/mips-gic.h"
extern int gic_get_c0_perfcount_int(void);
# 371 "/home/nathan/src/linux/arch/mips/include/asm/mips-gic.h"
extern int gic_get_c0_fdc_int(void);
# 107 "/home/nathan/src/linux/arch/mips/include/asm/mips-cps.h" 2






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int mips_cps_numclusters(void)
{
 unsigned int num_clusters;

 if (mips_cm_revision() < (((9) << __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((8) > (15)), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15))))))) | ((0) << __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((0) > (7)), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))))))))
  return 1;

 num_clusters = read_gcr_config() & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((23) > (29)), (23) > (29), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (23)) + 1) & (~(((0UL))) >> (32 - 1 - (29)))));
 num_clusters >>= __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((23) > (29)), (23) > (29), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (23)) + 1) & (~(((0UL))) >> (32 - 1 - (29))))));
 return num_clusters;
}
# 133 "/home/nathan/src/linux/arch/mips/include/asm/mips-cps.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) uint64_t mips_cps_cluster_config(unsigned int cluster)
{
 uint64_t config;

 if (mips_cm_revision() < (((9) << __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((8) > (15)), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15))))))) | ((0) << __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((0) > (7)), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7))))))))) {





  ({ int __ret_warn_on = !!(cluster != 0); if (__builtin_expect(!!(__ret_warn_on), 0)) do { do { } while(0); warn_slowpath_fmt("arch/mips/include/asm/mips-cps.h", 143, 9, ((void *)0)); do { } while(0); } while (0); __builtin_expect(!!(__ret_warn_on), 0); });
  config = read_gcr_config();
 } else {





  mips_cm_lock_other(cluster, 0, 0, 1);
  config = read_cpc_redir_config();
  mips_cm_unlock_other();
 }

 return config;
}
# 166 "/home/nathan/src/linux/arch/mips/include/asm/mips-cps.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int mips_cps_numcores(unsigned int cluster)
{
 if (!mips_cm_present())
  return 0;


 return (mips_cps_cluster_config(cluster) + 1) & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((0) > (7)), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7)))));
}
# 182 "/home/nathan/src/linux/arch/mips/include/asm/mips-cps.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int mips_cps_numiocu(unsigned int cluster)
{
 unsigned int num_iocu;

 if (!mips_cm_present())
  return 0;

 num_iocu = mips_cps_cluster_config(cluster) & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((8) > (15)), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15)))));
 num_iocu >>= __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((8) > (15)), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15))))));
 return num_iocu;
}
# 203 "/home/nathan/src/linux/arch/mips/include/asm/mips-cps.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int mips_cps_numvps(unsigned int cluster, unsigned int core)
{
 unsigned int cfg;

 if (!mips_cm_present())
  return 1;

 if ((!0 || !((6 < (6)) && (cpu_data[0].ases & (0x00000020))))
  && (!1 || !((6 >= (6)) && (cpu_data[0].options & (((((1ULL))) << (40)))))))
  return 1;

 mips_cm_lock_other(cluster, core, 0, 0);

 if (mips_cm_revision() < (((9) << __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((8) > (15)), (8) > (15), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (8)) + 1) & (~(((0UL))) >> (32 - 1 - (15))))))) | ((0) << __ffs(((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((0) > (7)), (0) > (7), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (7))))))))) {




  cfg = read_gcr_co_config();
 } else {





  cfg = read_cpc_co_config();
 }

 mips_cm_unlock_other();

 return (cfg + 1) & ((((int)(sizeof(struct { int:(-!!(__builtin_choose_expr( __builtin_constant_p((0) > (9)), (0) > (9), 0))); })))) + (((~(((0UL)))) - ((((1UL))) << (0)) + 1) & (~(((0UL))) >> (32 - 1 - (9)))));
}
# 17 "/home/nathan/src/linux/arch/mips/include/asm/smp-ops.h" 2





struct task_struct;

struct plat_smp_ops {
 void (*send_ipi_single)(int cpu, unsigned int action);
 void (*send_ipi_mask)(const struct cpumask *mask, unsigned int action);
 void (*init_secondary)(void);
 void (*smp_finish)(void);
 int (*boot_secondary)(int cpu, struct task_struct *idle);
 void (*smp_setup)(void);
 void (*prepare_cpus)(unsigned int max_cpus);
 void (*prepare_boot_cpu)(void);

 int (*cpu_disable)(void);
 void (*cpu_die)(unsigned int cpu);




};

extern void register_smp_ops(const struct plat_smp_ops *ops);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void plat_smp_setup(void)
{
 extern const struct plat_smp_ops *mp_ops;

 mp_ops->smp_setup();
}

extern void mips_smp_send_ipi_single(int cpu, unsigned int action);
extern void mips_smp_send_ipi_mask(const struct cpumask *mask,
          unsigned int action);
# 70 "/home/nathan/src/linux/arch/mips/include/asm/smp-ops.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int register_up_smp_ops(void)
{

 extern const struct plat_smp_ops up_smp_ops;

 register_smp_ops(&up_smp_ops);

 return 0;



}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int register_cmp_smp_ops(void)
{
# 95 "/home/nathan/src/linux/arch/mips/include/asm/smp-ops.h"
 return -19;

}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int register_vsmp_smp_ops(void)
{







 return -19;

}


extern int register_cps_smp_ops(void);
# 22 "/home/nathan/src/linux/arch/mips/include/asm/smp.h" 2

extern int smp_num_siblings;
extern cpumask_t cpu_sibling_map[];
extern cpumask_t cpu_core_map[];
extern cpumask_t cpu_foreign_map[];

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int raw_smp_processor_id(void)
{





 return current_thread_info()->cpu;

}




extern int __cpu_number_map[16];



extern int __cpu_logical_map[16];
# 58 "/home/nathan/src/linux/arch/mips/include/asm/smp.h"
extern cpumask_t cpu_coherent_mask;

extern void smp_bootstrap(void);

extern void calculate_cpu_foreign_map(void);






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void smp_send_reschedule(int cpu)
{
 extern const struct plat_smp_ops *mp_ops;

 mp_ops->send_ipi_single(cpu, 0x1);
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __cpu_disable(void)
{
 extern const struct plat_smp_ops *mp_ops;

 return mp_ops->cpu_disable();
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __cpu_die(unsigned int cpu)
{
 extern const struct plat_smp_ops *mp_ops;

 mp_ops->cpu_die(cpu);
}

extern void play_dead(void);
# 115 "/home/nathan/src/linux/arch/mips/include/asm/smp.h"
int mips_smp_ipi_allocate(const struct cpumask *mask);






int mips_smp_ipi_free(const struct cpumask *mask);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_send_call_function_single_ipi(int cpu)
{
 extern const struct plat_smp_ops *mp_ops;

 mp_ops->send_ipi_single(cpu, 0x2);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void arch_send_call_function_ipi_mask(const struct cpumask *mask)
{
 extern const struct plat_smp_ops *mp_ops;

 mp_ops->send_ipi_mask(mask, 0x2);
}
# 85 "/home/nathan/src/linux/include/linux/smp.h" 2
# 94 "/home/nathan/src/linux/include/linux/smp.h"
extern void smp_send_stop(void);




extern void smp_send_reschedule(int cpu);





extern void smp_prepare_cpus(unsigned int max_cpus);




extern int __cpu_up(unsigned int cpunum, struct task_struct *tidle);




extern void smp_cpus_done(unsigned int max_cpus);




void smp_call_function(smp_call_func_t func, void *info, int wait);
void smp_call_function_many(const struct cpumask *mask,
       smp_call_func_t func, void *info, bool wait);

int smp_call_function_any(const struct cpumask *mask,
     smp_call_func_t func, void *info, int wait);

void kick_all_cpus_sync(void);
void wake_up_all_idle_cpus(void);




void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) call_function_init(void);
void generic_smp_call_function_single_interrupt(void);







void smp_prepare_boot_cpu(void);

extern unsigned int setup_max_cpus;
extern void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) setup_nr_cpu_ids(void);
extern void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) smp_init(void);

extern int __boot_cpu_id;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int get_boot_cpu_id(void)
{
 return __boot_cpu_id;
}
# 245 "/home/nathan/src/linux/include/linux/smp.h"
extern void arch_disable_smp_support(void);

extern void arch_thaw_secondary_cpus_begin(void);
extern void arch_thaw_secondary_cpus_end(void);

void smp_setup_processor_id(void);

int smp_call_on_cpu(unsigned int cpu, int (*func)(void *), void *par,
      bool phys);


int smpcfd_prepare_cpu(unsigned int cpu);
int smpcfd_dead_cpu(unsigned int cpu);
int smpcfd_dying_cpu(unsigned int cpu);
# 13 "/home/nathan/src/linux/arch/mips/include/asm/cpu-type.h" 2


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__pure__)) __get_cpu_type(const int cpu_type)
{
 switch (cpu_type) {
# 33 "/home/nathan/src/linux/arch/mips/include/asm/cpu-type.h"
 case CPU_4KC:
 case CPU_ALCHEMY:
 case CPU_PR4450:




 case CPU_4KEC:
 case CPU_XBURST:



 case CPU_4KSC:
 case CPU_24K:
 case CPU_34K:
 case CPU_1004K:
 case CPU_74K:
 case CPU_1074K:
 case CPU_M14KC:
 case CPU_M14KEC:
 case CPU_INTERAPTIV:
 case CPU_PROAPTIV:
# 68 "/home/nathan/src/linux/arch/mips/include/asm/cpu-type.h"
 case CPU_QEMU_GENERIC:



 case CPU_5KC:
 case CPU_5KE:
 case CPU_20KC:
 case CPU_25KF:
 case CPU_SB1:
 case CPU_SB1A:
# 88 "/home/nathan/src/linux/arch/mips/include/asm/cpu-type.h"
 case CPU_M6250:



 case CPU_I6400:
 case CPU_I6500:
 case CPU_P6600:
# 178 "/home/nathan/src/linux/arch/mips/include/asm/cpu-type.h"
 case CPU_BMIPS32:
 case CPU_BMIPS3300:
# 201 "/home/nathan/src/linux/arch/mips/include/asm/cpu-type.h"
  break;
 default:
  do { ; __builtin_unreachable(); } while (0);
 }

 return cpu_type;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__pure__)) current_cpu_type(void)
{
 const int cpu_type = cpu_data[raw_smp_processor_id()].cputype;

 return __get_cpu_type(cpu_type);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__pure__)) boot_cpu_type(void)
{
 const int cpu_type = cpu_data[0].cputype;

 return __get_cpu_type(cpu_type);
}
# 20 "/home/nathan/src/linux/arch/mips/include/asm/timex.h" 2
# 40 "/home/nathan/src/linux/arch/mips/include/asm/timex.h"
typedef unsigned int cycles_t;
# 52 "/home/nathan/src/linux/arch/mips/include/asm/timex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int can_use_mips_counter(unsigned int prid)
{
 int comp = (prid & 0xff0000) != 0x000000;

 if (__builtin_constant_p((cpu_data[0].options & (((((1ULL))) << (7))))) && !(cpu_data[0].options & (((((1ULL))) << (7)))))
  return 0;
 else if (__builtin_constant_p(((((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((6 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((6 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) && ((((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((6 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((6 >= (6)) && (cpu_data[0].isa_level & (0x00000800)))))
  return 1;
 else if (__builtin_expect(!!(!__builtin_constant_p(((((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((6 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((6 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) && comp), 1))
  return 1;

 if (!__builtin_constant_p((cpu_data[0].options & (((((1ULL))) << (7))))))
  asm volatile("" : "=m" (cpu_data[0].options));
 if (__builtin_expect(!!((cpu_data[0].options & (((((1ULL))) << (7)))) && prid >= (0x0400 | ((5) << 4 | (0)))), 1))

  return 1;
 else
  return 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) cycles_t get_cycles(void)
{
 if (can_use_mips_counter(({ unsigned int __res; if (0 == 0) __asm__ ( "mfc0\t%0, " "$15" "\n\t" : "=r" (__res)); else __asm__ ( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$15" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; })))
  return ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$9" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$9" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; });
 else
  return 0;
}
# 87 "/home/nathan/src/linux/arch/mips/include/asm/timex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long random_get_entropy(void)
{
 unsigned int prid = ({ unsigned int __res; if (0 == 0) __asm__ ( "mfc0\t%0, " "$15" "\n\t" : "=r" (__res)); else __asm__ ( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$15" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; });
 unsigned int imp = prid & 0xff00;

 if (can_use_mips_counter(prid))
  return ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$9" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$9" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; });
 else if (__builtin_expect(!!(imp != 0x0300 && imp != 0x0600), 1))
  return ({ unsigned int __res; if (0 == 0) __asm__ __volatile__( "mfc0\t%0, " "$1" "\n\t" : "=r" (__res)); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mfc0\t%0, " "$1" ", " "0" "\n\t" ".set\tpop\n\t" : "=r" (__res)); __res; });
 else
  return 0;
}
# 66 "/home/nathan/src/linux/include/linux/timex.h" 2
# 139 "/home/nathan/src/linux/include/linux/timex.h"
extern unsigned long tick_usec;
extern unsigned long tick_nsec;
# 154 "/home/nathan/src/linux/include/linux/timex.h"
extern int do_adjtimex(struct __kernel_timex *);
extern int do_clock_adjtime(const clockid_t which_clock, struct __kernel_timex * ktx);

extern void hardpps(const struct timespec64 *, const struct timespec64 *);

int read_current_timer(unsigned long *timer_val);
# 14 "/home/nathan/src/linux/include/linux/time32.h" 2

# 1 "/home/nathan/src/linux/include/vdso/time32.h" 1




typedef s32 old_time32_t;

struct old_timespec32 {
 old_time32_t tv_sec;
 s32 tv_nsec;
};

struct old_timeval32 {
 old_time32_t tv_sec;
 s32 tv_usec;
};
# 16 "/home/nathan/src/linux/include/linux/time32.h" 2

struct old_itimerspec32 {
 struct old_timespec32 it_interval;
 struct old_timespec32 it_value;
};

struct old_utimbuf32 {
 old_time32_t actime;
 old_time32_t modtime;
};

struct old_timex32 {
 u32 modes;
 s32 offset;
 s32 freq;
 s32 maxerror;
 s32 esterror;
 s32 status;
 s32 constant;
 s32 precision;
 s32 tolerance;
 struct old_timeval32 time;
 s32 tick;
 s32 ppsfreq;
 s32 jitter;
 s32 shift;
 s32 stabil;
 s32 jitcnt;
 s32 calcnt;
 s32 errcnt;
 s32 stbcnt;
 s32 tai;

 s32:32; s32:32; s32:32; s32:32;
 s32:32; s32:32; s32:32; s32:32;
 s32:32; s32:32; s32:32;
};

extern int get_old_timespec32(struct timespec64 *, const void *);
extern int put_old_timespec32(const struct timespec64 *, void *);
extern int get_old_itimerspec32(struct itimerspec64 *its,
   const struct old_itimerspec32 *uits);
extern int put_old_itimerspec32(const struct itimerspec64 *its,
   struct old_itimerspec32 *uits);
struct __kernel_timex;
int get_old_timex32(struct __kernel_timex *, const struct old_timex32 *);
int put_old_timex32(struct old_timex32 *, const struct __kernel_timex *);







extern struct __kernel_old_timeval ns_to_kernel_old_timeval(s64 nsec);
# 61 "/home/nathan/src/linux/include/linux/time.h" 2

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool itimerspec64_valid(const struct itimerspec64 *its)
{
 if (!timespec64_valid(&(its->it_interval)) ||
  !timespec64_valid(&(its->it_value)))
  return false;

 return true;
}
# 100 "/home/nathan/src/linux/include/linux/time.h"
# 1 "/home/nathan/src/linux/include/vdso/time.h" 1






struct timens_offset {
 s64 sec;
 u64 nsec;
};
# 101 "/home/nathan/src/linux/include/linux/time.h" 2
# 25 "/home/nathan/src/linux/include/linux/ktime.h" 2
# 1 "/home/nathan/src/linux/include/linux/jiffies.h" 1
# 12 "/home/nathan/src/linux/include/linux/jiffies.h"
# 1 "/home/nathan/src/linux/include/vdso/jiffies.h" 1
# 13 "/home/nathan/src/linux/include/linux/jiffies.h" 2

# 1 "./include/generated/timeconst.h" 1
# 15 "/home/nathan/src/linux/include/linux/jiffies.h" 2
# 62 "/home/nathan/src/linux/include/linux/jiffies.h"
extern int register_refined_jiffies(long clock_tick_rate);
# 79 "/home/nathan/src/linux/include/linux/jiffies.h"
extern u64 __attribute__((__aligned__((1 << 7)), __section__(".data..cacheline_aligned"))) jiffies_64;
extern unsigned long volatile __attribute__((__aligned__((1 << 7)), __section__(".data..cacheline_aligned"))) jiffies;


u64 get_jiffies_64(void);
# 189 "/home/nathan/src/linux/include/linux/jiffies.h"
extern unsigned long preset_lpj;
# 290 "/home/nathan/src/linux/include/linux/jiffies.h"
extern unsigned int jiffies_to_msecs(const unsigned long j);
extern unsigned int jiffies_to_usecs(const unsigned long j);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 jiffies_to_nsecs(const unsigned long j)
{
 return (u64)jiffies_to_usecs(j) * 1000L;
}

extern u64 jiffies64_to_nsecs(u64 j);
extern u64 jiffies64_to_msecs(u64 j);

extern unsigned long __msecs_to_jiffies(const unsigned int m);






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long _msecs_to_jiffies(const unsigned int m)
{
 return (m + (1000L / 250) - 1) / (1000L / 250);
}
# 363 "/home/nathan/src/linux/include/linux/jiffies.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned long msecs_to_jiffies(const unsigned int m)
{
 if (__builtin_constant_p(m)) {
  if ((int)m < 0)
   return ((((long)(~0UL >> 1)) >> 1)-1);
  return _msecs_to_jiffies(m);
 } else {
  return __msecs_to_jiffies(m);
 }
}

extern unsigned long __usecs_to_jiffies(const unsigned int u);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long _usecs_to_jiffies(const unsigned int u)
{
 return (u + (1000000L / 250) - 1) / (1000000L / 250);
}
# 410 "/home/nathan/src/linux/include/linux/jiffies.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned long usecs_to_jiffies(const unsigned int u)
{
 if (__builtin_constant_p(u)) {
  if (u > jiffies_to_usecs(((((long)(~0UL >> 1)) >> 1)-1)))
   return ((((long)(~0UL >> 1)) >> 1)-1);
  return _usecs_to_jiffies(u);
 } else {
  return __usecs_to_jiffies(u);
 }
}

extern unsigned long timespec64_to_jiffies(const struct timespec64 *value);
extern void jiffies_to_timespec64(const unsigned long jiffies,
      struct timespec64 *value);
extern clock_t jiffies_to_clock_t(unsigned long x);
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) clock_t jiffies_delta_to_clock_t(long delta)
{
 return jiffies_to_clock_t(__builtin_choose_expr(((!!(sizeof((typeof(0L) *)1 == (typeof(delta) *)1))) && ((sizeof(int) == sizeof(*(8 ? ((void *)((long)(0L) * 0l)) : (int *)8))) && (sizeof(int) == sizeof(*(8 ? ((void *)((long)(delta) * 0l)) : (int *)8))))), ((0L) > (delta) ? (0L) : (delta)), ({ typeof(0L) __UNIQUE_ID___x70 = (0L); typeof(delta) __UNIQUE_ID___y71 = (delta); ((__UNIQUE_ID___x70) > (__UNIQUE_ID___y71) ? (__UNIQUE_ID___x70) : (__UNIQUE_ID___y71)); })));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int jiffies_delta_to_msecs(long delta)
{
 return jiffies_to_msecs(__builtin_choose_expr(((!!(sizeof((typeof(0L) *)1 == (typeof(delta) *)1))) && ((sizeof(int) == sizeof(*(8 ? ((void *)((long)(0L) * 0l)) : (int *)8))) && (sizeof(int) == sizeof(*(8 ? ((void *)((long)(delta) * 0l)) : (int *)8))))), ((0L) > (delta) ? (0L) : (delta)), ({ typeof(0L) __UNIQUE_ID___x72 = (0L); typeof(delta) __UNIQUE_ID___y73 = (delta); ((__UNIQUE_ID___x72) > (__UNIQUE_ID___y73) ? (__UNIQUE_ID___x72) : (__UNIQUE_ID___y73)); })));
}

extern unsigned long clock_t_to_jiffies(unsigned long x);
extern u64 jiffies_64_to_clock_t(u64 x);
extern u64 nsec_to_clock_t(u64 x);
extern u64 nsecs_to_jiffies64(u64 n);
extern unsigned long nsecs_to_jiffies(u64 n);
# 26 "/home/nathan/src/linux/include/linux/ktime.h" 2



typedef s64 ktime_t;
# 38 "/home/nathan/src/linux/include/linux/ktime.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_set(const s64 secs, const unsigned long nsecs)
{
 if (__builtin_expect(!!(secs >= (((s64)~((u64)1 << 63)) / 1000000000L)), 0))
  return ((s64)~((u64)1 << 63));

 return secs * 1000000000L + (s64)nsecs;
}
# 71 "/home/nathan/src/linux/include/linux/ktime.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t timespec64_to_ktime(struct timespec64 ts)
{
 return ktime_set(ts.tv_sec, ts.tv_nsec);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 ktime_to_ns(const ktime_t kt)
{
 return kt;
}
# 95 "/home/nathan/src/linux/include/linux/ktime.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int ktime_compare(const ktime_t cmp1, const ktime_t cmp2)
{
 if (cmp1 < cmp2)
  return -1;
 if (cmp1 > cmp2)
  return 1;
 return 0;
}
# 111 "/home/nathan/src/linux/include/linux/ktime.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool ktime_after(const ktime_t cmp1, const ktime_t cmp2)
{
 return ktime_compare(cmp1, cmp2) > 0;
}
# 123 "/home/nathan/src/linux/include/linux/ktime.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool ktime_before(const ktime_t cmp1, const ktime_t cmp2)
{
 return ktime_compare(cmp1, cmp2) < 0;
}


extern s64 __ktime_divns(const ktime_t kt, s64 div);
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 ktime_divns(const ktime_t kt, s64 div)
{




 __BUG_ON((unsigned long)(div < 0));
 if (__builtin_constant_p(div) && !(div >> 32)) {
  s64 ns = kt;
  u64 tmp = ns < 0 ? -ns : ns;

  ({ uint32_t __base = (div); uint32_t __rem; (void)(((typeof((tmp)) *)0) == ((uint64_t *)0)); if (__builtin_constant_p(__base) && is_power_of_2(__base)) { __rem = (tmp) & (__base - 1); (tmp) >>= ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); } else if ((4 >= 4) && __builtin_constant_p(__base) && __base != 0) { uint32_t __res_lo, __n_lo = (tmp); (tmp) = ({ uint64_t ___res, ___x, ___t, ___m, ___n = (tmp); uint32_t ___p, ___bias; ___p = 1 << ( __builtin_constant_p(__base) ? ((__base) < 2 ? 0 : 63 - __builtin_clzll(__base)) : (sizeof(__base) <= 4) ? __ilog2_u32(__base) : __ilog2_u64(__base) ); ___m = (~0ULL / __base) * ___p; ___m += (((~0ULL % __base + 1) * ___p) + __base - 1) / __base; ___x = ~0ULL / __base * __base - 1; ___res = ((___m & 0xffffffff) * (___x & 0xffffffff)) >> 32; ___t = ___res += (___m & 0xffffffff) * (___x >> 32); ___res += (___x & 0xffffffff) * (___m >> 32); ___t = (___res < ___t) ? (1ULL << 32) : 0; ___res = (___res >> 32) + ___t; ___res += (___m >> 32) * (___x >> 32); ___res /= ___p; if (~0ULL % (__base / (__base & -__base)) == 0) { ___n /= (__base & -__base); ___m = ~0ULL / (__base / (__base & -__base)); ___p = 1; ___bias = 1; } else if (___res != ___x / __base) { ___bias = 1; ___m = (~0ULL / __base) * ___p; ___m += ((~0ULL % __base + 1) * ___p) / __base; } else { uint32_t ___bits = -(___m & -___m); ___bits |= ___m >> 32; ___bits = (~___bits) << 1; if (!___bits) { ___p /= (___m & -___m); ___m /= (___m & -___m); } else { ___p >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); ___m >>= ( __builtin_constant_p(___bits) ? ((___bits) < 2 ? 0 : 63 - __builtin_clzll(___bits)) : (sizeof(___bits) <= 4) ? __ilog2_u32(___bits) : __ilog2_u64(___bits) ); } ___bias = 0; } ___res = __arch_xprod_64(___m, ___n, ___bias); ___res /= ___p; }); __res_lo = (tmp); __rem = __n_lo - __res_lo * __base; } else if (__builtin_expect(!!(((tmp) >> 32) == 0), 1)) { __rem = (uint32_t)(tmp) % __base; (tmp) = (uint32_t)(tmp) / __base; } else __rem = __div64_32(&(tmp), __base); __rem; });
  return ns < 0 ? -tmp : tmp;
 } else {
  return __ktime_divns(kt, div);
 }
}
# 159 "/home/nathan/src/linux/include/linux/ktime.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 ktime_to_us(const ktime_t kt)
{
 return ktime_divns(kt, 1000L);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 ktime_to_ms(const ktime_t kt)
{
 return ktime_divns(kt, 1000000L);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 ktime_us_delta(const ktime_t later, const ktime_t earlier)
{
       return ktime_to_us(((later) - (earlier)));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 ktime_ms_delta(const ktime_t later, const ktime_t earlier)
{
 return ktime_to_ms(((later) - (earlier)));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_add_us(const ktime_t kt, const u64 usec)
{
 return ((kt) + (usec * 1000L));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_add_ms(const ktime_t kt, const u64 msec)
{
 return ((kt) + (msec * 1000000L));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_sub_us(const ktime_t kt, const u64 usec)
{
 return ((kt) - (usec * 1000L));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_sub_ms(const ktime_t kt, const u64 msec)
{
 return ((kt) - (msec * 1000000L));
}

extern ktime_t ktime_add_safe(const ktime_t lhs, const ktime_t rhs);
# 209 "/home/nathan/src/linux/include/linux/ktime.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__warn_unused_result__)) bool ktime_to_timespec64_cond(const ktime_t kt,
             struct timespec64 *ts)
{
 if (kt) {
  *ts = ns_to_timespec64((kt));
  return true;
 } else {
  return false;
 }
}


# 1 "/home/nathan/src/linux/include/vdso/ktime.h" 1
# 221 "/home/nathan/src/linux/include/linux/ktime.h" 2

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ns_to_ktime(u64 ns)
{
 return ns;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ms_to_ktime(u64 ms)
{
 return ms * 1000000L;
}


# 1 "/home/nathan/src/linux/include/linux/timekeeping.h" 1








void timekeeping_init(void);
extern int timekeeping_suspended;


extern void legacy_timer_tick(unsigned long ticks);




extern int do_settimeofday64(const struct timespec64 *ts);
extern int do_sys_settimeofday64(const struct timespec64 *tv,
     const struct timezone *tz);
# 40 "/home/nathan/src/linux/include/linux/timekeeping.h"
extern void ktime_get_raw_ts64(struct timespec64 *ts);
extern void ktime_get_ts64(struct timespec64 *ts);
extern void ktime_get_real_ts64(struct timespec64 *tv);
extern void ktime_get_coarse_ts64(struct timespec64 *ts);
extern void ktime_get_coarse_real_ts64(struct timespec64 *ts);

void getboottime64(struct timespec64 *ts);




extern time64_t ktime_get_seconds(void);
extern time64_t __ktime_get_real_seconds(void);
extern time64_t ktime_get_real_seconds(void);





enum tk_offsets {
 TK_OFFS_REAL,
 TK_OFFS_BOOT,
 TK_OFFS_TAI,
 TK_OFFS_MAX,
};

extern ktime_t ktime_get(void);
extern ktime_t ktime_get_with_offset(enum tk_offsets offs);
extern ktime_t ktime_get_coarse_with_offset(enum tk_offsets offs);
extern ktime_t ktime_mono_to_any(ktime_t tmono, enum tk_offsets offs);
extern ktime_t ktime_get_raw(void);
extern u32 ktime_get_resolution_ns(void);




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_get_real(void)
{
 return ktime_get_with_offset(TK_OFFS_REAL);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_get_coarse_real(void)
{
 return ktime_get_coarse_with_offset(TK_OFFS_REAL);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_get_boottime(void)
{
 return ktime_get_with_offset(TK_OFFS_BOOT);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_get_coarse_boottime(void)
{
 return ktime_get_coarse_with_offset(TK_OFFS_BOOT);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_get_clocktai(void)
{
 return ktime_get_with_offset(TK_OFFS_TAI);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_get_coarse_clocktai(void)
{
 return ktime_get_coarse_with_offset(TK_OFFS_TAI);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_get_coarse(void)
{
 struct timespec64 ts;

 ktime_get_coarse_ts64(&ts);
 return timespec64_to_ktime(ts);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 ktime_get_coarse_ns(void)
{
 return ktime_to_ns(ktime_get_coarse());
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 ktime_get_coarse_real_ns(void)
{
 return ktime_to_ns(ktime_get_coarse_real());
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 ktime_get_coarse_boottime_ns(void)
{
 return ktime_to_ns(ktime_get_coarse_boottime());
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 ktime_get_coarse_clocktai_ns(void)
{
 return ktime_to_ns(ktime_get_coarse_clocktai());
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t ktime_mono_to_real(ktime_t mono)
{
 return ktime_mono_to_any(mono, TK_OFFS_REAL);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 ktime_get_ns(void)
{
 return ktime_to_ns(ktime_get());
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 ktime_get_real_ns(void)
{
 return ktime_to_ns(ktime_get_real());
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 ktime_get_boottime_ns(void)
{
 return ktime_to_ns(ktime_get_boottime());
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 ktime_get_clocktai_ns(void)
{
 return ktime_to_ns(ktime_get_clocktai());
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 ktime_get_raw_ns(void)
{
 return ktime_to_ns(ktime_get_raw());
}

extern u64 ktime_get_mono_fast_ns(void);
extern u64 ktime_get_raw_fast_ns(void);
extern u64 ktime_get_boot_fast_ns(void);
extern u64 ktime_get_real_fast_ns(void);






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ktime_get_boottime_ts64(struct timespec64 *ts)
{
 *ts = ns_to_timespec64((ktime_get_boottime()));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ktime_get_coarse_boottime_ts64(struct timespec64 *ts)
{
 *ts = ns_to_timespec64((ktime_get_coarse_boottime()));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) time64_t ktime_get_boottime_seconds(void)
{
 return ktime_divns(ktime_get_coarse_boottime(), 1000000000L);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ktime_get_clocktai_ts64(struct timespec64 *ts)
{
 *ts = ns_to_timespec64((ktime_get_clocktai()));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ktime_get_coarse_clocktai_ts64(struct timespec64 *ts)
{
 *ts = ns_to_timespec64((ktime_get_coarse_clocktai()));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) time64_t ktime_get_clocktai_seconds(void)
{
 return ktime_divns(ktime_get_coarse_clocktai(), 1000000000L);
}




extern bool timekeeping_rtc_skipsuspend(void);
extern bool timekeeping_rtc_skipresume(void);

extern void timekeeping_inject_sleeptime64(const struct timespec64 *delta);







struct ktime_timestamps {
 u64 mono;
 u64 boot;
 u64 real;
};
# 245 "/home/nathan/src/linux/include/linux/timekeeping.h"
struct system_time_snapshot {
 u64 cycles;
 ktime_t real;
 ktime_t raw;
 unsigned int clock_was_set_seq;
 u8 cs_was_changed_seq;
};
# 260 "/home/nathan/src/linux/include/linux/timekeeping.h"
struct system_device_crosststamp {
 ktime_t device;
 ktime_t sys_realtime;
 ktime_t sys_monoraw;
};
# 273 "/home/nathan/src/linux/include/linux/timekeeping.h"
struct system_counterval_t {
 u64 cycles;
 struct clocksource *cs;
};




extern int get_device_system_crosststamp(
   int (*get_time_fn)(ktime_t *device_time,
    struct system_counterval_t *system_counterval,
    void *ctx),
   void *ctx,
   struct system_time_snapshot *history,
   struct system_device_crosststamp *xtstamp);




extern void ktime_get_snapshot(struct system_time_snapshot *systime_snapshot);


extern void ktime_get_fast_timestamps(struct ktime_timestamps *snap);




extern int persistent_clock_is_local;

extern void read_persistent_clock64(struct timespec64 *ts);
void read_persistent_wall_and_boot_offset(struct timespec64 *wall_clock,
       struct timespec64 *boot_offset);

extern int update_persistent_clock64(struct timespec64 now);
# 233 "/home/nathan/src/linux/include/linux/ktime.h" 2
# 1 "/home/nathan/src/linux/include/linux/timekeeping32.h" 1








static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long get_seconds(void)
{
 return ktime_get_real_seconds();
}
# 234 "/home/nathan/src/linux/include/linux/ktime.h" 2
# 7 "/home/nathan/src/linux/include/linux/timer.h" 2

# 1 "/home/nathan/src/linux/include/linux/debugobjects.h" 1





# 1 "/home/nathan/src/linux/include/linux/spinlock.h" 1
# 58 "/home/nathan/src/linux/include/linux/spinlock.h"
# 1 "/home/nathan/src/linux/include/linux/bottom_half.h" 1
# 10 "/home/nathan/src/linux/include/linux/bottom_half.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __local_bh_disable_ip(unsigned long ip, unsigned int cnt)
{
 __preempt_count_add(cnt);
 __asm__ __volatile__("": : :"memory");
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void local_bh_disable(void)
{
 __local_bh_disable_ip(({ __label__ __here; __here: (unsigned long)&&__here; }), (2 * (1UL << (0 + 8))));
}

extern void _local_bh_enable(void);
extern void __local_bh_enable_ip(unsigned long ip, unsigned int cnt);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void local_bh_enable_ip(unsigned long ip)
{
 __local_bh_enable_ip(ip, (2 * (1UL << (0 + 8))));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void local_bh_enable(void)
{
 __local_bh_enable_ip(({ __label__ __here; __here: (unsigned long)&&__here; }), (2 * (1UL << (0 + 8))));
}
# 59 "/home/nathan/src/linux/include/linux/spinlock.h" 2
# 1 "/home/nathan/src/linux/include/linux/lockdep.h" 1
# 15 "/home/nathan/src/linux/include/linux/lockdep.h"
# 1 "./arch/mips/include/generated/asm/percpu.h" 1
# 16 "/home/nathan/src/linux/include/linux/lockdep.h" 2

struct task_struct;


extern int prove_locking;
extern int lock_stat;
# 321 "/home/nathan/src/linux/include/linux/lockdep.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_init_task(struct task_struct *task)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_off(void)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_on(void)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_set_selftest_task(struct task_struct *task)
{
}
# 368 "/home/nathan/src/linux/include/linux/lockdep.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_register_key(struct lock_class_key *key)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_unregister_key(struct lock_class_key *key)
{
}







extern int lock_is_held(const void *);
extern int lockdep_is_held(const void *);
# 401 "/home/nathan/src/linux/include/linux/lockdep.h"
enum xhlock_context_t {
 XHLOCK_HARD,
 XHLOCK_SOFT,
 XHLOCK_CTX_NR,
};
# 415 "/home/nathan/src/linux/include/linux/lockdep.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_invariant_state(bool force) {}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void lockdep_free_task(struct task_struct *task) {}
# 477 "/home/nathan/src/linux/include/linux/lockdep.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void print_irqtrace_events(struct task_struct *curr)
{
}
# 645 "/home/nathan/src/linux/include/linux/lockdep.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
lockdep_rcu_suspicious(const char *file, const int line, const char *s)
{
}
# 60 "/home/nathan/src/linux/include/linux/spinlock.h" 2

# 1 "/home/nathan/src/linux/arch/mips/include/asm/mmiowb.h" 1








# 1 "/home/nathan/src/linux/include/asm-generic/mmiowb.h" 1
# 10 "/home/nathan/src/linux/arch/mips/include/asm/mmiowb.h" 2
# 62 "/home/nathan/src/linux/include/linux/spinlock.h" 2
# 90 "/home/nathan/src/linux/include/linux/spinlock.h"
# 1 "/home/nathan/src/linux/arch/mips/include/asm/spinlock.h" 1
# 13 "/home/nathan/src/linux/arch/mips/include/asm/spinlock.h"
# 1 "./arch/mips/include/generated/asm/qrwlock.h" 1
# 1 "/home/nathan/src/linux/include/asm-generic/qrwlock.h" 1
# 30 "/home/nathan/src/linux/include/asm-generic/qrwlock.h"
extern void queued_read_lock_slowpath(struct qrwlock *lock);
extern void queued_write_lock_slowpath(struct qrwlock *lock);






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int queued_read_trylock(struct qrwlock *lock)
{
 int cnts;

 cnts = atomic_read(&lock->cnts);
 if (__builtin_expect(!!(!(cnts & 0x1ff)), 1)) {
  cnts = (u32)atomic_add_return_acquire((1U << 9), &lock->cnts);
  if (__builtin_expect(!!(!(cnts & 0x1ff)), 1))
   return 1;
  atomic_sub((1U << 9), &lock->cnts);
 }
 return 0;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int queued_write_trylock(struct qrwlock *lock)
{
 int cnts;

 cnts = atomic_read(&lock->cnts);
 if (__builtin_expect(!!(cnts), 0))
  return 0;

 return __builtin_expect(!!(atomic_try_cmpxchg_acquire(&lock->cnts, &cnts, 0x0ff)), 1);

}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void queued_read_lock(struct qrwlock *lock)
{
 int cnts;

 cnts = atomic_add_return_acquire((1U << 9), &lock->cnts);
 if (__builtin_expect(!!(!(cnts & 0x1ff)), 1))
  return;


 queued_read_lock_slowpath(lock);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void queued_write_lock(struct qrwlock *lock)
{
 int cnts = 0;

 if (__builtin_expect(!!(atomic_try_cmpxchg_acquire(&lock->cnts, &cnts, 0x0ff)), 1))
  return;

 queued_write_lock_slowpath(lock);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void queued_read_unlock(struct qrwlock *lock)
{



 (void)atomic_sub_return_release((1U << 9), &lock->cnts);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void queued_write_unlock(struct qrwlock *lock)
{
 do { do { extern void __compiletime_assert_74(void) ; if (!((sizeof(*&lock->wlocked) == sizeof(char) || sizeof(*&lock->wlocked) == sizeof(short) || sizeof(*&lock->wlocked) == sizeof(int) || sizeof(*&lock->wlocked) == sizeof(long)))) __compiletime_assert_74(); } while (0); __sync(); do { do { extern void __compiletime_assert_75(void) ; if (!((sizeof(*&lock->wlocked) == sizeof(char) || sizeof(*&lock->wlocked) == sizeof(short) || sizeof(*&lock->wlocked) == sizeof(int) || sizeof(*&lock->wlocked) == sizeof(long)) || sizeof(*&lock->wlocked) == sizeof(long long))) __compiletime_assert_75(); } while (0); do { *(volatile typeof(*&lock->wlocked) *)&(*&lock->wlocked) = (0); } while (0); } while (0); } while (0);
}
# 2 "./arch/mips/include/generated/asm/qrwlock.h" 2
# 14 "/home/nathan/src/linux/arch/mips/include/asm/spinlock.h" 2








static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void queued_spin_unlock(struct qspinlock *lock)
{

 wmb();
 do { do { extern void __compiletime_assert_76(void) ; if (!((sizeof(*&lock->locked) == sizeof(char) || sizeof(*&lock->locked) == sizeof(short) || sizeof(*&lock->locked) == sizeof(int) || sizeof(*&lock->locked) == sizeof(long)))) __compiletime_assert_76(); } while (0); __sync(); do { do { extern void __compiletime_assert_77(void) ; if (!((sizeof(*&lock->locked) == sizeof(char) || sizeof(*&lock->locked) == sizeof(short) || sizeof(*&lock->locked) == sizeof(int) || sizeof(*&lock->locked) == sizeof(long)) || sizeof(*&lock->locked) == sizeof(long long))) __compiletime_assert_77(); } while (0); do { *(volatile typeof(*&lock->locked) *)&(*&lock->locked) = (0); } while (0); } while (0); } while (0);
}


# 1 "./arch/mips/include/generated/asm/qspinlock.h" 1
# 1 "/home/nathan/src/linux/include/asm-generic/qspinlock.h" 1
# 22 "/home/nathan/src/linux/include/asm-generic/qspinlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int queued_spin_is_locked(struct qspinlock *lock)
{




 return atomic_read(&lock->val);
}
# 42 "/home/nathan/src/linux/include/asm-generic/qspinlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int queued_spin_value_unlocked(struct qspinlock lock)
{
 return !atomic_read(&lock.val);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int queued_spin_is_contended(struct qspinlock *lock)
{
 return atomic_read(&lock->val) & ~(((1U << 8) - 1) << 0);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int queued_spin_trylock(struct qspinlock *lock)
{
 int val = atomic_read(&lock->val);

 if (__builtin_expect(!!(val), 0))
  return 0;

 return __builtin_expect(!!(atomic_try_cmpxchg_acquire(&lock->val, &val, (1U << 0))), 1);
}

extern void queued_spin_lock_slowpath(struct qspinlock *lock, u32 val);






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void queued_spin_lock(struct qspinlock *lock)
{
 int val = 0;

 if (__builtin_expect(!!(atomic_try_cmpxchg_acquire(&lock->val, &val, (1U << 0))), 1))
  return;

 queued_spin_lock_slowpath(lock, val);
}
# 104 "/home/nathan/src/linux/include/asm-generic/qspinlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool virt_spin_lock(struct qspinlock *lock)
{
 return false;
}
# 2 "./arch/mips/include/generated/asm/qspinlock.h" 2
# 30 "/home/nathan/src/linux/arch/mips/include/asm/spinlock.h" 2
# 91 "/home/nathan/src/linux/include/linux/spinlock.h" 2
# 180 "/home/nathan/src/linux/include/linux/spinlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void do_raw_spin_lock(raw_spinlock_t *lock)
{
 (void)0;
 queued_spin_lock(&lock->raw_lock);
 do { } while (0);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
do_raw_spin_lock_flags(raw_spinlock_t *lock, unsigned long *flags)
{
 (void)0;
 queued_spin_lock(&lock->raw_lock);
 do { } while (0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int do_raw_spin_trylock(raw_spinlock_t *lock)
{
 int ret = queued_spin_trylock(&(lock)->raw_lock);

 if (ret)
  do { } while (0);

 return ret;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void do_raw_spin_unlock(raw_spinlock_t *lock)
{
 do { } while (0);
 queued_spin_unlock(&lock->raw_lock);
 (void)0;
}
# 312 "/home/nathan/src/linux/include/linux/spinlock.h"
# 1 "/home/nathan/src/linux/include/linux/rwlock.h" 1
# 313 "/home/nathan/src/linux/include/linux/spinlock.h" 2





# 1 "/home/nathan/src/linux/include/linux/spinlock_api_smp.h" 1
# 18 "/home/nathan/src/linux/include/linux/spinlock_api_smp.h"
int in_lock_functions(unsigned long addr);



void __attribute__((__section__(".spinlock.text"))) _raw_spin_lock(raw_spinlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_spin_lock_nested(raw_spinlock_t *lock, int subclass)
                        ;
void __attribute__((__section__(".spinlock.text")))
_raw_spin_lock_nest_lock(raw_spinlock_t *lock, struct lockdep_map *map)
                        ;
void __attribute__((__section__(".spinlock.text"))) _raw_spin_lock_bh(raw_spinlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_spin_lock_irq(raw_spinlock_t *lock)
                        ;

unsigned long __attribute__((__section__(".spinlock.text"))) _raw_spin_lock_irqsave(raw_spinlock_t *lock)
                        ;
unsigned long __attribute__((__section__(".spinlock.text")))
_raw_spin_lock_irqsave_nested(raw_spinlock_t *lock, int subclass)
                        ;
int __attribute__((__section__(".spinlock.text"))) _raw_spin_trylock(raw_spinlock_t *lock);
int __attribute__((__section__(".spinlock.text"))) _raw_spin_trylock_bh(raw_spinlock_t *lock);
void __attribute__((__section__(".spinlock.text"))) _raw_spin_unlock(raw_spinlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_spin_unlock_bh(raw_spinlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_spin_unlock_irq(raw_spinlock_t *lock) ;
void __attribute__((__section__(".spinlock.text")))
_raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)
                        ;
# 86 "/home/nathan/src/linux/include/linux/spinlock_api_smp.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __raw_spin_trylock(raw_spinlock_t *lock)
{
 __asm__ __volatile__("": : :"memory");
 if (do_raw_spin_trylock(lock)) {
  do { } while (0);
  return 1;
 }
 __asm__ __volatile__("": : :"memory");
 return 0;
}
# 104 "/home/nathan/src/linux/include/linux/spinlock_api_smp.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __raw_spin_lock_irqsave(raw_spinlock_t *lock)
{
 unsigned long flags;

 do { do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); } while (0);
 __asm__ __volatile__("": : :"memory");
 do { } while (0);
# 119 "/home/nathan/src/linux/include/linux/spinlock_api_smp.h"
 do_raw_spin_lock_flags(lock, &flags);

 return flags;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_spin_lock_irq(raw_spinlock_t *lock)
{
 do { arch_local_irq_disable(); } while (0);
 __asm__ __volatile__("": : :"memory");
 do { } while (0);
 do_raw_spin_lock(lock);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_spin_lock_bh(raw_spinlock_t *lock)
{
 __local_bh_disable_ip((unsigned long)__builtin_return_address(0), ((2 * (1UL << (0 + 8))) + 0));
 do { } while (0);
 do_raw_spin_lock(lock);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_spin_lock(raw_spinlock_t *lock)
{
 __asm__ __volatile__("": : :"memory");
 do { } while (0);
 do_raw_spin_lock(lock);
}



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_spin_unlock(raw_spinlock_t *lock)
{
 do { } while (0);
 do_raw_spin_unlock(lock);
 __asm__ __volatile__("": : :"memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_spin_unlock_irqrestore(raw_spinlock_t *lock,
         unsigned long flags)
{
 do { } while (0);
 do_raw_spin_unlock(lock);
 do { do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); } while (0);
 __asm__ __volatile__("": : :"memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_spin_unlock_irq(raw_spinlock_t *lock)
{
 do { } while (0);
 do_raw_spin_unlock(lock);
 do { arch_local_irq_enable(); } while (0);
 __asm__ __volatile__("": : :"memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_spin_unlock_bh(raw_spinlock_t *lock)
{
 do { } while (0);
 do_raw_spin_unlock(lock);
 __local_bh_enable_ip((unsigned long)__builtin_return_address(0), ((2 * (1UL << (0 + 8))) + 0));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __raw_spin_trylock_bh(raw_spinlock_t *lock)
{
 __local_bh_disable_ip((unsigned long)__builtin_return_address(0), ((2 * (1UL << (0 + 8))) + 0));
 if (do_raw_spin_trylock(lock)) {
  do { } while (0);
  return 1;
 }
 __local_bh_enable_ip((unsigned long)__builtin_return_address(0), ((2 * (1UL << (0 + 8))) + 0));
 return 0;
}


# 1 "/home/nathan/src/linux/include/linux/rwlock_api_smp.h" 1
# 18 "/home/nathan/src/linux/include/linux/rwlock_api_smp.h"
void __attribute__((__section__(".spinlock.text"))) _raw_read_lock(rwlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_write_lock(rwlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_read_lock_bh(rwlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_write_lock_bh(rwlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_read_lock_irq(rwlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_write_lock_irq(rwlock_t *lock) ;
unsigned long __attribute__((__section__(".spinlock.text"))) _raw_read_lock_irqsave(rwlock_t *lock)
                       ;
unsigned long __attribute__((__section__(".spinlock.text"))) _raw_write_lock_irqsave(rwlock_t *lock)
                       ;
int __attribute__((__section__(".spinlock.text"))) _raw_read_trylock(rwlock_t *lock);
int __attribute__((__section__(".spinlock.text"))) _raw_write_trylock(rwlock_t *lock);
void __attribute__((__section__(".spinlock.text"))) _raw_read_unlock(rwlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_write_unlock(rwlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_read_unlock_bh(rwlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_write_unlock_bh(rwlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_read_unlock_irq(rwlock_t *lock) ;
void __attribute__((__section__(".spinlock.text"))) _raw_write_unlock_irq(rwlock_t *lock) ;
void __attribute__((__section__(".spinlock.text")))
_raw_read_unlock_irqrestore(rwlock_t *lock, unsigned long flags)
                       ;
void __attribute__((__section__(".spinlock.text")))
_raw_write_unlock_irqrestore(rwlock_t *lock, unsigned long flags)
                       ;
# 117 "/home/nathan/src/linux/include/linux/rwlock_api_smp.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __raw_read_trylock(rwlock_t *lock)
{
 __asm__ __volatile__("": : :"memory");
 if (queued_read_trylock(&(lock)->raw_lock)) {
  do { if (0) do { } while (0); else do { } while (0); } while (0);
  return 1;
 }
 __asm__ __volatile__("": : :"memory");
 return 0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __raw_write_trylock(rwlock_t *lock)
{
 __asm__ __volatile__("": : :"memory");
 if (queued_write_trylock(&(lock)->raw_lock)) {
  do { } while (0);
  return 1;
 }
 __asm__ __volatile__("": : :"memory");
 return 0;
}
# 146 "/home/nathan/src/linux/include/linux/rwlock_api_smp.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_read_lock(rwlock_t *lock)
{
 __asm__ __volatile__("": : :"memory");
 do { if (0) do { } while (0); else do { } while (0); } while (0);
 do {(void)0; queued_read_lock(&(lock)->raw_lock); } while (0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __raw_read_lock_irqsave(rwlock_t *lock)
{
 unsigned long flags;

 do { do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); } while (0);
 __asm__ __volatile__("": : :"memory");
 do { if (0) do { } while (0); else do { } while (0); } while (0);
 do {(void)0; queued_read_lock(&((lock))->raw_lock); } while (0);

 return flags;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_read_lock_irq(rwlock_t *lock)
{
 do { arch_local_irq_disable(); } while (0);
 __asm__ __volatile__("": : :"memory");
 do { if (0) do { } while (0); else do { } while (0); } while (0);
 do {(void)0; queued_read_lock(&(lock)->raw_lock); } while (0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_read_lock_bh(rwlock_t *lock)
{
 __local_bh_disable_ip((unsigned long)__builtin_return_address(0), ((2 * (1UL << (0 + 8))) + 0));
 do { if (0) do { } while (0); else do { } while (0); } while (0);
 do {(void)0; queued_read_lock(&(lock)->raw_lock); } while (0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __raw_write_lock_irqsave(rwlock_t *lock)
{
 unsigned long flags;

 do { do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = arch_local_irq_save(); } while (0); } while (0);
 __asm__ __volatile__("": : :"memory");
 do { } while (0);
 do {(void)0; queued_write_lock(&((lock))->raw_lock); } while (0);

 return flags;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_write_lock_irq(rwlock_t *lock)
{
 do { arch_local_irq_disable(); } while (0);
 __asm__ __volatile__("": : :"memory");
 do { } while (0);
 do {(void)0; queued_write_lock(&(lock)->raw_lock); } while (0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_write_lock_bh(rwlock_t *lock)
{
 __local_bh_disable_ip((unsigned long)__builtin_return_address(0), ((2 * (1UL << (0 + 8))) + 0));
 do { } while (0);
 do {(void)0; queued_write_lock(&(lock)->raw_lock); } while (0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_write_lock(rwlock_t *lock)
{
 __asm__ __volatile__("": : :"memory");
 do { } while (0);
 do {(void)0; queued_write_lock(&(lock)->raw_lock); } while (0);
}



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_write_unlock(rwlock_t *lock)
{
 do { } while (0);
 do {queued_write_unlock(&(lock)->raw_lock); (void)0; } while (0);
 __asm__ __volatile__("": : :"memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_read_unlock(rwlock_t *lock)
{
 do { } while (0);
 do {queued_read_unlock(&(lock)->raw_lock); (void)0; } while (0);
 __asm__ __volatile__("": : :"memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
__raw_read_unlock_irqrestore(rwlock_t *lock, unsigned long flags)
{
 do { } while (0);
 do {queued_read_unlock(&(lock)->raw_lock); (void)0; } while (0);
 do { do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); } while (0);
 __asm__ __volatile__("": : :"memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_read_unlock_irq(rwlock_t *lock)
{
 do { } while (0);
 do {queued_read_unlock(&(lock)->raw_lock); (void)0; } while (0);
 do { arch_local_irq_enable(); } while (0);
 __asm__ __volatile__("": : :"memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_read_unlock_bh(rwlock_t *lock)
{
 do { } while (0);
 do {queued_read_unlock(&(lock)->raw_lock); (void)0; } while (0);
 __local_bh_enable_ip((unsigned long)__builtin_return_address(0), ((2 * (1UL << (0 + 8))) + 0));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_write_unlock_irqrestore(rwlock_t *lock,
          unsigned long flags)
{
 do { } while (0);
 do {queued_write_unlock(&(lock)->raw_lock); (void)0; } while (0);
 do { do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); arch_local_irq_restore(flags); } while (0); } while (0);
 __asm__ __volatile__("": : :"memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_write_unlock_irq(rwlock_t *lock)
{
 do { } while (0);
 do {queued_write_unlock(&(lock)->raw_lock); (void)0; } while (0);
 do { arch_local_irq_enable(); } while (0);
 __asm__ __volatile__("": : :"memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __raw_write_unlock_bh(rwlock_t *lock)
{
 do { } while (0);
 do {queued_write_unlock(&(lock)->raw_lock); (void)0; } while (0);
 __local_bh_enable_ip((unsigned long)__builtin_return_address(0), ((2 * (1UL << (0 + 8))) + 0));
}
# 191 "/home/nathan/src/linux/include/linux/spinlock_api_smp.h" 2
# 319 "/home/nathan/src/linux/include/linux/spinlock.h" 2








static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) raw_spinlock_t *spinlock_check(spinlock_t *lock)
{
 return &lock->rlock;
}
# 352 "/home/nathan/src/linux/include/linux/spinlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void spin_lock(spinlock_t *lock)
{
 _raw_spin_lock(&lock->rlock);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void spin_lock_bh(spinlock_t *lock)
{
 _raw_spin_lock_bh(&lock->rlock);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int spin_trylock(spinlock_t *lock)
{
 return (_raw_spin_trylock(&lock->rlock));
}
# 377 "/home/nathan/src/linux/include/linux/spinlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void spin_lock_irq(spinlock_t *lock)
{
 _raw_spin_lock_irq(&lock->rlock);
}
# 392 "/home/nathan/src/linux/include/linux/spinlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void spin_unlock(spinlock_t *lock)
{
 __raw_spin_unlock(&lock->rlock);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void spin_unlock_bh(spinlock_t *lock)
{
 _raw_spin_unlock_bh(&lock->rlock);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void spin_unlock_irq(spinlock_t *lock)
{
 __raw_spin_unlock_irq(&lock->rlock);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags)
{
 do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); _raw_spin_unlock_irqrestore(&lock->rlock, flags); } while (0);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int spin_trylock_bh(spinlock_t *lock)
{
 return (_raw_spin_trylock_bh(&lock->rlock));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int spin_trylock_irq(spinlock_t *lock)
{
 return ({ do { arch_local_irq_disable(); } while (0); (_raw_spin_trylock(&lock->rlock)) ? 1 : ({ do { arch_local_irq_enable(); } while (0); 0; }); });
}
# 445 "/home/nathan/src/linux/include/linux/spinlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int spin_is_locked(spinlock_t *lock)
{
 return queued_spin_is_locked(&(&lock->rlock)->raw_lock);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int spin_is_contended(spinlock_t *lock)
{
 return queued_spin_is_contended(&(&lock->rlock)->raw_lock);
}
# 470 "/home/nathan/src/linux/include/linux/spinlock.h"
extern int _atomic_dec_and_lock(atomic_t *atomic, spinlock_t *lock);



extern int _atomic_dec_and_lock_irqsave(atomic_t *atomic, spinlock_t *lock,
     unsigned long *flags);



int __alloc_bucket_spinlocks(spinlock_t **locks, unsigned int *lock_mask,
        size_t max_size, unsigned int cpu_mult,
        gfp_t gfp, const char *name,
        struct lock_class_key *key);
# 494 "/home/nathan/src/linux/include/linux/spinlock.h"
void free_bucket_spinlocks(spinlock_t *locks);
# 7 "/home/nathan/src/linux/include/linux/debugobjects.h" 2

enum debug_obj_state {
 ODEBUG_STATE_NONE,
 ODEBUG_STATE_INIT,
 ODEBUG_STATE_INACTIVE,
 ODEBUG_STATE_ACTIVE,
 ODEBUG_STATE_DESTROYED,
 ODEBUG_STATE_NOTAVAILABLE,
 ODEBUG_STATE_MAX,
};

struct debug_obj_descr;
# 28 "/home/nathan/src/linux/include/linux/debugobjects.h"
struct debug_obj {
 struct hlist_node node;
 enum debug_obj_state state;
 unsigned int astate;
 void *object;
 const struct debug_obj_descr *descr;
};
# 55 "/home/nathan/src/linux/include/linux/debugobjects.h"
struct debug_obj_descr {
 const char *name;
 void *(*debug_hint)(void *addr);
 bool (*is_static_object)(void *addr);
 bool (*fixup_init)(void *addr, enum debug_obj_state state);
 bool (*fixup_activate)(void *addr, enum debug_obj_state state);
 bool (*fixup_destroy)(void *addr, enum debug_obj_state state);
 bool (*fixup_free)(void *addr, enum debug_obj_state state);
 bool (*fixup_assert_init)(void *addr, enum debug_obj_state state);
};
# 88 "/home/nathan/src/linux/include/linux/debugobjects.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
debug_object_init (void *addr, const struct debug_obj_descr *descr) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
debug_object_init_on_stack(void *addr, const struct debug_obj_descr *descr) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int
debug_object_activate (void *addr, const struct debug_obj_descr *descr) { return 0; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
debug_object_deactivate(void *addr, const struct debug_obj_descr *descr) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
debug_object_destroy (void *addr, const struct debug_obj_descr *descr) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
debug_object_free (void *addr, const struct debug_obj_descr *descr) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
debug_object_assert_init(void *addr, const struct debug_obj_descr *descr) { }

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void debug_objects_early_init(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void debug_objects_mem_init(void) { }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
debug_check_no_obj_freed(const void *address, unsigned long size) { }
# 9 "/home/nathan/src/linux/include/linux/timer.h" 2


struct timer_list {




 struct hlist_node entry;
 unsigned long expires;
 void (*function)(struct timer_list *);
 u32 flags;




};
# 91 "/home/nathan/src/linux/include/linux/timer.h"
void init_timer_key(struct timer_list *timer,
      void (*func)(struct timer_list *), unsigned int flags,
      const char *name, struct lock_class_key *key);







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void init_timer_on_stack_key(struct timer_list *timer,
        void (*func)(struct timer_list *),
        unsigned int flags,
        const char *name,
        struct lock_class_key *key)
{
 init_timer_key(timer, func, flags, name, key);
}
# 150 "/home/nathan/src/linux/include/linux/timer.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void destroy_timer_on_stack(struct timer_list *timer) { }
# 166 "/home/nathan/src/linux/include/linux/timer.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int timer_pending(const struct timer_list * timer)
{
 return !hlist_unhashed_lockless(&timer->entry);
}

extern void add_timer_on(struct timer_list *timer, int cpu);
extern int del_timer(struct timer_list * timer);
extern int mod_timer(struct timer_list *timer, unsigned long expires);
extern int mod_timer_pending(struct timer_list *timer, unsigned long expires);
extern int timer_reduce(struct timer_list *timer, unsigned long expires);







extern void add_timer(struct timer_list *timer);

extern int try_to_del_timer_sync(struct timer_list *timer);


  extern int del_timer_sync(struct timer_list *timer);






extern void init_timers(void);
struct hrtimer;
extern enum hrtimer_restart it_real_fn(struct hrtimer *);


struct ctl_table;

extern unsigned int sysctl_timer_migration;
int timer_migration_handler(struct ctl_table *table, int write,
       void *buffer, size_t *lenp, loff_t *ppos);


unsigned long __round_jiffies(unsigned long j, int cpu);
unsigned long __round_jiffies_relative(unsigned long j, int cpu);
unsigned long round_jiffies(unsigned long j);
unsigned long round_jiffies_relative(unsigned long j);

unsigned long __round_jiffies_up(unsigned long j, int cpu);
unsigned long __round_jiffies_up_relative(unsigned long j, int cpu);
unsigned long round_jiffies_up(unsigned long j);
unsigned long round_jiffies_up_relative(unsigned long j);


int timers_prepare_cpu(unsigned int cpu);
int timers_dead_cpu(unsigned int cpu);
# 10 "/home/nathan/src/linux/include/linux/workqueue.h" 2






# 1 "/home/nathan/src/linux/include/linux/rcupdate.h" 1
# 38 "/home/nathan/src/linux/include/linux/rcupdate.h"
void call_rcu(struct callback_head *head, rcu_callback_t func);
void rcu_barrier_tasks(void);
void rcu_barrier_tasks_rude(void);
void synchronize_rcu(void);
# 61 "/home/nathan/src/linux/include/linux/rcupdate.h"
void rcu_read_unlock_strict(void);


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __rcu_read_lock(void)
{
 __asm__ __volatile__("": : :"memory");
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __rcu_read_unlock(void)
{
 __asm__ __volatile__("": : :"memory");
 rcu_read_unlock_strict();
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int rcu_preempt_depth(void)
{
 return 0;
}




void rcu_init(void);
extern int rcu_scheduler_active __attribute__((__section__(".data..read_mostly")));
void rcu_sched_clock_irq(int user);
void rcu_report_dead(unsigned int cpu);
void rcutree_migrate_callbacks(int cpu);


void rcu_sysrq_start(void);
void rcu_sysrq_end(void);
# 101 "/home/nathan/src/linux/include/linux/rcupdate.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rcu_user_enter(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rcu_user_exit(void) { }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rcu_init_nohz(void) { }
# 181 "/home/nathan/src/linux/include/linux/rcupdate.h"
void exit_tasks_rcu_start(void);
void exit_tasks_rcu_finish(void);
# 211 "/home/nathan/src/linux/include/linux/rcupdate.h"
# 1 "/home/nathan/src/linux/include/linux/rcutree.h" 1
# 20 "/home/nathan/src/linux/include/linux/rcutree.h"
void rcu_softirq_qs(void);
void rcu_note_context_switch(bool preempt);
int rcu_needs_cpu(u64 basem, u64 *nextevt);
void rcu_cpu_stall_reset(void);






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rcu_virt_note_context_switch(int cpu)
{
 rcu_note_context_switch(false);
}

void synchronize_rcu_expedited(void);
void kvfree_call_rcu(struct callback_head *head, rcu_callback_t func);

void rcu_barrier(void);
bool rcu_eqs_special_set(int cpu);
void rcu_momentary_dyntick_idle(void);
void kfree_rcu_scheduler_running(void);
bool rcu_gp_might_be_stalled(void);
unsigned long get_state_synchronize_rcu(void);
void cond_synchronize_rcu(unsigned long oldstate);

void rcu_idle_enter(void);
void rcu_idle_exit(void);
void rcu_irq_enter(void);
void rcu_irq_exit(void);
void rcu_irq_exit_preempt(void);
void rcu_irq_enter_irqson(void);
void rcu_irq_exit_irqson(void);
bool rcu_is_idle_cpu(int cpu);




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rcu_irq_exit_check_preempt(void) { }


void exit_rcu(void);

void rcu_scheduler_starting(void);
extern int rcu_scheduler_active __attribute__((__section__(".data..read_mostly")));
void rcu_end_inkernel_boot(void);
bool rcu_inkernel_boot_has_ended(void);
bool rcu_is_watching(void);

void rcu_all_qs(void);



int rcutree_prepare_cpu(unsigned int cpu);
int rcutree_online_cpu(unsigned int cpu);
int rcutree_offline_cpu(unsigned int cpu);
int rcutree_dead_cpu(unsigned int cpu);
int rcutree_dying_cpu(unsigned int cpu);
void rcu_cpu_starting(unsigned int cpu);
# 212 "/home/nathan/src/linux/include/linux/rcupdate.h" 2
# 232 "/home/nathan/src/linux/include/linux/rcupdate.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void init_rcu_head(struct callback_head *head) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void destroy_rcu_head(struct callback_head *head) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void init_rcu_head_on_stack(struct callback_head *head) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void destroy_rcu_head_on_stack(struct callback_head *head) { }





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool rcu_lockdep_current_cpu_online(void) { return true; }


extern struct lockdep_map rcu_lock_map;
extern struct lockdep_map rcu_bh_lock_map;
extern struct lockdep_map rcu_sched_lock_map;
extern struct lockdep_map rcu_callback_map;
# 272 "/home/nathan/src/linux/include/linux/rcupdate.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int rcu_read_lock_held(void)
{
 return 1;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int rcu_read_lock_bh_held(void)
{
 return 1;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int rcu_read_lock_sched_held(void)
{
 return !0;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int rcu_read_lock_any_held(void)
{
 return !0;
}
# 638 "/home/nathan/src/linux/include/linux/rcupdate.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void rcu_read_lock(void)
{
 __rcu_read_lock();
 (void)0;
 do { } while (0);
 do { } while (0 && (!rcu_is_watching()));

}
# 690 "/home/nathan/src/linux/include/linux/rcupdate.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rcu_read_unlock(void)
{
 do { } while (0 && (!rcu_is_watching()));

 (void)0;
 __rcu_read_unlock();
 do { } while (0);
}
# 711 "/home/nathan/src/linux/include/linux/rcupdate.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rcu_read_lock_bh(void)
{
 local_bh_disable();
 (void)0;
 do { } while (0);
 do { } while (0 && (!rcu_is_watching()));

}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rcu_read_unlock_bh(void)
{
 do { } while (0 && (!rcu_is_watching()));

 do { } while (0);
 (void)0;
 local_bh_enable();
}
# 746 "/home/nathan/src/linux/include/linux/rcupdate.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rcu_read_lock_sched(void)
{
 __asm__ __volatile__("": : :"memory");
 (void)0;
 do { } while (0);
 do { } while (0 && (!rcu_is_watching()));

}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__no_instrument_function__)) void rcu_read_lock_sched_notrace(void)
{
 __asm__ __volatile__("": : :"memory");
 (void)0;
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rcu_read_unlock_sched(void)
{
 do { } while (0 && (!rcu_is_watching()));

 do { } while (0);
 (void)0;
 __asm__ __volatile__("": : :"memory");
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__no_instrument_function__)) void rcu_read_unlock_sched_notrace(void)
{
 (void)0;
 __asm__ __volatile__("": : :"memory");
}
# 950 "/home/nathan/src/linux/include/linux/rcupdate.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rcu_head_init(struct callback_head *rhp)
{
 rhp->func = (rcu_callback_t)~0L;
}
# 968 "/home/nathan/src/linux/include/linux/rcupdate.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool
rcu_head_after_call_rcu(struct callback_head *rhp, rcu_callback_t f)
{
 rcu_callback_t func = ({ do { extern void __compiletime_assert_78(void) ; if (!((sizeof(rhp->func) == sizeof(char) || sizeof(rhp->func) == sizeof(short) || sizeof(rhp->func) == sizeof(int) || sizeof(rhp->func) == sizeof(long)) || sizeof(rhp->func) == sizeof(long long))) __compiletime_assert_78(); } while (0); (*(const volatile typeof( _Generic((rhp->func), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (rhp->func))) *)&(rhp->func)); });

 if (func == f)
  return true;
 ({ static bool __attribute__((__section__(".data.once"))) __warned; int __ret_warn_once = !!(func != (rcu_callback_t)~0L); if (__builtin_expect(!!(__ret_warn_once && !__warned), 0)) { __warned = true; ({ int __ret_warn_on = !!(1); if (__builtin_expect(!!(__ret_warn_on), 0)) do { do { } while(0); warn_slowpath_fmt("include/linux/rcupdate.h", 975, 9, ((void *)0)); do { } while(0); } while (0); __builtin_expect(!!(__ret_warn_on), 0); }); } __builtin_expect(!!(__ret_warn_once), 0); });
 return false;
}


extern int rcu_expedited;
extern int rcu_normal;
# 17 "/home/nathan/src/linux/include/linux/workqueue.h" 2

struct workqueue_struct;

struct work_struct;
typedef void (*work_func_t)(struct work_struct *work);
void delayed_work_timer_fn(struct timer_list *t);







enum {
 WORK_STRUCT_PENDING_BIT = 0,
 WORK_STRUCT_DELAYED_BIT = 1,
 WORK_STRUCT_PWQ_BIT = 2,
 WORK_STRUCT_LINKED_BIT = 3,




 WORK_STRUCT_COLOR_SHIFT = 4,


 WORK_STRUCT_COLOR_BITS = 4,

 WORK_STRUCT_PENDING = 1 << WORK_STRUCT_PENDING_BIT,
 WORK_STRUCT_DELAYED = 1 << WORK_STRUCT_DELAYED_BIT,
 WORK_STRUCT_PWQ = 1 << WORK_STRUCT_PWQ_BIT,
 WORK_STRUCT_LINKED = 1 << WORK_STRUCT_LINKED_BIT,



 WORK_STRUCT_STATIC = 0,






 WORK_NR_COLORS = (1 << WORK_STRUCT_COLOR_BITS) - 1,
 WORK_NO_COLOR = WORK_NR_COLORS,


 WORK_CPU_UNBOUND = 16,






 WORK_STRUCT_FLAG_BITS = WORK_STRUCT_COLOR_SHIFT +
      WORK_STRUCT_COLOR_BITS,


 WORK_OFFQ_FLAG_BASE = WORK_STRUCT_COLOR_SHIFT,

 __WORK_OFFQ_CANCELING = WORK_OFFQ_FLAG_BASE,
 WORK_OFFQ_CANCELING = (1 << __WORK_OFFQ_CANCELING),






 WORK_OFFQ_FLAG_BITS = 1,
 WORK_OFFQ_POOL_SHIFT = WORK_OFFQ_FLAG_BASE + WORK_OFFQ_FLAG_BITS,
 WORK_OFFQ_LEFT = 32 - WORK_OFFQ_POOL_SHIFT,
 WORK_OFFQ_POOL_BITS = WORK_OFFQ_LEFT <= 31 ? WORK_OFFQ_LEFT : 31,
 WORK_OFFQ_POOL_NONE = (1LU << WORK_OFFQ_POOL_BITS) - 1,


 WORK_STRUCT_FLAG_MASK = (1UL << WORK_STRUCT_FLAG_BITS) - 1,
 WORK_STRUCT_WQ_DATA_MASK = ~WORK_STRUCT_FLAG_MASK,
 WORK_STRUCT_NO_POOL = (unsigned long)WORK_OFFQ_POOL_NONE << WORK_OFFQ_POOL_SHIFT,


 WORK_BUSY_PENDING = 1 << 0,
 WORK_BUSY_RUNNING = 1 << 1,


 WORKER_DESC_LEN = 24,
};

struct work_struct {
 atomic_long_t data;
 struct list_head entry;
 work_func_t func;



};





struct delayed_work {
 struct work_struct work;
 struct timer_list timer;


 struct workqueue_struct *wq;
 int cpu;
};

struct rcu_work {
 struct work_struct work;
 struct callback_head rcu;


 struct workqueue_struct *wq;
};






struct workqueue_attrs {



 int nice;




 cpumask_var_t cpumask;
# 155 "/home/nathan/src/linux/include/linux/workqueue.h"
 bool no_numa;
};

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct delayed_work *to_delayed_work(struct work_struct *work)
{
 return ({ void *__mptr = (void *)(work); do { extern void __compiletime_assert_79(void) ; if (!(!(!__builtin_types_compatible_p(typeof(*(work)), typeof(((struct delayed_work *)0)->work)) && !__builtin_types_compatible_p(typeof(*(work)), typeof(void))))) __compiletime_assert_79(); } while (0); ((struct delayed_work *)(__mptr - __builtin_offsetof(struct delayed_work, work))); });
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct rcu_work *to_rcu_work(struct work_struct *work)
{
 return ({ void *__mptr = (void *)(work); do { extern void __compiletime_assert_80(void) ; if (!(!(!__builtin_types_compatible_p(typeof(*(work)), typeof(((struct rcu_work *)0)->work)) && !__builtin_types_compatible_p(typeof(*(work)), typeof(void))))) __compiletime_assert_80(); } while (0); ((struct rcu_work *)(__mptr - __builtin_offsetof(struct rcu_work, work))); });
}

struct execute_work {
 struct work_struct work;
};
# 215 "/home/nathan/src/linux/include/linux/workqueue.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __init_work(struct work_struct *work, int onstack) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void destroy_work_on_stack(struct work_struct *work) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void destroy_delayed_work_on_stack(struct delayed_work *work) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned int work_static(struct work_struct *work) { return 0; }
# 308 "/home/nathan/src/linux/include/linux/workqueue.h"
enum {
 WQ_UNBOUND = 1 << 1,
 WQ_FREEZABLE = 1 << 2,
 WQ_MEM_RECLAIM = 1 << 3,
 WQ_HIGHPRI = 1 << 4,
 WQ_CPU_INTENSIVE = 1 << 5,
 WQ_SYSFS = 1 << 6,
# 341 "/home/nathan/src/linux/include/linux/workqueue.h"
 WQ_POWER_EFFICIENT = 1 << 7,

 __WQ_DRAINING = 1 << 16,
 __WQ_ORDERED = 1 << 17,
 __WQ_LEGACY = 1 << 18,
 __WQ_ORDERED_EXPLICIT = 1 << 19,

 WQ_MAX_ACTIVE = 512,
 WQ_MAX_UNBOUND_PER_CPU = 4,
 WQ_DFL_ACTIVE = WQ_MAX_ACTIVE / 2,
};
# 385 "/home/nathan/src/linux/include/linux/workqueue.h"
extern struct workqueue_struct *system_wq;
extern struct workqueue_struct *system_highpri_wq;
extern struct workqueue_struct *system_long_wq;
extern struct workqueue_struct *system_unbound_wq;
extern struct workqueue_struct *system_freezable_wq;
extern struct workqueue_struct *system_power_efficient_wq;
extern struct workqueue_struct *system_freezable_power_efficient_wq;
# 407 "/home/nathan/src/linux/include/linux/workqueue.h"
struct workqueue_struct *alloc_workqueue(const char *fmt,
      unsigned int flags,
      int max_active, ...);
# 436 "/home/nathan/src/linux/include/linux/workqueue.h"
extern void destroy_workqueue(struct workqueue_struct *wq);

struct workqueue_attrs *alloc_workqueue_attrs(void);
void free_workqueue_attrs(struct workqueue_attrs *attrs);
int apply_workqueue_attrs(struct workqueue_struct *wq,
     const struct workqueue_attrs *attrs);
int workqueue_set_unbound_cpumask(cpumask_var_t cpumask);

extern bool queue_work_on(int cpu, struct workqueue_struct *wq,
   struct work_struct *work);
extern bool queue_work_node(int node, struct workqueue_struct *wq,
       struct work_struct *work);
extern bool queue_delayed_work_on(int cpu, struct workqueue_struct *wq,
   struct delayed_work *work, unsigned long delay);
extern bool mod_delayed_work_on(int cpu, struct workqueue_struct *wq,
   struct delayed_work *dwork, unsigned long delay);
extern bool queue_rcu_work(struct workqueue_struct *wq, struct rcu_work *rwork);

extern void flush_workqueue(struct workqueue_struct *wq);
extern void drain_workqueue(struct workqueue_struct *wq);

extern int schedule_on_each_cpu(work_func_t func);

int execute_in_process_context(work_func_t fn, struct execute_work *);

extern bool flush_work(struct work_struct *work);
extern bool cancel_work_sync(struct work_struct *work);

extern bool flush_delayed_work(struct delayed_work *dwork);
extern bool cancel_delayed_work(struct delayed_work *dwork);
extern bool cancel_delayed_work_sync(struct delayed_work *dwork);

extern bool flush_rcu_work(struct rcu_work *rwork);

extern void workqueue_set_max_active(struct workqueue_struct *wq,
         int max_active);
extern struct work_struct *current_work(void);
extern bool current_is_workqueue_rescuer(void);
extern bool workqueue_congested(int cpu, struct workqueue_struct *wq);
extern unsigned int work_busy(struct work_struct *work);
extern __attribute__((__format__(printf, 1, 2))) void set_worker_desc(const char *fmt, ...);
extern void print_worker_info(const char *log_lvl, struct task_struct *task);
extern void show_workqueue_state(void);
extern void wq_worker_comm(char *buf, size_t size, struct task_struct *task);
# 504 "/home/nathan/src/linux/include/linux/workqueue.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool queue_work(struct workqueue_struct *wq,
         struct work_struct *work)
{
 return queue_work_on(WORK_CPU_UNBOUND, wq, work);
}
# 518 "/home/nathan/src/linux/include/linux/workqueue.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool queue_delayed_work(struct workqueue_struct *wq,
          struct delayed_work *dwork,
          unsigned long delay)
{
 return queue_delayed_work_on(WORK_CPU_UNBOUND, wq, dwork, delay);
}
# 533 "/home/nathan/src/linux/include/linux/workqueue.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool mod_delayed_work(struct workqueue_struct *wq,
        struct delayed_work *dwork,
        unsigned long delay)
{
 return mod_delayed_work_on(WORK_CPU_UNBOUND, wq, dwork, delay);
}
# 547 "/home/nathan/src/linux/include/linux/workqueue.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool schedule_work_on(int cpu, struct work_struct *work)
{
 return queue_work_on(cpu, system_wq, work);
}
# 566 "/home/nathan/src/linux/include/linux/workqueue.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool schedule_work(struct work_struct *work)
{
 return queue_work(system_wq, work);
}
# 595 "/home/nathan/src/linux/include/linux/workqueue.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void flush_scheduled_work(void)
{
 flush_workqueue(system_wq);
}
# 609 "/home/nathan/src/linux/include/linux/workqueue.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool schedule_delayed_work_on(int cpu, struct delayed_work *dwork,
         unsigned long delay)
{
 return queue_delayed_work_on(cpu, system_wq, dwork, delay);
}
# 623 "/home/nathan/src/linux/include/linux/workqueue.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool schedule_delayed_work(struct delayed_work *dwork,
      unsigned long delay)
{
 return queue_delayed_work(system_wq, dwork, delay);
}
# 639 "/home/nathan/src/linux/include/linux/workqueue.h"
long work_on_cpu(int cpu, long (*fn)(void *), void *arg);
long work_on_cpu_safe(int cpu, long (*fn)(void *), void *arg);



extern void freeze_workqueues_begin(void);
extern bool freeze_workqueues_busy(void);
extern void thaw_workqueues(void);



int workqueue_sysfs_register(struct workqueue_struct *wq);
# 659 "/home/nathan/src/linux/include/linux/workqueue.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void wq_watchdog_touch(int cpu) { }



int workqueue_prepare_cpu(unsigned int cpu);
int workqueue_online_cpu(unsigned int cpu);
int workqueue_offline_cpu(unsigned int cpu);


void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) workqueue_init_early(void);
void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) workqueue_init(void);
# 13 "/home/nathan/src/linux/include/linux/pm.h" 2

# 1 "/home/nathan/src/linux/include/linux/wait.h" 1
# 11 "/home/nathan/src/linux/include/linux/wait.h"
# 1 "./arch/mips/include/generated/asm/current.h" 1
# 1 "/home/nathan/src/linux/include/asm-generic/current.h" 1
# 2 "./arch/mips/include/generated/asm/current.h" 2
# 12 "/home/nathan/src/linux/include/linux/wait.h" 2
# 1 "/home/nathan/src/linux/include/uapi/linux/wait.h" 1
# 13 "/home/nathan/src/linux/include/linux/wait.h" 2

typedef struct wait_queue_entry wait_queue_entry_t;

typedef int (*wait_queue_func_t)(struct wait_queue_entry *wq_entry, unsigned mode, int flags, void *key);
int default_wake_function(struct wait_queue_entry *wq_entry, unsigned mode, int flags, void *key);
# 30 "/home/nathan/src/linux/include/linux/wait.h"
struct wait_queue_entry {
 unsigned int flags;
 void *private;
 wait_queue_func_t func;
 struct list_head entry;
};

struct wait_queue_head {
 spinlock_t lock;
 struct list_head head;
};
typedef struct wait_queue_head wait_queue_head_t;

struct task_struct;
# 64 "/home/nathan/src/linux/include/linux/wait.h"
extern void __init_waitqueue_head(struct wait_queue_head *wq_head, const char *name, struct lock_class_key *);
# 82 "/home/nathan/src/linux/include/linux/wait.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void init_waitqueue_entry(struct wait_queue_entry *wq_entry, struct task_struct *p)
{
 wq_entry->flags = 0;
 wq_entry->private = p;
 wq_entry->func = default_wake_function;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
init_waitqueue_func_entry(struct wait_queue_entry *wq_entry, wait_queue_func_t func)
{
 wq_entry->flags = 0;
 wq_entry->private = ((void *)0);
 wq_entry->func = func;
}
# 127 "/home/nathan/src/linux/include/linux/wait.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int waitqueue_active(struct wait_queue_head *wq_head)
{
 return !list_empty(&wq_head->head);
}
# 140 "/home/nathan/src/linux/include/linux/wait.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool wq_has_single_sleeper(struct wait_queue_head *wq_head)
{
 return list_is_singular(&wq_head->head);
}
# 153 "/home/nathan/src/linux/include/linux/wait.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool wq_has_sleeper(struct wait_queue_head *wq_head)
{







 __sync();
 return waitqueue_active(wq_head);
}

extern void add_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
extern void add_wait_queue_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
extern void add_wait_queue_priority(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
extern void remove_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __add_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)
{
 struct list_head *head = &wq_head->head;
 struct wait_queue_entry *wq;

 for (wq = ({ void *__mptr = (void *)((&wq_head->head)->next); do { extern void __compiletime_assert_81(void) ; if (!(!(!__builtin_types_compatible_p(typeof(*((&wq_head->head)->next)), typeof(((typeof(*wq) *)0)->entry)) && !__builtin_types_compatible_p(typeof(*((&wq_head->head)->next)), typeof(void))))) __compiletime_assert_81(); } while (0); ((typeof(*wq) *)(__mptr - __builtin_offsetof(typeof(*wq), entry))); }); !(&wq->entry == (&wq_head->head)); wq = ({ void *__mptr = (void *)((wq)->entry.next); do { extern void __compiletime_assert_82(void) ; if (!(!(!__builtin_types_compatible_p(typeof(*((wq)->entry.next)), typeof(((typeof(*(wq)) *)0)->entry)) && !__builtin_types_compatible_p(typeof(*((wq)->entry.next)), typeof(void))))) __compiletime_assert_82(); } while (0); ((typeof(*(wq)) *)(__mptr - __builtin_offsetof(typeof(*(wq)), entry))); })) {
  if (!(wq->flags & 0x20))
   break;
  head = &wq->entry;
 }
 list_add(&wq_entry->entry, head);
}




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
__add_wait_queue_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)
{
 wq_entry->flags |= 0x01;
 __add_wait_queue(wq_head, wq_entry);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __add_wait_queue_entry_tail(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)
{
 list_add_tail(&wq_entry->entry, &wq_head->head);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
__add_wait_queue_entry_tail_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)
{
 wq_entry->flags |= 0x01;
 __add_wait_queue_entry_tail(wq_head, wq_entry);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
__remove_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)
{
 list_del(&wq_entry->entry);
}

void __wake_up(struct wait_queue_head *wq_head, unsigned int mode, int nr, void *key);
void __wake_up_locked_key(struct wait_queue_head *wq_head, unsigned int mode, void *key);
void __wake_up_locked_key_bookmark(struct wait_queue_head *wq_head,
  unsigned int mode, void *key, wait_queue_entry_t *bookmark);
void __wake_up_sync_key(struct wait_queue_head *wq_head, unsigned int mode, void *key);
void __wake_up_locked_sync_key(struct wait_queue_head *wq_head, unsigned int mode, void *key);
void __wake_up_locked(struct wait_queue_head *wq_head, unsigned int mode, int nr);
void __wake_up_sync(struct wait_queue_head *wq_head, unsigned int mode);
# 260 "/home/nathan/src/linux/include/linux/wait.h"
extern void init_wait_entry(struct wait_queue_entry *wq_entry, int flags);
# 744 "/home/nathan/src/linux/include/linux/wait.h"
extern int do_wait_intr(wait_queue_head_t *, wait_queue_entry_t *);
extern int do_wait_intr_irq(wait_queue_head_t *, wait_queue_entry_t *);
# 1138 "/home/nathan/src/linux/include/linux/wait.h"
void prepare_to_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state);
void prepare_to_wait_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state);
long prepare_to_wait_event(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state);
void finish_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
long wait_woken(struct wait_queue_entry *wq_entry, unsigned mode, long timeout);
int woken_wake_function(struct wait_queue_entry *wq_entry, unsigned mode, int sync, void *key);
int autoremove_wake_function(struct wait_queue_entry *wq_entry, unsigned mode, int sync, void *key);
# 1163 "/home/nathan/src/linux/include/linux/wait.h"
bool try_invoke_on_locked_down_task(struct task_struct *p, bool (*func)(struct task_struct *t, void *arg), void *arg);
# 15 "/home/nathan/src/linux/include/linux/pm.h" 2

# 1 "/home/nathan/src/linux/include/linux/hrtimer.h" 1
# 15 "/home/nathan/src/linux/include/linux/hrtimer.h"
# 1 "/home/nathan/src/linux/include/linux/hrtimer_defs.h" 1
# 16 "/home/nathan/src/linux/include/linux/hrtimer.h" 2
# 1 "/home/nathan/src/linux/include/linux/rbtree.h" 1
# 24 "/home/nathan/src/linux/include/linux/rbtree.h"
struct rb_node {
 unsigned long __rb_parent_color;
 struct rb_node *rb_right;
 struct rb_node *rb_left;
} __attribute__((aligned(sizeof(long))));


struct rb_root {
 struct rb_node *rb_node;
};
# 49 "/home/nathan/src/linux/include/linux/rbtree.h"
extern void rb_insert_color(struct rb_node *, struct rb_root *);
extern void rb_erase(struct rb_node *, struct rb_root *);



extern struct rb_node *rb_next(const struct rb_node *);
extern struct rb_node *rb_prev(const struct rb_node *);
extern struct rb_node *rb_first(const struct rb_root *);
extern struct rb_node *rb_last(const struct rb_root *);


extern struct rb_node *rb_first_postorder(const struct rb_root *);
extern struct rb_node *rb_next_postorder(const struct rb_node *);


extern void rb_replace_node(struct rb_node *victim, struct rb_node *new,
       struct rb_root *root);
extern void rb_replace_node_rcu(struct rb_node *victim, struct rb_node *new,
    struct rb_root *root);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rb_link_node(struct rb_node *node, struct rb_node *parent,
    struct rb_node **rb_link)
{
 node->__rb_parent_color = (unsigned long)parent;
 node->rb_left = node->rb_right = ((void *)0);

 *rb_link = node;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rb_link_node_rcu(struct rb_node *node, struct rb_node *parent,
        struct rb_node **rb_link)
{
 node->__rb_parent_color = (unsigned long)parent;
 node->rb_left = node->rb_right = ((void *)0);

 do { uintptr_t _r_a_p__v = (uintptr_t)(node); ; if (__builtin_constant_p(node) && (_r_a_p__v) == (uintptr_t)((void *)0)) do { do { extern void __compiletime_assert_83(void) ; if (!((sizeof((*rb_link)) == sizeof(char) || sizeof((*rb_link)) == sizeof(short) || sizeof((*rb_link)) == sizeof(int) || sizeof((*rb_link)) == sizeof(long)) || sizeof((*rb_link)) == sizeof(long long))) __compiletime_assert_83(); } while (0); do { *(volatile typeof((*rb_link)) *)&((*rb_link)) = ((typeof(*rb_link))(_r_a_p__v)); } while (0); } while (0); else do { do { extern void __compiletime_assert_84(void) ; if (!((sizeof(*&*rb_link) == sizeof(char) || sizeof(*&*rb_link) == sizeof(short) || sizeof(*&*rb_link) == sizeof(int) || sizeof(*&*rb_link) == sizeof(long)))) __compiletime_assert_84(); } while (0); __sync(); do { do { extern void __compiletime_assert_85(void) ; if (!((sizeof(*&*rb_link) == sizeof(char) || sizeof(*&*rb_link) == sizeof(short) || sizeof(*&*rb_link) == sizeof(int) || sizeof(*&*rb_link) == sizeof(long)) || sizeof(*&*rb_link) == sizeof(long long))) __compiletime_assert_85(); } while (0); do { *(volatile typeof(*&*rb_link) *)&(*&*rb_link) = ((typeof(*((typeof(*rb_link))_r_a_p__v)) *)((typeof(*rb_link))_r_a_p__v)); } while (0); } while (0); } while (0); } while (0);
}
# 125 "/home/nathan/src/linux/include/linux/rbtree.h"
struct rb_root_cached {
 struct rb_root rb_root;
 struct rb_node *rb_leftmost;
};






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rb_insert_color_cached(struct rb_node *node,
       struct rb_root_cached *root,
       bool leftmost)
{
 if (leftmost)
  root->rb_leftmost = node;
 rb_insert_color(node, &root->rb_root);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rb_erase_cached(struct rb_node *node,
       struct rb_root_cached *root)
{
 if (root->rb_leftmost == node)
  root->rb_leftmost = rb_next(node);
 rb_erase(node, &root->rb_root);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void rb_replace_node_cached(struct rb_node *victim,
       struct rb_node *new,
       struct rb_root_cached *root)
{
 if (root->rb_leftmost == victim)
  root->rb_leftmost = new;
 rb_replace_node(victim, new, &root->rb_root);
}
# 17 "/home/nathan/src/linux/include/linux/hrtimer.h" 2


# 1 "/home/nathan/src/linux/include/linux/percpu.h" 1




# 1 "/home/nathan/src/linux/include/linux/mmdebug.h" 1







struct page;
struct vm_area_struct;
struct mm_struct;

extern void dump_page(struct page *page, const char *reason);
extern void __dump_page(struct page *page, const char *reason);
void dump_vma(const struct vm_area_struct *vma);
void dump_mm(const struct mm_struct *mm);
# 6 "/home/nathan/src/linux/include/linux/percpu.h" 2







# 1 "./arch/mips/include/generated/asm/percpu.h" 1
# 14 "/home/nathan/src/linux/include/linux/percpu.h" 2
# 65 "/home/nathan/src/linux/include/linux/percpu.h"
extern void *pcpu_base_addr;
extern const unsigned long *pcpu_unit_offsets;

struct pcpu_group_info {
 int nr_units;
 unsigned long base_offset;
 unsigned int *cpu_map;

};

struct pcpu_alloc_info {
 size_t static_size;
 size_t reserved_size;
 size_t dyn_size;
 size_t unit_size;
 size_t atom_size;
 size_t alloc_size;
 size_t __ai_size;
 int nr_groups;
 struct pcpu_group_info groups[];
};

enum pcpu_fc {
 PCPU_FC_AUTO,
 PCPU_FC_EMBED,
 PCPU_FC_PAGE,

 PCPU_FC_NR,
};
extern const char * const pcpu_fc_names[PCPU_FC_NR];

extern enum pcpu_fc pcpu_chosen_fc;

typedef void * (*pcpu_fc_alloc_fn_t)(unsigned int cpu, size_t size,
         size_t align);
typedef void (*pcpu_fc_free_fn_t)(void *ptr, size_t size);
typedef void (*pcpu_fc_populate_pte_fn_t)(unsigned long addr);
typedef int (pcpu_fc_cpu_distance_fn_t)(unsigned int from, unsigned int to);

extern struct pcpu_alloc_info * __attribute__((__section__(".init.text"))) __attribute__((__cold__)) pcpu_alloc_alloc_info(int nr_groups,
            int nr_units);
extern void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) pcpu_free_alloc_info(struct pcpu_alloc_info *ai);

extern void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) pcpu_setup_first_chunk(const struct pcpu_alloc_info *ai,
      void *base_addr);
# 126 "/home/nathan/src/linux/include/linux/percpu.h"
extern void *__alloc_reserved_percpu(size_t size, size_t align);
extern bool __is_kernel_percpu_address(unsigned long addr, unsigned long *can_addr);
extern bool is_kernel_percpu_address(unsigned long addr);


extern void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) setup_per_cpu_areas(void);


extern void *__alloc_percpu_gfp(size_t size, size_t align, gfp_t gfp);
extern void *__alloc_percpu(size_t size, size_t align);
extern void free_percpu(void *__pdata);
extern phys_addr_t per_cpu_ptr_to_phys(void *addr);
# 146 "/home/nathan/src/linux/include/linux/percpu.h"
extern unsigned long pcpu_nr_pages(void);
# 20 "/home/nathan/src/linux/include/linux/hrtimer.h" 2
# 1 "/home/nathan/src/linux/include/linux/seqlock.h" 1
# 19 "/home/nathan/src/linux/include/linux/seqlock.h"
# 1 "/home/nathan/src/linux/include/linux/mutex.h" 1
# 14 "/home/nathan/src/linux/include/linux/mutex.h"
# 1 "./arch/mips/include/generated/asm/current.h" 1
# 15 "/home/nathan/src/linux/include/linux/mutex.h" 2





# 1 "/home/nathan/src/linux/include/linux/osq_lock.h" 1








struct optimistic_spin_node {
 struct optimistic_spin_node *next, *prev;
 int locked;
 int cpu;
};

struct optimistic_spin_queue {




 atomic_t tail;
};






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void osq_lock_init(struct optimistic_spin_queue *lock)
{
 atomic_set(&lock->tail, (0));
}

extern bool osq_lock(struct optimistic_spin_queue *lock);
extern void osq_unlock(struct optimistic_spin_queue *lock);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool osq_is_locked(struct optimistic_spin_queue *lock)
{
 return atomic_read(&lock->tail) != (0);
}
# 21 "/home/nathan/src/linux/include/linux/mutex.h" 2
# 1 "/home/nathan/src/linux/include/linux/debug_locks.h" 1








struct task_struct;

extern int debug_locks __attribute__((__section__(".data..read_mostly")));
extern int debug_locks_silent __attribute__((__section__(".data..read_mostly")));


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) int __debug_locks_off(void)
{
 return ({ __typeof__(*(&debug_locks)) __res; if (!0) do { } while (0); __res = (__typeof__(*(&debug_locks))) __xchg((&debug_locks), (unsigned long)(0), sizeof(*(&debug_locks))); do { } while (0); __res; });
}




extern int debug_locks_off(void);
# 49 "/home/nathan/src/linux/include/linux/debug_locks.h"
struct task_struct;







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void debug_show_all_locks(void)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void debug_show_held_locks(struct task_struct *task)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
debug_check_no_locks_freed(const void *from, unsigned long len)
{
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
debug_check_no_locks_held(void)
{
}
# 22 "/home/nathan/src/linux/include/linux/mutex.h" 2

struct ww_acquire_ctx;
# 53 "/home/nathan/src/linux/include/linux/mutex.h"
struct mutex {
 atomic_long_t owner;
 spinlock_t wait_lock;



 struct list_head wait_list;






};

struct ww_class;
struct ww_acquire_ctx;

struct ww_mutex {
 struct mutex base;
 struct ww_acquire_ctx *ctx;



};





struct mutex_waiter {
 struct list_head list;
 struct task_struct *task;
 struct ww_acquire_ctx *ww_ctx;



};
# 103 "/home/nathan/src/linux/include/linux/mutex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void mutex_destroy(struct mutex *lock) {}
# 142 "/home/nathan/src/linux/include/linux/mutex.h"
extern void __mutex_init(struct mutex *lock, const char *name,
    struct lock_class_key *key);







extern bool mutex_is_locked(struct mutex *lock);
# 179 "/home/nathan/src/linux/include/linux/mutex.h"
extern void mutex_lock(struct mutex *lock);
extern int __attribute__((__warn_unused_result__)) mutex_lock_interruptible(struct mutex *lock);
extern int __attribute__((__warn_unused_result__)) mutex_lock_killable(struct mutex *lock);
extern void mutex_lock_io(struct mutex *lock);
# 197 "/home/nathan/src/linux/include/linux/mutex.h"
extern int mutex_trylock(struct mutex *lock);
extern void mutex_unlock(struct mutex *lock);

extern int atomic_dec_and_mutex_lock(atomic_t *cnt, struct mutex *lock);





enum mutex_trylock_recursive_enum {
 MUTEX_TRYLOCK_FAILED = 0,
 MUTEX_TRYLOCK_SUCCESS = 1,
 MUTEX_TRYLOCK_RECURSIVE,
};
# 224 "/home/nathan/src/linux/include/linux/mutex.h"
extern __attribute__((__warn_unused_result__)) enum mutex_trylock_recursive_enum
mutex_trylock_recursive(struct mutex *lock);
# 20 "/home/nathan/src/linux/include/linux/seqlock.h" 2
# 1 "/home/nathan/src/linux/include/linux/ww_mutex.h" 1
# 22 "/home/nathan/src/linux/include/linux/ww_mutex.h"
struct ww_class {
 atomic_long_t stamp;
 struct lock_class_key acquire_key;
 struct lock_class_key mutex_key;
 const char *acquire_name;
 const char *mutex_name;
 unsigned int is_wait_die;
};

struct ww_acquire_ctx {
 struct task_struct *task;
 unsigned long stamp;
 unsigned int acquired;
 unsigned short wounded;
 unsigned short is_wait_die;
# 49 "/home/nathan/src/linux/include/linux/ww_mutex.h"
};
# 87 "/home/nathan/src/linux/include/linux/ww_mutex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ww_mutex_init(struct ww_mutex *lock,
     struct ww_class *ww_class)
{
 __mutex_init(&lock->base, ww_class->mutex_name, &ww_class->mutex_key);
 lock->ctx = ((void *)0);



}
# 121 "/home/nathan/src/linux/include/linux/ww_mutex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ww_acquire_init(struct ww_acquire_ctx *ctx,
       struct ww_class *ww_class)
{
 ctx->task = (current_thread_info()->task);
 ctx->stamp = atomic_long_inc_return_relaxed(&ww_class->stamp);
 ctx->acquired = 0;
 ctx->wounded = false;
 ctx->is_wait_die = ww_class->is_wait_die;
# 144 "/home/nathan/src/linux/include/linux/ww_mutex.h"
}
# 157 "/home/nathan/src/linux/include/linux/ww_mutex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ww_acquire_done(struct ww_acquire_ctx *ctx)
{






}
# 174 "/home/nathan/src/linux/include/linux/ww_mutex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ww_acquire_fini(struct ww_acquire_ctx *ctx)
{
# 191 "/home/nathan/src/linux/include/linux/ww_mutex.h"
}
# 222 "/home/nathan/src/linux/include/linux/ww_mutex.h"
extern int ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx);
# 254 "/home/nathan/src/linux/include/linux/ww_mutex.h"
extern int __attribute__((__warn_unused_result__)) ww_mutex_lock_interruptible(struct ww_mutex *lock,
          struct ww_acquire_ctx *ctx);
# 280 "/home/nathan/src/linux/include/linux/ww_mutex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
ww_mutex_lock_slow(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)
{
 int ret;



 ret = ww_mutex_lock(lock, ctx);
 (void)ret;
}
# 316 "/home/nathan/src/linux/include/linux/ww_mutex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__))
ww_mutex_lock_slow_interruptible(struct ww_mutex *lock,
     struct ww_acquire_ctx *ctx)
{



 return ww_mutex_lock_interruptible(lock, ctx);
}

extern void ww_mutex_unlock(struct ww_mutex *lock);
# 335 "/home/nathan/src/linux/include/linux/ww_mutex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int __attribute__((__warn_unused_result__)) ww_mutex_trylock(struct ww_mutex *lock)
{
 return mutex_trylock(&lock->base);
}
# 348 "/home/nathan/src/linux/include/linux/ww_mutex.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ww_mutex_destroy(struct ww_mutex *lock)
{
 mutex_destroy(&lock->base);
}







static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool ww_mutex_is_locked(struct ww_mutex *lock)
{
 return mutex_is_locked(&lock->base);
}
# 21 "/home/nathan/src/linux/include/linux/seqlock.h" 2
# 65 "/home/nathan/src/linux/include/linux/seqlock.h"
typedef struct seqcount {
 unsigned sequence;



} seqcount_t;

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __seqcount_init(seqcount_t *s, const char *name,
       struct lock_class_key *key)
{



 do { (void)(name); (void)(key); } while (0);
 s->sequence = 0;
}
# 254 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) seqcount_t *__seqprop_ptr(seqcount_t *s)
{
 return s;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned __seqprop_sequence(const seqcount_t *s)
{
 return ({ do { extern void __compiletime_assert_86(void) ; if (!((sizeof(s->sequence) == sizeof(char) || sizeof(s->sequence) == sizeof(short) || sizeof(s->sequence) == sizeof(int) || sizeof(s->sequence) == sizeof(long)) || sizeof(s->sequence) == sizeof(long long))) __compiletime_assert_86(); } while (0); (*(const volatile typeof( _Generic((s->sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->sequence))) *)&(s->sequence)); });
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool __seqprop_preemptible(const seqcount_t *s)
{
 return false;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void __seqprop_assert(const seqcount_t *s)
{
 do { } while (0);
}



typedef struct seqcount_raw_spinlock { seqcount_t seqcount; ; } seqcount_raw_spinlock_t; static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) seqcount_t * __seqprop_raw_spinlock_ptr(seqcount_raw_spinlock_t *s) { return &s->seqcount; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned __seqprop_raw_spinlock_sequence(const seqcount_raw_spinlock_t *s) { unsigned seq = ({ do { extern void __compiletime_assert_87(void) ; if (!((sizeof(s->seqcount.sequence) == sizeof(char) || sizeof(s->seqcount.sequence) == sizeof(short) || sizeof(s->seqcount.sequence) == sizeof(int) || sizeof(s->seqcount.sequence) == sizeof(long)) || sizeof(s->seqcount.sequence) == sizeof(long long))) __compiletime_assert_87(); } while (0); (*(const volatile typeof( _Generic((s->seqcount.sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->seqcount.sequence))) *)&(s->seqcount.sequence)); }); if (!0) return seq; if (false && __builtin_expect(!!(seq & 1), 0)) { ; ; seq = ({ do { extern void __compiletime_assert_88(void) ; if (!((sizeof(s->seqcount.sequence) == sizeof(char) || sizeof(s->seqcount.sequence) == sizeof(short) || sizeof(s->seqcount.sequence) == sizeof(int) || sizeof(s->seqcount.sequence) == sizeof(long)) || sizeof(s->seqcount.sequence) == sizeof(long long))) __compiletime_assert_88(); } while (0); (*(const volatile typeof( _Generic((s->seqcount.sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->seqcount.sequence))) *)&(s->seqcount.sequence)); }); } return seq; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool __seqprop_raw_spinlock_preemptible(const seqcount_raw_spinlock_t *s) { if (!0) return false; return false; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __seqprop_raw_spinlock_assert(const seqcount_raw_spinlock_t *s) { ; }
typedef struct seqcount_spinlock { seqcount_t seqcount; ; } seqcount_spinlock_t; static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) seqcount_t * __seqprop_spinlock_ptr(seqcount_spinlock_t *s) { return &s->seqcount; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned __seqprop_spinlock_sequence(const seqcount_spinlock_t *s) { unsigned seq = ({ do { extern void __compiletime_assert_89(void) ; if (!((sizeof(s->seqcount.sequence) == sizeof(char) || sizeof(s->seqcount.sequence) == sizeof(short) || sizeof(s->seqcount.sequence) == sizeof(int) || sizeof(s->seqcount.sequence) == sizeof(long)) || sizeof(s->seqcount.sequence) == sizeof(long long))) __compiletime_assert_89(); } while (0); (*(const volatile typeof( _Generic((s->seqcount.sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->seqcount.sequence))) *)&(s->seqcount.sequence)); }); if (!0) return seq; if (0 && __builtin_expect(!!(seq & 1), 0)) { ; ; seq = ({ do { extern void __compiletime_assert_90(void) ; if (!((sizeof(s->seqcount.sequence) == sizeof(char) || sizeof(s->seqcount.sequence) == sizeof(short) || sizeof(s->seqcount.sequence) == sizeof(int) || sizeof(s->seqcount.sequence) == sizeof(long)) || sizeof(s->seqcount.sequence) == sizeof(long long))) __compiletime_assert_90(); } while (0); (*(const volatile typeof( _Generic((s->seqcount.sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->seqcount.sequence))) *)&(s->seqcount.sequence)); }); } return seq; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool __seqprop_spinlock_preemptible(const seqcount_spinlock_t *s) { if (!0) return 0; return false; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __seqprop_spinlock_assert(const seqcount_spinlock_t *s) { ; }
typedef struct seqcount_rwlock { seqcount_t seqcount; ; } seqcount_rwlock_t; static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) seqcount_t * __seqprop_rwlock_ptr(seqcount_rwlock_t *s) { return &s->seqcount; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned __seqprop_rwlock_sequence(const seqcount_rwlock_t *s) { unsigned seq = ({ do { extern void __compiletime_assert_91(void) ; if (!((sizeof(s->seqcount.sequence) == sizeof(char) || sizeof(s->seqcount.sequence) == sizeof(short) || sizeof(s->seqcount.sequence) == sizeof(int) || sizeof(s->seqcount.sequence) == sizeof(long)) || sizeof(s->seqcount.sequence) == sizeof(long long))) __compiletime_assert_91(); } while (0); (*(const volatile typeof( _Generic((s->seqcount.sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->seqcount.sequence))) *)&(s->seqcount.sequence)); }); if (!0) return seq; if (0 && __builtin_expect(!!(seq & 1), 0)) { ; ; seq = ({ do { extern void __compiletime_assert_92(void) ; if (!((sizeof(s->seqcount.sequence) == sizeof(char) || sizeof(s->seqcount.sequence) == sizeof(short) || sizeof(s->seqcount.sequence) == sizeof(int) || sizeof(s->seqcount.sequence) == sizeof(long)) || sizeof(s->seqcount.sequence) == sizeof(long long))) __compiletime_assert_92(); } while (0); (*(const volatile typeof( _Generic((s->seqcount.sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->seqcount.sequence))) *)&(s->seqcount.sequence)); }); } return seq; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool __seqprop_rwlock_preemptible(const seqcount_rwlock_t *s) { if (!0) return 0; return false; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __seqprop_rwlock_assert(const seqcount_rwlock_t *s) { ; }
typedef struct seqcount_mutex { seqcount_t seqcount; ; } seqcount_mutex_t; static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) seqcount_t * __seqprop_mutex_ptr(seqcount_mutex_t *s) { return &s->seqcount; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned __seqprop_mutex_sequence(const seqcount_mutex_t *s) { unsigned seq = ({ do { extern void __compiletime_assert_93(void) ; if (!((sizeof(s->seqcount.sequence) == sizeof(char) || sizeof(s->seqcount.sequence) == sizeof(short) || sizeof(s->seqcount.sequence) == sizeof(int) || sizeof(s->seqcount.sequence) == sizeof(long)) || sizeof(s->seqcount.sequence) == sizeof(long long))) __compiletime_assert_93(); } while (0); (*(const volatile typeof( _Generic((s->seqcount.sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->seqcount.sequence))) *)&(s->seqcount.sequence)); }); if (!0) return seq; if (true && __builtin_expect(!!(seq & 1), 0)) { ; ; seq = ({ do { extern void __compiletime_assert_94(void) ; if (!((sizeof(s->seqcount.sequence) == sizeof(char) || sizeof(s->seqcount.sequence) == sizeof(short) || sizeof(s->seqcount.sequence) == sizeof(int) || sizeof(s->seqcount.sequence) == sizeof(long)) || sizeof(s->seqcount.sequence) == sizeof(long long))) __compiletime_assert_94(); } while (0); (*(const volatile typeof( _Generic((s->seqcount.sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->seqcount.sequence))) *)&(s->seqcount.sequence)); }); } return seq; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool __seqprop_mutex_preemptible(const seqcount_mutex_t *s) { if (!0) return true; return false; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __seqprop_mutex_assert(const seqcount_mutex_t *s) { ; }
typedef struct seqcount_ww_mutex { seqcount_t seqcount; ; } seqcount_ww_mutex_t; static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) seqcount_t * __seqprop_ww_mutex_ptr(seqcount_ww_mutex_t *s) { return &s->seqcount; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) unsigned __seqprop_ww_mutex_sequence(const seqcount_ww_mutex_t *s) { unsigned seq = ({ do { extern void __compiletime_assert_95(void) ; if (!((sizeof(s->seqcount.sequence) == sizeof(char) || sizeof(s->seqcount.sequence) == sizeof(short) || sizeof(s->seqcount.sequence) == sizeof(int) || sizeof(s->seqcount.sequence) == sizeof(long)) || sizeof(s->seqcount.sequence) == sizeof(long long))) __compiletime_assert_95(); } while (0); (*(const volatile typeof( _Generic((s->seqcount.sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->seqcount.sequence))) *)&(s->seqcount.sequence)); }); if (!0) return seq; if (true && __builtin_expect(!!(seq & 1), 0)) { ; ; seq = ({ do { extern void __compiletime_assert_96(void) ; if (!((sizeof(s->seqcount.sequence) == sizeof(char) || sizeof(s->seqcount.sequence) == sizeof(short) || sizeof(s->seqcount.sequence) == sizeof(int) || sizeof(s->seqcount.sequence) == sizeof(long)) || sizeof(s->seqcount.sequence) == sizeof(long long))) __compiletime_assert_96(); } while (0); (*(const volatile typeof( _Generic((s->seqcount.sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->seqcount.sequence))) *)&(s->seqcount.sequence)); }); } return seq; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) bool __seqprop_ww_mutex_preemptible(const seqcount_ww_mutex_t *s) { if (!0) return true; return false; } static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__always_inline__)) void __seqprop_ww_mutex_assert(const seqcount_ww_mutex_t *s) { ; }
# 430 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int do___read_seqcount_retry(const seqcount_t *s, unsigned start)
{
 kcsan_atomic_next(0);
 return __builtin_expect(!!(({ do { extern void __compiletime_assert_97(void) ; if (!((sizeof(s->sequence) == sizeof(char) || sizeof(s->sequence) == sizeof(short) || sizeof(s->sequence) == sizeof(int) || sizeof(s->sequence) == sizeof(long)) || sizeof(s->sequence) == sizeof(long long))) __compiletime_assert_97(); } while (0); (*(const volatile typeof( _Generic((s->sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->sequence))) *)&(s->sequence)); }) != start), 0);
}
# 450 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int do_read_seqcount_retry(const seqcount_t *s, unsigned start)
{
 rmb();
 return do___read_seqcount_retry(s, start);
}
# 470 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void do_raw_write_seqcount_begin(seqcount_t *s)
{
 kcsan_nestable_atomic_begin();
 s->sequence++;
 wmb();
}
# 491 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void do_raw_write_seqcount_end(seqcount_t *s)
{
 wmb();
 s->sequence++;
 kcsan_nestable_atomic_end();
}
# 517 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void do_write_seqcount_begin_nested(seqcount_t *s, int subclass)
{
 do_raw_write_seqcount_begin(s);
 do { } while (0);
}
# 543 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void do_write_seqcount_begin(seqcount_t *s)
{
 do_write_seqcount_begin_nested(s, 0);
}
# 563 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void do_write_seqcount_end(seqcount_t *s)
{
 do { } while (0);
 do_raw_write_seqcount_end(s);
}
# 613 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void do_raw_write_seqcount_barrier(seqcount_t *s)
{
 kcsan_nestable_atomic_begin();
 s->sequence++;
 wmb();
 s->sequence++;
 kcsan_nestable_atomic_end();
}
# 633 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void do_write_seqcount_invalidate(seqcount_t *s)
{
 wmb();
 kcsan_nestable_atomic_begin();
 s->sequence+=2;
 kcsan_nestable_atomic_end();
}
# 651 "/home/nathan/src/linux/include/linux/seqlock.h"
typedef struct {
 seqcount_t seqcount;
} seqcount_latch_t;
# 667 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void seqcount_latch_init(seqcount_latch_t *s)
{
 __seqcount_init(&s->seqcount, ((void *)0), ((void *)0));
}
# 683 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned raw_read_seqcount_latch(const seqcount_latch_t *s)
{




 return ({ do { extern void __compiletime_assert_98(void) ; if (!((sizeof(s->seqcount.sequence) == sizeof(char) || sizeof(s->seqcount.sequence) == sizeof(short) || sizeof(s->seqcount.sequence) == sizeof(int) || sizeof(s->seqcount.sequence) == sizeof(long)) || sizeof(s->seqcount.sequence) == sizeof(long long))) __compiletime_assert_98(); } while (0); (*(const volatile typeof( _Generic((s->seqcount.sequence), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (s->seqcount.sequence))) *)&(s->seqcount.sequence)); });
}
# 699 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int
read_seqcount_latch_retry(const seqcount_latch_t *s, unsigned start)
{
 return do_read_seqcount_retry(_Generic(*(&s->seqcount), seqcount_t: __seqprop_ptr((void *)(&s->seqcount)), seqcount_raw_spinlock_t: __seqprop_raw_spinlock_ptr((void *)((&s->seqcount))), seqcount_spinlock_t: __seqprop_spinlock_ptr((void *)((&s->seqcount))), seqcount_rwlock_t: __seqprop_rwlock_ptr((void *)((&s->seqcount))), seqcount_mutex_t: __seqprop_mutex_ptr((void *)((&s->seqcount))), seqcount_ww_mutex_t: __seqprop_ww_mutex_ptr((void *)((&s->seqcount)))), start);
}
# 786 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void raw_write_seqcount_latch(seqcount_latch_t *s)
{
 wmb();
 s->seqcount.sequence++;
 wmb();
}
# 803 "/home/nathan/src/linux/include/linux/seqlock.h"
typedef struct {




 seqcount_spinlock_t seqcount;
 spinlock_t lock;
} seqlock_t;
# 841 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned read_seqbegin(const seqlock_t *sl)
{
 unsigned ret = ({ ; ({ unsigned _seq = ({ unsigned __seq; while ((__seq = _Generic(*(&sl->seqcount), seqcount_t: __seqprop_sequence((void *)(&sl->seqcount)), seqcount_raw_spinlock_t: __seqprop_raw_spinlock_sequence((void *)((&sl->seqcount))), seqcount_spinlock_t: __seqprop_spinlock_sequence((void *)((&sl->seqcount))), seqcount_rwlock_t: __seqprop_rwlock_sequence((void *)((&sl->seqcount))), seqcount_mutex_t: __seqprop_mutex_sequence((void *)((&sl->seqcount))), seqcount_ww_mutex_t: __seqprop_ww_mutex_sequence((void *)((&sl->seqcount))))) & 1) __asm__ __volatile__("": : :"memory"); kcsan_atomic_next(1000); __seq; }); rmb(); _seq; }); });

 kcsan_atomic_next(0);
 kcsan_flat_atomic_begin();
 return ret;
}
# 861 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned read_seqretry(const seqlock_t *sl, unsigned start)
{




 kcsan_flat_atomic_end();

 return do_read_seqcount_retry(_Generic(*(&sl->seqcount), seqcount_t: __seqprop_ptr((void *)(&sl->seqcount)), seqcount_raw_spinlock_t: __seqprop_raw_spinlock_ptr((void *)((&sl->seqcount))), seqcount_spinlock_t: __seqprop_spinlock_ptr((void *)((&sl->seqcount))), seqcount_rwlock_t: __seqprop_rwlock_ptr((void *)((&sl->seqcount))), seqcount_mutex_t: __seqprop_mutex_ptr((void *)((&sl->seqcount))), seqcount_ww_mutex_t: __seqprop_ww_mutex_ptr((void *)((&sl->seqcount)))), start);
}
# 891 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_seqlock(seqlock_t *sl)
{
 spin_lock(&sl->lock);
 do_write_seqcount_begin(&sl->seqcount.seqcount);
}
# 904 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_sequnlock(seqlock_t *sl)
{
 do_write_seqcount_end(&sl->seqcount.seqcount);
 spin_unlock(&sl->lock);
}
# 917 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_seqlock_bh(seqlock_t *sl)
{
 spin_lock_bh(&sl->lock);
 do_write_seqcount_begin(&sl->seqcount.seqcount);
}
# 931 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_sequnlock_bh(seqlock_t *sl)
{
 do_write_seqcount_end(&sl->seqcount.seqcount);
 spin_unlock_bh(&sl->lock);
}
# 944 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_seqlock_irq(seqlock_t *sl)
{
 spin_lock_irq(&sl->lock);
 do_write_seqcount_begin(&sl->seqcount.seqcount);
}
# 957 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void write_sequnlock_irq(seqlock_t *sl)
{
 do_write_seqcount_end(&sl->seqcount.seqcount);
 spin_unlock_irq(&sl->lock);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __write_seqlock_irqsave(seqlock_t *sl)
{
 unsigned long flags;

 do { do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = _raw_spin_lock_irqsave(spinlock_check(&sl->lock)); } while (0); } while (0);
 do_write_seqcount_begin(&sl->seqcount.seqcount);
 return flags;
}
# 994 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
write_sequnlock_irqrestore(seqlock_t *sl, unsigned long flags)
{
 do_write_seqcount_end(&sl->seqcount.seqcount);
 spin_unlock_irqrestore(&sl->lock, flags);
}
# 1017 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void read_seqlock_excl(seqlock_t *sl)
{
 spin_lock(&sl->lock);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void read_sequnlock_excl(seqlock_t *sl)
{
 spin_unlock(&sl->lock);
}
# 1040 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void read_seqlock_excl_bh(seqlock_t *sl)
{
 spin_lock_bh(&sl->lock);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void read_sequnlock_excl_bh(seqlock_t *sl)
{
 spin_unlock_bh(&sl->lock);
}
# 1064 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void read_seqlock_excl_irq(seqlock_t *sl)
{
 spin_lock_irq(&sl->lock);
}






static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void read_sequnlock_excl_irq(seqlock_t *sl)
{
 spin_unlock_irq(&sl->lock);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long __read_seqlock_excl_irqsave(seqlock_t *sl)
{
 unsigned long flags;

 do { do { ({ unsigned long __dummy; typeof(flags) __dummy2; (void)(&__dummy == &__dummy2); 1; }); flags = _raw_spin_lock_irqsave(spinlock_check(&sl->lock)); } while (0); } while (0);
 return flags;
}
# 1107 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
read_sequnlock_excl_irqrestore(seqlock_t *sl, unsigned long flags)
{
 spin_unlock_irqrestore(&sl->lock, flags);
}
# 1144 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void read_seqbegin_or_lock(seqlock_t *lock, int *seq)
{
 if (!(*seq & 1))
  *seq = read_seqbegin(lock);
 else
  read_seqlock_excl(lock);
}
# 1159 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int need_seqretry(seqlock_t *lock, int seq)
{
 return !(seq & 1) && read_seqretry(lock, seq);
}
# 1172 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void done_seqretry(seqlock_t *lock, int seq)
{
 if (seq & 1)
  read_sequnlock_excl(lock);
}
# 1198 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) unsigned long
read_seqbegin_or_lock_irqsave(seqlock_t *lock, int *seq)
{
 unsigned long flags = 0;

 if (!(*seq & 1))
  *seq = read_seqbegin(lock);
 else
  do { flags = __read_seqlock_excl_irqsave(lock); } while (0);

 return flags;
}
# 1223 "/home/nathan/src/linux/include/linux/seqlock.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void
done_seqretry_irqrestore(seqlock_t *lock, int seq, unsigned long flags)
{
 if (seq & 1)
  read_sequnlock_excl_irqrestore(lock, flags);
}
# 21 "/home/nathan/src/linux/include/linux/hrtimer.h" 2

# 1 "/home/nathan/src/linux/include/linux/timerqueue.h" 1








struct timerqueue_node {
 struct rb_node node;
 ktime_t expires;
};

struct timerqueue_head {
 struct rb_root_cached rb_root;
};


extern bool timerqueue_add(struct timerqueue_head *head,
      struct timerqueue_node *node);
extern bool timerqueue_del(struct timerqueue_head *head,
      struct timerqueue_node *node);
extern struct timerqueue_node *timerqueue_iterate_next(
      struct timerqueue_node *node);
# 33 "/home/nathan/src/linux/include/linux/timerqueue.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__))
struct timerqueue_node *timerqueue_getnext(struct timerqueue_head *head)
{
 struct rb_node *leftmost = (&head->rb_root)->rb_leftmost;

 return ({ void *__mptr = (void *)(leftmost); do { extern void __compiletime_assert_99(void) ; if (!(!(!__builtin_types_compatible_p(typeof(*(leftmost)), typeof(((struct timerqueue_node *)0)->node)) && !__builtin_types_compatible_p(typeof(*(leftmost)), typeof(void))))) __compiletime_assert_99(); } while (0); ((struct timerqueue_node *)(__mptr - __builtin_offsetof(struct timerqueue_node, node))); });
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void timerqueue_init(struct timerqueue_node *node)
{
 ((&node->node)->__rb_parent_color = (unsigned long)(&node->node));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool timerqueue_node_queued(struct timerqueue_node *node)
{
 return !((&node->node)->__rb_parent_color == (unsigned long)(&node->node));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool timerqueue_node_expires(struct timerqueue_node *node)
{
 return node->expires;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void timerqueue_init_head(struct timerqueue_head *head)
{
 head->rb_root = (struct rb_root_cached) { {((void *)0), }, ((void *)0) };
}
# 23 "/home/nathan/src/linux/include/linux/hrtimer.h" 2

struct hrtimer_clock_base;
struct hrtimer_cpu_base;
# 39 "/home/nathan/src/linux/include/linux/hrtimer.h"
enum hrtimer_mode {
 HRTIMER_MODE_ABS = 0x00,
 HRTIMER_MODE_REL = 0x01,
 HRTIMER_MODE_PINNED = 0x02,
 HRTIMER_MODE_SOFT = 0x04,
 HRTIMER_MODE_HARD = 0x08,

 HRTIMER_MODE_ABS_PINNED = HRTIMER_MODE_ABS | HRTIMER_MODE_PINNED,
 HRTIMER_MODE_REL_PINNED = HRTIMER_MODE_REL | HRTIMER_MODE_PINNED,

 HRTIMER_MODE_ABS_SOFT = HRTIMER_MODE_ABS | HRTIMER_MODE_SOFT,
 HRTIMER_MODE_REL_SOFT = HRTIMER_MODE_REL | HRTIMER_MODE_SOFT,

 HRTIMER_MODE_ABS_PINNED_SOFT = HRTIMER_MODE_ABS_PINNED | HRTIMER_MODE_SOFT,
 HRTIMER_MODE_REL_PINNED_SOFT = HRTIMER_MODE_REL_PINNED | HRTIMER_MODE_SOFT,

 HRTIMER_MODE_ABS_HARD = HRTIMER_MODE_ABS | HRTIMER_MODE_HARD,
 HRTIMER_MODE_REL_HARD = HRTIMER_MODE_REL | HRTIMER_MODE_HARD,

 HRTIMER_MODE_ABS_PINNED_HARD = HRTIMER_MODE_ABS_PINNED | HRTIMER_MODE_HARD,
 HRTIMER_MODE_REL_PINNED_HARD = HRTIMER_MODE_REL_PINNED | HRTIMER_MODE_HARD,
};




enum hrtimer_restart {
 HRTIMER_NORESTART,
 HRTIMER_RESTART,
};
# 118 "/home/nathan/src/linux/include/linux/hrtimer.h"
struct hrtimer {
 struct timerqueue_node node;
 ktime_t _softexpires;
 enum hrtimer_restart (*function)(struct hrtimer *);
 struct hrtimer_clock_base *base;
 u8 state;
 u8 is_rel;
 u8 is_soft;
 u8 is_hard;
};
# 136 "/home/nathan/src/linux/include/linux/hrtimer.h"
struct hrtimer_sleeper {
 struct hrtimer timer;
 struct task_struct *task;
};
# 159 "/home/nathan/src/linux/include/linux/hrtimer.h"
struct hrtimer_clock_base {
 struct hrtimer_cpu_base *cpu_base;
 unsigned int index;
 clockid_t clockid;
 seqcount_raw_spinlock_t seq;
 struct hrtimer *running;
 struct timerqueue_head active;
 ktime_t (*get_time)(void);
 ktime_t offset;
} ;

enum hrtimer_base_type {
 HRTIMER_BASE_MONOTONIC,
 HRTIMER_BASE_REALTIME,
 HRTIMER_BASE_BOOTTIME,
 HRTIMER_BASE_TAI,
 HRTIMER_BASE_MONOTONIC_SOFT,
 HRTIMER_BASE_REALTIME_SOFT,
 HRTIMER_BASE_BOOTTIME_SOFT,
 HRTIMER_BASE_TAI_SOFT,
 HRTIMER_MAX_CLOCK_BASES,
};
# 214 "/home/nathan/src/linux/include/linux/hrtimer.h"
struct hrtimer_cpu_base {
 raw_spinlock_t lock;
 unsigned int cpu;
 unsigned int active_bases;
 unsigned int clock_was_set_seq;
 unsigned int hres_active : 1,
     in_hrtirq : 1,
     hang_detected : 1,
     softirq_activated : 1;
# 233 "/home/nathan/src/linux/include/linux/hrtimer.h"
 ktime_t expires_next;
 struct hrtimer *next_timer;
 ktime_t softirq_expires_next;
 struct hrtimer *softirq_next_timer;
 struct hrtimer_clock_base clock_base[HRTIMER_MAX_CLOCK_BASES];
} __attribute__((__aligned__((1 << 7))));

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hrtimer_set_expires(struct hrtimer *timer, ktime_t time)
{
 timer->node.expires = time;
 timer->_softexpires = time;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hrtimer_set_expires_range(struct hrtimer *timer, ktime_t time, ktime_t delta)
{
 timer->_softexpires = time;
 timer->node.expires = ktime_add_safe(time, delta);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hrtimer_set_expires_range_ns(struct hrtimer *timer, ktime_t time, u64 delta)
{
 timer->_softexpires = time;
 timer->node.expires = ktime_add_safe(time, ns_to_ktime(delta));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hrtimer_set_expires_tv64(struct hrtimer *timer, s64 tv64)
{
 timer->node.expires = tv64;
 timer->_softexpires = tv64;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hrtimer_add_expires(struct hrtimer *timer, ktime_t time)
{
 timer->node.expires = ktime_add_safe(timer->node.expires, time);
 timer->_softexpires = ktime_add_safe(timer->_softexpires, time);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hrtimer_add_expires_ns(struct hrtimer *timer, u64 ns)
{
 timer->node.expires = ((timer->node.expires) + (ns));
 timer->_softexpires = ((timer->_softexpires) + (ns));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t hrtimer_get_expires(const struct hrtimer *timer)
{
 return timer->node.expires;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t hrtimer_get_softexpires(const struct hrtimer *timer)
{
 return timer->_softexpires;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 hrtimer_get_expires_tv64(const struct hrtimer *timer)
{
 return timer->node.expires;
}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 hrtimer_get_softexpires_tv64(const struct hrtimer *timer)
{
 return timer->_softexpires;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) s64 hrtimer_get_expires_ns(const struct hrtimer *timer)
{
 return ktime_to_ns(timer->node.expires);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t hrtimer_expires_remaining(const struct hrtimer *timer)
{
 return ((timer->node.expires) - (timer->base->get_time()));
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t hrtimer_cb_get_time(struct hrtimer *timer)
{
 return timer->base->get_time();
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int hrtimer_is_hres_active(struct hrtimer *timer)
{
 return 0 ?
  timer->base->cpu_base->hres_active : 0;
}
# 329 "/home/nathan/src/linux/include/linux/hrtimer.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void clock_was_set_delayed(void) { }



static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t
__hrtimer_expires_remaining_adjusted(const struct hrtimer *timer, ktime_t now)
{
 ktime_t rem = ((timer->node.expires) - (now));





 if (0 && timer->is_rel)
  rem -= (unsigned int)((1000000000L +250/2)/250);
 return rem;
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t
hrtimer_expires_remaining_adjusted(const struct hrtimer *timer)
{
 return __hrtimer_expires_remaining_adjusted(timer,
          timer->base->get_time());
}

extern void clock_was_set(void);

extern void timerfd_clock_was_set(void);



extern void hrtimers_resume(void);

extern __attribute__((section(".data..percpu" ""))) __typeof__(struct tick_device) tick_cpu_device;




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hrtimer_cancel_wait_running(struct hrtimer *timer)
{
 __asm__ __volatile__("": : :"memory");
}





extern void hrtimer_init(struct hrtimer *timer, clockid_t which_clock,
    enum hrtimer_mode mode);
extern void hrtimer_init_sleeper(struct hrtimer_sleeper *sl, clockid_t clock_id,
     enum hrtimer_mode mode);
# 390 "/home/nathan/src/linux/include/linux/hrtimer.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hrtimer_init_on_stack(struct hrtimer *timer,
      clockid_t which_clock,
      enum hrtimer_mode mode)
{
 hrtimer_init(timer, which_clock, mode);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hrtimer_init_sleeper_on_stack(struct hrtimer_sleeper *sl,
       clockid_t clock_id,
       enum hrtimer_mode mode)
{
 hrtimer_init_sleeper(sl, clock_id, mode);
}

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void destroy_hrtimer_on_stack(struct hrtimer *timer) { }



extern void hrtimer_start_range_ns(struct hrtimer *timer, ktime_t tim,
       u64 range_ns, const enum hrtimer_mode mode);
# 419 "/home/nathan/src/linux/include/linux/hrtimer.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hrtimer_start(struct hrtimer *timer, ktime_t tim,
     const enum hrtimer_mode mode)
{
 hrtimer_start_range_ns(timer, tim, 0, mode);
}

extern int hrtimer_cancel(struct hrtimer *timer);
extern int hrtimer_try_to_cancel(struct hrtimer *timer);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hrtimer_start_expires(struct hrtimer *timer,
      enum hrtimer_mode mode)
{
 u64 delta;
 ktime_t soft, hard;
 soft = hrtimer_get_softexpires(timer);
 hard = hrtimer_get_expires(timer);
 delta = ktime_to_ns(((hard) - (soft)));
 hrtimer_start_range_ns(timer, soft, delta, mode);
}

void hrtimer_sleeper_start_expires(struct hrtimer_sleeper *sl,
       enum hrtimer_mode mode);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void hrtimer_restart(struct hrtimer *timer)
{
 hrtimer_start_expires(timer, HRTIMER_MODE_ABS);
}


extern ktime_t __hrtimer_get_remaining(const struct hrtimer *timer, bool adjust);





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) ktime_t hrtimer_get_remaining(const struct hrtimer *timer)
{
 return __hrtimer_get_remaining(timer, false);
}

extern u64 hrtimer_get_next_event(void);
extern u64 hrtimer_next_event_without(const struct hrtimer *exclude);

extern bool hrtimer_active(const struct hrtimer *timer);
# 472 "/home/nathan/src/linux/include/linux/hrtimer.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool hrtimer_is_queued(struct hrtimer *timer)
{

 return !!(({ do { extern void __compiletime_assert_100(void) ; if (!((sizeof(timer->state) == sizeof(char) || sizeof(timer->state) == sizeof(short) || sizeof(timer->state) == sizeof(int) || sizeof(timer->state) == sizeof(long)) || sizeof(timer->state) == sizeof(long long))) __compiletime_assert_100(); } while (0); (*(const volatile typeof( _Generic((timer->state), char: (char)0, unsigned char: (unsigned char)0, signed char: (signed char)0, unsigned short: (unsigned short)0, signed short: (signed short)0, unsigned int: (unsigned int)0, signed int: (signed int)0, unsigned long: (unsigned long)0, signed long: (signed long)0, unsigned long long: (unsigned long long)0, signed long long: (signed long long)0, default: (timer->state))) *)&(timer->state)); }) & 0x01);
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int hrtimer_callback_running(struct hrtimer *timer)
{
 return timer->base->running == timer;
}


extern u64
hrtimer_forward(struct hrtimer *timer, ktime_t now, ktime_t interval);
# 507 "/home/nathan/src/linux/include/linux/hrtimer.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 hrtimer_forward_now(struct hrtimer *timer,
          ktime_t interval)
{
 return hrtimer_forward(timer, timer->base->get_time(), interval);
}



extern int nanosleep_copyout(struct restart_block *, struct timespec64 *);
extern long hrtimer_nanosleep(ktime_t rqtp, const enum hrtimer_mode mode,
         const clockid_t clockid);

extern int schedule_hrtimeout_range(ktime_t *expires, u64 delta,
        const enum hrtimer_mode mode);
extern int schedule_hrtimeout_range_clock(ktime_t *expires,
       u64 delta,
       const enum hrtimer_mode mode,
       clockid_t clock_id);
extern int schedule_hrtimeout(ktime_t *expires, const enum hrtimer_mode mode);


extern void hrtimer_run_queues(void);


extern void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) hrtimers_init(void);


extern void sysrq_timer_list_show(void);

int hrtimers_prepare_cpu(unsigned int cpu);

int hrtimers_dead_cpu(unsigned int cpu);
# 17 "/home/nathan/src/linux/include/linux/pm.h" 2
# 1 "/home/nathan/src/linux/include/linux/completion.h" 1
# 12 "/home/nathan/src/linux/include/linux/completion.h"
# 1 "/home/nathan/src/linux/include/linux/swait.h" 1








# 1 "./arch/mips/include/generated/asm/current.h" 1
# 10 "/home/nathan/src/linux/include/linux/swait.h" 2
# 41 "/home/nathan/src/linux/include/linux/swait.h"
struct task_struct;

struct swait_queue_head {
 raw_spinlock_t lock;
 struct list_head task_list;
};

struct swait_queue {
 struct task_struct *task;
 struct list_head task_list;
};
# 69 "/home/nathan/src/linux/include/linux/swait.h"
extern void __init_swait_queue_head(struct swait_queue_head *q, const char *name,
        struct lock_class_key *key);
# 121 "/home/nathan/src/linux/include/linux/swait.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int swait_active(struct swait_queue_head *wq)
{
 return !list_empty(&wq->task_list);
}
# 134 "/home/nathan/src/linux/include/linux/swait.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool swq_has_sleeper(struct swait_queue_head *wq)
{







 __sync();
 return swait_active(wq);
}

extern void swake_up_one(struct swait_queue_head *q);
extern void swake_up_all(struct swait_queue_head *q);
extern void swake_up_locked(struct swait_queue_head *q);

extern void prepare_to_swait_exclusive(struct swait_queue_head *q, struct swait_queue *wait, int state);
extern long prepare_to_swait_event(struct swait_queue_head *q, struct swait_queue *wait, int state);

extern void __finish_swait(struct swait_queue_head *q, struct swait_queue *wait);
extern void finish_swait(struct swait_queue_head *q, struct swait_queue *wait);
# 13 "/home/nathan/src/linux/include/linux/completion.h" 2
# 26 "/home/nathan/src/linux/include/linux/completion.h"
struct completion {
 unsigned int done;
 struct swait_queue_head wait;
};


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void complete_acquire(struct completion *x) {}
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void complete_release(struct completion *x) {}
# 84 "/home/nathan/src/linux/include/linux/completion.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void init_completion(struct completion *x)
{
 x->done = 0;
 do { static struct lock_class_key __key; __init_swait_queue_head((&x->wait), "&x->wait", &__key); } while (0);
}
# 97 "/home/nathan/src/linux/include/linux/completion.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void reinit_completion(struct completion *x)
{
 x->done = 0;
}

extern void wait_for_completion(struct completion *);
extern void wait_for_completion_io(struct completion *);
extern int wait_for_completion_interruptible(struct completion *x);
extern int wait_for_completion_killable(struct completion *x);
extern unsigned long wait_for_completion_timeout(struct completion *x,
         unsigned long timeout);
extern unsigned long wait_for_completion_io_timeout(struct completion *x,
          unsigned long timeout);
extern long wait_for_completion_interruptible_timeout(
 struct completion *x, unsigned long timeout);
extern long wait_for_completion_killable_timeout(
 struct completion *x, unsigned long timeout);
extern bool try_wait_for_completion(struct completion *x);
extern bool completion_done(struct completion *x);

extern void complete(struct completion *);
extern void complete_all(struct completion *);
# 18 "/home/nathan/src/linux/include/linux/pm.h" 2




extern void (*pm_power_off)(void);
extern void (*pm_power_off_prepare)(void);

struct device;

extern void pm_vt_switch_required(struct device *dev, bool required);
extern void pm_vt_switch_unregister(struct device *dev);
# 42 "/home/nathan/src/linux/include/linux/pm.h"
struct device;


extern const char power_group_name[];




typedef struct pm_message {
 int event;
} pm_message_t;
# 278 "/home/nathan/src/linux/include/linux/pm.h"
struct dev_pm_ops {
 int (*prepare)(struct device *dev);
 void (*complete)(struct device *dev);
 int (*suspend)(struct device *dev);
 int (*resume)(struct device *dev);
 int (*freeze)(struct device *dev);
 int (*thaw)(struct device *dev);
 int (*poweroff)(struct device *dev);
 int (*restore)(struct device *dev);
 int (*suspend_late)(struct device *dev);
 int (*resume_early)(struct device *dev);
 int (*freeze_late)(struct device *dev);
 int (*thaw_early)(struct device *dev);
 int (*poweroff_late)(struct device *dev);
 int (*restore_early)(struct device *dev);
 int (*suspend_noirq)(struct device *dev);
 int (*resume_noirq)(struct device *dev);
 int (*freeze_noirq)(struct device *dev);
 int (*thaw_noirq)(struct device *dev);
 int (*poweroff_noirq)(struct device *dev);
 int (*restore_noirq)(struct device *dev);
 int (*runtime_suspend)(struct device *dev);
 int (*runtime_resume)(struct device *dev);
 int (*runtime_idle)(struct device *dev);
};
# 502 "/home/nathan/src/linux/include/linux/pm.h"
enum rpm_status {
 RPM_ACTIVE = 0,
 RPM_RESUMING,
 RPM_SUSPENDED,
 RPM_SUSPENDING,
};
# 524 "/home/nathan/src/linux/include/linux/pm.h"
enum rpm_request {
 RPM_REQ_NONE = 0,
 RPM_REQ_IDLE,
 RPM_REQ_SUSPEND,
 RPM_REQ_AUTOSUSPEND,
 RPM_REQ_RESUME,
};

struct wakeup_source;
struct wake_irq;
struct pm_domain_data;

struct pm_subsys_data {
 spinlock_t lock;
 unsigned int refcount;

 struct list_head clock_list;




};
# 565 "/home/nathan/src/linux/include/linux/pm.h"
struct dev_pm_info {
 pm_message_t power_state;
 unsigned int can_wakeup:1;
 unsigned int async_suspend:1;
 bool in_dpm_list:1;
 bool is_prepared:1;
 bool is_suspended:1;
 bool is_noirq_suspended:1;
 bool is_late_suspended:1;
 bool no_pm:1;
 bool early_init:1;
 bool direct_complete:1;
 u32 driver_flags;
 spinlock_t lock;

 struct list_head entry;
 struct completion completion;
 struct wakeup_source *wakeup;
 bool wakeup_path:1;
 bool syscore:1;
 bool no_pm_callbacks:1;
 unsigned int must_resume:1;
 unsigned int may_skip_resume:1;




 struct hrtimer suspend_timer;
 u64 timer_expires;
 struct work_struct work;
 wait_queue_head_t wait_queue;
 struct wake_irq *wakeirq;
 atomic_t usage_count;
 atomic_t child_count;
 unsigned int disable_depth:3;
 unsigned int idle_notification:1;
 unsigned int request_pending:1;
 unsigned int deferred_resume:1;
 unsigned int runtime_auto:1;
 bool ignore_children:1;
 unsigned int no_callbacks:1;
 unsigned int irq_safe:1;
 unsigned int use_autosuspend:1;
 unsigned int timer_autosuspends:1;
 unsigned int memalloc_noio:1;
 unsigned int links_count;
 enum rpm_request request;
 enum rpm_status runtime_status;
 int runtime_error;
 int autosuspend_delay;
 u64 last_busy;
 u64 active_time;
 u64 suspended_time;
 u64 accounting_timestamp;

 struct pm_subsys_data *subsys_data;
 void (*set_latency_tolerance)(struct device *, s32);
 struct dev_pm_qos *qos;
};

extern int dev_pm_get_subsys_data(struct device *dev);
extern void dev_pm_put_subsys_data(struct device *dev);
# 642 "/home/nathan/src/linux/include/linux/pm.h"
struct dev_pm_domain {
 struct dev_pm_ops ops;
 int (*start)(struct device *dev);
 void (*detach)(struct device *dev, bool power_off);
 int (*activate)(struct device *dev);
 void (*sync)(struct device *dev);
 void (*dismiss)(struct device *dev);
};
# 706 "/home/nathan/src/linux/include/linux/pm.h"
extern void device_pm_lock(void);
extern void dpm_resume_start(pm_message_t state);
extern void dpm_resume_end(pm_message_t state);
extern void dpm_resume_noirq(pm_message_t state);
extern void dpm_resume_early(pm_message_t state);
extern void dpm_resume(pm_message_t state);
extern void dpm_complete(pm_message_t state);

extern void device_pm_unlock(void);
extern int dpm_suspend_end(pm_message_t state);
extern int dpm_suspend_start(pm_message_t state);
extern int dpm_suspend_noirq(pm_message_t state);
extern int dpm_suspend_late(pm_message_t state);
extern int dpm_suspend(pm_message_t state);
extern int dpm_prepare(pm_message_t state);

extern void __suspend_report_result(const char *function, void *fn, int ret);






extern int device_pm_wait_for_dev(struct device *sub, struct device *dev);
extern void dpm_for_each_dev(void *data, void (*fn)(struct device *, void *));

extern int pm_generic_prepare(struct device *dev);
extern int pm_generic_suspend_late(struct device *dev);
extern int pm_generic_suspend_noirq(struct device *dev);
extern int pm_generic_suspend(struct device *dev);
extern int pm_generic_resume_early(struct device *dev);
extern int pm_generic_resume_noirq(struct device *dev);
extern int pm_generic_resume(struct device *dev);
extern int pm_generic_freeze_noirq(struct device *dev);
extern int pm_generic_freeze_late(struct device *dev);
extern int pm_generic_freeze(struct device *dev);
extern int pm_generic_thaw_noirq(struct device *dev);
extern int pm_generic_thaw_early(struct device *dev);
extern int pm_generic_thaw(struct device *dev);
extern int pm_generic_restore_noirq(struct device *dev);
extern int pm_generic_restore_early(struct device *dev);
extern int pm_generic_restore(struct device *dev);
extern int pm_generic_poweroff_noirq(struct device *dev);
extern int pm_generic_poweroff_late(struct device *dev);
extern int pm_generic_poweroff(struct device *dev);
extern void pm_generic_complete(struct device *dev);

extern bool dev_pm_skip_resume(struct device *dev);
extern bool dev_pm_skip_suspend(struct device *dev);
# 800 "/home/nathan/src/linux/include/linux/pm.h"
enum dpm_order {
 DPM_ORDER_NONE,
 DPM_ORDER_DEV_AFTER_PARENT,
 DPM_ORDER_PARENT_BEFORE_DEV,
 DPM_ORDER_DEV_LAST,
};
# 12 "/home/nathan/src/linux/arch/mips/kernel/reset.c" 2

# 1 "/home/nathan/src/linux/include/linux/reboot.h" 1





# 1 "/home/nathan/src/linux/include/linux/notifier.h" 1
# 15 "/home/nathan/src/linux/include/linux/notifier.h"
# 1 "/home/nathan/src/linux/include/linux/rwsem.h" 1
# 35 "/home/nathan/src/linux/include/linux/rwsem.h"
struct rw_semaphore {
 atomic_long_t count;





 atomic_long_t owner;



 raw_spinlock_t wait_lock;
 struct list_head wait_list;






};


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int rwsem_is_locked(struct rw_semaphore *sem)
{
 return atomic_long_read(&sem->count) != 0;
}
# 101 "/home/nathan/src/linux/include/linux/rwsem.h"
extern void __init_rwsem(struct rw_semaphore *sem, const char *name,
    struct lock_class_key *key);
# 117 "/home/nathan/src/linux/include/linux/rwsem.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int rwsem_is_contended(struct rw_semaphore *sem)
{
 return !list_empty(&sem->wait_list);
}




extern void down_read(struct rw_semaphore *sem);
extern int __attribute__((__warn_unused_result__)) down_read_interruptible(struct rw_semaphore *sem);
extern int __attribute__((__warn_unused_result__)) down_read_killable(struct rw_semaphore *sem);




extern int down_read_trylock(struct rw_semaphore *sem);




extern void down_write(struct rw_semaphore *sem);
extern int __attribute__((__warn_unused_result__)) down_write_killable(struct rw_semaphore *sem);




extern int down_write_trylock(struct rw_semaphore *sem);




extern void up_read(struct rw_semaphore *sem);




extern void up_write(struct rw_semaphore *sem);




extern void downgrade_write(struct rw_semaphore *sem);
# 16 "/home/nathan/src/linux/include/linux/notifier.h" 2
# 1 "/home/nathan/src/linux/include/linux/srcu.h" 1
# 22 "/home/nathan/src/linux/include/linux/srcu.h"
# 1 "/home/nathan/src/linux/include/linux/rcu_segcblist.h" 1
# 21 "/home/nathan/src/linux/include/linux/rcu_segcblist.h"
struct rcu_cblist {
 struct callback_head *head;
 struct callback_head **tail;
 long len;
};
# 66 "/home/nathan/src/linux/include/linux/rcu_segcblist.h"
struct rcu_segcblist {
 struct callback_head *head;
 struct callback_head **tails[4];
 unsigned long gp_seq[4];



 long len;

 u8 enabled;
 u8 offloaded;
};
# 23 "/home/nathan/src/linux/include/linux/srcu.h" 2

struct srcu_struct;
# 41 "/home/nathan/src/linux/include/linux/srcu.h"
int init_srcu_struct(struct srcu_struct *ssp);








# 1 "/home/nathan/src/linux/include/linux/srcutree.h" 1
# 14 "/home/nathan/src/linux/include/linux/srcutree.h"
# 1 "/home/nathan/src/linux/include/linux/rcu_node_tree.h" 1
# 15 "/home/nathan/src/linux/include/linux/srcutree.h" 2


struct srcu_node;
struct srcu_struct;





struct srcu_data {

 unsigned long srcu_lock_count[2];
 unsigned long srcu_unlock_count[2];


 spinlock_t lock __attribute__((__aligned__(1 << (7))));
 struct rcu_segcblist srcu_cblist;
 unsigned long srcu_gp_seq_needed;
 unsigned long srcu_gp_seq_needed_exp;
 bool srcu_cblist_invoking;
 struct timer_list delay_work;
 struct work_struct work;
 struct callback_head srcu_barrier_head;
 struct srcu_node *mynode;
 unsigned long grpmask;

 int cpu;
 struct srcu_struct *ssp;
};




struct srcu_node {
 spinlock_t lock;
 unsigned long srcu_have_cbs[4];


 unsigned long srcu_data_have_cbs[4];

 unsigned long srcu_gp_seq_needed_exp;
 struct srcu_node *srcu_parent;
 int grplo;
 int grphi;
};




struct srcu_struct {
 struct srcu_node node[1];
 struct srcu_node *level[1 + 1];

 struct mutex srcu_cb_mutex;
 spinlock_t lock;
 struct mutex srcu_gp_mutex;
 unsigned int srcu_idx;
 unsigned long srcu_gp_seq;
 unsigned long srcu_gp_seq_needed;
 unsigned long srcu_gp_seq_needed_exp;
 unsigned long srcu_last_gp_end;
 struct srcu_data *sda;
 unsigned long srcu_barrier_seq;
 struct mutex srcu_barrier_mutex;
 struct completion srcu_barrier_completion;

 atomic_t srcu_barrier_cpu_cnt;


 struct delayed_work work;



};
# 137 "/home/nathan/src/linux/include/linux/srcutree.h"
void synchronize_srcu_expedited(struct srcu_struct *ssp);
void srcu_barrier(struct srcu_struct *ssp);
void srcu_torture_stats_print(struct srcu_struct *ssp, char *tt, char *tf);
# 50 "/home/nathan/src/linux/include/linux/srcu.h" 2







void call_srcu(struct srcu_struct *ssp, struct callback_head *head,
  void (*func)(struct callback_head *head));
void cleanup_srcu_struct(struct srcu_struct *ssp);
int __srcu_read_lock(struct srcu_struct *ssp) ;
void __srcu_read_unlock(struct srcu_struct *ssp, int idx) ;
void synchronize_srcu(struct srcu_struct *ssp);
# 91 "/home/nathan/src/linux/include/linux/srcu.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int srcu_read_lock_held(const struct srcu_struct *ssp)
{
 return 1;
}
# 150 "/home/nathan/src/linux/include/linux/srcu.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int srcu_read_lock(struct srcu_struct *ssp)
{
 int retval;

 retval = __srcu_read_lock(ssp);
 do { } while (0);
 return retval;
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__no_instrument_function__)) int
srcu_read_lock_notrace(struct srcu_struct *ssp)
{
 int retval;

 retval = __srcu_read_lock(ssp);
 return retval;
}
# 176 "/home/nathan/src/linux/include/linux/srcu.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void srcu_read_unlock(struct srcu_struct *ssp, int idx)

{
 ({ static bool __attribute__((__section__(".data.once"))) __warned; int __ret_warn_once = !!(idx & ~0x1); if (__builtin_expect(!!(__ret_warn_once && !__warned), 0)) { __warned = true; ({ int __ret_warn_on = !!(1); if (__builtin_expect(!!(__ret_warn_on), 0)) do { do { } while(0); warn_slowpath_fmt("include/linux/srcu.h", 179, 9, ((void *)0)); do { } while(0); } while (0); __builtin_expect(!!(__ret_warn_on), 0); }); } __builtin_expect(!!(__ret_warn_once), 0); });
 do { } while (0);
 __srcu_read_unlock(ssp, idx);
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) __attribute__((__no_instrument_function__)) void
srcu_read_unlock_notrace(struct srcu_struct *ssp, int idx)
{
 __srcu_read_unlock(ssp, idx);
}
# 200 "/home/nathan/src/linux/include/linux/srcu.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void smp_mb__after_srcu_read_unlock(void)
{

}
# 17 "/home/nathan/src/linux/include/linux/notifier.h" 2
# 49 "/home/nathan/src/linux/include/linux/notifier.h"
struct notifier_block;

typedef int (*notifier_fn_t)(struct notifier_block *nb,
   unsigned long action, void *data);

struct notifier_block {
 notifier_fn_t notifier_call;
 struct notifier_block *next;
 int priority;
};

struct atomic_notifier_head {
 spinlock_t lock;
 struct notifier_block *head;
};

struct blocking_notifier_head {
 struct rw_semaphore rwsem;
 struct notifier_block *head;
};

struct raw_notifier_head {
 struct notifier_block *head;
};

struct srcu_notifier_head {
 struct mutex mutex;
 struct srcu_struct srcu;
 struct notifier_block *head;
};
# 93 "/home/nathan/src/linux/include/linux/notifier.h"
extern void srcu_init_notifier_head(struct srcu_notifier_head *nh);
# 144 "/home/nathan/src/linux/include/linux/notifier.h"
extern int atomic_notifier_chain_register(struct atomic_notifier_head *nh,
  struct notifier_block *nb);
extern int blocking_notifier_chain_register(struct blocking_notifier_head *nh,
  struct notifier_block *nb);
extern int raw_notifier_chain_register(struct raw_notifier_head *nh,
  struct notifier_block *nb);
extern int srcu_notifier_chain_register(struct srcu_notifier_head *nh,
  struct notifier_block *nb);

extern int atomic_notifier_chain_unregister(struct atomic_notifier_head *nh,
  struct notifier_block *nb);
extern int blocking_notifier_chain_unregister(struct blocking_notifier_head *nh,
  struct notifier_block *nb);
extern int raw_notifier_chain_unregister(struct raw_notifier_head *nh,
  struct notifier_block *nb);
extern int srcu_notifier_chain_unregister(struct srcu_notifier_head *nh,
  struct notifier_block *nb);

extern int atomic_notifier_call_chain(struct atomic_notifier_head *nh,
  unsigned long val, void *v);
extern int blocking_notifier_call_chain(struct blocking_notifier_head *nh,
  unsigned long val, void *v);
extern int raw_notifier_call_chain(struct raw_notifier_head *nh,
  unsigned long val, void *v);
extern int srcu_notifier_call_chain(struct srcu_notifier_head *nh,
  unsigned long val, void *v);

extern int atomic_notifier_call_chain_robust(struct atomic_notifier_head *nh,
  unsigned long val_up, unsigned long val_down, void *v);
extern int blocking_notifier_call_chain_robust(struct blocking_notifier_head *nh,
  unsigned long val_up, unsigned long val_down, void *v);
extern int raw_notifier_call_chain_robust(struct raw_notifier_head *nh,
  unsigned long val_up, unsigned long val_down, void *v);
# 189 "/home/nathan/src/linux/include/linux/notifier.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int notifier_from_errno(int err)
{
 if (err)
  return 0x8000 | (0x0001 - err);

 return 0x0001;
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int notifier_to_errno(int ret)
{
 ret &= ~0x8000;
 return ret > 0x0001 ? 0x0001 - ret : 0;
}
# 233 "/home/nathan/src/linux/include/linux/notifier.h"
extern struct blocking_notifier_head reboot_notifier_list;
# 7 "/home/nathan/src/linux/include/linux/reboot.h" 2
# 1 "/home/nathan/src/linux/include/uapi/linux/reboot.h" 1
# 8 "/home/nathan/src/linux/include/linux/reboot.h" 2

struct device;






enum reboot_mode {
 REBOOT_UNDEFINED = -1,
 REBOOT_COLD = 0,
 REBOOT_WARM,
 REBOOT_HARD,
 REBOOT_SOFT,
 REBOOT_GPIO,
};
extern enum reboot_mode reboot_mode;
extern enum reboot_mode panic_reboot_mode;

enum reboot_type {
 BOOT_TRIPLE = 't',
 BOOT_KBD = 'k',
 BOOT_BIOS = 'b',
 BOOT_ACPI = 'a',
 BOOT_EFI = 'e',
 BOOT_CF9_FORCE = 'p',
 BOOT_CF9_SAFE = 'q',
};
extern enum reboot_type reboot_type;

extern int reboot_default;
extern int reboot_cpu;
extern int reboot_force;


extern int register_reboot_notifier(struct notifier_block *);
extern int unregister_reboot_notifier(struct notifier_block *);

extern int devm_register_reboot_notifier(struct device *, struct notifier_block *);

extern int register_restart_handler(struct notifier_block *);
extern int unregister_restart_handler(struct notifier_block *);
extern void do_kernel_restart(char *cmd);





extern void migrate_to_reboot_cpu(void);
extern void machine_restart(char *cmd);
extern void machine_halt(void);
extern void machine_power_off(void);

extern void machine_shutdown(void);
struct pt_regs;
extern void machine_crash_shutdown(struct pt_regs *);





extern void kernel_restart_prepare(char *cmd);
extern void kernel_restart(char *cmd);
extern void kernel_halt(void);
extern void kernel_power_off(void);

extern int C_A_D;
void ctrl_alt_del(void);


extern char poweroff_cmd[256];

extern void orderly_poweroff(bool force);
extern void orderly_reboot(void);





extern void emergency_restart(void);

# 1 "./arch/mips/include/generated/asm/emergency-restart.h" 1
# 1 "/home/nathan/src/linux/include/asm-generic/emergency-restart.h" 1




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void machine_emergency_restart(void)
{
 machine_restart(((void *)0));
}
# 2 "./arch/mips/include/generated/asm/emergency-restart.h" 2
# 89 "/home/nathan/src/linux/include/linux/reboot.h" 2
# 14 "/home/nathan/src/linux/arch/mips/kernel/reset.c" 2
# 1 "/home/nathan/src/linux/include/linux/delay.h" 1
# 24 "/home/nathan/src/linux/include/linux/delay.h"
extern unsigned long loops_per_jiffy;


# 1 "/home/nathan/src/linux/arch/mips/include/asm/delay.h" 1
# 16 "/home/nathan/src/linux/arch/mips/include/asm/delay.h"
extern void __delay(unsigned long loops);
extern void __ndelay(unsigned long ns);
extern void __udelay(unsigned long us);
# 27 "/home/nathan/src/linux/include/linux/delay.h" 2
# 56 "/home/nathan/src/linux/include/linux/delay.h"
extern unsigned long lpj_fine;
void calibrate_delay(void);
void __attribute__((weak)) calibration_delay_done(void);
void msleep(unsigned int msecs);
unsigned long msleep_interruptible(unsigned int msecs);
void usleep_range(unsigned long min, unsigned long max);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void ssleep(unsigned int seconds)
{
 msleep(seconds * 1000);
}


static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void fsleep(unsigned long usecs)
{
 if (usecs <= 10)
  __udelay(usecs);
 else if (usecs <= 20000)
  usleep_range(usecs, 2 * usecs);
 else
  msleep((((usecs) + (1000) - 1) / (1000)));
}
# 15 "/home/nathan/src/linux/arch/mips/kernel/reset.c" 2


# 1 "/home/nathan/src/linux/arch/mips/include/asm/idle.h" 1




# 1 "/home/nathan/src/linux/include/linux/cpuidle.h" 1
# 22 "/home/nathan/src/linux/include/linux/cpuidle.h"
struct module;

struct cpuidle_device;
struct cpuidle_driver;
# 35 "/home/nathan/src/linux/include/linux/cpuidle.h"
struct cpuidle_state_usage {
 unsigned long long disable;
 unsigned long long usage;
 u64 time_ns;
 unsigned long long above;
 unsigned long long below;
 unsigned long long rejected;

 unsigned long long s2idle_usage;
 unsigned long long s2idle_time;

};

struct cpuidle_state {
 char name[16];
 char desc[32];

 u64 exit_latency_ns;
 u64 target_residency_ns;
 unsigned int flags;
 unsigned int exit_latency;
 int power_usage;
 unsigned int target_residency;

 int (*enter) (struct cpuidle_device *dev,
   struct cpuidle_driver *drv,
   int index);

 int (*enter_dead) (struct cpuidle_device *dev, int index);
# 73 "/home/nathan/src/linux/include/linux/cpuidle.h"
 int (*enter_s2idle)(struct cpuidle_device *dev,
       struct cpuidle_driver *drv,
       int index);
};
# 88 "/home/nathan/src/linux/include/linux/cpuidle.h"
struct cpuidle_device_kobj;
struct cpuidle_state_kobj;
struct cpuidle_driver_kobj;

struct cpuidle_device {
 unsigned int registered:1;
 unsigned int enabled:1;
 unsigned int poll_time_limit:1;
 unsigned int cpu;
 ktime_t next_hrtimer;

 int last_state_idx;
 u64 last_residency_ns;
 u64 poll_limit_ns;
 u64 forced_idle_latency_limit_ns;
 struct cpuidle_state_usage states_usage[10];
 struct cpuidle_state_kobj *kobjs[10];
 struct cpuidle_driver_kobj *kobj_driver;
 struct cpuidle_device_kobj *kobj_dev;
 struct list_head device_list;





};

extern __attribute__((section(".data..percpu" ""))) __typeof__(struct cpuidle_device *) cpuidle_devices;
extern __attribute__((section(".data..percpu" ""))) __typeof__(struct cpuidle_device) cpuidle_dev;





struct cpuidle_driver {
 const char *name;
 struct module *owner;


 unsigned int bctimer:1;

 struct cpuidle_state states[10];
 int state_count;
 int safe_state_index;


 struct cpumask *cpumask;


 const char *governor;
};
# 176 "/home/nathan/src/linux/include/linux/cpuidle.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void disable_cpuidle(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) bool cpuidle_not_available(struct cpuidle_driver *drv,
      struct cpuidle_device *dev)
{return true; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpuidle_select(struct cpuidle_driver *drv,
     struct cpuidle_device *dev, bool *stop_tick)
{return -19; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpuidle_enter(struct cpuidle_driver *drv,
    struct cpuidle_device *dev, int index)
{return -19; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_reflect(struct cpuidle_device *dev, int index) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) u64 cpuidle_poll_time(struct cpuidle_driver *drv,
        struct cpuidle_device *dev)
{return 0; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpuidle_register_driver(struct cpuidle_driver *drv)
{return -19; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct cpuidle_driver *cpuidle_get_driver(void) {return ((void *)0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_driver_state_disabled(struct cpuidle_driver *drv,
            int idx, bool disable) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_unregister_driver(struct cpuidle_driver *drv) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpuidle_register_device(struct cpuidle_device *dev)
{return -19; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_unregister_device(struct cpuidle_device *dev) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpuidle_register(struct cpuidle_driver *drv,
       const struct cpumask *const coupled_cpus)
{return -19; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_unregister(struct cpuidle_driver *drv) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_pause_and_lock(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_resume_and_unlock(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_pause(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_resume(void) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpuidle_enable_device(struct cpuidle_device *dev)
{return -19; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_disable_device(struct cpuidle_device *dev) { }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpuidle_play_dead(void) {return -19; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct cpuidle_driver *cpuidle_get_cpu_driver(
 struct cpuidle_device *dev) {return ((void *)0); }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) struct cpuidle_device *cpuidle_get_device(void) {return ((void *)0); }
# 224 "/home/nathan/src/linux/include/linux/cpuidle.h"
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpuidle_find_deepest_state(struct cpuidle_driver *drv,
          struct cpuidle_device *dev,
          u64 latency_limit_ns)
{return -19; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int cpuidle_enter_s2idle(struct cpuidle_driver *drv,
           struct cpuidle_device *dev)
{return -19; }
static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_use_deepest_state(u64 latency_limit_ns)
{
}



extern void sched_idle_set_state(struct cpuidle_state *idle_state);
extern void default_idle_call(void);




static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_coupled_parallel_barrier(struct cpuidle_device *dev, atomic_t *a)
{
}





static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) void cpuidle_poll_state_init(struct cpuidle_driver *drv) {}






struct cpuidle_governor {
 char name[16];
 struct list_head governor_list;
 unsigned int rating;

 int (*enable) (struct cpuidle_driver *drv,
     struct cpuidle_device *dev);
 void (*disable) (struct cpuidle_driver *drv,
     struct cpuidle_device *dev);

 int (*select) (struct cpuidle_driver *drv,
     struct cpuidle_device *dev,
     bool *stop_tick);
 void (*reflect) (struct cpuidle_device *dev, int index);
};

extern int cpuidle_register_governor(struct cpuidle_governor *gov);
extern s64 cpuidle_governor_latency_req(unsigned int cpu);
# 6 "/home/nathan/src/linux/arch/mips/include/asm/idle.h" 2


extern void (*cpu_wait)(void);
extern void r4k_wait(void);
extern void __r4k_wait(void);
extern void r4k_wait_irqoff(void);

static inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((__no_instrument_function__)) int using_rollback_handler(void)
{
 return cpu_wait == r4k_wait;
}

extern void __attribute__((__section__(".init.text"))) __attribute__((__cold__)) check_wait(void);

extern int mips_cpuidle_wait_enter(struct cpuidle_device *dev,
       struct cpuidle_driver *drv, int index);
# 18 "/home/nathan/src/linux/arch/mips/kernel/reset.c" 2

# 1 "/home/nathan/src/linux/arch/mips/include/asm/reboot.h" 1
# 12 "/home/nathan/src/linux/arch/mips/include/asm/reboot.h"
extern void (*_machine_restart)(char *command);
extern void (*_machine_halt)(void);
# 20 "/home/nathan/src/linux/arch/mips/kernel/reset.c" 2






void (*_machine_restart)(char *command);
void (*_machine_halt)(void);
void (*pm_power_off)(void);

static int __ksym_marker_pm_power_off[0] __attribute__((__section__(".discard.ksym"))) __attribute__((__used__)); ;

static void machine_hang(void)
{





 do { arch_local_irq_disable(); } while (0);





 clear_c0_status(0x0000ff00);

 while (true) {
  if (((((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000010)))) | (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000020)))) | (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000100)))) | ((6 >= (6)) || (cpu_data[0].isa_level & (0x00000400))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (1)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000040))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (2)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000080))))) | ((cpu_data[0].isa_level & (0x00000002 | 0x00000004 | 0x00000008 | 0x00000040 | 0x00000080 | 0x00000200 | 0x00000800)) && (((6 >= (5)) && (6 < (6))) || ((6 < (6)) && (cpu_data[0].isa_level & (0x00000200))))) | ((6 >= (6)) && (cpu_data[0].isa_level & (0x00000800))))) {





   asm volatile(
    ".set	push\n\t"
    ".set	" "mips64r6" "\n\t"
    "wait\n\t"
    ".set	pop");
  } else if (cpu_wait) {





   cpu_wait();
   do { arch_local_irq_disable(); } while (0);
  } else {






  }
# 83 "/home/nathan/src/linux/arch/mips/kernel/reset.c"
  if ((cpu_data[0].options & (((((1ULL))) << (7)))))
   do { if (0 == 0) __asm__ __volatile__( "mtc0\t%z0, " "$11" "\n\t" : : "Jr" ((unsigned int)(0))); else __asm__ __volatile__( ".set\tpush\n\t" ".set\tmips32\n\t" "mtc0\t%z0, " "$11" ", " "0" "\n\t" ".set\tpop" : : "Jr" ((unsigned int)(0))); } while (0);
 }
}

void machine_restart(char *command)
{
 if (_machine_restart)
  _machine_restart(command);


 __asm__ __volatile__("": : :"memory");
 smp_send_stop();

 do_kernel_restart(command);
 ( (__builtin_constant_p(1000) && (1000)<=(1000 / 250)) ? __udelay((1000)*1000) : ({unsigned long __ms=(1000); while (__ms--) __udelay(1000);}));
 printk("\001" "0" "Reboot failed -- System halted\n");
 machine_hang();
}

void machine_halt(void)
{
 if (_machine_halt)
  _machine_halt();


 __asm__ __volatile__("": : :"memory");
 smp_send_stop();

 machine_hang();
}

void machine_power_off(void)
{
 if (pm_power_off)
  pm_power_off();


 __asm__ __volatile__("": : :"memory");
 smp_send_stop();

 machine_hang();
}
